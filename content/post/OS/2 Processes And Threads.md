---
title: 2 Processes And Threads
categories:
  - OS
date: 2023-10-21 20:54:29
tags:
---

# 2 Processes And Threads

## Process Concept

**进程**是执行中的程序。
**程序**是存储在磁盘上的可执行文件。
当可执行文件加载到内存中时，程序成为进程。

一个进程包括：
- 程序代码，称为文本部分。
- 数据部分，包含全局变量。
- 进程控制块（PCB）

**进程映像**=代码段+数据段+PCB，进程映像是静态的，进程是动态的；
进程是进程映像/进程实体的运行过程，是系统进行**资源分配和调度**的一个独立单位；
进程控制块PCB是存放进程的管理和控制信息的数据结构，进程控制块PCB是进程存在的唯一标志（类似于身份证）；
所谓创建进程实质上就是创建进程映像中的PCB，撤销进程实质上是撤销进程的PCB；

进程的执行必须按顺序进行。进程就是一个程序的运行时，包含了一些权限控制。
进程之间不共享数据，每个进程有自己独立的地址空间，一个进程至少包含一个或多个线程；

- 一个进程本身可以是其他代码的执行环境，例如JVM
  - 可执行的Java程序在Java虚拟机（JVM）中执行。
    - JVM作为一个进程执行：
      - 解释加载的Java代码
      - 代表该代码采取行动（通过本机机器指令）。
- 例如，java程序：命令java将JVM作为普通进程运行。JVM执行Java程序。

### Process State

随着进程的执行，它会改变状态。一个进程可能处于以下状态之一：
- new：进程正在被创建。
- running：正在执行指令。
- waiting：进程正在等待某个事件发生。
- ready：进程等待被分配到处理器。
- terminated：进程已经执行完成。

在任何给定时间，每个处理器上只能运行一个进程，但有许多进程可能处于就绪和等待状态。

![image-20231022112846918](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/image-20231022112846918.png)

### Process Control Block(PCB)

每个进程都由一个 PCB（进程控制块）表示，也被称为进程控制块。PCB是进程存在的唯一标志！
PCB 包含与每个进程相关的信息：
- 进程状态
- 程序计数器
- CPU 寄存器
- CPU 调度信息 - 优先级、调度队列指针
- 内存管理信息
- 账户信息 - 使用的 CPU 时间量，自启动以来经过的时钟时间，时间限制，帐户号码等
- I/O 状态信息 - 分配给进程的 I/O 设备列表，打开文件列表等
- 进程号 - 标识符，例如：该进程的标识符，其父进程的标识符，用户标识符等。
	- **PID**是操作系统中的**进程标识符**，操作系统中每打开一个程序都会创建一个进程ID也就是PID，在运行时每个进程有唯一的PID编号，进程终止后PID标识符会被系统回收利用；

![image-20231028100736715](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/image-20231028100736715.png)

### CPU Switch From Process to Process

![image-20231022113115983](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/image-20231022113115983.png)

### 进程的地址空间

地址空间分为物理地址空间(内存、磁盘)和虚拟地址空间；

因为操作系统的缘故，对一个进程/程序来说似乎独占所有硬件资源，一般一个进程会分为如下几个段，其中堆向上生长，栈向下生长（注意这里的地址空间是`虚拟地址空间`，之后也会讲，分段常用于用户视图）

### Process Feature

进程的基本特征是对比单个程序的顺序执行提出的，也是对进程管理提出的基本要求：

动态性：进程具有一定的生命周期，是动态产生、变化和消亡；
并发性：指多个进程实体同时存于内存中，能在一段时间内同时运行；
独立性：指进程实体是一个能够独立运行、独立获得资源和独立接受调度的基本单位；
异步性：进程按照各自独立的、不可预知的速度向前推进，为了避免异步，在操作系统中必须配置相应的进程同步机制；
结构性：结构上看，进程实体是由程序段、数据段以及进程控制块三部分组成；

### When to Switch a Process

时钟中断（Clock interrupt）: 进程已经执行了最大允许的时间片。

I/O 中断（I/O interrupt）: 处理内存错误时，可能需要将虚拟内存中的数据载入主内存。

陷阱（Trap）: 当发生错误时，可能会导致进程进入终止/退出状态。

系统调用（System call）: 例如，文件打开等操作。

## Process Scheduling

多道程序设计的目标是最大化CPU利用率。通过在多个进程之间频繁切换CPU，使用户感觉好像它们都在同时运行。分时共享的目标则是让用户在程序运行时与之互动。

进程调度程序负责选择一个可用的进程在CPU上执行。在单处理器系统上，由于硬件资源的限制，最多只能运行一个进程。其余的进程将不得不等待，直到CPU空闲并可以重新调度它们。

通过合理的进程调度和时间分配，多道程序设计和分时共享可以有效地提高系统的整体性能和用户满意度。

CPU管理的最终结构概括为操作系统启动多个进程，并能够在多个进程之间调度/切换，从而实现CPU高效管理；

![image-20231028155337741](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/image-20231028155337741.png)

（1）在操作系统中现在有三个进程，其PID分别是1、2、3；

（2）现在正在执行的是2号进程；

（3）进程1执行到53地址处停了下来，进程3执行到250地址处停了下来，进程1停下来的原因是进程1用完了时间片，进程3停下来的原因是进程3要等到磁盘读写完成；

（4）进程1和进程3停下来的执行现场分别存放在各自的PCB中；

（5）操作系统通过这些PCB可以感知、了解并控制各个进程，操作系统对进程的管理关键在于对这些PCB的管理；

多进程视图是操作系统的核心视图.操作系统在从开机启动到最后关机的全部运行过程中都要围绕这个多进程视图工作；

一个进程执行完毕以后可以调用exit（）来退出自己，但shell不会调用exit（）退出自己，除非关机。因此shell进程会一直执行，不断创建新的进程，并用这些新进程完成各种各样的任务。在操作系统最终关机时，会将系统中所有进程杀死；

编写操作系统中的进程管理模块，需要做到以下两点：

- 从上层用户角度想象系统中的多个进程，要在头脑里形成这样的画面，操作系统里有多个进程，每个进程各司其职，要做新的工作就会在系统中创建出的新进程等；
- 从下层系统内核角度感知和控制系统中的多个进程；

### Scheduling Queues

作业队列 - 系统中的所有进程集合。

就绪队列 - 驻留在主存储器中、准备好等待执行的所有进程的集合。

通常存储为链表。

头部包含指向列表中第一个和最后一个PCB的指针。

![image-20231022124009426](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/image-20231022124009426.png)

设备队列 - 等待I/O设备的进程列表。每个设备都有自己的设备队列。

![image-20231022124104757](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/image-20231022124104757.png)

### Representation of Process Scheduling

![image-20231022124326353](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/image-20231022124326353.png)

### Schedulers

Long-term scheduler (or job scheduler)选择哪些进程应该被带入就绪队列。
Short-term scheduler (or CPU scheduler)选择下一个应该执行哪个进程并分配CPU。

主要区别：执行频率。

短期调度器被调用频率非常高（毫秒）（调度器必须快）。
长期调度器被调用频率非常低（调度器可能很慢）（秒，分钟）（调度器必须快）。
长期调度器控制多道程序的程度，即在内存中的进程数。

进程可以分为以下两种：
1. I/O密集型进程（I/O-bound process）：花费大量时间进行I/O操作而不是计算，存在许多短暂的CPU突发。
2. 计算密集型进程（CPU-bound process）：花费大量时间进行计算；很少有非常长的CPU突发。选择好的进程组合。

如果所有进程都是I/O密集型的，准备队列将几乎总是空的，CPU调度程序几乎没有工作要做。如果所有进程都是计算密集型的，I/O等待队列将几乎总是空的，设备将无法使用。

短期调度（Short-term Scheduling）

1. **目的**：短期调度，也称为CPU调度，主要负责决定哪个就绪进程应该被分配CPU时间。
2. **频率**：这种类型的调度发生得非常频繁，通常以毫秒级别计算。
3. **调度对象**：它关注的是处于就绪队列中的进程或线程。
4. **特点**：
   - 快速和频繁：因为必须频繁地做出决策，所以短期调度算法需要非常快速和高效。
   - 决定进程执行顺序：它负责选择下一个将使用CPU的进程。

中期调度（Medium-term Scheduling）

1. **目的**：中期调度主要负责调整系统的多道程序程度，通过实施进程的挂起和唤醒来控制系统的负载。
2. **频率**：这种调度发生的频率低于短期调度，但比长期调度更频繁。
3. **调度对象**：它主要处理已经开始执行但暂时被挂起的进程。
4. **特点**：
   - 内存管理：中期调度常常与内存管理相关联，如页面置换算法。
   - 减少负载：通过将进程移出或移入就绪队列来减少系统负载。

长期调度（Long-term Scheduling）

1. **目的**：长期调度，也称为作业调度，负责决定哪些进程应从作业池中移入就绪队列。
2. **频率**：这种调度发生得较不频繁，通常以秒或更长的时间间隔计算。
3. **调度对象**：它涉及决定哪些新进程被引入内存的就绪队列。
4. **特点**：
   - 影响系统的多道程序程度：长期调度决定了系统中同时运行的进程数。
   - 性能和资源利用率：它影响整体系统性能和资源的利用率。

### Medium-Term Scheduling

该进程被中程调度程序交换出去，存储在磁盘上，稍后又被交换进来。

Medium-Term Scheduling（中期调度）的主要作用是避免某些进程长时间等待。当一个进程在等待I/O操作完成时，它会被移至I/O等待队列。如果进程在等待过程中被换出（swapped out），则它将被存储在磁盘上，并在稍后被换入（swapped in）由中期调度器进行操作。这样，当CPU执行速度超过I/O操作速度时，所有进程都可以等待I/O操作完成，从而释放更多的内存空间。在等待期间，进程的状态变为“交换等待”（swapped waiting）。

### Swapped/Suspended Processes

处理器的速度通常比I/O设备快，因此在某些情况下，所有的进程都可能在等待I/O操作。为了释放更多内存，这些进程会被交换到磁盘上。

等待状态被转换为“swapped waiting”，表示进程已被交换到磁盘上。在这个过程中，还引入了两种新的状态：
- "swapped waiting"（挂起等待/阻塞）：表示进程已被交换到磁盘，正在等待某些事件的发生。
- "swapped ready"（挂起就绪）：表示进程已准备好执行，但仍然位于磁盘上，等待被交换回内存执行。

### Reasons for Process swapped out

进程被换出的原因有多种，包括：
1. 在多道程序环境下，系统会根据优先级、CPU时间片、内存使用情况等因素来调度进程，如果一个进程在等待I/O操作（例如磁盘读写），或者它的优先级低于其他进程，那么它可能会被暂时换出，以便其他进程可以继续执行。
2. 当CPU切换到另一个进程时，系统需要保存旧进程的状态并加载新进程的保存状态，这个过程被称为上下文切换。如果系统频繁地进行上下文切换，那么每个进程可能会被短暂地暂停并被换出，以便其他进程可以执行。
3. 在内存不足时，系统会将一些进程暂时换出到磁盘上，以便为其他进程腾出空间。
4. 在某些情况下，父进程可能会希望暂停其子进程的执行，以检查或修改被暂停的进程，或者协调多个进程的活动。这可以通过将子进程换出到磁盘来实现。
5. 操作系统需要释放足够的内存来引入其他进程，如果当前没有足够的内存，那么一些进程可能会被暂停并被换出到磁盘上。
6. 进程可能由于其他原因被换出，例如它已经完成了它的任务或者出现了错误。

### Context Switch

当CPU切换到另一个进程时，需要进行上下文切换（Context Switch）。这是指系统必须保存当前进程的状态，并加载下一个进程的保存状态。这个过程包括保存处理器状态，包括程序计数器和其它寄存器，更新PCB以及内存管理数据结构，并恢复选定进程的上下文。这个过程是纯开销，系统在切换过程中并不执行任何有用的工作。上下文切换的时间取决于很多因素，包括系统的设计和进程的性质。在多任务处理中，上下文切换是很重要的，它使得各个进程可以共享CPU资源，并且可以有效地管理系统的运行。

上下文在进程的 PCB 中表示。

当 CPU 切换到另一个进程时，系统必须保存旧进程的状态并加载新进程的已保存状态。这被称为上下文切换。

上下文切换包括以下步骤：
1. 保存处理器的上下文，包括程序计数器和其他寄存器。
2. 更新当前正在运行的进程的 PCB。
3. 将 PCB 移动到适当的队列 - 就绪队列或等待队列。
4. 选择另一个进程执行（调度）。
5. 更新所选进程的 PCB。
6. 更新内存管理数据结构。
7. 恢复所选进程的上下文。

上下文切换时间是纯粹的开销，系统在切换期间不执行有用的工作。上下文切换时间取决于硬件支持。

多进程视图工作的核心是多个进程之间的来回切换，这也是并发的基本含义，操作系统实现多进程视图需要解决如下两点：

什么时候切换；
具体如何切换；
切换的时机就是当CPU出现空闲的时候，这种空闲点也被称为调度点，调度点可以是当前进程在执行过程中产生的如exit()，也可以是操作系统强行加入的如进程分配的时间片耗尽；

//一个调度点的实例代码
某个进程{
 	启动磁盘写；
    pCur.state='W';//将进程状态修改为阻塞态
    将pCur放在DiskWaitQueue;//pCur就是用于保存 “CPU中当前进程执行现场” 的PCB结构，当然它就是当前进程的PCB，便于将来能够切换回当前进程
    schedule();//调用schedule函数完成进程切换
}

操作系统调用函数schedule()实现切换，其实现原理如下：

从就绪队列中选出下一个进程的PCB，我们称为pNew；
用PCB结构pNew中存放的执行现场去替换CPU中的PC、AX等寄存器；
为了能够切换回当前进程，切换之前还应将CPU中的“当前进程执行现场”保存在当前进程的PCB结构中，该PCB结构我们称为pCur；
这其中如何选择pNew需要精心设计算法，如果只是简单的选择就绪队列首部的进程作为下一个进程，这样公平但是对于某些应当需要优先执行的进程来说非常致命；

简单给出schedule函数的基本代码结构

schedule(){
    pNew=getNext(ReadyQueue);
    switch_to(pCur,pNew);
}
switch_to(pCur,pNew){
    //保存当前进程的PCB结构
    pCur.ax=CPU.ax;
    pCur.bx=CPU.bx;
    ...
    //用pNew中的执行现场替换CPU中的寄存器
    CPU.ax=pNew.ax;
    CPU.bx=pNew.bx;
}

### 进程的组织

要论述操作系统是如何实现多进程视图（前面已经给出过图示）的，第一步要解决的问题就是在计算机中如何组织多个进程；

操作系统管理进程的关键就是管理进程对应的PCB数据结构，所以很容易就能想到，组织多个进程就是用合适的数据结构来管理这些PCB；

PCB之间存在简单的线性关系，简单而高效的方式就是将这些PCB组织成队列，并且在管理进程时需要区分进程位于哪个队列，根据进程状态概念可以分类描述操作系统中的进程：

运行态：当前占有CPU、正在执行的进程状态；
就绪态：一个进程具备所有可执行的条件，只要获得了CPU就能开始执行；
阻塞态：也称为睡眠态或等待态，指进程缺少某些条件（比如磁盘正在读写、打印机忙等），即使分配了CPU也无法执行的状态；
基于单CPU的背景，因此只有一个CPU意味着只会有一个处于运行态的进程，多个阻塞队列（多种等待事件），一个就绪队列（都在等待CPU），故形成下图所示多进程基本组织方式

![image-20231028160030893](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/image-20231028160030893.png)

上图类似于一张合照，是某一时刻下多个进程在操作系统中的样子，当然利用进程状态还可以描述一个进程在其执行过程中的演化过程（该过程常被称为进程的生存周期）

![image-20231028160053253](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/image-20231028160053253.png)

#### 进程隔离

尽管多个进程同时在内存中交替执行可以提高CPU的使用效率，但是同时在内存中的多个进程也会相互影响（比如某个进程把另一个进程的内存地址给修改了）；

解决上述问题的办法就是使用地址隔离

![image-20231028160003767](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/image-20231028160003767.png)

进程操作的地址并不是真的物理内存地址，而是通过一个映射表对应到一个真实的物理地址，这也是需要用GDT表和页表来翻译CS:EIP的根本原因；

操作系统给每个进程分配的真实的内存区域是只属于该进程的、互相不重叠的，就算进程1和进程2同时访问的地址是100，但是通过映射表后访问的真实地址其实是2100和1100；

## Operations on Processes

### Process Creation

允许一个进程创建另一个进程，此时创建者称为父进程，被创建的进程称为子进程：
**子进程可以继承父进程所拥有的资源**；
子进程被撤销的时候需要将从父进程那里获得的资源归还给父进程；
撤销父进程必须同时撤销其所有的子进程；

创建一个新进程的过程：
1. 为新进程分配唯一的PID并申请一个空白的PCB，若PCB申请失败则创建失败；
2. 为新进程的程序和数据以及用户栈分配必要的内存空间，若资源不足不会导致创建失败，而是处于阻塞态等待内存资源；
3. 初始化PCB，主要包括初始化标志信息、初始化处理机状态信息以及初始化处理机控制信息、进程优先级等；
4. 若就绪队列能够接纳新进程则将新进程插入就绪队列等待被调度运行；

进程创建的原因
- 提交批处理作业
- 用户登录
- 创建以提供打印等服务的目的
- 进程创建另一个进程

创建进程涉及以下步骤：
1. 为进程分配一个唯一的进程标识符，通常是一个整数。
2. 为进程分配内存空间。
3. 初始化进程控制块（PCB）。
4. 建立适当的链接，例如将新进程添加到用于调度队列的链接列表中。
5. 创建或扩展其他数据结构，以维护相关信息，例如维护一个账户文件。
6. 处理资源共享，这涉及确定新进程与其父进程之间共享的资源，可以有不同的模式，如父进程和子进程共享所有资源、子进程共享父进程的一部分资源、或父进程和子进程之间不共享任何资源。
7. 当创建一个进程时，通常会传递初始化数据，这些数据可能从父进程传递给子进程，以便子进程能够正确初始化。

![image-20231026212614335](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/image-20231026212614335.png)

在进程创建方面，有一些执行和地址空间的选择：
- 执行方面，有两种可能性：
  1. 父进程和子进程并发执行。
  2. 父进程等待，直到其一些或全部子进程终止。
- 地址空间方面，有两种可能性：
  1. 子进程是父进程的副本，它们共享相同的地址空间。
  2. 子进程有一个程序加载到它自己的地址空间中，独立于父进程。

在UNIX系统中，每个进程都由其进程标识符（PID）唯一标识，可以通过系统调用`fork`创建新进程。在创建子进程后，可以使用`exec`系统调用将子进程的内存空间替换为新程序，实现程序的更改。这些机制允许UNIX系统创建和管理进程，支持各种并发和应用程序切换操作。

### Process Termination

引起进程终止的事件有：

正常结束：表示进程的任务完成并准备退出运行；
异常结束：进程运行过程中发生异常导致程序无法继续运行；
外界干预：进程因为外界的请求而终止运行；
撤销原语如下：

1.根据被终止进程的标识符检索PCB，从中读出该进程的状态；
2.若被终止的进程处于执行状态则立即终止该进程的执行，将处理机的资源分配给其他进程；
3.若该进程有子孙进程则将其所有子孙进程终止；
4.将该进程拥有的全部资源归还给其父进程或操作系统；
5.将该PCB从所在队列删除；

进程终止的原因可以有很多，包括但不限于：

1. 正常完成：进程成功完成其任务。
2. 超出时间限制：进程运行时间超过了设定的最大限制。
3. 内存不足：进程需要的内存资源不可用。
4. 边界违规：进程试图访问超出其分配边界的内存。
5. 保护错误：例如，尝试向只读文件写入。
6. 算术错误：进程执行的数学运算导致错误。
7. 时间超出：进程等待某个事件的时间超过了指定的最大等待时间。
8. I/O 失败：例如，尝试打开一个不存在的文件。
9. 无效指令：当尝试执行非法或无效的指令时发生。
10. 特权指令：尝试执行只有特权进程才能执行的指令。
11. 数据滥用：例如，类型错误。
12. 操作系统干预：当操作系统介入处理进程问题，如解决死锁时。
13. 父进程终止：子进程会在其父进程终止时终止。

这些是可能导致进程终止的各种情况，操作系统会根据不同的终止原因采取适当的处理措施。

进程终止可以由多种方式触发：

1. 进程执行完最后一条语句，然后请求操作系统删除它（通过 `exit`）。

2. 进程将数据输出给父进程，然后等待父进程的确认（通过 `wait`）。

3. 操作系统会释放进程占用的资源，包括内存和其他系统资源。

此外，父进程也可以由多种原因来终止其子进程的执行，例如：

- 子进程占用的资源超出了分配的限额。
- 子进程执行的任务不再需要。
- 父进程本身终止。

需要注意的是，如果一个父进程终止，操作系统通常不允许其子进程继续运行，这可以防止子进程在没有父进程的情况下执行。因此，通常由操作系统来处理子进程的终止。

### 进程的阻塞和唤醒

进程的阻塞是进程自身的一种主动行为，只有处于运行状态的进程才可能转换为阻塞态，阻塞原语的执行过程如下：

1.找到将要被阻塞进程的PID对应的PCB；
2.若该进程为运行态则保护其现场并将其状态转换为阻塞态；
3.把该PCB插入相应事件的等待队列，将处理机资源调度给其他就绪进程；

当被阻塞进程需要的资源到达，由相关进程调用唤醒原语，将等待该事件的进程唤醒，唤醒原语如下：

1.在该事件的等待队列中找到相应进程的PCB；
2.将其从等待队列中移出，并置其状态为就绪态；
3.把该PCB插入就绪队列，等待调度程序调度；

注意：Block 原语和Wakeup 原语是一对作用刚好相反的原语，必须成对使用。Block原语是由被阻塞进程自我调用实现的，而Wakeup原语则是由一个与被唤醒进程合作或被其他相关的进程调用实现的；

## Interprocess Communication

独立进程（Independent process）不能影响或被另一个进程的执行所影响。

协作进程（Cooperating process）可以影响或被另一个进程的执行所影响。进程协作的优点包括：
1. 信息共享：允许进程之间共享数据和信息，从而实现协同工作。
2. 计算加速：多个进程协同工作可以加速计算和任务的完成。
3. 模块化：将系统划分为多个协作的模块或进程，使系统更易于管理和维护。
4. 方便性：允许不同的进程协同执行各自的任务，从而提高系统的灵活性和效率。

进程协作通常可以使用两种基本模型来实现：
1. **共享内存**（Shared-memory）：多个进程可以访问相同的内存空间，从中读取和写入数据，以实现协同工作。允许进程之间以最大的速度和便利进行通信。
2. **消息传递**（Message passing）：进程之间通过发送和接收消息来进行通信，以协同执行任务。这种方式更加分离，进程之间互相独立。
   1. 数据交换的方式：消息传递适用于需要交换较少数据的情况，因为它不需要考虑数据冲突。每个进程可以将消息发送给其他进程，实现数据交换。
   2. 跨计算机通信：消息传递更容易在不同计算机之间实现，因为它允许进程在不同计算机上发送和接收消息，适用于分布式系统和网络通信。
### Shared-memory systems
- 在通信的进程之间**存在一块可直接访问的共享空间**，通过对这片共享空间进行写/读操作实现进程之间的信息交换。
- 在对共享空间进行写/读操作时，需要使用**同步互斥工具**（如P操作、V操作），对共享空间的写/读进行控制。
- 共享存储又分为两种：
	- 低级方式的共享是基于数据结构的共享；
	- 高级方式的共享则是基于存储区的共享。
- 操作系统只负责为通信进程提供可共享使用的存储空间和同步互斥工具，而数据交换则由用户自己安排读/写指令完成。
- 注意，进程空间一般都是独立的，进程运行期间一般不能访问其他进程的空间，想让两个进程共享空间，必须通过特殊的系统调用实现，而**进程内的线程是自然共享进程空间**的。

### Message-passing systems

在消息传递系统中，进程间的数据交换以**格式化的消息（Message） 为单位**。若通信的进程之间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信。
进程通过系统提供的发送消息和接收消息两个原语进行数据交换。这种方式隐藏了通信实现细节，使通信过程对用户透明，简化了通信程序的设计，是当前应用最广泛的进程间通信机制。
在微内核操作系统中，微内核与服务器之间的通信就采用了消息传递机制。由于该机制能很好地支持多处理机系统、分布式系统和计算机网络，因此也成为这些领域最主要的通信工具。

消息传递的基本结构:
- 发送消息：send(message)
- 接收消息：receive(message)

当进程P和Q需要通信时，它们需要：
- 建立一个用于连接它们的通信链路。
- 使用send和receive操作来交换消息。

通信链路的实现包括逻辑方面和物理方面：
1. 逻辑方面：涉及逻辑属性，例如通信链路的属性。
2. 物理方面：可能涉及共享内存或硬件互连等物理元素。

1）**直接通信方式**。发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息。

直接通信中的命名问题包括以下内容：
1. 进程必须显式地为对方命名：
   - `send(P, message)`：向进程P发送消息。
   - `receive(Q, message)`：从进程Q接收消息。
2. 通信链路的属性：
   - 通信链路是自动建立的。
   - 一个通信链路与恰好一个进程对相关联。
   - 每对通信进程之间存在恰好一个通信链路。
   - 通信链路可以是单向的，但通常是双向的。
3. 寻址的不对称性：`receive(id, message)`会导致定义的进程模块的可重用性受限。

2)**间接通信方式**。发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息。
这种中间实体一般称为信箱（也称为端口）。该通信方式广泛应用于计算机网络中。
1. **特点**：
	1. 每个邮箱都有唯一的标识符（id）。
	2. 进程只有在共享同一个邮箱的情况下才能进行通信。
	3. 通信的原语包括：
	   - `send(A, message)`：将消息发送到邮箱A。
	   - `receive(A, message)`：从邮箱A接收消息。
	1. 通信链路的属性包括：
		1. 链路只有在进程共享一个邮箱时才会建立。
		2. 一个链路可以与多个进程相关联。
		3. 每对进程可以共享多个通信链路。
		4. 链路可以是单向的或双向的。
2. **多进程共享邮箱的通信难题**：
	- 当多个进程共享一个邮箱，例如进程P1、P2和P3共享邮箱A时，如果P1使用`send(A, message)`发送消息到邮箱A，实际的接收者成为了一个问题。
	- 为此，存在几种可能的解决方案：
		- **允许一个链路与多个进程相关联**：例如，消息可以被发送到与此链路相关联的任一进程。
		- **限制同时接收的进程**：只允许一个进程执行`receive()`操作，确保只有特定进程接收到消息。
		- **系统随机选择接收者**：系统选择一个接收者，但会通知发送者哪个进程接收了消息。这种方式需要进一步同步和协调，但为发送者和接收者提供了关于消息交付状态的明确信息。
3. **邮箱的所有权**：
	- 邮箱可以由特定的进程拥有，或者由操作系统独立地拥有。
	- **进程拥有的邮箱**：此邮箱的所有者是唯一可以通过它接收消息的进程。而其他进程可以发送消息到这个邮箱。
	- **操作系统拥有的邮箱**：此类邮箱是独立的，不属于任何特定进程。进程可以通过操作系统提供的机制对邮箱执行一系列操作，如创建、发送/接收消息以及删除。
4. **消息传递的同步性：**
	- 消息传递可能是同步的（阻塞）或异步的（非阻塞）。
	- **阻塞消息传递**：
		- **发送方阻塞**：直到消息被接收。
		- **接收方阻塞**：直到消息可用。
	- **非阻塞消息传递**：
		- **发送方**：发送消息后继续执行其他操作。
		- **接收方**：无论消息是否可用，都会立即检索。
5. **消息队列缓冲：**
	- 消息队列是与通信链路相关的，并有三种可能的缓冲方式：
	- **零容量**：没有消息缓存。发送方必须等待接收方准备好会合。
	- **有界容量**：队列具有固定的大小，例如n条消息。当队列满时，发送方必须等待。
	- **无界容量**：队列大小是无限的，所以发送方无需等待，可以随时发送消息。

### Producer-Consumer Problem

协作进程中的常见范例是生产者-消费者问题，其中一个生产者进程生成信息，而一个消费者进程获取并使用该信息。

#### Shared-memory

定义：使用一个共同的内存区域或缓冲区，该区域可以由**生产者写入数据**，并由**消费者读取和消费数据**。

主要有两种类型的缓冲区：
1. 无界缓冲区（unbounded-buffer）：不对缓冲区的大小设定实际限制，可以不断地存储项目。
2. 有界缓冲区（bounded-buffer）：假定缓冲区有一个固定的大小，即缓冲区中可以存储的项目数量有限。

不论使用哪种缓冲区类型，生产者和消费者之间需要进行同步。这确保生产者不会在缓冲区已满时添加数据，也确保消费者不会从空的缓冲区中读取数据。

关于同步：在多进程环境中，由于调度和执行顺序是不确定的，可能会导致数据不一致或其他错误。因此，引入了**临界区**的概念，确保在给定时间内只有一个进程可以访问共享资源或数据。

#### Pipe

管道是一种在进程间进行通信的方法。它允许一个进程的输出成为另一个进程的输入。

- **定义**：管道是一个通信机制，允许一个进程向管道的一端写入数据，而另一个进程从另一端读取数据。
- **特性**：
  - 数据在管道中是**先进先出**的。
  - 如果管道为空，读进程会被阻塞，直到有数据可读。
  - 如果管道已满，写进程会被阻塞，直到有空间可写。
  - 管道在Linux中通常有一个固定的大小（例如，4KB）。当管道满时，写操作会被阻塞。当管道空时，读操作会被阻塞。
  - 管道可以用于父子进程间的通信。一个进程可以创建一个管道，并将其传递给其子进程。
  - 通常，管道只支持单向通信。要进行双向通信，可能需要两个管道。

**注意**：从管道读取的数据是一次性的。一旦数据被读取，它就从管道中删除了。
## Example of IPC Systems

POSIX shared memory 

Message passing in the Mach operating system 

Windows

## Communication in Client-Server Systems

### Sockets 

套接字（Socket）

套接字是用于通信的端点。

它是 IP 地址与端口号的组合。例如，套接字 161.25.19.8:1625 指的是主机 161.25.19.8 上的端口 1625。

通信是在一对套接字之间进行的。

所有低于 1024 的端口都被认为是众所周知的，可以用来实现标准服务。

例如，FTP 服务器监听端口 21，telnet 服务器监听端口 23，Web 或 HTTP 服务器监听端口 80。

当客户端进程发起连接请求时，它会由其主机计算机分配一个端口（大于 1024）。

Socket通信是一种常见且高效的分布式进程通信方式。它是一种低级通信形式，允许在分布式进程之间交换未经结构化的字节流。在Socket通信中，所有的连接必须是唯一的。

### Remote Procedure Calls (RPC) 

远程过程调用（RPC）是一种抽象的过程调用方法，用于在网络系统上的进程之间进行通信。通过RPC，交换的消息是结构良好的。

- 每个消息都是发送到远程系统上某个端口的RPC守护进程。每个消息包含要执行的函数标识符和要传递给该函数的参数。然后按照请求执行该函数，并将任何输出以单独的消息发送回请求者。

- 端口是消息数据包的起始处的一个数字。系统拥有一个网络地址，但可以在该地址内有多个不同的端口，以区分支持的多个网络服务。如果远程进程需要某项服务，它会将消息地址定向到适当的端口。RPC的语义允许客户端以与本地调用过程相同的方式调用远程主机上的过程。

- 为此，客户端提供了一个存根（stub），作为服务器上实际过程的客户端代理。客户端存根用于定位服务器上的端口，对参数进行编组，并向服务器发送消息。服务器端存根接收此消息，解包编组的参数，并在服务器上执行过程。返回值使用相同的技术传递回客户端。

- 数据的表示在不同机器上可能是不同的，因此需要一种机器无关的数据表示方式，如外部数据表示（XDR）。客户端将机器相关数据转换为XDR，服务器将XDR数据解组并转换为机器相关表示。

- 调用的语义为“仅一次”——将时间戳附加到每条消息，服务器必须保留其已经处理的消息的所有时间戳历史记录，以确保不会处理重复消息。还有“正好一次”——服务器向客户端发送确认消息，确保消息的唯一性。

- 绑定信息可以预先确定，即使用固定端口地址，也可以通过约会机制进行动态绑定，根据需要绑定端口。

![image-20231026224220358](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/image-20231026224220358.png)

### Remote Method Invocation (RMI, Java) 

RMI（远程方法调用）是类似于RPC的Java机制，允许一个机器上的Java程序调用远程对象的方法。

RMI使用存根（stubs）和骨架（skeletons）来实现远程对象，因此对于客户端和服务器来说，远程方法是透明的。存根是远程对象的代理，位于客户端。骨架负责解组参数并在服务器上调用所需的方法。

RMI有关参数传递行为的规则如下：

- 如果已经编组的参数是本地对象，它们将使用对象序列化技术进行复制传递。
- 如果参数也是远程对象，它们将通过引用传递。
- 如果要将本地对象作为参数传递给远程对象，它们必须实现`java.io.Serializable`接口。



# Threads
## Threads
线程，也称为轻量级进程（LWP），是CPU利用的基本单位。
- 包括线程ID、程序计数器、寄存器集合和堆栈。
- 与属于同一进程的其他线程共享其代码段、数据段和其他操作系统资源，如打开的文件和信号。
- 引入进程之后，进程是资源（除CPU外的系统资源）分配的单位，内核级线程是处理器调度和分配的单位。
- 线程本身不具有资源，它可以共享所属进程的全部资源
- 一个线程可以创建和撤销另一个线程，同一进程中的多个线程之间可以并发执行。

线程与进程的比较：
- 调度
	- 在同一进程中，线程的切换不会引起进程切换。但从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
- 资源
	- 线程不拥有系统资源（仅有一点必不可少、能保证独立运行的资源），但线程可以访问其隶属进程的系统资源
- 独立性
	- 每个进程都拥有独立的地址空间和资源，除了共享全局变量，不允许其他进程访问。某进程中的线程对其他进程不可见。同一进程中的不同线程是为了提高并发性及进行相互之间的合作而创建的，它们共享进程的地址空间和资源。
- 系统开销
	- 由于一个进程内部有多个线程，若线程的切换发生在同一个进程内部，则只需要很少的时空开销。
	- 由于同一进程内的多个线程共享进程的地址空间，因此这些线程之间的同步与通信非常容易实现。
- 支持多处理机系统
	- 可以将进程中的多个线程分配到多个处理机上执行。

**线程的属性**
- 每个线程都应有一个唯一的标识符和一个线程控制块，线程控制块记录了线程执行的寄存器和栈等现场状态。
- 不同的线程可以执行相同的程序，即同一个服务程序被不同的用户调用时，操作系统把它们创建成不同的线程。

### Thread States
线程的三种基本状态：Running, ready, waiting

与线程状态变化相关的操作包括：
- Spawn：创建另一个线程
- Block、Unblock：阻塞或解除阻塞线程
- Finish：释放寄存器上下文和堆栈资源
### Multicore Programming
多核编程是一种允许系统同时执行多个任务的编程方法。并行性意味着系统能够同时执行多个任务，而并发性则支持多个任务同时取得进展。在单处理器/核心系统中，调度程序提供并发性。CPU设计者通过添加硬件来提高线程性能，以提高系统性能。

## Multithreading Models
- 用户级线程，在内核之上支持，无需内核支持而由用户程序管理。
	- 所有线程管理由应用程序完成。内核不知道线程的存在。用户线程是在内核之上支持的，由用户级别的线程库实现。该库提供线程的创建、调度和管理支持，无需内核的支持。
	- 在用户级线程中，有关线程管理(创建、撤销和切换等)的所有工作都由应用程序在用户空间中完成，内核意识不到线程的存在。应用程序可以通过使用线程库设计成多线程程序。通常，应用程序从单线程开始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生例程创建一个在相同进程中运行的新线程。
	- 三种主要的线程库：
		- POSIX Pthreads
		- Win32 线程
		- Java 线程
- 内核线程，由操作系统直接支持和管理。 最终，用户线程和内核线程之间必须存在关系。
	- 受操作系统直接支持。内核在内核空间中执行线程的创建、调度和管理。内核维护进程和线程的上下文信息。
	- 在操作系统中，无论是系统进程还是用户进程，都是在操作系统内核的支持下运行的，与内核紧密相关。内核级线程同样也是在内核的支持下运行的，线程管理的所有工作也是在内核空间内实现的。内核空间也为每个内核级线程设置一个线程控制块，内核根据该控制块感知某线程的存在，并对其加以控制。图2.5(b)说明了内核级线程的实现方式。
	- 这种实现方式的优点如下：①能发挥多处理机的优势，内核能同时调度同一进程中的多个线程并行执行。②如果进程中的一个线程被阻塞，内核可以调度该进程中的其他线程占用处理机，也可运行其他进程中的线程。③内核支持线程具有很小的数据结构和堆栈，线程切换比较快、开销小。④内核本身也可采用多线程技术，可以提高系统的执行速度和效率。
	- 这种实现方式的缺点如下：同一进程中的线程切换，需要从用户态转到核心态进行，系统开销较大。这是因为用户进程的线程在用户态运行，而线程调度和管理是在内核实现的。
	- 调度是以线程为基础进行的。支持内核线程的系统示例包括Windows XP/2000、Solaris、Linux、Tru64 UNIX和Mac OS X。
- 有三种常见的线程实现类型：
	- 多对一（Many-to-One）
		- 在单个内核线程映射到多个用户级线程。线程管理在用户空间中完成。如果一个线程执行了一个阻塞的系统调用，整个进程会被阻塞。在多处理器上，多个线程无法并行运行，因为每次只能有一个线程访问内核。这种模型适用于不支持内核线程的系统，但目前很少有系统使用这种模型。例如，Solaris 2中提供的Solaris Green Threads是一个可用于Solaris的线程库，还有GNU Portable Threads。
	- 一对一（One-to-One）
		- 在这种模型中，每个用户级线程都映射到一个内核线程。当一个线程执行一个阻塞的系统调用时，允许另一个线程运行。这允许多个线程在多处理器上并行运行。创建一个用户线程需要创建相应的内核线程。系统支持的线程数量受到限制。使用这种模型的 系统包括Windows、Linux以及Solaris 9及更高版本。
	- 多对多（Many-to-Many）
		- 这种模型允许许多用户级线程映射到许多内核线程。操作系统可以创建足够数量的内核线程。当一个线程执行一个阻塞的系统调用时，内核可以调度另一个线程进行执行。支持这种模型的系统示例包括Solaris 9之前的版本以及具有ThreadFiber包的Windows。
		这三种模型之间的比较如下：
1. Many-to-One模型允许开发人员创建任意数量的用户线程，但无法实现真正的并发，因为内核一次只能调度一个线程。
2. One-to-One模型允许更大的并发性，但开发人员必须小心，不要在应用程序中创建过多的线程。
3. Many-to-Many模型允许开发人员创建必要数量的用户线程，而相应的内核线程可以在多处理器上并行运行。
这些模型的选择取决于应用程序的性质和运行环境。Many-to-Many模型通常提供最大的灵活性和性能，因为它允许更好的并发性和利用多处理器系统的优势。但是，开发人员必须小心管理线程的数量，以避免过多的开销。
![截图_20231103210339.png](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/%E6%88%AA%E5%9B%BE_20231103210339.png)

## Threads Libraries
线程库（Thread Libraries）提供了程序员创建和管理线程的API。有两种主要的实现方式：
1. 在用户空间提供一个完全不依赖内核支持的库。所有的代码和数据结构都存在于用户空间中。
2. 实现一个在操作系统直接支持的内核级库。所有的代码和数据结构都存在于内核空间中。
主要的线程库包括：
- POSIX Pthreads：一种通用的线程库，支持多个操作系统，包括Linux和Unix系统。
- Win32：Windows操作系统上的线程库。
- Java：Java编程语言内置的线程支持。
这些库允许程序员轻松地创建、管理和同步线程，从而实现多线程应用程序。不同的操作系统和编程语言可能提供不同的线程库来满足特定需求。

在多线程编程中，全局数据（Global Data）和局部数据（Local Data）之间存在不同的访问规则：
- 对于POSIX和Windows线程，在全局范围声明的数据将在同一进程中的所有线程之间共享。这意味着多个线程可以访问和修改这些全局数据。
- Java没有全局数据的概念，因此访问共享数据必须在线程之间进行显式安排。在Java中，局部数据通常存储在栈上，因为每个线程都有自己的栈，所以局部数据的每个线程都有一份拷贝。
  

创建多个线程的一般策略包括异步线程和同步线程：
- 异步线程（Asynchronous Threading）：在这种策略中，一旦父线程创建了子线程，父线程就会继续执行，使得父线程和子线程同时执行。这种策略通常用于多线程服务器等场景。
- 同步线程（Synchronous Threading）：在这种策略中，父线程会等待子线程完成其任务后再继续执行。这种策略用于需要等待子线程结果的场景。
同步线程（Synchronous Threading）是一种策略，当父线程创建一个或多个子线程后，必须等待所有子线程终止后才能继续执行。这被称为"fork-join"策略。
在同步线程策略中，由父线程创建的各个子线程会并发执行工作，但父线程必须等待这些工作完成后才能继续执行。一旦每个线程完成了它的工作，它就会终止并与其父线程合并（join）。只有在所有子线程都已合并后，父线程才能恢复执行。
通常，同步线程涉及大量线程之间的数据共享。例如，父线程可能会合并其各个子线程计算的结果。
这种策略适用于需要等待子线程完成工作并收集结果的情况。
## Threading Issues
### fork() 和 exec() 系统调用的问题。
当一个程序中的线程调用 fork() 时，新的进程会复制所有线程还是只有一个线程？
・ 如果一个线程调用 fork()，那么新进程会复制所有线程。  
・ 新的进程只复制发起 fork() 系统调用的那个线程。
如果 fork() 后立即调用 exec()，那么只复制调用线程是合适的。
・ 如果一个线程调用 exec()，那么指定参数中的程序将替换整个进程，包括所有线程。  
・ 如果分离的进程在 fork() 后没有调用 exec()，那么分离的进程应复制所有线程。
这段内容主要阐述了在操作系统中，当程序创建新进程时，如何处理线程的复制问题。根据不同的情况，新进程会复制所有线程或仅复制发起 fork() 的线程。同时，当新进程调用 exec() 时，会替换整个进程的所有线程。如果新进程没有立即调用 exec()，那么需要复制所有线程。这是因为操作系统在处理进程创建和线程复制时，需要确保进程和线程的资源正确分配和执行路径。
### thread cancellation
线程取消是指在线程完成之前终止线程的过程。线程取消主要有两种场景：异步取消和延迟取消。
异步取消：当一个线程立即终止目标线程时，这种方式就是异步取消。在这种方式下，终止线程的操作是立即发生的，不需要等待目标线程执行到某个取消点。
延迟取消：在这种场景下，目标线程会定期检查是否需要终止。当满足取消条件时，线程才会被终止。这种方式相对于异步取消，更加灵活，但需要线程自身具备检查和处理取消的机制。
线程取消的困难之处在于，当线程被取消时，可能正在执行的任务没有完成，或者正在占用资源。为了解决这个问题，操作系统和线程库通常提供了一种机制，使线程能够在被取消时释放资源并进行清理工作。
在 Pthreads 库中，线程取消是通过 pthread_cancel() 函数实现的。该函数请求终止指定线程，但实际的终止取决于线程的状态。线程可以设置自己的取消状态和类型，也可以在运行过程中检查是否需要终止。默认情况下，线程的取消类型是延迟取消，即线程在达到取消点时才会被终止。在 Linux 系统中，线程取消是通过信号处理的机制实现的。
 这段内容主要讲述了线程取消的相关知识。在线程取消中，Pthread 库提供了一个用于取消线程的函数：pthread_cancel（tid）。
◼ 当调用 pthread_cancel（tid）时，请求取消线程。但实际的取消操作取决于线程的状态：
  • 线程可以通过 API 设置其取消状态和类型。  
  • 如果线程禁用了取消功能，那么取消操作将一直保持待处理状态，直到线程启用它。
◼ Pthread 库的默认取消类型是延迟取消。
  • 只有在线程达到取消点时，才会发生取消。  
  • 取消点可以通过调用 pthread_testcancel() 函数来创建。  
  • 当取消点被触发时，清理处理程序将被调用，以释放资源。
◼ 在 Linux 系统中，线程取消是通过信号处理的机制实现的。
综上所述，这段内容主要介绍了线程取消的原理和方法，以及 Pthread 库在线程取消过程中的作用。线程取消分为异步取消和延迟取消，其中延迟取消是默认方式。在线程达到取消点时，线程将被取消，并执行清理处理程序以释放资源。在 Linux 系统中，线程取消是通过信号处理的机制实现的。
### signal handling
 【信号处理】（Signal handling）是操作系统中用于处理进程接收到的信号的过程。信号是一种用于通知进程某个特定事件已发生的方式。这些事件可能包括硬件信号（如内存访问错误、除以零等，）、软件信号（如终止进程的特定键盘操作，如 Ctrl+C）以及其他各种事件。
信号处理的主要目的是让进程在接收到信号后能够采取相应的措施。信号处理可以分为两类：同步信号处理和异步信号处理。
1. 同步信号处理：同步信号是由进程自身的行为引发的，例如非法内存访问或除以零等操作。这类信号会直接传递给引发该信号的进程。当同步信号发生时，进程必须处理该信号。
2. 异步信号处理：异步信号是由进程外部的事件引发的，如终止进程的特定键盘操作。这类信号会传递给正在运行的进程。与同步信号不同，异步信号的处理方式取决于信号类型和进程的配置。有些异步信号需要发送给所有线程，如 Ctrl+C；而有些信号只发送给非阻塞信号的线程。
在多线程程序中，信号处理需要确保信号传递给应该处理的线程。信号处理的方法取决于信号类型。同步信号需要传递给生成该信号的线程，而某些异步信号需要发送给所有线程，或者仅发送给非阻塞信号的线程。某些 UNIX 版本的多线程允许线程指定它接受哪些信号并阻塞哪些信号。
### thread pools
 【线程池】（Thread pools）是一种用于管理和管理线程的技术。其核心思想是在程序启动时创建一批线程，并将它们放入一个池中等待分配任务。当服务器接收到请求时，它会从线程池中唤醒一个线程，将请求传递给它进行处理。线程处理完请求后，会返回线程池等待下一次分配任务。如果线程池中没有可用的线程，服务器会等待直到有线程空闲为止。
线程池的优点主要有以下几点：
1. 通常比等待创建新线程更快地服务请求。  
2. 允许将应用程序中的线程数量与线程池的大小绑定。  
3. 提高系统资源利用率，降低上下文切换的开销。
总之，线程池有助于提高程序的运行效率，特别是在处理大量并发请求的场景中。
### thread-specific data
 【线程特定数据】（Thread-specific data）是指在多线程程序中，每个线程都有自己的数据副本，这些数据与其他线程中的数据相互独立。线程特定数据允许每个线程拥有自己的数据副本，以便在并发环境下实现数据隔离，避免数据冲突和竞争条件。
线程特定数据的主要优点如下：
1. 提高程序的并发性能，因为每个线程可以独立地处理任务，而无需等待其他线程完成操作。  
2. 降低数据竞争和同步开销，因为每个线程都有自己的数据副本，从而减少了锁和其他同步原语的使用。  
3. 使线程能够更好地协同工作，因为每个线程可以独立地处理任务，并根据需要共享结果。
线程特定数据与本地变量、静态数据有所不同：
1. 本地变量：本地变量仅在单个函数调用期间可见，而在多线程环境下，不同线程之间的本地变量是相互独立的。  
2. 静态数据：静态数据在程序运行期间始终保持不变，可以被所有线程共享。然而，在多线程环境下，静态数据可能引发竞争条件和死锁等问题。
总之，线程特定数据是一种在多线程程序中管理和保护数据的方法，有助于提高程序的性能和稳定性。
### Scheduler Activations
 【调度器激活】（Scheduler Activations）是一种在操作系统中实现线程与内核之间通信的方法。它允许用户线程库与内核线程之间进行交互，以便内核能够通知应用程序关于某些事件的信息。调度器激活在多线程应用程序中发挥着重要作用，因为它提供了一种机制，使应用程序能够在适当的时候接收内核的通知并进行相应的处理。
调度器激活的主要特点如下：
1. 提供了一种用户线程与内核线程之间通信的机制。  
2. 内核可以通过调度器激活向应用程序通知特定事件，如信号、时间戳等。  
3. 用户线程库可以处理内核通知，并在适当的时候执行相应的操作。  
4. 调度器激活通常使用轻量级进程（Lightweight Process，LWP）作为用户线程与内核线程之间的中介。
在 openEuler 操作系统中，线程的实现采用了 1:1 模型，其线程库是 NPTL（Native POSIX Thread Library）。openEuler 的进程和线程在地址空间中的布局采用了类似的方式，即一个进程由一个线程组及其共享的资源组成。当应用程序中的一个线程即将阻塞时，内核会向该线程发送一个调度器激活，通知应用程序分配一个新的轻量级进程。然后，应用程序在这个新的轻量级进程中运行一个调度器激活处理程序，用于处理阻塞线程的状态保存和重新调度等操作。
总之，调度器激活是操作系统中实现线程与内核之间通信的一种重要机制，它有助于提高多线程应用程序的性能和稳定性。
