---
title: 6 Main Memory And Virtual Memory
date: 2023-12-25 19:54:47
tags: 
categories:
  - OS
---
# Main Memory

## Background

计算机内存由大量存储单元组成，每个单元有地址。程序需要将指令和数据加载到内存中才能运行。
内存和寄存器是CPU可以直接访问的存储单元。寄存器访问速度快，内存访问速度较慢。
Cache位于内存和CPU之间，用于暂存常用数据，以加速CPU的访问。
指令执行需要经历取指令、解码、取操作数、执行和存储结果等多个步骤。内存访问是其中较慢的一步。
为了保护内存，需要硬件提供地址映射功能，确保每个进程只能访问自己的地址空间。
内存管理的目标是高效地为多个进程分配内存，同时满足进程对内存的需求。

## Swapping

进程可以暂时从内存中交换到备份存储设备上，然后被重新调入内存以继续执行。
进程的物理内存空间可以超过物理内存的大小。
备份存储设备Backing store - fast disk，足以容纳所有用户的内存映像副本。
交换出的进程是否会被交换回它之前使用的相同内存空间，取决于地址绑定方法。
Roll out, Roll in - 基于优先级的调度算法。
就绪队列 - 包含所有在备份存储设备上或在内存中并且准备运行的过程。
调度程序 - CPU调度器决定执行一个进程时被调用。
**如果下一个进程不在内存中，且没有空闲内存区域，调度程序会交换掉当前内存中的一个进程，并调入所需进程。**
上下文切换时间可能非常高。
总传输时间与交换的内存量成正比。
用户必须告知系统其对内存需求的任何变化。
永不交换带有未决I/O操作的过程。
标准交换在现代操作系统中不使用。

## Contiguous Memory Allocation

1. 内存需要同时满足操作系统和用户进程的需求。
2. 内存通常被划分为操作系统分区(低内存，包含中断向量)和用户进程分区(高内存)。
3. 用户空间进一步划分为多个分区。
4. 对每个进程进行单分区分配。 
5. 使用重定位寄存器方案（relocation-register scheme）来保护用户进程，使其相互隔离，并防止改变操作系统代码和数据。
	1. 重定位寄存器Relocation/base register包含最小物理地址值。
	2. 限制寄存器limit register包含逻辑地址范围。
	3. 每个逻辑地址必须小于限制寄存器的值。

MMU动态映射逻辑地址到物理地址，调度程序加载重定位和限制寄存器，逻辑地址必须小于限制寄存器的值，否则会导致越界访问，触发trap异常。

> 重定位寄存器的作用：
>
> 1. **基址调整**：重定位寄存器的主要作用是存储一个基址值，这个值在运行时被加到进程的虚拟地址上，以产生实际的物理地址。这种机制允许系统动态地改变进程在物理内存中的位置。
> 2. **支持进程隔离**：通过使用重定位寄存器，操作系统可以确保一个进程不能访问到其他进程的内存空间。这提高了系统的安全性和稳定性。
> 3. **内存保护**：重定位寄存器也被用于内存保护。操作系统可以设置边界，以保证进程只能访问分配给它的内存区域。如果进程尝试访问超出这个范围的内存，会触发一个异常，例如段错误。
> 4. **简化链接和加载**：在程序加载时，重定位寄存器使得程序无需知道其在物理内存中的实际位置。程序可以在编译时使用相对地址，加载时由操作系统通过重定位寄存器调整这些地址。
> 5. **上下文切换时的更新**：在多任务操作系统中，当CPU从一个进程切换到另一个进程时，操作系统会更新重定位寄存器以反映新进程的内存基址。
> 6. **与虚拟内存的关系**：在现代操作系统中，虚拟内存的使用使得重定位寄存器的角色变得不那么直接显著，因为地址转换更多地依赖于分页机制和页表。然而，在某些体系结构和早期系统中，重定位寄存器仍然是内存管理的重要组成部分。

### Fixed Partitioning

固定分区方式将内存分成多个固定大小的分区(partitions)。
- 如果分区大小等于或小于进程大小，则可以将进程加载到可用的分区中。
- 所有分区都充满后，操作系统可以将进程从某个分区交换出去。
- 如果程序大小超过分区大小，程序员需要设计程序使用覆盖(overlay)技术。
- 分区大小不同时，内存使用效率低，任何大小程序都会占用整个分区，导致内部碎片。

### Placement Algorithm with Partitions

内存分区的放置算法
- 相等大小分区(Equal-size partitions)：所有分区大小相等，使用哪个分区并不重要。
- 不等大小分区(Unequal-size partitions)：可以为每个进程分配其最适合的较小分区。为每个分区创建一个队列，进程的分配方式要尽量减少分区内的浪费内存。
- 数据结构：每个分区包含分区ID、基地址、限制地址、状态等信息。

### Variable-partition

可变分区(Variable-partition scheme)内存管理方式
可变分区(也称为动态分区，Dynamic Partitioning)是一种动态分配内存的方式。
- 内存被分成大小和数量可变的分区(partitions)。
- 初始时，所有内存都可供用户进程使用，形成一个大的空闲区(hole)。
- 内存中散布着各种大小的空闲区。
- 操作系统维护一个表，包含哪些分区已被分配以及给哪个进程使用等信息。
- 当一个进程到达时，它从足够大的空闲区中分配内存。
- 进程退出时，释放其分区，相邻的空闲分区合并。

### Dynamic Storage-Allocation Problem

动态存储分配问题是如何从一组空闲区中满足大小为n的请求。
- First-fit：选择第一个足够大的空闲区分配。
- Best-fit：选择最小且足够大的空闲区分配。
- Worst-fit：选择最大的空闲区分配。
首次适应法和最佳适应法在速度和存储利用率方面优于最差适应法。但是这些算法都存在外部碎片问题。

### Fragmentation

内存碎片(Fragmentation)
- 外部碎片(External Fragmentation)：存在足够的内存空间来满足请求，但是这些内存空间不连续。
- 内部碎片(Internal Fragmentation)：分配的内存可能比请求的内存略大，这个大小差异是分区内的内存，但是没有被使用。
- 对首次适应法(First Fit)的统计分析表明，给定N个块被分配，另外0.5N个块将因碎片化而无法使用。
- 1/3的内存可能无法使用 -> 50%规则。
 该段内容主要介绍了内存碎片(Fragmentation)的问题以及通过整理内存来减少碎片的方法。
- 通过整理内存(Compaction)来减少外部碎片，即将所有空闲内存移动到一起形成一个大的内存块。整理内存需要在执行时动态地进行，并且需要锁定内存中的作业以避免在进行I/O操作时出现错误。
- 备份存储(Backing store)也会存在类似的问题。

## Paging

### Paging

1. **进程的物理地址空间可以是离散的**：这意味着一个进程的不同部分可以存储在物理内存的不同位置，而不是必须连续。
2. **实现分页的基本方法**：
   - **物理内存分块**：物理内存被划分为固定大小的块，称为帧（frames）。
   - **逻辑内存分块**：逻辑内存（即进程视角下的内存）也被划分为与帧大小相同的块，称为页（pages）。
   - **备份存储分块**：备份存储（如硬盘）被划分为与内存帧相同大小的块，以便存储不在物理内存中的页。
   - **页的大小**：页的大小通常是2的幂次方，范围在512字节到16MB之间。
3. **页的加载与内存分配**：
   - 当进程需要执行时，它的页被加载到内存中任何可用的帧中。
   - 进程在帧可用时被分配内存，这有助于避免外部碎片（内存中未被使用的空间）和不同大小内存块带来的问题。
4. **运行进程所需的内存分配**：要运行一个包含n个页的程序，需要找到n个空闲的帧并将程序加载到这些帧中。
5. **页表的作用**：
   - 操作系统为每个进程维护一个页表（page table）。
   - 页表包含每个页在物理内存中的帧位置信息。
   - 页表用于将进程的逻辑地址转换为物理地址。
6. **内部碎片问题**：内部碎片（internal fragmentation）通常发生在内存分配的最后一个页中，当页未完全使用时。
7. **逻辑地址的分解**：
   - 每个逻辑地址分为两部分：页号（p）和页偏移（d）。
   - 页号用作在页表中索引，以找到每个页在物理内存中的基地址。
   - 页偏移与基地址组合，定义了发送给内存单元的实际物理地址。
8. 内存访问次数
	1. 对于简单的分页系统，可能只需要一次额外的内存访问来获取页表项。两次访问内存。
	2. 对于多级页表（如现代操作系统中常用的），可能需要多次内存访问。每一级页表都可能需要单独的内存访问。n级页表访问n+1次内存。
### Address structure

![](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/20231225214116.png)

![](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/20231225215035.png)
![](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/20231225215145.png)

> 
> 逻辑地址的大小一般要大于物理地址的大小。
> 
> 相等的情况：在某些系统中，逻辑地址空间的大小可以与物理地址空间的大小相等。这通常发生在不使用特殊内存管理技术（如分页或分段）的简单系统中。
> 逻辑地址空间大于物理地址空间：在使用虚拟内存技术的系统中，逻辑地址空间通常大于物理地址空间。这是因为虚拟内存允许操作系统利用硬盘空间作为扩展的内存，使得进程看起来拥有比实际物理内存更多的内存。在这种情况下，逻辑地址用于表示进程的地址空间，而物理地址则是实际存储在物理内存中的地址。
> 物理地址空间大于逻辑地址空间：这种情况较少见，但在某些特殊的硬件或操作系统设计中可能发生。例如，某些高端服务器或特殊用途的计算机可能具有更大的物理内存，而操作系统可能只允许每个进程访问其中的一部分。
> 动态关系：在某些系统中，逻辑地址空间和物理地址空间的大小关系可能不是静态固定的，而是根据当前的内存使用情况和操作系统策略动态变化的。
> 

![](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/20231225215613.png)
![](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/20231225215645.png)

页的大小跟帧的大小相同，以便进行无缝映射。

### Fragmentation

分页式内存管理避免了外部碎片化，但存在内部碎片化问题。
例如，如果页面大小为2048字节，进程大小为72766字节，则需要35个页面，但进程只使用了1086字节的内部碎片。
最坏情况下内部碎片化等于1个页面大小，平均碎片化等于页面大小的一半。
所以页面大小越小越好吗？不是，因为每个页面表项都需要内存，页面大小越小，需要的页面表项越多。

### Hardware support

1. 使用一组寄存器用于页表的管理(<256项)。
2. 对于较大的页表(例如100万项)，页表会保存在主内存中。
3. 页表基址寄存器(PTBR)指向页表的位置。
4. 页表长度寄存器(PTLR)表示页表的大小。
5. 在这种方案中，每次数据/指令访问都需要访问两次内存，一次是页表项，一次是数据/指令。
6. 为了解决两次内存访问的问题，使用了一种特殊的、小型的、快速查找的硬件高速缓存，称为翻译旁路缓冲(TLBs)或关联内存。
7. TLB的功能与内存高速缓存相似，它保存了最近使用的页表项，以加速页号到帧号的映射查找。

### TLB --Translation Look-aside Buffer

TLB是一个高速的关联存储器，它包含最近使用的页表项。每个TLB项包含两个部分：键和值(页号，帧号)。给定一个逻辑地址，处理器会同时比较所有键，如果找到匹配的键(命中)，则直接获取对应的帧号并形成物理地址；如果没有找到匹配的键(未命中)，则使用逻辑地址中的页号去索引进程的页表以获取帧号。

![](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/20231226101851.png)

当TLB未命中时(miss)，会将页表项的值加载到TLB中，以便下次更快地访问。TLB通常比较小(64到1024个条目)。需要考虑替换策略(例如LRU)。一些TLB条目可以永久性地固定下来，以便快速访问，例如关键的内核代码的条目。
一些TLB在每条目中存储地址空间标识符(ASID),ASID唯一标识每个进程，用于为该进程提供地址空间保护。ASID允许多个不同的进程同时拥有TLB条目。

### Effective Access Time (EAT)

EAT(有效访问时间)是CPU访问内存所需的时间，包括查找TLB的时间和访问内存的时间。其中查找TLB的时间取决于TLB的命中率，即找到页表项的概率。TLB的查找时间是一个常数，假设为ε nanoseconds。访问内存的时间取决于内存的周期时间，假设为θ nanoseconds。
当TLB命中时，有效访问时间EAT = ε + θ；
当TLB未命中时，有效访问时间EAT = (ε + 2θ) * (1 - α) + α * θ
其中α是TLB的命中率。
例如，如果TLB查找时间为20ns，内存周期时间为100ns, TLB命中率为0.8，则有效访问时间为：
EAT = (20 + 100) * 0.8 + 20 * 0.2 * 100 = 140ns
如果TLB查找时间为20ns，内存周期时间为100ns, TLB命中率为0.98，则有效访问时间为：
EAT = (20 + 100) * 0.98 + 20 * 0.02 * 100 = 122ns

### Memory Protection

1. 内存保护通过在每个帧(frame)上关联保护位来实现。通常这些保护位保存在页表中。
2. RW位可以定义一个页是可读写的还是只读的，还可以添加更多位来指示页是只执行的等。
3. 页表中的每个条目都带有有效位。
	1. “有效”表示对应的页在进程的逻辑地址空间内，因此是合法的页。
	2. “无效”表示对应的页不在进程的逻辑地址空间内。
	3. 也可以使用页表长度寄存器(PTLR)。
4. 任何违反都会导致陷入内核。

### Shared Pages

Shared Pages是指多个进程共享同一只读(不可变)代码的内存页。这些共享代码必须出现在所有进程的逻辑地址空间中的相同位置。这类似于多个线程共享同一个进程空间。Shared Pages也可以用于进程间通信，如果允许共享读写页的话。
而Private Pages则是指每个进程都有自己的代码和数据的独立内存页。这些私有的代码和数据页可以在逻辑地址空间的任意位置出现。

## Structure of the Page Table

### Hierarchical Paging

层次页表结构：将页表自身也进行分页，可以减少内存占用。常见的有双级页表。

![](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/20231226195032.png)
![](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/20231226195115.png)

### Hashed Page Tables

Hashed Page Tables(散列表页表)在地址空间大于32位时常见。
散列表中的每个条目包含一个链表，其中元素通过哈希函数散列到同一位置。每个元素包含三个字段：
(1)虚拟页号 
(2)对应的物理页号
(3)指向下一个元素的指针
逻辑页号通过哈希函数散列到散列表中，并与链表中元素的(1)字段进行比较查找匹配项。如果找到匹配项，则提取对应的物理页号(2)。如果没有匹配项，则继续搜索链表中的后续元素以查找匹配逻辑页号。

![](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/20231226195906.png)

### Inverted Page Tables

Inverted Page Table(反向页表)是一种内存管理的数据结构，其包含每个真实内存帧(frame)的一个条目，每个条目包含该帧的虚拟地址以及该帧所属进程的地址空间标识符(ASID)等信息。与标准页表相比，反向页表将虚拟地址空间和物理地址空间颠倒了，从而需要额外的地址空间来存储进程的地址空间信息。

![](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/20231226200504.png)

## Segmentation

分段是将程序划分为逻辑上的段（如代码段、数据段、堆段和栈段）的过程，这些段在程序的执行过程中被映射到物理内存。

程序由多个段组成，每个段是一个逻辑单元，如主程序、过程/函数/方法、公共块、对象、栈/符号表/数组、局部变量/全局变量等。
段的长度各不相同。
段内的元素通过相对于段起始地址的偏移来标识。
分段是一种支持用户对内存这种视图的内存管理方案。
每个段都有自己的名称和长度。

以下是决定程序分段的几个关键步骤：

1. **编译阶段**：
   - 在编译时，编译器将源代码转换为机器代码，并将其组织成不同的段。
   - 例如，编译器会将程序的函数和方法放入代码段，静态变量放入数据段，等等。
2. **链接阶段**：
   - 链接器将编译后的代码（和库代码）合并，形成一个完整的可执行文件。
   - 在这个过程中，链接器决定了各个段的相对位置，并创建了一个包含这些信息的段表。
3. **加载时**：
   - 当程序被加载到内存中执行时，操作系统根据可执行文件中的信息，将这些段映射到物理内存。
   - 操作系统还处理如何为这些段分配内存，以及这些段的保护和权限设置。
4. **动态链接**：
   - 对于使用动态链接库（DLLs）的程序，某些段可能在程序运行时动态加载。
   - 这种情况下，具体的段分配可能会在程序执行期间发生，而不是在程序启动时一次性完成。

### Segmentation Architecture

- 逻辑地址由段号和偏移组成，如<段号，偏移>
- 分段表将二维的用户定义地址映射为一维的物理地址，每个表项包含段基址(包含段在内存中的起始物理地址)和段限制(指定段的长度)
- 分段表基址寄存器(STBR)指向分段表在内存中的位置
- 分段表长度寄存器(STLR)表示程序使用的段数
- 如果段号s小于STLR，则段号s是合法的。

![image-20231229170935685](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/image-20231229170935685.png)

![image-20231229170949879](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/image-20231229170949879.png)

### Fragmentation

- 在分段式内存管理中，内存是根据段的大小动态分配的。每个段的大小根据程序的需求而定，并不是固定的。
- 然而，随着程序的加载和卸载，内存中会出现不连续的空闲区域。这些零散的空闲区域可能无法被有效利用，尤其是当需要分配一个大的内存段时，即使总空闲内存量足够，但由于这些空闲区域是分散的，无法满足连续内存的需求。
- 这种情况称为外部碎片。它发生在已分配内存块的外部，因此得名“外部碎片”。

## Segmentation With Paging

段页式内存管理是一种计算机内存管理技术，它结合了分段和分页两种方法。在这种方案中，地址空间被分成多个段，每个段进一步被划分为多个页。地址映射表在段页式内存管理中扮演着至关重要的角色，它负责将虚拟地址转换为物理地址。下面是段页式内存管理中地址映射的基本过程：

1. **虚拟地址结构**：在段页式管理中，虚拟地址通常包含两部分——段号和段内偏移。段内偏移进一步分为页号和页内偏移。
2. **段表**：系统为每个进程维护一个段表，段表存储每个段的信息，如段的基址、大小等。段表还包括指向页表的指针。
3. **页表**：每个段有一个页表，页表存储页的物理地址信息。页表负责将段内的虚拟页号映射到物理内存的页帧号。
4. **地址转换过程**：
    - 根据虚拟地址中的段号，访问段表，获取段的基本信息和对应的页表地址。
    - 使用虚拟地址中的页号，访问该段的页表，找到对应页的物理帧号。
    - 将物理帧号与虚拟地址中的页内偏移结合，形成最终的物理地址。

![](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/20240105205607.png)

段页存储不会产生外部碎片，因位先分段，再分页，分页后就离散化了，每个页可以分在内存的任何一个页，这个段页就成了逻辑上的概念，实质上变成了分页的管理，所以按照分页来看，是没有外部碎片的。那些理解成在一个段内再分页的同鞋，你们理解错啦！比如A页和B页逻辑上是在1号段里面，但是分页后，A页可以存在内存的任何地方B页也是，在实际的内存存放这两个页的时候，并不是先在内存化出一个段的长度出来，然后在段内分页的！
# Virtual Memory

## Background

1. 代码需要加载到内存中才能执行，但整个程序很少被全部使用到。例如错误代码、不寻常的程序、大的数据结构等只需要程序的一部分代码。
2. 整个程序代码不需要同时都在内存中。
3. 考虑执行只部分加载的程序的能力。程序不再受物理内存的限制，每个程序在运行时需要更少的内存，因此可以在相同时间内运行更多的程序。
4. 提高了CPU利用率和吞吐量，而响应时间和周转时间没有增加。
5. 加载或交换程序到内存时需要的I/O更少，每个用户程序运行得更快。

虚拟内存将用户逻辑内存与物理内存分离。其主要优点包括：
1. 只需要程序的一部分在内存中执行，逻辑地址空间可以比物理地址空间大很多。
2. 允许多个进程共享逻辑地址空间。
3. 允许更高效地创建进程。 
4. 可以并发运行更多的程序。
5. 加载或交换进程时需要的I/O更少。
6. 按需分配内存，提高内存利用率。

Virtual-address Space虚拟地址空间是进程在内存中的逻辑视图。
它从地址0开始，地址连续直到空间结束。
物理内存以页框(page frames)的形式组织。
内存管理单元(MMU)将逻辑地址映射到物理地址。
虚拟地址空间可以比物理内存大。

## Demand Paging

需求分页是在程序需要使用某页时才将其调入内存，而不是预先将整个程序加载到内存中。它通过延迟换页(Lazy swapper)来避免不必要的内存交换。需求分页由交换程序(Swapper)负责操作整个进程，而页面程序(Pager)负责操作进程中的单个页面。当程序需要某页时，会引用它，如果该页已经在内存中，则无需换页；如果该页不在内存中，则需要检测并将其调入内存。需求分页不需要改变程序的行为，也不需要程序员改变代码。它实现了按需分配内存，提高了内存利用率。

### Valid-Invalid Bit

Valid-Invalid Bit(有效无效位)是与每个页表项相关联的一个位。它表示该页表项所对应的页面是否有效且在内存中。
- 如果有效无效位是v，则表示页面有效且在内存中。
- 如果有效无效位是i，则表示页面无效或有效但不在内存中。
初始时，页表中所有页表项的有效无效位都设置为i。 
当一个页面被加载到帧中时，该帧的帧号会被写入页表项，并将有效无效位设置为v。
在地址转换过程中，如果页表项中的有效无效位是i，则表示产生缺页异常。

![image-20231227224400719](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/image-20231227224400719.png)



### Steps in Handling a Page Fault

1. 如果程序访问一个未在内存中的页面，首先会产生一个页面错误中断。
2. 操作系统会查看一个内部表格(一般指页表，与进程控制块PCB一起保存)来决定如何处理：
	- 如果是无效的访问，则中止进程。
	- 如果访问有效但页面不在内存中，则将页面调入内存。
3. 找到一个空闲的帧(frame)。
4. 通过计划磁盘操作将页面读入帧中。 
5. 重置页面表，将帧号写入页面表项，设置验证位"v"。
6. 重新启动导致页面错误的指令。

 ### Aspects of Demand Paging

- 纯按需分页是一种极端情况，在进程启动时，内存中没有任何页面。操作系统会将指令指针设置为进程的第一个指令，由于页面不在内存中，会导致缺页异常。
- 对于每个进程，在第一次访问时也会发生页面错误。
- 实际上，一个指令可能需要访问多个页面，所以会导致多次页面错误。例如，取指令和译码指令从内存中取出两个数字并存储结果，会访问4个页面，导致4次页面错误。但由于参考的局部性，这种痛苦程度会减小。
- 按需分页需要硬件支持，包括带有有效位无效位的页表和用于交换的二级存储(交换设备)。
- 在缺页异常时，需要重置指令指针，重新启动进程。

### Stages in Demand Paging (worse case)

 需求页面的最坏情况下的步骤如下：
1. 中断到操作系统。
2. 保存用户寄存器和进程状态。 
3. 确定中断是一个页面故障。
4. 检查页面引用是否合法，并确定页面在磁盘上的位置。
5. 从磁盘向一个空闲帧发出读取请求：
    ① 在此设备队列中等待读取请求得到服务。
    ② 等待设备查找和/或延迟时间。
    ③ 开始将页面传输到空闲帧。
6. 在等待期间，将CPU分配给其他用户。
7. 从磁盘输入/输出子系统接收中断(I/O完成)。
8. 保存其他用户的寄存器和进程状态。
9. 确定中断来自磁盘。
10. 修改页表和其他表，以显示页面现在在内存中。
11. 准备好，等待CPU再次分配给此进程。
12. 恢复用户寄存器，进程状态和新页表，然后继续中断的指令。

### Performance of Demand Paging

有效访问时间EAT=(1-p)×memory access time+p×page fault service time

## Copy-on-write

COW(Copy-on-Write)允许父进程和子进程在内存中共享相同的页面。只有当一个进程修改共享页面时，才会进行页面复制。这可以更高效地进行进程创建，因为只需要复制修改过的页面。只需要标记可以修改的页面为COW即可。

空闲页面通常从一个空闲页面池中分配。池中应该总是有空的页面帧，以便快速执行按需页面替换。在分配页面之前，通常会使用零填充技术，将页面清零，擦除其之前的内容。
`vfork()`不使用写时复制技术。它通过挂起父进程并让子进程使用父进程的地址空间来实现高效的进程创建。
如果子进程修改了父进程的地址空间中的任何页面，这些修改在父进程恢复时将可见。
`vfork()`的设计是让子进程立即调用`exec()`函数。它是一种非常高效的进程创建方法，有时用于实现UNIX命令行shell接口。

## Page Replacement

1. 页面替换是因为进程页面和内核/I/O缓冲区等都需要使用内存空间。
2. 需要决定为进程页面、内核和I/O缓冲区等分配多少内存空间。
3. 可以为I/O缓冲区预留一个固定的内存百分比。也可以让用户进程和I/O子系统竞争使用全部内存。
4. 如果内存中没有空闲页面，可以终止用户进程、交换进程或者进行页面替换。
5. 页面替换可以提高内存利用率，让更多进程并发执行，对用户透明。

### Basic Page Replacement

基本页面替换算法包括以下步骤：
1. 在磁盘上查找所需页面的位置。
2. 找到一个空闲页面帧：
    - 如果有一个空闲页面帧，就使用它。
    - 如果没有空闲页面帧，使用页面替换算法选择一个牺牲页面帧。
    - 将牺牲页面帧写入磁盘，如果脏页面，还需要更改页面和页面帧表。
3. 将所需页面读入到刚释放的页面帧中。
4. 更新页面和页面帧表。
5. 通过重新启动引起中断的指令，继续执行进程。
6. 现在可能需要2次页面传输(1次出栈和1次进栈)，增加了有效访问时间。

当发生页面替换，例如将内存中的 `page0` 替换为 `page1` 时，操作系统需要执行以下步骤来更新页表和内存：

1. **选择替换页面**：首先，操作系统使用页面置换算法（如 LRU、FIFO、时钟算法等）来选择一个要被替换出内存的页面。假设 `page0` 被选中。
2. **检查替换页面的状态**：
   - 如果 `page0` 被修改过（脏页面），操作系统需要将它的内容写回到辅助存储（如硬盘）。这确保了修改被保存，以便将来再次访问时可以从辅助存储中重新加载。
   - 如果 `page0` 未被修改（干净页面），可以直接将其从内存中移除，因为辅助存储上已有其最新副本。
3. **更新页表**：
   - 修改 `page0` 对应的页表项，将其有效-无效位设置为无效（i）。这表明 `page0` 不再位于物理内存中。
   - 为 `page1` 创建或更新相应的页表项，包括指向新分配的物理帧的帧号，并将其有效-无效位设置为有效（v）。
4. **将新页面调入内存**：
   - 将 `page1` 从辅助存储读取到刚刚释放的帧中。这个过程可能涉及到磁盘的I/O操作。
5. **重置访问控制信息**：对于新调入内存的 `page1`，可能需要重置或更新与其相关的访问控制信息，如使用频率、最近访问时间等，这些信息常用于页面置换算法。
6. **重新执行指令**：最后，操作系统将控制权返回给导致缺页异常的程序，允许它重试原本失败的内存访问操作。由于 `page1` 现在已经在内存中，该操作应能够成功执行。

整个过程中，操作系统确保了内存中的数据与辅助存储之间的一致性，并通过页表项的更新保持了虚拟地址到物理地址映射的准确性。这样，进程就可以无缝地继续运行，即使其内存页面发生了替换。

使用修改位(dirty bit)可以减少页面传输的开销。修改位用于表示页面自从上次加载到内存后是否被修改过。只有修改过的页面才会被写入磁盘。页面替换完成了逻辑内存和物理内存的分离。大容量的虚拟内存可以在较小的物理内存上提供。如果没有按需页面替换，一个进程的所有页面仍然必须驻留在物理内存中。

帧分配算法决定了每个进程应该获得多少帧以及当发生缺页时应该替换哪些帧。页面替换算法希望在首次访问和再次访问时都能获得最低的缺页率，被替换的页面应该是未来最不可能被引用的页面。页面替换算法旨在获得页面故障的最小数量。评估页面替换算法的方法是，在特定的内存引用序列上运行算法，并计算该序列上的页面故障数量。

### reference strings

### FIFO (First-In-First-Out) Algorithm

先进先出

<img src="https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/image-20231229101441346.png" alt="image-20231229101441346" style="zoom:50%;" />

Belady’s anomaly证明了在使用先入先出(FIFO)页面替换算法时，增加页面帧数量反而可能导致更多缺页中断。例如，对于参考字符串3,2,1,0,3,2,4,3,2,1,0,4,3槽，总共获得9次缺页中断，但如果增加槽数到4，则总共获得10次缺页中断。

### Optimal Algorithm

替换将来最长时间没被使用的。

![image-20231229101740235](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/image-20231229101740235.png)

### Least Recently Used Algorithm

选择最长时间未被访问的页面进行替换。

![image-20231229102706588](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/image-20231229102706588.png)

### LRU implementation

 LRU(Least Recently Used)页面置换算法的实现需要硬件支持，主要问题是确定各个页面最后一次被使用的顺序。每个页面都包含一个计数器和时间使用字段，CPU需要增加一个逻辑时钟或计数器，每次内存访问时都会增加该计数器的值。每次访问页面时，会将计数器的值复制到页表中该页面的时间使用字段。当需要替换页面时，会查看各个计数器的值，选择具有最小时间值的页面进行替换。

页面置换算法的实现可以使用栈来维护一个页面号码的双链表。当页面被引用时，将其移动到栈顶；不需要搜索替换页面，LRU页面总是在栈底。

![image-20231229104419308](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/image-20231229104419308.png)

### LRU Approximation Algorithms

LRU 需要特殊硬件并且仍然缓慢。

- 为每个页面条目关联一个比特，初始设置为0。
- 当页面被引用时，由硬件将该比特置为1。
- 替换值为0的页面条目(如果存在的话)。
- 问题：我们不知道页面的顺序。

- 每个页面在内存中的表中关联一个8位的字节。
- 在定期的定时器中断中，操作系统将每个页面的引用位移入8位字节的最高位，将其他位右移1位并丢弃最低位。
- 每个8位字节包含过去8个时间段中页面使用的状态。
- 数值最低的页面是LRU页面，可以被替换。

 Second chance 算法是一个FIFO页面置换算法的变种，它需要额外的参考位(reference bit)来跟踪每个页面的最近访问时间。当需要替换一个页面时，如果该页面最近被访问过(参考位为1)，则不替换该页面，而是将下一个页面(按时钟顺序)替换出去。这样可以减少页面替换的次数，提高效率。

 Enhanced Second-Chance算法考虑了参考位和修改位，将每个页面分为四个类别：
- (0,0) 既未被最近访问也未被修改的页面，是最理想的替换对象。
- (0,1) 未被最近访问但已被修改的页面，在替换前需要先写回磁盘。 
- (1,0) 最近被访问但内容未被修改的页面，很可能很快会被再次访问。
- (1,1) 最近被访问且内容已被修改的页面，在替换前需要先写回磁盘。
根据页面所属类别，从最低的非空类别中遇到的第一个页面开始替换。可能需要多次搜索环形队列。

 Counting-based page replacement 算法通过为每个页面维护一个引用计数器来统计页面被访问的次数。
LFU (Least Frequently Used) 算法根据计数器的值选择引用次数最少的页面进行替换。
MFU (Most Frequently Used) 算法则选择引用次数最多的页面进行替换，认为引用次数最多的页面最有可能正在被使用。
这两种算法都不太常见，因为它们需要为每个页面维护引用计数器，增加了实现的复杂性。

### Page-Buffering Algorithm

该算法维护一个空闲帧的池子。当发生页面错误时，先选择一个受害帧，然后在受害帧被写出之前，将所需页面读入池中的一个空闲帧。当受害帧稍后被写出时，其帧被添加到空闲帧池中。可能还会维护一个被修改页面的列表。每当分页设备空闲时，选择一个被修改的页面并将其写入磁盘，然后重置其修改位。还可能保持一个空闲帧的池子，但要记住每个帧中有哪个页面。如果在该帧被重用之前需要旧页面，可以直接从空闲帧池中重用该页面。

## Allocation of Frames

操作系统中每个进程需要的最小页面数。

这个需求根据进程使用的指令类型和内存寻址方式而变化。例如，仅使用单一内存地址指令的进程至少需要两个帧，而允许一级间接寻址的进程至少需要三个帧。特定指令，如PDP-11上的移动指令或IBM 370上的MVC指令，可能需要六页，因为它们复杂并可能涉及间接引用。该部分还提到了两种主要的帧分配方案：固定分配和优先级分配。这些分配方法确保了内存的有效使用，避免浪费。

### Fixed Allocation

1. **等量分配**：例如，如果有93个帧和5个进程，每个进程分配18个帧，剩余的3个帧用作空闲帧缓冲池。
2. **比例分配**：根据每个进程的大小分配可用内存。具体来说，每个进程的虚拟内存大小为si，总虚拟内存为S（所有si之和）。每个进程的分配比例（ai）是其虚拟内存大小（si）除以总虚拟内存（S），乘以总帧数（m）。每个进程的分配数（ai）调整为大于其最小帧数的整数，且总和不超过m。分配可能根据多程序级别而变化。

### Priority Allocation

使用基于优先级而非大小的比例分配方案，或者结合大小和优先级来进行分配。

这种分配是动态的，随着多程序级别和进程大小的变化而变化。

如果进程 P i 发生页面错误，选择替换它的某个帧。局部替换是从优先级较低的进程中选择替换一个帧。全局替换则是从整个系统范围内选择替换一个帧。

### Global vs. Local replacement

全局替换（Global Replacement）和局部替换（Local Replacement）是操作系统中页面替换策略的两种不同方法，它们用于决定当发生页面错误（Page Fault）时，应该从内存中移除哪个页面以便为新页面腾出空间。
1. **全局替换 (Global Replacement)**:
   - 在全局替换策略中，当某个进程需要替换页面时，它可以从整个系统的内存帧中选择一个页面进行替换。这意味着一个进程可能会取代（或“偷取”）另一个进程的内存页面。
   - 这种方法由操作系统来管理，它维护一个所有空闲帧的列表。当发生页面错误时，操作系统会从这个列表中选择一个页面来替换。
   - 优点是可以提高系统吞吐量（即整个系统的效率和性能），因为它可以更灵活地分配和管理内存资源。
   - 缺点是单个进程可能无法有效控制自己的页面错误率，因为它的页面可能被其他进程所替换。
2. **局部替换 (Local Replacement)**:
   - 局部替换策略限制页面替换仅在发生页面错误的那个进程的内存帧中进行。这意味着进程只能替换属于自己的页面。
   - 在这种策略下，每个进程的页面错误完全由该进程自己的分页行为决定，不受其他进程的影响。
   - 优点是进程对自己的内存管理有更大的控制权，可以更好地优化自己的页面错误率。
   - 缺点是可能导致整体系统吞吐量降低，因为内存资源分配可能不如全局替换那样灵活和高效。

## Thrashing

### Thrashing

Thrashing(过度换页)是指当一个进程没有足够数量的页面时，页面故障率非常高。每次页面故障需要获取页面，替换现有的页面，但很快需要替换回原来的页面，这会导致：
- 低CPU利用率，因为大部分时间都在进行页面替换
- 操作系统认为需要增加多进程的程度
- 向系统中添加另一个进程
当一个进程花费大部分时间在页面替换而不是执行时，就说明该进程处于过度换页状态。要避免过度换页，必须为进程分配足够数量的页面。

thrashing的发生是因为：
- 进程的局部性大小(locality size)大于总内存大小(total memory size)。
- 使用了局部(或优先级)页面替换算法，这可以限制抖动的影响。
  为了防止抖动，必须为进程提供它需要的所有页面。

如何知道进程需要多少页面？
- 通过查看进程实际上使用的页面数量来确定。

进程执行的局部性模型是：
- 局部性：一组正在一起使用的页面。
- 进程从一个局部性迁移到另一个局部性。
- 局部性可能重叠。

### Working-Set Model

1. **工作集窗口大小Δ**: 这是衡量工作集大小的一个关键参数，表示在一定数量的页面引用中考虑的页面集合。例如，如果Δ是10,000，那么工作集包括最近10,000个页面引用。
2. **工作集（Working Set）**: 它是在最近Δ个页面引用中出现的那些页面的集合。这反映了一个进程在最近一段时间内的内存使用情况。
3. **WSSi（进程Pi的工作集大小）**: 这是指在特定时刻进程Pi的工作集中页面的数量。这个数字随时间变化，因为进程的内存需求可能会增加或减少。
4. **工作集大小的准确性与Δ的选择有关**: 如果Δ设置得太小，可能无法准确反映进程的内存需求；如果设置得太大，可能会过度估计所需的内存。理想的Δ值应该能够合理反映进程的实际内存使用模式。
5. **总工作集大小D**: 它是所有进程工作集大小的总和，用于近似表示程序的局部性（即内存访问的局限性）。如果D超过了系统中可用的内存帧数量m，可能会导致频繁的页面调度和内存抖动，就需要挂起一个进程。难点在于持续跟踪工作集。
6. **跟踪工作集的方法**：通过定期中断和维护页面访问位来跟踪工作集。这种方法有助于识别哪些页面属于当前的工作集，但可能无法精确反映快速变化的工作集。
	1. 使用定时器定期中断，例如每隔5000时间单位中断一次。
	2. 为每个页面维护两个内存位，一个用于记录页面最近一次被访问的时间，一个用于记录页面是否在工作集中。
	3. 在定时器中断时，将所有页面的访问时间位清零，并将工作集中的页面的访问时间位置1。
	4. 根据页面访问时间位判断页面是否在工作集中。
7. **改进方法**: 通过增加历史位数量和提高定时器中断频率，可以更准确地跟踪页面的工作集。这有助于操作系统更有效地管理内存，减少页面错误和提高系统性能。

### Page-Fault Frequency Scheme

Page-Fault Frequency Scheme是一种更直接的工作集模型替代方法。
它通过建立一个可接受的页面故障率，并使用局部替换策略来控制页面故障频率。如果实际的页面故障率过低，进程会丢失一个页面框；如果实际的页面故障率过高，进程会增加一个页面框。选择一个进程，将其交换到外部存储设备。

## Memory-mapped file

Memory-mapped files(内存映射文件)通过将磁盘块映射到内存页中来简化并加速文件访问。文件初始化时使用按需调页，将文件系统中的一个页大小的文件块装入物理帧。后续的读写操作都被视为普通的内存访问。当数据被写入内存时，会在页缓存扫描脏页时或者文件关闭时才写入磁盘。

一些操作系统(例如Solaris)选择通过特定的系统调用(如mmap())将文件映射到内存，而一些操作系统则通过特定的系统调用(如mmap())将文件映射到内核地址空间。这使得进程可以像访问内存一样访问文件，而不需要通过标准的I/O操作(open(), read(), write(), close())。这种方式利用了高效的内存管理子系统。

Memory-mapped files允许多个进程同时映射同一个文件，从而在内存中共享该文件的页面。

COW(Copy-on-Write)可以用于读/写非共享页面。它允许进程以只读模式共享文件，但每个进程都可以对其修改的数据保留自己的副本。
内存映射文件可以用于共享内存。

<img src="https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/image-20231229153649258.png" alt="image-20231229153649258" style="zoom: 50%;" />

Memory-mapped I/O是将内存地址映射到设备寄存器，通过读写这些内存地址来在CPU和设备之间传输数据。这种方式适用于响应时间较快的设备，如视频控制器。它也可以用于其他设备，如串口和并口，用于连接调制解调器和打印机到计算机。通过这种方式，CPU通过读写几个设备寄存器(I/O端口)来与这些设备进行数据传输。

## Allocating Kernel Memory

内核内存与用户内存不同，它通常从一个不同的空闲内存池中分配，而不是和普通用户模式进程使用的内存池相同。原因有两点：
- 内核请求不同大小的数据结构内存，有些小于一个页面的大小。
- 一些内核内存需要是连续的，例如用于设备I/O。某些硬件设备需要直接与物理内存交互，可能需要连续的内存页面。

内核内存分配使用Buddy System伙伴系统和Slab allocation两种方式。

### Buddy System

伙伴系统(Buddy System)将内存从一个固定大小的内存段中分配，该内存段由物理上连续的页面组成。 伙伴系统使用2的幂次方大小的分配器。 内存以2的幂次方大小的单元分配。 请求大小向上取2的下一个最高幂次方。 整个可用的内存空间被看作是一个大小为2U的单一块。 如果请求大小在2U-1和2U之间，则整个块被分配。 否则，块被分成两个大小相等的伙伴块。 进程继续，直到生成一个最小大小为s的块。

### Slab Allocation

1. 将物理内存划分为固定大小的内存块，称为slab。
2. 将多个slab组成一个缓存(cache)。
3. 为每个内核数据结构(如进程控制块PCB)创建一个单独的缓存。
4. 在创建缓存时，先将缓存填充一些初始化的空对象。
5. 当需要使用该内核数据结构时，从缓存中分配一个对象(实例)并标记为已使用。
6. 当缓存中的对象都标记为已使用时，需要分配新的slab来扩展缓存。
7. 该分配方式可以避免内存碎片，同时可以快速地满足内存请求。

## Other considerations

### Prepaging

Prepaging是为了减少进程启动或者换出进程重新启动时产生的大量缺页中断。它通过提前将进程需要的页面加载到内存中来实现。如果预加载的页面没有被使用，就会浪费I/O和内存资源。预加载页面有一定的优势，需要比较使用预加载页面的成本和处理相应缺页中断的成本，来判断是否使用预加载页面。例如，如果预加载S个页面，实际上只使用了S*a个页面(0<a<1)，那么预加载S个页面的成本是否小于处理S*(1-a)个不必要的缺页中断的成本。如果a接近1，预加载就更有优势。

### Page Size

1. 页面表的大小：每个活跃进程都需要一个自己的页面表副本，所以较大的页面大小是可取的。
2. 碎片化：为了最小化内部碎片化，需要较小的页面大小。 
3. I/O开销：I/O时间主要由搜索时间和延迟时间组成，而传输时间通常较小。为了最小化I/O时间，需要较大的页面大小。
4. 局部性：较小的页面大小可以改善局部性，减少总的I/O。但是为了最小化页面错误，需要较大的页面大小。
5. 页面大小通常在4KB到4MB之间选择。
所以页面大小需要在减小碎片化和I/O开销与提高局部性和减少页面错误之间做权衡。

### TLB Reach

TLB Reach指的是从TLB(Translation Lookaside Buffer)可以访问的内存范围。
TLB Reach = (TLB Size) x (Page Size)
理想情况下，每个进程的工作集应该存储在TLB中。否则，页面错误率会很高，进程会在页表中花费大量时间而不是TLB中解析内存引用。
增加TLB Reach的方法包括：
- 增加Page Size，但这可能会导致碎片化增加，因为不是所有应用程序都需要大Page Size。
- 提供多种Page Size，这可以让需要大Page Size的应用程序使用它们，而不会增加碎片化。

### Inverted Page Tables

Inverted Page Tables的目的是减少跟踪虚拟到物理地址转换所需的物理内存。它使用一个表项来跟踪每个物理帧中的虚拟内存页，表项由进程ID和页面号索引。当发生页面错误时，还需要其他信息，例如每个虚拟页的位置和页面数量。必须为每个进程保留一个外部页面表，根据需要进行页面换入和换出。页面错误现在可能需要生成另一个页面错误来换入需要的页面表。

### Program Structure

仔细选择数据结构和编程结构可以提高局部性，从而降低缺页错误率和工作集中的页面数量。例如，栈具有很好的局部性，因为访问总是从栈顶开始。而散列表则设计成散布引用，产生较差的局部性。编译器和加载器对页面管理有很大影响。将代码和数据分离并生成可重入代码意味着代码页可以只读，永远不会被修改。加载器可以避免将程序段放在跨页面边界位置。经常相互调用的程序段可以打包到同一页面中。

### I/O interlock

1. **考虑挂起的I/O操作**：
   - 用于设备I/O的内存页必须被锁定，防止被页面替换算法选中用于淘汰。
   - 不允许直接对用户内存执行I/O操作。
   - 数据在系统内存和用户内存之间进行复制。
   - I/O操作只在系统内存和I/O设备之间进行。

2. **允许将页面锁定到内存中**：
   - 每个帧都关联一个锁定位。
   - 被锁定的页面不能被替换。
   - 当I/O完成后，页面解锁。

3. **页面固定来锁定到内存中**：
   - 操作系统内核的部分或全部被锁定在内存中。
   - 用户进程可能需要将页面锁定到内存中。
   - 考虑到具有需求分页、优先级调度和全局替换的系统：
     - 低优先级进程L发生缺页。
     - 操作系统选择一个替换帧，并调入所需页面。
     - 然后，L进入就绪队列，可能长时间不被选中。
     - 当L等待时，高优先级进程H发生缺页。
     - 寻找替换页面时，可能是L刚调入的页面—它是干净的，且长时间未使用。

4. **使用锁定位来防止新调入页面的替换**，直到至少被使用一次：
   - 当页面被选为替换对象时，其锁定位被打开。
   - 锁定保持到引起缺页的进程再次被调度。

5. **大多数操作系统都提供系统调用**，允许应用请求将其逻辑地址空间的一部分固定。

6. **危险性**：锁定位可能被打开但永远不关闭。
   - 被锁定的帧变得无法使用。



