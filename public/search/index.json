[{"content":"概述 概念 计算机网络和分布式系统 计算机网络 (Computer Networks)：由==自主计算机互联起来的集合体== (a group of interconnected computers)，与主从计算的的区别，每台计算机都有独立的操作系统，不从属某台主机。\n分布式系统 (Distributed System)：对用户看起来是一个==单独系统==的计算机集合。存在着一个能为用户自动管理资源的网络操作系统。\n关系：计算机网络是分布式系统的技术基础，而分布式系统是计算机网发展的高级阶段。www是原型在Internet 的分布式系统。\n组成 从组成部分看 一个完整的计算机网络主要由==硬件、软件、协议==三大部分组成，缺一不可。 ==硬件==主要由主机（也称端系统）、通信链路（如双绞线、光纤）、交换设备（如路由器、交换机等）和通信处理机（如网卡）等组成。 ==软件==主要包括各种实现资源共享的软件和方便用户使用的各种工具软件（如网络操作系统、邮件收发程序、 FTP 程序、聊天程序等）。软件部分多属千应用层。 ==协议==是计算机网络的核心，如同交通规则制约汽车 驾驶一样，协议规定了网络传输数据时所遵循的规范。\n从工作方式上看 计算机网络（这里主要指 Internet,即因特网）可分为==边缘部分和核心部分==。 ==边缘部分==由所有连接到因特网上、供用户直接使用的主机组成，用来进行通信（如 传输数据、音频或视频）和资源共享； ==核心部分==由大量的网络和连接这些网络的路由器组成，它为边缘部分提供连通性和交换服务。图I. I 给出了这两部分的示意图。\n从功能组成上 计算机网络由==通信子网和资源子网==组成。 ==通信子网==由各种传输介质、 通信设备和相应的网络协议组成，它使网络具有数据传输、交换、控制和存储的能力， 实现联网计算机之间的数据通信。 ==资源子网==是实现资源共享功能的设备及其软件的集合， 向网络用户提供共享其他计算机上的硬件资源、软件资源和数据资源的服务。\n功能 ==数据通信==是计算机网络最基本和最重要的功能，用来实现联网计算机之间各种信息的传输，并将分散在不同地理位置的计算机联系起来，进行统一的调配、控制和管理。例如，文件传输、电子邮件等应用，离开了计算机网络将无法实现。 ==资源共享==可以是软件共享、数据共享，也可以是硬件共享。它使计算机网络中的资源互通有无、分工协作，从而极大地提高硬件资源、软件资源和数据资源的利用率。 ==分布式存储==：当计算机网络中的某个计算机系统负荷过重时，可以将其处理的某个复杂任务分配给网络中的其他计算机系统，从而利用空闲计算机资源以提高整个系统的利用率。 ==提高可靠性==：计算机网络中的各台计算机可以通过网络互为替代机。 ==负载均衡==：将工作任务均衡地分配给计算机网络中的各台计算机。 分类 按分布范固分类 广域网 (WAN) 。 广域网的任务是==提供长距离通信==，运送主机所发送的数据，其覆盖范围通常是直径为几十千米到几于千米的区域，因而有时也称远程网。广域网是因特网的核心部分。连接广域网的各结点交换机的链路一般都是==高速链路==，具有较大的==通信容址==。 城域网(MAN) 。 城域网的覆盖范围可以跨越几个街区甚至整个城市，覆盖区域的直径范围是 5~50km。城域网大多采用==以太网==技术，因此有时也常并入局域网的范围讨论。 局域网 (LAN) 。 局域网一般用微机或工作站通过高速线路相连，覆盖范围==较小==，通常是直径为几十米到几千米的区域。局域网在计算机配置的数量上没有太多的限制，少的可以只有两台，多的可达几百台。传统上，局域网使用==广播==技术，而广域网使用==交换==技术。 个人区域网 (PAN) 。 个人区域网是指在个人工作的地方将消费电子设备（如平板电脑、 智能手机等）用无线技术连接起来的网络，也常称为无线个人区域网 (WPAN），覆盖区域的直径约为 10m。 按传输技术分类 广播式网络。 所有联网计算机都共享==一个公共通信信道==。当一台计算机利用共享通信信道发送报文分组时，所有其他的计算机都会“收听”到这个分组。接收到该分组的计算机将通过检查目的地址来决定是否接收该分组。 ==局域网==基本上都采用广播式通信技术，广域网中的无线、卫星通信网络也采用广播式通信技术。 点对点网络。 ==每条物理线路连接一对计算机==。 若通信的两台主机之间没有直接连接的线路，则它们之间的分组传输就要通过中间结点进行接收、存储和转发，直至目的结点。 按拓扑结构分类 网络拓扑结构是指由网中结点（路由器、主机等）与通信线路（网线）之间的几何关系（如 总线形、环形）表示的网络结构，主要指通信子网的拓扑结构。 按网络的拓扑结构，主要分为总线形、星形、环形和网状网络等。#card 总线形网络。用单根传输线把计算机连接起来。总线形网络的优点是建网容易、增／减结点方便、节省线路。缺点是重负载时通信效率不高、总线任意一处对故障敏感。 星型网络。每个终端或计算机都以单独的线路与中央设备相连。中央设备早期是计算机，现在一般是交换机或路由器。星形网络便于集中控制和管理，因为端用户之间的通信必须经过中央设备。缺点是成本高、中央设备对故障敏感。 环形网络。所有计算机接口设备连接成一个环。环形网络最典型的例子是令牌环局域网。环可以是单环，也可以是双环，环中信号是单向传输的。 网状网络。一般情况下，每个结点至少有两条路径与其他结点相连，多用在广域网中。 星形、总线形和环形网络多用于局域网，网状网络多用于广域网。\n按交换技术分类 交换技术是指各台主机之间、各通信设备之间或主机与通信设备之间为交换信息所采用的数 据格式和交换装置的方式。按交换技术可将网络分为如下几种。\n电路交换网络。==在源结点和目的结点之间建立一条专用的通路用于传送数据，包括建立连接、传输数据和断开连接三个阶段。==最典型的电路交换网是传统电话网络。该类网络的主要特点是整个报文的比特流连续地从源点直达终点，好像是在一条管道中传 送。优点是数据直接传送、时延小。缺点是线路利用率低、不能充分利用线路容盘、不便于进行差错控制。 报文交换网络。用户数据加上源地址、目的地址、校验码等辅助信息，然后封装成报文。整个报文传送到相邻结点，全部存储后，再转发给下一个结点，重复这一过程直到到达目的结点。每个报文可以单独选择到达目的结点的路径。报文交换网络也称==存储－转发网==络，主要特点是==整个报文先传送到相邻结点，全部存储后查找转发表，转发到下一个结点。==优点是可以较为充分地利用线路容量，可以实现不同链路之间不同数据传输速率的转换，可以实现格式转换，可以实现一对多、多对一的访问，可以实现差错控制。缺点是增大了资源开销（如辅助信息导致处理时间和存储资源的开销），增加了缓冲时延，需要额外的控制机制来保证多个报文的顺序不乱序，缓冲区 难以管理（因为报文的大小不确定，接收方在接收到报文之前不能预知报文的大小）。 分组交换网络，也称包交换网络。其原理是，将数据分成较短的固定长度的数据块，在每个数据块中加上目的地址、源地址等辅助信息组成分组（包），以存储－转发方式传输。 其主要特点是==单个分组（它只是整个报文的一部分）传送到相邻结点，存储后查找转发表，转发到下一个结点。==除具备报文交换网络的优点外，分组交换网络还具有自身的优点：缓冲易于管理；包的平均时延更小，网络占用的平均缓冲区更少；更易于标准化； 更适合应用。现在的主流网络基本上都可视为分组交换网络。\n性能指标 带宽(Bandwidth)。本来表示通信线路允许通过的信号频带范围，单位是赫兹(Hz) 。而 在计算机网络中，带宽表示==网络的通信线路所能传送数据的能力==，是数字信道所能传送 的“最高数据传输速率”的同义语，单位是比特／秒 (bis) 。 时延(Delay)。指数据（一个报文或分组）从网络（或链路）的一端传送到另一端所需要的总时间，它由 4 部分构成：==发送时延、传播时延、处理时延和排队时延==。 发送时延。结点将分组的所有比特推向（传输）链路所需的时间，即从发送分组的第一个比特算起，到该分组的最后一个比特发送完毕所需的时间，因此也称传输时延。计算公式为==发送时延＝分组长度／信道宽度== 传播时延。电磁波在信道中传播一定的距离需要花费的时间，即一个比特从链路的一端传播到另一端所用的时间。计算公式为==传播时延＝信道长度／电磁波在信道上的传播速率== 处理时延。数据==在交换结点为存储转发而进行的工作==所花费的时间。例如，分析分组的首部、从分组中提取数据部分、进行差错检验或查找适当的路由等。 排队时延。分组在进入路由器后要先在输入队列中排队等待处理。路由器确定转发端口后，还要在输出队列中排队等待转发，这就产生了排队时延。 时延带宽积。指发送端发送的第一个比特即将到达终点时，发送端已经发出了多少个比特，因此又称以比特为单位的链路长度，即==时延带宽积＝传播时延×信道带宽==。 考虑一个代表链路的圆柱形管道，其长度表示链路的传播时延，横截面积表示链路带宽，则时延带宽积表示该管道可以容纳的比特数量。 往返时延 (Round-Trip Time, RTT) 。指==从发送端发出一个短分组，到发送端收到来自接收端的确认（接收端收到数据后立即发送确认），总共经历的时延。==在互联网中，往返时延还包括各中间结点的处理时延、排队时延及转发数据时的发送时延。 吞吐量(Throughput)。指==单位时间内通过某个网络（或信道、接口）的数据量==。吞吐量受网络带宽或网络额定速率的限制。 速率 (Speed) 。网络中的速率是指连接到计算机网络上的主机在数字信道上传送数据的速率，也称==数据传送速率、数据率或比特率==，单位为 b/s （比特／秒） （或 bit/s, 有时也写为bps) 。数据率较高时，可用 kb/s (k= 10^3) 、 Mb/s (M= 10^6) 或 Gb/s (G= 10^9) 表示。 在计算机网络中，通常把最高数据传输速率称为带宽。 信道利用率。指出某一信道有百分之多少的时间是有数据通过的，即==信道利用率＝有数据通过时间／（有＋无）数据通过时间==。 计算机网络体系结构和参考模型 计算机网络分层结构 计算机网络协议、接口、服务的概念 ISO/OSI 参考模型和 TCP/IP模型 ","date":"2024-01-18T17:06:34Z","permalink":"https://www.xxx.blog/post/1-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/","title":"1 计算机网络体系结构"},{"content":"2 线性表 线性表 四个特征 唯一的第一个元素\n唯一的最后元素\n除了最后元素之外，其他元素有唯一的后继\n除了第一元素之外，其他元素有唯一的前驱\n线性表定义 线性表是最简单、最基本、也是最常用的线性结构\n具有相同数据类型的n(n\u0026gt;=0)个数据元素的有限序列，通常记为：$ (a_1,a_2,… ,a_{i-1},a_i,a_{i+1},…a_n)$\n其中n为表长， n＝0 时称为空表。线性表元素序号从1开始。\n线性表基本操作 (1) 线性表初始化：InitList(\u0026amp;L)\n(2) 销毁线性表：DestroyList(\u0026amp;L)\n(3) 将线性表置空：ClearList(\u0026amp;L)\n(4) 判断线性表是否为空：ListEmpty(L)\n(5) 求线性表的长度：ListLength (L)\n(6) 取表元：GetElem(L,i,\u0026amp;e)\n(7)按值查找：LocateElem(L,e,compare())\n返回满足条件的数据元素的位序，如果不存在返回0\n(8)前驱：PriorElem(L,cur_e, \u0026amp;pre_e)\n(9)后继：NextElem(L,cur_e,\u0026amp;next_e)\n(10)插入操作：ListInsert (\u0026amp;L,i,e)\n(11) 删除操作：ListDelete (\u0026amp;L,i,\u0026amp;e)\n(12) 遍历操作：ListTraverse (L,visit())\n依次对L的每个数据元素调用函数visit()\n线性表的顺序存储（顺序表） “用一组地址连续的存储单元依次存放线性表中的数据元素”，即以“存储位置相邻”表示“位序相继的两个数据元素之间的前驱和后继的关系(有序对\u0026lt; ai-1,ai \u0026gt;)”，并以表中第一个元素的存储位置作为线性表的起始地址，称作线性表的基地址。\n线性表的存储类型描述 静态分配：\n#define MaxSize 50 typedef struct{ ElemType data[MaxSize]; int length; }SqList; 动态分配：\n#define LIST_INIT_SIZE 50 typedef struct{ ElemType *elem; // 存储空间基址 int length; // 当前长度 int listsize; // 允许的最大存储容量 }SqList;　// 俗称 顺序表 初始化操作 // 构造一个空的线性表 L bool InitList_Sq(SqList \u0026amp;L){ L.elem = (ElemType*)malloc(LIST_INIT_SIZE*sizeof(ElemType)); if (!L.elem) exit(OVERFLOW);　// 存储分配失败 L.length = 0;　// 顺序表的初始长度为0 L.listsize = LIST_INIT_SIZE; // 初始存储容量 return OK; } // InitList_Sq 此算法的时间复杂度为O (1)。\n取表元操作 取线性表中的第i个元素即L.elem[i-1]存到e中，1\u0026lt;=i\u0026lt;=L.length\nbool GetElem_Sq(L, i, \u0026amp;e) { if (i \u0026lt; 1 || i \u0026gt; L.length) return ERROR; // i值不合法 e = L.elem[i - 1]; return OK; } 插入元素操作 把e放到第pos位（1\u0026lt;=pos\u0026lt;=L.length+1），先判断pos是否合法，若合法，将后面元素后移，再插入。\nbool ListInsert_Sq(SqList \u0026amp;L, int pos, ElemType e){ if (pos \u0026lt; 1 || pos \u0026gt; L.length + 1) return ERROR; // 插入位置不合法 if (L.length \u0026gt;= L.listsize) return ERROR; // 当前存储空间已满，无法插入 for (j = L.length; j \u0026gt;= pos; j--){ // 从最后一个到插入位置 L.elem[j] = L.elem[j - 1]; } // 插入位置及之后元素右移 L.elem[pos - 1] = e; // 插入 e L.length++; // 表长增1 return TRUE; } // ListInsert 最好情况：在表尾插入，O(1)\n最坏情况：在表头插入，O(n)\n平均情况：O(n)\n优化：\nbool ListInsert_Sq(SqList \u0026amp;L, int pos, ElemType e){ if (pos \u0026lt; 1 || pos \u0026gt; L.length + 1) return ERROR; // 插入位置不合法　if (L.length \u0026gt;= L.listsize) return ERROR; // 当前存储空间已满，无法插入 q = \u0026amp;(L.elem[pos - 1]); // q为插入位置 for (p = \u0026amp;(L.elem[L.length - 1]); p \u0026gt;= q; --p){ *(p + 1) = *p; } // 插入位置及之后元素右移 L.elem[pos - 1] = e; // 插入 e L.length++; // 表长增1 return TRUE; } // ListInsert 本算法中注意以下问题：\n① 顺序表中数据区域有MAXSIZE个存储单元，所以在向顺序表中做插入时先检查表空间是否满了，在表满的情况下除非扩展空间否则不能再做插入。\n② 要检验插入位置的有效性，这里 pos 的有效范围是：1≤pos≤n+1，其中 n 为原表长。\n③ 注意数据的移动方向。\n④ 表长的修改。\n删除元素操作 bool ListDelete_Sq(SqList \u0026amp;L, int pos, ElemType \u0026amp;e){ if(pos \u0026lt; 1 || pos \u0026gt; L.length) return FALSE ; // 删除位置不合法 e = L.elem[pos-1]; for(j = pos; j\u0026lt;L.length; j++) {//从pos后面一个开始一直到最后 L.elem[j-1] = L.elem[j]; } // 被删除元素之后的元素左移 L.length--; // 表长减1 return TRUE; } // ListDelete 本算法中注意以下问题：\n① 删除第i个元素，i的取值为 1≤i≤n ,否则第i个元素不存在，因此，要检查删除位置的有效性。\n② 当表空时不能做删除，因表空时 L.length的值为0，条件（i\u0026lt;1||i\u0026gt;L.length）也包括了对表空的检查。\n③ 删除ai 之后，该数据已不存在，如果需要，先取出，再做删除。\n④ 修改表长。\n最好情况：删除表尾元素O(1)\n最坏情况：删除表头元素O(n)\n平均情况：O(n)\n元素定位操作 在顺序表L中查找第1个值与 e 满足相等条件的元素，若找到，则返回其在 L 中的位序，否则返回0。\nint LocateElem_Sq(SqList L, ElemType e){ i = 1;　// i 的初值为第1元素的位序 p = L.elem; // p 的初值为第1元素的存储位置 while (i \u0026lt;= L.length \u0026amp;\u0026amp; !equal(*p++,e)) ++i;　// 依次进行判定 if (i \u0026lt;= L.length) return i; // 找到满足判定条件的数据元素为第 i 个元素 else return 0;　// 该线性表中不存在满足判定的数据元素 } // LocateElem 一种更通俗的解法：\nint LocateElem(SqList L,ElemType e){ int i; for(i=0;i\u0026lt;L.length;i++) if(L.data[i]==e) return i+1; return 0; } 最好情况：查找的元素就在表头O(1)\n最坏情况：查找的元素在表尾或者不存在时，O(n)\n平均情况：O(n)\n线性表的链式存储（链表） 结点定义如下：\ntypedef struct LNode{ ElemType data; struct LNode *next; }LNode，*LinkList； 通常用头指针来表示一个单链表。\n头结点和头指针的区分：\n不管带不带头结点，头指针都始终指向链表的第一个结点，而头结点是带头结点的链表中的第一个结点，结点内通常不存储信息。\n引入头结点后，可以带来两个优点:\n由于第一个数据结点的位置被存放在头结点的指针域中，因此在链表的第一个位置上的操作和在表的其他位置上的操作一致，无须进行特殊处理。 无论链表是否为空，其头指针都是指向头结点的非空指针(空表中头结点的指针域为空), 因此空表和非空表的处理也就得到了统一。 单链表 建立链表 头插法 将新节点放到表头\nLinkList List_HeadInsert(LinkList \u0026amp;L){ LNode *s; int x; L=(LinkList)malloc(sizeof(LNode)); L-\u0026gt;next=NULL; scanf(\u0026#34;%d\u0026#34;,\u0026amp;x); while(x!=9999){ //x=9999表示结束 s=(LNode*)malloc(sizeof(LNode)); s-\u0026gt;data=x; s-\u0026gt;next=L-\u0026gt;next; L-\u0026gt;next=s; } return L; } 读入数据的顺序与生成的链表中的元素的顺序相反\nO(n)\n尾插法 增加一个尾指针r\nLinkList List_TailInsert(LinkList \u0026amp;L){ int x; L=(LinkList)malloc(sizeof(LNode)); LNode *s,*r; r=L; L-\u0026gt;next=NULL; scanf(\u0026#34;%d\u0026#34;,\u0026amp;x); while(x!=9999){ //x=9999表示结束 s=(LNode*)malloc(sizeof(LNode)); s-\u0026gt;data=x; r-\u0026gt;next=s; r=s; } r-\u0026gt;next=NULL; return L; } 查找结点 按序号查找 从第1个节点出发，顺next域已知往下查找，直到找到第i个节点为止。否则返回NULL。\nLNode *GetElem(LinkList L,int i){ if(i\u0026lt;1) return NULL; int j=1; LNode *p=L-\u0026gt;next; while(p!=NULL \u0026amp;\u0026amp; j\u0026lt;i){ p=p-\u0026gt;next; j++; } return p; } O(n)\n按值查找 查找给定值e，返回该节点的指针，否则返回NULL\nLNode *LocateElem(LinkList L,ElemType e){ LNode *p=L-\u0026gt;next; while(p!=NULL \u0026amp;\u0026amp; p-\u0026gt;data!=e){ p=p-\u0026gt;next; } return p; } O(n)\n插入结点 将值为x的节点插入到单链表的第i个位置上\n先检测插入的合法性，找到前驱节点，再插入\np=GetElem(L,i-1); s-\u0026gt;next=p-\u0026gt;next; p-\u0026gt;next=s; 删除结点 将第i个节点删除，先检查删除位置合法性再找i-1节点\np=GetElem(L,i-1); q=p-\u0026gt;next; p-\u0026gt;next=q-\u0026gt;next; free(q); O(n)\n双向链表 prior data next typedef struct dlnode{ ElemType data; struct dlnode *prior,*next; }DLNode,*DLinkList; 在双向链表中，通过某结点的指针p既可以直接得到它的后继结点的指针p-\u0026gt;next，也可以直接得到它的前驱结点的的指针p-\u0026gt;prior。\np-\u0026gt;prior-\u0026gt;next == p== p-\u0026gt;next-\u0026gt;prior\n插入结点 设p指向双向链表中某结点，s指向待插入的值为x的新结点，将s插入到p的前面。操作如下：\n①s-\u0026gt;prior=p-\u0026gt;prior;\n②p-\u0026gt;prior-\u0026gt;next=s;\n③s-\u0026gt;next=p;\n④p-\u0026gt;prior=s;\n上面指针操作的顺序不是唯一的，但也不是任意的，操作①必须要放到操作④的前面完成，否则*p的前驱结点的指针就丢掉了。\n删除结点 设p指向双向链表中某结点，删除*p。\n操作如下：\n①p-\u0026gt;prior-\u0026gt;next=p-\u0026gt;next;\n②p-\u0026gt;next-\u0026gt;prior=p-\u0026gt;prior;\n③free(p);\n循环链表 表中最后一个结点的指针不是NULL而改为指向头结点\n静态链表 静态链表借助数组来描述线性表的链式存储结构，结点也有数据域data和指针域next, 与前面所讲的链表中的指针不同的是，这里的指针是结点的相对地址(数组下标) ，又称游标。和顺序表一样，静态链表也要预先分配一块连续的内存空间。\n#define MaxSize 50 typedef struct{ ElemType data; int next; }SLinkList[MaxSize]; 静态链表以next==-l作为其结束的标志.\n顺序表和链表比较 存取(读写)方式 顺序表可以顺序存取，也可以随机存取，链表只能从表头顺序存取元素。例如在第i个位置 上执行存或取的操作，顺序表仅需一次访问，而链表则需从表头开始依次访问i次。\n逻辑结构与物理结构 采用顺序存储时，逻辑上相邻的元素，对应的物理存储位置也相邻。而采用链式存储时，逻辑上相邻的元素，物理存储位置不一定相邻，对应的逻辑关系是通过指针链接来表示的。\n查找、插入和删除操作 对于按值查找，顺序表无序时，两者的时间复杂度均为On；顺序表有序时，可采用折半查找，此时的时间复杂度为O(log2n)o\n对于按序号查找，顺序表支持随机访问，时间复杂度仅为O1，而链表的平均时间复杂度为On。顺序表的插入、删除操作，平均需要移动半个表长的元素。链表的插入、删除操作，只需 修改相关结点的指针域即可。由于链表的每个结点都带有指针域，故而存储密度不够大。\n空间分配 顺序存储在静态存储分配情形下，一旦存储空间装满就不能扩充，若再加入新元素，则会出 现内存溢出，因此需要预先分配足够大的存储空间。预先分配过大，可能会导致顺序表后部大量闲置；预先分配过小，又会造成溢出。动态存储分配虽然存储空间可以扩充，但需要移动大量元 素，导致操作效率降低，而且若内存中没有更大块的连续存储空间，则会导致分配失败。链式存储的结点空间只在需要时申请分配，只要内存有空间就可以分配，操作灵活、高效。\n","date":"2024-01-16T14:56:50Z","permalink":"https://www.xxx.blog/post/2-%E7%BA%BF%E6%80%A7%E8%A1%A8/","title":"2 线性表"},{"content":"绪论 什么是数据结构 程序 = 算法 + 数据结构\n基本概念和术语 数据 (data)： 信息的载体，被计算机识别、存储加工处理的对象。\n数据元素（data element）：数据的基本单位。通常作为一个整体进行考虑。一个数据元素可由若干个数据项组成。\n数据项(data item)：具有独立含义的标识单位，是数据不可分割的最小单位。\n数据对象(data object)：是性质相同的数据元素的集合，是数据的一个子集。（某种数据类型元素的集合）\n数据对象可以是有限的，也可以是无限的。\n数据结构（data structure）: 相互之间存在着一种或多种特定关系的数据元素的集合。\n结构（structure）: 数据元素之间的关系，可以看做是从具体问题抽象出来的数学模型，与计算机无关，与数据的存储无关，也叫做逻辑结构。\n根据数据元素之间关系的不同特性，通常有下列 4 类基本结构：\n集合 线性结构 树形结构 图状结构或网状结构 从逻辑上可以把数据结构分成线性结构和非线性结构两大类。\n存储结构：数据结构在计算机中的表示。包括数据元素的表示和关系的表示。主要有顺序存储、链式存储、索引存储和散列存储。比如循环队列是一种顺序存储。\n数据类型（data type）：数据类型是一个值的集合和定义在此集合上的一组操作的总称 。\n原子类型 结构类型 抽象数据类型 算法和算法分析 算法的五个特征 有穷性 确定性 可行性 输入 输出 算法效率的度量 时间复杂度 语句的频度f(n)：在算法中重复执行的次数 所有语句的频度之和T(n) 时间复杂度：$T(n)=O(f(n))$，式中$O$的含义是$T(n)$的数量级 时间复杂度的数学定义：存在正常数C和n~0~，使得当$n \\geq n_0$时，都满足$0 \\leq T(n) \\leq Cf(n)$ 时间复杂度分析规则： 加法规则：$T(n)=T_1(n)+T_2(n)=O(f(n))+O(g(n))=O(max(f(n),g(n)))$ 乘法规则：$T(n)=T_1(n)*T_2(n)=O(f(n))*O(g(n))=O(f(n)*g(n))$ 空间复杂度 一个程序在执行时除需要存储空间来存放本身所用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为实现计算所需信息的辅助空间 。若输入数据所占 空间只取决于问题本身，和算法无关，则只需分析除输入和程序之外的额外空间。 算法原地工作是指算法所需的辅助空间为常量，即O(1)。\n引用和指针的区别 指针是一个存储内存地址的变量，引用是一个变量的别名。一般通过指针来访问其指向的内存地址中的内容，通过引用这个别名来使用实际的变量。\n指针有自己的存储空间，引用没有。\n指针可以不初始化，通过赋值可以指向任意同类型的内存；但是引用必须初始化，而且引用一经引用一块内存，再也不能引用其它内存了，即引用不能被改变。\n因为str是一个指针变量，作函数参数时是传值，不是传引用，并不能改变函数外变量的值。\n","date":"2024-01-15T14:56:45Z","permalink":"https://www.xxx.blog/post/1-%E7%BB%AA%E8%AE%BA/","title":"1 绪论"},{"content":"Mass-Storage Structure Disk Structure Disk Attachment Disk Scheduling※ FCFS SSTF SCAN scan得先到199在回去\n199-53+199-14\nC-SCAN 从199-0这一段也要计算\n199-53+199+37\nLOOK C-LOOK Disk Management Swap-Space Management ","date":"2024-01-05T15:38:45Z","permalink":"https://www.xxx.blog/post/8-mass-storage-structure/","title":"8 Mass-Storage Structure"},{"content":"File-System File Concept 连续的逻辑地址空间指的是操作系统为用户提供了统一的逻辑视图来访问存储设备上的信息。文件是一个命名的、相关的信息的集合，这些信息被记录在次级存储设备上。文件是逻辑次级存储的最小分配单元。常见的文件类型包括程序源代码、目标代码和数据文件(数字、字符、二进制)。文件可以是自由格式的，也可以是格式固定的。文件的信息由其创建者定义。文件通过其名称进行命名，并可以通过名称进行访问，是独立的。\nFile Attributes 文件属性包括：\n名称(Name): 仅以人类可读的形式保存的信息。 标识符(Identifier): 在系统中唯一标识文件的数字，非人类可读的文件名。 类型(Type): 用于支持不同类型的系统。 位置(Location): 设备上文件的位置指针。 大小(Size): 文件当前的大小。 保护(Protection): 访问控制信息，控制谁可以进行读、写、执行操作。 时间、日期和用户标识(Time, date, and user identification): 用于保护、安全性和使用监控的数据。 这些文件属性保存在目录结构中，该结构由维护在磁盘上的目录条目组成。目录条目由文件名和唯一的id组成，id反过来指向其他文件属性。\nFile Operations 文件是一个抽象数据类型。文件操作的最小集合包括：\nCreate - 找到空间，在目录中为文件创建条目。 Write - 文件名，要写入的信息，写入指针。 Read - 文件名，内存中的位置，读取指针。每个进程有一个当前文件位置指针。 Reposition within file - 文件seek，不需要I/O。 Delete - 文件名，释放文件空间，删除目录条目。 Truncate - 将长度重置为0，释放文件空间。 这些基本操作可以组合起来执行其他文件操作，比如复制。大多数文件操作涉及搜索目录以查找与文件名相关联的条目。 Open-file table是一个内核数据结构，包含有关所有打开文件的的信息。 Open(Fi)操作会在磁盘上的目录结构中查找Fi的条目，并将该条目的内容移动到打开文件表中。它还会返回打开文件表中该条目的一个指针，并接受访问模式信息，如创建、只读、读写、只追加等。 Close(Fi)操作会将打开文件表中Fi的条目的内容移动到磁盘上的目录结构中。\n文件共享意味着多个进程和应用程序可以同时打开同一个文件。 为此，需要两个级别的内部表：\n进程打开文件表：每个进程都有一个进程打开文件表，用于跟踪该进程打开的所有文件以及进程对文件的使用信息，如当前文件指针、访问权限、计费信息等。 系统打开文件表：包含进程无关的信息，如文件在磁盘上的位置、访问日期、文件大小等。每个进程打开文件表的条目都指向一个系统打开文件表的条目。 这样，进程可以独立地使用进程打开文件表，而系统可以使用系统打开文件表来维护进程无关的信息。 Open File Locking 文件锁允许一个进程锁定文件，防止其他进程访问它。 一些操作系统和文件系统提供文件锁，它类似读写锁，包括共享锁和独占锁。共享锁允许多个进程同时获取，独占锁类似写锁，只允许一个进程获取。 文件锁可以调解进程对文件的访问。操作系统可以提供强制或建议的文件锁机制。强制机制根据持有的锁和请求的锁来拒绝访问，而建议机制允许进程查看锁的状态并决定如何操作。\nFile types 操作系统是否应该识别并支持文件类型是一个常见的问题。实现文件类型的常见技术是将类型作为文件名的一部分。文件名被分割成两部分：文件名和扩展名，以点字符分隔。系统使用扩展名来表示文件的类型和可以对该文件进行的操作类型。应用程序也使用扩展名来表示它们感兴趣的文件类型。一些操作系统，每个文件都有一个类型和创作者属性，包含创建该文件的应用程序的名称。在UNIX系统中，一些文件在开头存储一个魔法数字，以大致表示文件的类型。\nFile Structure 文件结构可以分为三种：\n无结构 - 顺序的字符串或字节 简单记录结构 - 行、固定长度、可变长度 复杂结构 - 格式化文档、可重定位加载文件 操作系统和程序都可以决定文件的内部结构。\nInternal file structure 逻辑结构分为两类：\n文本文件：一系列8位字节 记录文件：一系列固定或可变长度的记录 逻辑地址包括文件起始位置的偏移量和逻辑记录号。 物理结构是一组磁盘块。基本I/O函数以块为单位操作。 逻辑地址到物理地址的映射包括逻辑块号、物理磁盘块号和块内偏移量。 内部碎片化是由于逻辑记录大小、物理块大小和打包技术决定的逻辑记录数与物理块数之间的差异。磁盘空间总是以块为单位分配的。\nAccess Methods 文件组织方式主要根据以下几个标准进行分类：\n反映不同的文件结构 - 不同的存储和处理数据的方式。 快速访问 - 单记录访问时需要快速访问，而在批处理模式下不需要。 更新方便性 - CD-ROM上的文件不需要更新，所以这不需要考虑。 存储经济性 - 数据冗余度最小化，冗余度可以用来加速访问，如索引。 维护简单性 - 可靠性。 根据这些标准，文件组织方式主要分为： 堆积文件(Pile File) 顺序文件(Sequential File) 索引顺序文件(Indexed Sequential File) 索引文件(Indexed File) 直接文件(Direct File，或散列文件(Hashed File)) 顺序访问方式包括：\n读取下一个记录 写入下一个记录 重置 重写，最后一次写入后不再读取 直接访问方式包括：\n读取(n) 写入(n) 定位(n) 读取下一个记录，写入下一个记录 重写(n) n为相对块号，第一个为0。 直接访问方式可以模拟顺序访问。 其他访问方式可以建立在直接访问方式之上，通常涉及为文件创建索引。索引可以保存在内存中，以快速确定要操作的数据的位置。如果索引太大，可以使用二级或多级索引文件。索引文件和相对文件的区别在于，索引文件使用索引来定位数据，而相对文件直接使用文件中的偏移量来定位数据。\nDirectory Structure 每个系统中的磁盘至少包含一个分区。有些系统允许分区的大小大于磁盘，以便将磁盘组合成一个逻辑结构。 磁盘或分区可以以原始状态使用，例如交换空间。也可以格式化一个文件系统。\n包含文件系统的实体被称为卷(volume)。 每个卷包含的文件系统也在设备目录或卷表目(volume table of contents)中跟踪该文件系统信息。 目录中包含文件名、文件类型、文件位置等信息。 磁盘或分区可以通过RAID(Redundant Arrays of Independent Drives)来防止故障。 目录结构可以看作是一个符号表，它将文件名转换成目录项(directory entry)。 目录结构为文件名和文件本身提供了映射。 目录结构本身是由操作系统拥有的一个文件。 目录结构和文件都存储在磁盘上。\nSingle-Level Directory 文件系统的基本结构 所有文件都包含在同一个目录中：这意味着文件系统没有使用子目录或分层结构，所有文件都存储在一个共同的位置。\n文件的索引方式\n文件列表，每个文件一个条目：这种方式下，系统会维护一个列表，列表中每个条目代表一个文件。这有点类似于目录，其中每个文件都有对应的条目。 顺序文件，以文件名作为关键字：这里的顺序文件可能指的是索引文件，它根据文件名（作为关键字）来组织文件，允许按文件名顺序访问文件。 遇到的问题\n命名问题 文件必须有唯一的名称：在这样的系统中，由于所有文件都在同一个目录下，因此每个文件的名称必须是唯一的，以避免混淆。 文件名的长度：文件名的长度可能受限，这可能影响到如何命名文件和组织数据。 分组问题：这可能指的是如何有效地将文件分组以便管理，尤其是当所有文件都在一个目录下时。在没有子目录或分类的情况下，组织和检索文件可能会变得更加困难。 Two-Level Directory 这种文件系统结构设计用来解决单级目录系统中文件命名冲突和文件组织问题。\n特点\n为每个用户创建单独的目录：在双级目录系统中，每个用户都有自己的目录，这有助于隔离不同用户的文件。 主文件目录和用户文件目录： 主文件目录：包含每个用户的条目，这些条目可以通过用户名或账号进行索引。它提供了用户目录的地址和访问控制信息。 用户文件目录：每个用户都有一个自己的文件目录，这个目录是该用户文件的简单列表。不同用户可以有同名的文件，因为它们存储在各自的目录中。 优势\n高效的搜索：由于文件被组织在各自的用户目录中，搜索特定用户的文件变得更加高效。 限制\n没有分组能力：这种系统不支持跨用户的文件分组，每个用户的文件都被限制在自己的目录中。 文件共享\n路径名：由用户名和文件名定义。例如，如果一个用户想要访问另一个用户的文件，他们可能需要使用特定的路径名。 特殊的用户目录：包含系统文件。这可能是为了系统管理而设置的，不同于普通用户的目录。 搜索路径：是指系统搜索文件时遍历的目录序列。这可以帮助系统决定在哪些目录中查找文件。 Tree-Structured Directories 这是一种常见的目录结构，其中每个文件都有一个独特的路径名。\n特点 允许用户创建自己的子目录：用户可以组织文件，将它们放在不同的子目录中。 每个用户目录可能包含一个或多个子目录和文件作为条目。 所有目录具有相同的内部格式。 目录条目中的一个位用于定义条目是文件（0）还是子目录（1）。 优势 高效搜索：由于其树形结构，可以快速定位文件和目录。 命名方便：每个文件的路径名是唯一的，方便用户识别和访问。 分组能力：用户可以通过创建子目录来有效地组织和管理文件。 当前目录（工作目录） 在会计文件中，存储了指向用户初始目录的指针或名称。该信息被复制到该用户的本地变量中。 创建新文件默认在当前目录中进行。 删除文件：使用命令 rm \u0026lt;文件名\u0026gt;。 更改当前目录：使用命令 cd /路径。可以使用绝对或相对路径名。 创建新的子目录 在当前目录下创建新的子目录，使用命令 mkdir \u0026lt;目录名\u0026gt;。 例如，在当前目录 /mail 下，创建一个名为 count 的新目录：mkdir count。 删除子目录 删除空目录：在某些系统（如MS-DOS）中，只能删除空目录。 删除所有文件和子目录：在某些系统（如UNIX）中，可以删除包含所有文件和子目录的目录。 Acyclic-Graph Directories 这种目录结构允许共享子目录和文件，是一种较为复杂的文件系统结构。\n特点 相同的文件或子目录可以出现在两个不同的目录中。 共享的文件/目录与文件/目录的两份拷贝不同。 实现共享文件和子目录的方式 创建一个新的目录条目，称为链接（例如UNIX中的链接）：这是指向另一个文件或子目录的指针。 路径名：目录条目被标记为链接。 解析链接：遵循指针定位文件。 链接与原始目录条目明显不同。 在所有共享目录中复制有关共享文件的所有信息： 两个条目相同且等价。 原始文件和副本无法区分。 问题：修改文件时如何保持一致性？ 问题 一个文件可能有多个绝对路径名：不同的文件名可能指向同一个文件（别名问题）。 遍历整个文件系统：累计所有文件的统计信息，将所有文件复制到备份存储中。 共享文件的删除： 删除任何人删除的文件时出现悬挂指针（dangling pointers）。 例如，如果字典删除了计数➢链接，删除链接不会影响原始文件。 删除文件条目，留下悬挂的链接。 文件引用列表，反向指针。 删除共享文件的问题（续） 保留文件直到删除了对它的所有引用： 解决方案：文件引用列表、文件引用计数、反向指针，以便我们可以删除所有指针。 可变大小记录可能是一个问题。 General Graph Directory 与无环图目录（Acyclic-Graph Directory）相比，通用图目录允许目录结构中存在循环（cycles），这意味着目录可以直接或间接地引用自身。\n优势 无环图的主要优势是遍历图的算法相对简单。例如，可以避免对共享子目录的重复搜索，也更容易确定何时没有更多对文件的引用。 问题 设计不良的算法可能导致无限循环，不断地在循环中搜索而永远不会结束。 文件删除的判定 在无环图目录结构中，当引用计数为0时可以删除文件。 在通用图目录结构中，由于存在循环，即使无法再引用目录或文件，引用计数可能不为0。 这种异常情况源于自引用的可能性（即循环）。 解决方案：使用垃圾收集。 第一遍：遍历整个文件系统，标记所有可以访问的内容。 第二遍：收集所有未标记的内容到自由空间列表中。 避免循环的方法 仅允许链接到文件而非子目录：这样可以保证没有循环。 在添加新链接时使用循环检测算法来确定是否可行。但这种方法非常昂贵，尤其是当图在磁盘存储上时。 更简单的算法：在目录遍历期间绕过链接。 File System Mounting 文件系统必须挂载后才能被访问。 挂载过程包括：操作系统被提供设备名称和挂载点(mount point) - 文件结构中用于挂载文件系统的位置。 操作系统通过设备驱动程序读取设备目录并验证目录具有期望的格式，来验证设备包含有效的文件系统。 操作系统在目录结构中记录文件系统已挂载在指定的挂载点。 系统通过语义(semantics)来明确功能：\n可能不允许在包含文件的目录上挂载文件系统。 可能使挂载的文件系统在该目录上可用，直到卸载文件系统才会遮挡该目录中现有的文件。 可能允许同一文件系统在不同的挂载点上重复挂载。 可能只允许每个文件系统挂载一次。 File Sharing 多用户系统中共享文件是必要的。文件和目录的共享可以通过保护机制来实现。多用户系统需要更多的文件和目录属性，包括文件/目录所有者、文件/目录用户、访问权限等。在多用户系统中，用户ID可以识别用户，允许为每个用户设置权限和保护。组ID可以让用户属于组，允许组访问权限。文件/目录的所有者和组可以设置访问权限。\nRemote File Systems 远程文件系统使用网络允许不同系统之间的文件系统访问。 主要有三种方法： 通过像FTP这样的程序手动传输文件，适用于匿名和认证访问。 使用分布式文件系统(DFS)，远程目录对本地机器可见，机器间集成更紧密。 通过WWW自动访问，需要浏览器，使用匿名文件交换。 云计算正在被使用。\nFailure Modes 所有文件系统都有故障模式。本地文件系统故障的原因包括磁盘故障、磁盘控制器故障、电缆故障、主机适配器故障、目录结构或其他非用户数据的损坏、用户或系统管理员的错误。远程文件系统增加了新的故障模式，例如网络故障、服务器故障。从故障中恢复可能需要涉及每个远程请求的状态信息。如果服务器和客户端都维护它们当前的活动和打开的文件的知识，那么它们就可以无缝地从故障中恢复。无状态协议像NFS V3将所有信息包含在每项请求中，这使得恢复很容易，但安全性较低。在NFS V4中，它被设计成有状态的，以证明其安全性、性能和功能。\nConsistency Semantics 一致性语义(Consistency semantics)规定了多个用户如何同时访问共享文件。它指定了一个用户对数据的修改何时对其他用户可见。它类似于第6章中的进程同步算法，但由于磁盘I/O和网络延迟(对于远程文件系统)，通常比较简单。UFS(Unix文件系统)实现了以下一致性语义：\n每个文件关联到单个物理映像。 对同一打开文件的其他用户的写入立即可见。 共享文件指针以允许多个用户并发地读取和写入。 一致性语义(Consistency semantics)规定了多个用户如何同时访问共享文件。\nAFS(Andrew File System)实现了复杂的远程文件共享语义：服务器记录客户端的行为，并保留客户端缓存的文件信息。当客户端更改文件时，服务器使用回调承诺技术通知其他客户端。只有在文件关闭后，写入才对会话可见。 不可变的共享文件，由其创建者声明为只读的。文件名不能重复，内容不能更改。 Protection 可靠性涉及文件副本的备份，保护涉及对文件的访问控制，文件所有者/创建者应该能够控制对文件可以进行什么操作以及由谁进行操作。文件访问类型包括读取、写入、执行、追加、删除、列出等。\nAccess control 访问模式：读、写、执行\n读（Read, R）：查看文件内容的权限。 写（Write, W）：修改或删除文件的权限。 执行（Execute, X）：运行文件的权限，对于脚本或程序尤其重要。 取决于用户的身份\n根据用户的身份，访问权限可能会有所不同。这通常通过以下方式管理：\n访问控制列表（Access-Control List, ACL）：一种表格，将每个文件与特定用户关联，并定义每个用户拥有的访问类型（读、写、执行）。 三类用户\n拥有者（Owner）：创建文件的用户。通常拥有最多的权限。 群组（Group）：一组需要类似访问权限的共享文件的用户。 普通用户（Universe/Public）：系统中的所有其他用户。 访问控制信息\n用户访问：读写执行（RWX，二进制表示为111，十进制表示为7） 群组访问：读写（RW，二进制表示为110，十进制表示为6） 公共访问：执行（X，二进制表示为001，十进制表示为1） 权限控制的优势与问题\n优势：增强安全性，确保只有授权用户才能访问特定的文件或目录。 问题：可能导致配置复杂，如果不正确设置，可能会不慎阻止合法用户的访问或允许非授权访问。 群组的创建和修改\n只有管理员或超级用户（superuser）能创建和修改群组。 管理员可以创建一个具有唯一名称的群组，比如G，并向群组中添加用户。 对于特定的文件（比如“game”）或子目录，可以定义适当的访问权限。 更改用户的访问方法\n例如，使用chmod命令更改文件权限：\nchmod G +w o=x file 表示给群组G增加写权限，给其他用户（public）设置执行权限。 chgrp G game 表示将文件“game”关联到群组G。 File System Implementation File System Structure 文件定义 文件：是相关信息的集合，是逻辑存储单元。它可以包含文本、图像、程序或其他数据类型。 磁盘特性 磁盘可就地写入：即在磁盘上直接修改数据，而无需先移动数据。 磁盘可直接访问任意给定的信息块：这意味着可以高效地检索和存储数据。 内存与磁盘间的I/O传输以块为单位：数据在内存和磁盘之间以块的形式进行传输。 文件系统位置 文件系统位于**次级存储（如磁盘）**上，它提供了用户对存储的接口，将逻辑地址映射到物理地址。 功能 提供有效且方便的磁盘访问：允许数据被轻松存储、定位和检索。 文件系统结构 主要设计问题 用户界面：涉及定义文件及其属性、文件操作和目录结构。 将逻辑文件系统映射到物理次级存储设备的算法和数据结构。 文件控制块：存储有关文件的信息的存储结构。 设备驱动程序：控制物理设备。 文件系统组织成层：这有助于管理和优化存储和检索操作。 总的来说，文件是存储在磁盘等次级存储设备上的逻辑存储单位，文件系统提供了有效的方式来组织、存储、检索和管理这些文件。文件系统的设计要考虑用户界面、存储映射算法和数据结构、以及文件和设备管理的不同层次。\nLayered File System 应用程序层（application programs）： 系统调用用于文件操作。 逻辑文件系统层（logical file system）： 管理元数据信息。 管理目录结构。 通过文件控制块（FCB，例如索引节点inodes）维护文件结构。 负责保护和安全性。 文件组织模块层（file-organization module）： 理解文件、逻辑地址和物理块。 将逻辑块地址转换为物理块地址。 空闲空间管理器，磁盘分配。 基本文件系统层（basic file system）： 向适当的设备驱动程序发出通用命令来读写磁盘上的物理块。 管理内存缓冲区和缓存（分配、释放、替换），例如I/O缓冲区、目录/数据的磁盘缓存。 I/O控制层（I/O control）： 设备驱动程序和中断处理程序。 在主内存和磁盘系统之间传输信息。 将如“读取驱动器1，柱面72，磨道2，扇区10”的命令转换为内存位置1060的低级硬件特定命令。 设备层（devices）： 这一层与物理硬件直接交互。 File Systems 在操作系统中，存在多种文件系统，每种都有自己的格式：\nCD-ROM使用ISO 9660格式：这是一个由制造商共同商定的标准格式。 Unix系统通常使用UFS（Unix File System）：它基于伯克利快速文件系统（Berkeley FFS）。 Windows支持多种文件系统： FAT（File Allocation Table）：较老的文件系统，曾广泛用于早期Windows版本和可移动存储设备。 FAT32：FAT的扩展版本，支持更大的磁盘和文件尺寸。 NTFS（New Technology File System）：Windows的现代文件系统，提供安全性、文件恢复和大文件支持等特性。 此外，Windows也支持软盘、CD、DVD等多种存储媒介的文件系统。 Linux支持40多种类型的文件系统： 标准Linux文件系统：扩展文件系统（extended file system），包括ext2。 常用的文件系统：ext3和ext4，它们提供了日志功能和更高的数据完整性。 分布式文件系统：专门用于分布式计算环境，如网络文件系统（NFS）等。 新的文件系统仍在不断推出： ZFS（Zettabyte File System）：一种高容量、高性能的文件系统，提供了卓越的数据完整性保护。 OpenZFS：ZFS的一个开源版本。 Google GFS（Google File System）：用于大规模分布式计算系统的文件系统。 Oracle ASM（Automatic Storage Management）：一种数据库文件系统，用于简化数据库数据的存储管理。 FUSE（Filesystem in Userspace）：一种允许用户在用户空间中创建文件系统的接口，增加了灵活性和安全性。 File System Implementation On-disk File System Structures 在磁盘上，文件系统可能包含以下部分：\n启动操作系统的信息：如果操作系统存储在该磁盘上，这部分信息会告诉计算机如何从磁盘启动操作系统。\n块的总数：磁盘上数据存储的基本单位，文件系统会跟踪总共有多少块。\n空闲块的数量和位置：文件系统需要管理空闲块以便存储新的数据。\n目录结构：包含文件和子目录的组织结构。\n个别文件：具体的数据内容。\n磁盘结构\n启动控制块（Boot Control Block）（每个卷）： 通常是卷的第一个块。 在UFS中称为启动块，在NTFS中称为分区启动扇区。 卷/分区控制块（Volume/Partition Control Block）（每个卷）： 包含块的详细信息、块大小、空闲块计数和空闲块指针、空闲文件控制块（FCB）计数和空闲FCB指针。 在UFS中称为超级块，在NTFS中是主文件表（Master File Table）的一部分。 目录结构（每个文件系统）： 在UFS中包含文件名和关联的inode编号。 在NTFS中包含在主文件表中。 文件控制块（FCB）（每个文件）： 包含关于文件的信息的存储结构，包括所有权、权限和文件内容的位置。 在UFS中称为inode，在NTFS中也是主文件表（作为关系数据库）的一部分。 以上结构确保了文件系统能够有效地管理和定位磁盘上的数据，同时也保证了数据的安全和可访问性。每种文件系统（如UFS、NTFS）都有其特定的实现方式和数据结构。\nIn-Memory File System Structures 在内存中的文件系统结构用于：\n文件系统管理：这包括管理文件系统的挂载、目录结构、文件的打开和关闭等。 通过缓存改善性能：数据缓存可以减少对次级存储（如硬盘）的访问次数，从而提高系统性能。 内存中的结构 内存中的挂载表（In-memory mount table）： 存储文件系统的挂载信息、挂载点、文件系统类型等。 内存中的目录结构缓存： 加速目录访问和查找操作。 系统范围的打开文件表（System-wide open-file table）（系统中只有一张表）： 包含每个打开文件的文件控制块（FCB）的副本。 每个打开的文件有一个条目。 每个进程的打开文件表（Per-process open-file table）（每个进程一张表）： 包含指向系统范围打开文件表中相应条目的指针。 每个由该进程打开的文件有一个条目。 缓冲区： 存放来自次级存储的数据块。 Partitions and Mounting 分区与挂载是操作系统管理磁盘存储的基本概念。\n分区\n一个磁盘可以被分成多个分区，或者一个分区可以跨越多个磁盘。 每个分区可以是： “原始”（raw）：不包含文件系统，只是一系列的块。 “已格式化”（cooked）：包含文件系统。 启动信息\n启动信息可以存储在一个单独的分区中，它有自己的格式，并作为一个镜像加载到内存中，在预定义的位置开始执行。 引导加载程序（Boot loader）\n知道足够的文件系统结构信息，能够找到并加载内核并开始执行。 理解多个文件系统和多个操作系统可以占用启动空间。 根分区\n在启动时挂载的根分区，包含操作系统内核和可能的其他系统文件。 其他分区\n其他分区可以在启动时自动挂载，或者稍后手动挂载。 挂载时检查\n在挂载时，会检查文件系统的一致性。 通过请求设备驱动程序读取目录并验证目录是否具有预期的格式。 检查所有元数据是否正确。 如果不正确，则修复后重试。 如果正确，则添加到挂载表中，允许访问。 挂载表（Mount table）\n包含已挂载文件系统的信息。 分区允许操作系统将磁盘空间划分为独立的区域，每个区域可以独立管理和挂载。挂载是操作系统识别和准备访问文件系统的过程。通过挂载表，系统可以跟踪所有已挂载的文件系统及其相关信息。这些概念对于操作系统有效管理存储和确保数据的完整性至关重要。\nVirtual File Systems 现代操作系统需要同时支持多种类型的文件系统。这是如何实现的，以及用户如何在不同类型的文件系统之间无缝切换？\n虚拟文件系统（Virtual File System, VFS）\n支持多种文件系统：\n操作系统必须能够支持多种不同的文件系统类型，包括网络文件系统。 集成到目录结构中：\n操作系统如何允许多种类型的文件系统被集成到一个目录结构中？ 用户无缝切换：\n用户如何在文件系统空间中无缝地在不同文件系统类型之间移动？ VFS的实现方法\n大多数操作系统（包括Unix）使用面向对象的技术来实现文件系统，这就是VFS。 VFS的功能\n允许不同的文件系统类型在同一个结构内实现：\n这包括本地文件系统和网络文件系统。 简化、组织和模块化实现：\n通过数据结构和过程来隔离基本的系统调用功能与实现细节。 VFS如何工作\n将文件系统通用操作与实现细节分离：\n实现可以是众多文件系统类型之一，或者是网络文件系统。 实现了节点（vnodes）：\n节点持有索引节点（inodes）或网络文件的详细信息。 将操作分派给适当的文件系统实现例程：\n这样用户通过相同的系统调用接口（API）就可以访问不同类型的文件系统。 API针对的是VFS接口：\n而不是任何特定类型的文件系统。 综上所述，VFS提供了一个抽象层，使得操作系统可以通过一个统一的接口与多种不同的文件系统交互。这样，无论用户正在访问的是本地文件系统、外部存储设备上的文件系统，还是网络文件系统，体验都是一致的。VFS的设计允许操作系统开发者在不改变用户界面的情况下，增加对新文件系统类型的支持。\nDirectory Implementation 在文件系统中，文件名通常与它们数据块的指针关联，这样的结构可以用多种方式组织：\n线性列表\n优点：编程简单。 缺点：执行时间消耗大，因为每次搜索都需要遍历整个列表。 线性搜索时间：查找文件时可能需要遍历整个文件列表，这在文件数量很多时效率低下。 排序列表\n通过对文件名列表排序，可以使用二分搜索，这样可以减少平均搜索时间。 平衡树\n平衡树（如AVL树或红黑树）可以进一步优化搜索时间，因为它们保证了在最坏的情况下仍然具有较好的搜索效率。 哈希表\n使用哈希数据结构的线性列表可以减少目录搜索时间。 碰撞问题：两个文件名可能映射到同一哈希位置（哈希冲突）。 链式溢出：一种解决哈希冲突的方法，即在冲突发生时使用链表将冲突的元素连接起来。 困难： 固定大小：哈希表的大小通常是固定的，这可能限制了文件系统的扩展性。 哈希函数选择：一个好的哈希函数应该减少冲突，同时均匀地分布数据。选择或设计一个适合文件系统需求的哈希函数可能具有挑战性。 Allocation Methods Contiguous Allocation 将一组连续的磁盘块一次性分配给文件。 记录文件起始位置和长度。 它支持顺序访问和直接访问。 优势 读写性能高：由于数据块是连续的，读取文件时磁头移动最小，可以快速连续地读写数据。 管理简单：文件系统不需要复杂的算法来跟踪文件的各个部分，因为它们总是在一起的。 不会产生外部碎片：每个文件保存为一连串连续的块，因此不会在文件之间留下未使用的空间。 逻辑地址转物理地址 假设文件开始于磁盘上的块号 B，并且每个块有 S 个字节。如果你想访问文件中的逻辑地址 L（例如，文件的第 L 个字节），你可以使用以下步骤来找到对应的物理地址： 计算逻辑地址 L 所在的块号：BlockNum = L / S。 计算逻辑地址 L 在其块内的偏移量：Offset = L % S。 然后，物理块号就是 PhysicalBlock = B + BlockNum。 物理地址就是 PhysicalBlock 块的起始地址加上 Offset。 Linked Allocation 链接分配是一种基于单个块的分配方式，每个文件都是一组散布在磁盘上的磁盘块的链表。 目录包含第一个和最后一个块的指针，每个块包含指向链表中下一个块的指针。 没有外部碎片化，任何空闲块都可以用于满足请求。 缺点是：没有随机访问，空间用于指针，可靠性较差。 访问第n块逻辑块时需要依次读$0-(n-1)$块，即$n-1$次磁盘IO 逻辑地址转物理地址 假设你要访问文件的第 L 字节，这里的 L 是文件内的逻辑地址： 确定起始块：从文件的目录项中获取指向文件第一个数据块的指针。 计算块号：确定 L 所在的数据块。这需要知道每个数据块的大小 S（不包括存储下一个块指针的空间）。计算逻辑地址 L 所在的数据块编号为 BlockNum = L / S。 遍历数据块链：从文件的第一个数据块开始，遵循每个块中的指针，直到到达第 BlockNum 个块。 计算块内偏移量：确定 L 在找到的数据块内的位置，即块内偏移量 Offset = L % S。 定位物理地址：使用块号和块内偏移量来确定数据的物理地址。 Indexed Allocation 每个文件都有自己的索引块，索引块是一个磁盘块地址的数组。 目录包含索引块的块号。 索引块可以避免外部碎片化，并实现文件的随机访问。 逻辑地址转物理地址 假设文件最大大小为256KB，块大小为1KB，逻辑地址为 LA： 一级索引分配 计算逻辑块号和块内偏移：\n$Q = \\frac{LA}{1024}$：确定逻辑地址 LA 所在的数据块编号。 $R = LA \\mod 1024$：确定 LA 在其数据块中的偏移量。 在索引表中找到相应的数据块：\n使用Q作为索引，在索引块中找到指向实际数据块的指针。 该指针指向的是文件中第Q个块的物理位置。 二级索引分配 第一级索引块号 ( Q1 ) 和 第一级块内偏移 ( R1 )： $Q1 = \\frac{LA}{1024}$ $Q2 = \\frac{Q1}{256}$ ：第二级索引块序号。 $R2 = Q1 \\mod 256$：第二级索引块内偏移。 使用 ( Q2 ) 在外索引块中找到内索引块的物理块号；然后使用 ( R2 ) 在该内索引块中找到实际数据块的物理块号。 Performance 文件访问方式的选择取决于文件访问类型。\n对于连续访问，索引块和数据块的连续分配方式比较适合。而对于链接访问，索引块和数据块的链接分配方式更适合。\n在文件创建时声明访问类型，可以选择连续分配或链接分配。索引分配方式更复杂，需要根据索引结构、文件大小以及所需块的位置来决定。\n单块访问可能需要2次I/O操作来读取索引块，然后1次操作读取数据块。或者需要3次I/O操作来读取2次索引块，然后1次操作读取数据块。群集可以提高吞吐量，减少CPU开销，将连续分配与索引分配结合使用，对于小文件(最多3-4个块)使用连续分配，如果文件变得很大，则自动切换到索引分配。\nFree-Space Management Bit map / Bit vector Linked list Grouping Counting ","date":"2023-12-30T12:45:59Z","permalink":"https://www.xxx.blog/post/7-file-system/","title":"7 File-System"},{"content":"Main Memory Background 计算机内存由大量存储单元组成，每个单元有地址。程序需要将指令和数据加载到内存中才能运行。 内存和寄存器是CPU可以直接访问的存储单元。寄存器访问速度快，内存访问速度较慢。 Cache位于内存和CPU之间，用于暂存常用数据，以加速CPU的访问。 指令执行需要经历取指令、解码、取操作数、执行和存储结果等多个步骤。内存访问是其中较慢的一步。 为了保护内存，需要硬件提供地址映射功能，确保每个进程只能访问自己的地址空间。 内存管理的目标是高效地为多个进程分配内存，同时满足进程对内存的需求。\nSwapping 进程可以暂时从内存中交换到备份存储设备上，然后被重新调入内存以继续执行。 进程的物理内存空间可以超过物理内存的大小。 备份存储设备Backing store - fast disk，足以容纳所有用户的内存映像副本。 交换出的进程是否会被交换回它之前使用的相同内存空间，取决于地址绑定方法。 Roll out, Roll in - 基于优先级的调度算法。 就绪队列 - 包含所有在备份存储设备上或在内存中并且准备运行的过程。 调度程序 - CPU调度器决定执行一个进程时被调用。 如果下一个进程不在内存中，且没有空闲内存区域，调度程序会交换掉当前内存中的一个进程，并调入所需进程。 上下文切换时间可能非常高。 总传输时间与交换的内存量成正比。 用户必须告知系统其对内存需求的任何变化。 永不交换带有未决I/O操作的过程。 标准交换在现代操作系统中不使用。\nContiguous Memory Allocation 内存需要同时满足操作系统和用户进程的需求。 内存通常被划分为操作系统分区(低内存，包含中断向量)和用户进程分区(高内存)。 用户空间进一步划分为多个分区。 对每个进程进行单分区分配。 使用重定位寄存器方案（relocation-register scheme）来保护用户进程，使其相互隔离，并防止改变操作系统代码和数据。 重定位寄存器Relocation/base register包含最小物理地址值。 限制寄存器limit register包含逻辑地址范围。 每个逻辑地址必须小于限制寄存器的值。 MMU动态映射逻辑地址到物理地址，调度程序加载重定位和限制寄存器，逻辑地址必须小于限制寄存器的值，否则会导致越界访问，触发trap异常。\n重定位寄存器的作用：\n基址调整：重定位寄存器的主要作用是存储一个基址值，这个值在运行时被加到进程的虚拟地址上，以产生实际的物理地址。这种机制允许系统动态地改变进程在物理内存中的位置。 支持进程隔离：通过使用重定位寄存器，操作系统可以确保一个进程不能访问到其他进程的内存空间。这提高了系统的安全性和稳定性。 内存保护：重定位寄存器也被用于内存保护。操作系统可以设置边界，以保证进程只能访问分配给它的内存区域。如果进程尝试访问超出这个范围的内存，会触发一个异常，例如段错误。 简化链接和加载：在程序加载时，重定位寄存器使得程序无需知道其在物理内存中的实际位置。程序可以在编译时使用相对地址，加载时由操作系统通过重定位寄存器调整这些地址。 上下文切换时的更新：在多任务操作系统中，当CPU从一个进程切换到另一个进程时，操作系统会更新重定位寄存器以反映新进程的内存基址。 与虚拟内存的关系：在现代操作系统中，虚拟内存的使用使得重定位寄存器的角色变得不那么直接显著，因为地址转换更多地依赖于分页机制和页表。然而，在某些体系结构和早期系统中，重定位寄存器仍然是内存管理的重要组成部分。 Fixed Partitioning 固定分区方式将内存分成多个固定大小的分区(partitions)。\n如果分区大小等于或小于进程大小，则可以将进程加载到可用的分区中。 所有分区都充满后，操作系统可以将进程从某个分区交换出去。 如果程序大小超过分区大小，程序员需要设计程序使用覆盖(overlay)技术。 分区大小不同时，内存使用效率低，任何大小程序都会占用整个分区，导致内部碎片。 Placement Algorithm with Partitions 内存分区的放置算法\n相等大小分区(Equal-size partitions)：所有分区大小相等，使用哪个分区并不重要。 不等大小分区(Unequal-size partitions)：可以为每个进程分配其最适合的较小分区。为每个分区创建一个队列，进程的分配方式要尽量减少分区内的浪费内存。 数据结构：每个分区包含分区ID、基地址、限制地址、状态等信息。 Variable-partition 可变分区(Variable-partition scheme)内存管理方式 可变分区(也称为动态分区，Dynamic Partitioning)是一种动态分配内存的方式。\n内存被分成大小和数量可变的分区(partitions)。 初始时，所有内存都可供用户进程使用，形成一个大的空闲区(hole)。 内存中散布着各种大小的空闲区。 操作系统维护一个表，包含哪些分区已被分配以及给哪个进程使用等信息。 当一个进程到达时，它从足够大的空闲区中分配内存。 进程退出时，释放其分区，相邻的空闲分区合并。 Dynamic Storage-Allocation Problem 动态存储分配问题是如何从一组空闲区中满足大小为n的请求。\nFirst-fit：选择第一个足够大的空闲区分配。 Best-fit：选择最小且足够大的空闲区分配。 Worst-fit：选择最大的空闲区分配。 首次适应法和最佳适应法在速度和存储利用率方面优于最差适应法。但是这些算法都存在外部碎片问题。 Fragmentation 内存碎片(Fragmentation)\n外部碎片(External Fragmentation)：存在足够的内存空间来满足请求，但是这些内存空间不连续。 内部碎片(Internal Fragmentation)：分配的内存可能比请求的内存略大，这个大小差异是分区内的内存，但是没有被使用。 对首次适应法(First Fit)的统计分析表明，给定N个块被分配，另外0.5N个块将因碎片化而无法使用。 1/3的内存可能无法使用 -\u0026gt; 50%规则。 该段内容主要介绍了内存碎片(Fragmentation)的问题以及通过整理内存来减少碎片的方法。 通过整理内存(Compaction)来减少外部碎片，即将所有空闲内存移动到一起形成一个大的内存块。整理内存需要在执行时动态地进行，并且需要锁定内存中的作业以避免在进行I/O操作时出现错误。 备份存储(Backing store)也会存在类似的问题。 Paging Paging 进程的物理地址空间可以是离散的：这意味着一个进程的不同部分可以存储在物理内存的不同位置，而不是必须连续。 实现分页的基本方法： 物理内存分块：物理内存被划分为固定大小的块，称为帧（frames）。 逻辑内存分块：逻辑内存（即进程视角下的内存）也被划分为与帧大小相同的块，称为页（pages）。 备份存储分块：备份存储（如硬盘）被划分为与内存帧相同大小的块，以便存储不在物理内存中的页。 页的大小：页的大小通常是2的幂次方，范围在512字节到16MB之间。 页的加载与内存分配： 当进程需要执行时，它的页被加载到内存中任何可用的帧中。 进程在帧可用时被分配内存，这有助于避免外部碎片（内存中未被使用的空间）和不同大小内存块带来的问题。 运行进程所需的内存分配：要运行一个包含n个页的程序，需要找到n个空闲的帧并将程序加载到这些帧中。 页表的作用： 操作系统为每个进程维护一个页表（page table）。 页表包含每个页在物理内存中的帧位置信息。 页表用于将进程的逻辑地址转换为物理地址。 内部碎片问题：内部碎片（internal fragmentation）通常发生在内存分配的最后一个页中，当页未完全使用时。 逻辑地址的分解： 每个逻辑地址分为两部分：页号（p）和页偏移（d）。 页号用作在页表中索引，以找到每个页在物理内存中的基地址。 页偏移与基地址组合，定义了发送给内存单元的实际物理地址。 内存访问次数 对于简单的分页系统，可能只需要一次额外的内存访问来获取页表项。两次访问内存。 对于多级页表（如现代操作系统中常用的），可能需要多次内存访问。每一级页表都可能需要单独的内存访问。n级页表访问n+1次内存。 Address structure 逻辑地址的大小一般要大于物理地址的大小。\n相等的情况：在某些系统中，逻辑地址空间的大小可以与物理地址空间的大小相等。这通常发生在不使用特殊内存管理技术（如分页或分段）的简单系统中。 逻辑地址空间大于物理地址空间：在使用虚拟内存技术的系统中，逻辑地址空间通常大于物理地址空间。这是因为虚拟内存允许操作系统利用硬盘空间作为扩展的内存，使得进程看起来拥有比实际物理内存更多的内存。在这种情况下，逻辑地址用于表示进程的地址空间，而物理地址则是实际存储在物理内存中的地址。 物理地址空间大于逻辑地址空间：这种情况较少见，但在某些特殊的硬件或操作系统设计中可能发生。例如，某些高端服务器或特殊用途的计算机可能具有更大的物理内存，而操作系统可能只允许每个进程访问其中的一部分。 动态关系：在某些系统中，逻辑地址空间和物理地址空间的大小关系可能不是静态固定的，而是根据当前的内存使用情况和操作系统策略动态变化的。\n页的大小跟帧的大小相同，以便进行无缝映射。\nFragmentation 分页式内存管理避免了外部碎片化，但存在内部碎片化问题。 例如，如果页面大小为2048字节，进程大小为72766字节，则需要35个页面，但进程只使用了1086字节的内部碎片。 最坏情况下内部碎片化等于1个页面大小，平均碎片化等于页面大小的一半。 所以页面大小越小越好吗？不是，因为每个页面表项都需要内存，页面大小越小，需要的页面表项越多。\nHardware support 使用一组寄存器用于页表的管理(\u0026lt;256项)。 对于较大的页表(例如100万项)，页表会保存在主内存中。 页表基址寄存器(PTBR)指向页表的位置。 页表长度寄存器(PTLR)表示页表的大小。 在这种方案中，每次数据/指令访问都需要访问两次内存，一次是页表项，一次是数据/指令。 为了解决两次内存访问的问题，使用了一种特殊的、小型的、快速查找的硬件高速缓存，称为翻译旁路缓冲(TLBs)或关联内存。 TLB的功能与内存高速缓存相似，它保存了最近使用的页表项，以加速页号到帧号的映射查找。 TLB \u0026ndash;Translation Look-aside Buffer TLB是一个高速的关联存储器，它包含最近使用的页表项。每个TLB项包含两个部分：键和值(页号，帧号)。给定一个逻辑地址，处理器会同时比较所有键，如果找到匹配的键(命中)，则直接获取对应的帧号并形成物理地址；如果没有找到匹配的键(未命中)，则使用逻辑地址中的页号去索引进程的页表以获取帧号。\n当TLB未命中时(miss)，会将页表项的值加载到TLB中，以便下次更快地访问。TLB通常比较小(64到1024个条目)。需要考虑替换策略(例如LRU)。一些TLB条目可以永久性地固定下来，以便快速访问，例如关键的内核代码的条目。 一些TLB在每条目中存储地址空间标识符(ASID),ASID唯一标识每个进程，用于为该进程提供地址空间保护。ASID允许多个不同的进程同时拥有TLB条目。\nEffective Access Time (EAT) EAT(有效访问时间)是CPU访问内存所需的时间，包括查找TLB的时间和访问内存的时间。其中查找TLB的时间取决于TLB的命中率，即找到页表项的概率。TLB的查找时间是一个常数，假设为ε nanoseconds。访问内存的时间取决于内存的周期时间，假设为θ nanoseconds。 当TLB命中时，有效访问时间EAT = ε + θ； 当TLB未命中时，有效访问时间EAT = (ε + 2θ) * (1 - α) + α * θ 其中α是TLB的命中率。 例如，如果TLB查找时间为20ns，内存周期时间为100ns, TLB命中率为0.8，则有效访问时间为： EAT = (20 + 100) * 0.8 + 20 * 0.2 * 100 = 140ns 如果TLB查找时间为20ns，内存周期时间为100ns, TLB命中率为0.98，则有效访问时间为： EAT = (20 + 100) * 0.98 + 20 * 0.02 * 100 = 122ns\nMemory Protection 内存保护通过在每个帧(frame)上关联保护位来实现。通常这些保护位保存在页表中。 RW位可以定义一个页是可读写的还是只读的，还可以添加更多位来指示页是只执行的等。 页表中的每个条目都带有有效位。 “有效”表示对应的页在进程的逻辑地址空间内，因此是合法的页。 “无效”表示对应的页不在进程的逻辑地址空间内。 也可以使用页表长度寄存器(PTLR)。 任何违反都会导致陷入内核。 Shared Pages Shared Pages是指多个进程共享同一只读(不可变)代码的内存页。这些共享代码必须出现在所有进程的逻辑地址空间中的相同位置。这类似于多个线程共享同一个进程空间。Shared Pages也可以用于进程间通信，如果允许共享读写页的话。 而Private Pages则是指每个进程都有自己的代码和数据的独立内存页。这些私有的代码和数据页可以在逻辑地址空间的任意位置出现。\nStructure of the Page Table Hierarchical Paging 层次页表结构：将页表自身也进行分页，可以减少内存占用。常见的有双级页表。\nHashed Page Tables Hashed Page Tables(散列表页表)在地址空间大于32位时常见。 散列表中的每个条目包含一个链表，其中元素通过哈希函数散列到同一位置。每个元素包含三个字段： (1)虚拟页号 (2)对应的物理页号 (3)指向下一个元素的指针 逻辑页号通过哈希函数散列到散列表中，并与链表中元素的(1)字段进行比较查找匹配项。如果找到匹配项，则提取对应的物理页号(2)。如果没有匹配项，则继续搜索链表中的后续元素以查找匹配逻辑页号。\nInverted Page Tables Inverted Page Table(反向页表)是一种内存管理的数据结构，其包含每个真实内存帧(frame)的一个条目，每个条目包含该帧的虚拟地址以及该帧所属进程的地址空间标识符(ASID)等信息。与标准页表相比，反向页表将虚拟地址空间和物理地址空间颠倒了，从而需要额外的地址空间来存储进程的地址空间信息。\nSegmentation 分段是将程序划分为逻辑上的段（如代码段、数据段、堆段和栈段）的过程，这些段在程序的执行过程中被映射到物理内存。\n程序由多个段组成，每个段是一个逻辑单元，如主程序、过程/函数/方法、公共块、对象、栈/符号表/数组、局部变量/全局变量等。 段的长度各不相同。 段内的元素通过相对于段起始地址的偏移来标识。 分段是一种支持用户对内存这种视图的内存管理方案。 每个段都有自己的名称和长度。\n以下是决定程序分段的几个关键步骤：\n编译阶段： 在编译时，编译器将源代码转换为机器代码，并将其组织成不同的段。 例如，编译器会将程序的函数和方法放入代码段，静态变量放入数据段，等等。 链接阶段： 链接器将编译后的代码（和库代码）合并，形成一个完整的可执行文件。 在这个过程中，链接器决定了各个段的相对位置，并创建了一个包含这些信息的段表。 加载时： 当程序被加载到内存中执行时，操作系统根据可执行文件中的信息，将这些段映射到物理内存。 操作系统还处理如何为这些段分配内存，以及这些段的保护和权限设置。 动态链接： 对于使用动态链接库（DLLs）的程序，某些段可能在程序运行时动态加载。 这种情况下，具体的段分配可能会在程序执行期间发生，而不是在程序启动时一次性完成。 Segmentation Architecture 逻辑地址由段号和偏移组成，如\u0026lt;段号，偏移\u0026gt; 分段表将二维的用户定义地址映射为一维的物理地址，每个表项包含段基址(包含段在内存中的起始物理地址)和段限制(指定段的长度) 分段表基址寄存器(STBR)指向分段表在内存中的位置 分段表长度寄存器(STLR)表示程序使用的段数 如果段号s小于STLR，则段号s是合法的。 Fragmentation 在分段式内存管理中，内存是根据段的大小动态分配的。每个段的大小根据程序的需求而定，并不是固定的。 然而，随着程序的加载和卸载，内存中会出现不连续的空闲区域。这些零散的空闲区域可能无法被有效利用，尤其是当需要分配一个大的内存段时，即使总空闲内存量足够，但由于这些空闲区域是分散的，无法满足连续内存的需求。 这种情况称为外部碎片。它发生在已分配内存块的外部，因此得名“外部碎片”。 Segmentation With Paging 段页式内存管理是一种计算机内存管理技术，它结合了分段和分页两种方法。在这种方案中，地址空间被分成多个段，每个段进一步被划分为多个页。地址映射表在段页式内存管理中扮演着至关重要的角色，它负责将虚拟地址转换为物理地址。下面是段页式内存管理中地址映射的基本过程：\n虚拟地址结构：在段页式管理中，虚拟地址通常包含两部分——段号和段内偏移。段内偏移进一步分为页号和页内偏移。 段表：系统为每个进程维护一个段表，段表存储每个段的信息，如段的基址、大小等。段表还包括指向页表的指针。 页表：每个段有一个页表，页表存储页的物理地址信息。页表负责将段内的虚拟页号映射到物理内存的页帧号。 地址转换过程： 根据虚拟地址中的段号，访问段表，获取段的基本信息和对应的页表地址。 使用虚拟地址中的页号，访问该段的页表，找到对应页的物理帧号。 将物理帧号与虚拟地址中的页内偏移结合，形成最终的物理地址。 段页存储不会产生外部碎片，因位先分段，再分页，分页后就离散化了，每个页可以分在内存的任何一个页，这个段页就成了逻辑上的概念，实质上变成了分页的管理，所以按照分页来看，是没有外部碎片的。那些理解成在一个段内再分页的同鞋，你们理解错啦！比如A页和B页逻辑上是在1号段里面，但是分页后，A页可以存在内存的任何地方B页也是，在实际的内存存放这两个页的时候，并不是先在内存化出一个段的长度出来，然后在段内分页的！\nVirtual Memory Background 代码需要加载到内存中才能执行，但整个程序很少被全部使用到。例如错误代码、不寻常的程序、大的数据结构等只需要程序的一部分代码。 整个程序代码不需要同时都在内存中。 考虑执行只部分加载的程序的能力。程序不再受物理内存的限制，每个程序在运行时需要更少的内存，因此可以在相同时间内运行更多的程序。 提高了CPU利用率和吞吐量，而响应时间和周转时间没有增加。 加载或交换程序到内存时需要的I/O更少，每个用户程序运行得更快。 虚拟内存将用户逻辑内存与物理内存分离。其主要优点包括：\n只需要程序的一部分在内存中执行，逻辑地址空间可以比物理地址空间大很多。 允许多个进程共享逻辑地址空间。 允许更高效地创建进程。 可以并发运行更多的程序。 加载或交换进程时需要的I/O更少。 按需分配内存，提高内存利用率。 Virtual-address Space虚拟地址空间是进程在内存中的逻辑视图。 它从地址0开始，地址连续直到空间结束。 物理内存以页框(page frames)的形式组织。 内存管理单元(MMU)将逻辑地址映射到物理地址。 虚拟地址空间可以比物理内存大。\nDemand Paging 需求分页是在程序需要使用某页时才将其调入内存，而不是预先将整个程序加载到内存中。它通过延迟换页(Lazy swapper)来避免不必要的内存交换。需求分页由交换程序(Swapper)负责操作整个进程，而页面程序(Pager)负责操作进程中的单个页面。当程序需要某页时，会引用它，如果该页已经在内存中，则无需换页；如果该页不在内存中，则需要检测并将其调入内存。需求分页不需要改变程序的行为，也不需要程序员改变代码。它实现了按需分配内存，提高了内存利用率。\nValid-Invalid Bit Valid-Invalid Bit(有效无效位)是与每个页表项相关联的一个位。它表示该页表项所对应的页面是否有效且在内存中。\n如果有效无效位是v，则表示页面有效且在内存中。 如果有效无效位是i，则表示页面无效或有效但不在内存中。 初始时，页表中所有页表项的有效无效位都设置为i。 当一个页面被加载到帧中时，该帧的帧号会被写入页表项，并将有效无效位设置为v。 在地址转换过程中，如果页表项中的有效无效位是i，则表示产生缺页异常。 Steps in Handling a Page Fault 如果程序访问一个未在内存中的页面，首先会产生一个页面错误中断。 操作系统会查看一个内部表格(一般指页表，与进程控制块PCB一起保存)来决定如何处理： 如果是无效的访问，则中止进程。 如果访问有效但页面不在内存中，则将页面调入内存。 找到一个空闲的帧(frame)。 通过计划磁盘操作将页面读入帧中。 重置页面表，将帧号写入页面表项，设置验证位\u0026quot;v\u0026quot;。 重新启动导致页面错误的指令。 Aspects of Demand Paging 纯按需分页是一种极端情况，在进程启动时，内存中没有任何页面。操作系统会将指令指针设置为进程的第一个指令，由于页面不在内存中，会导致缺页异常。 对于每个进程，在第一次访问时也会发生页面错误。 实际上，一个指令可能需要访问多个页面，所以会导致多次页面错误。例如，取指令和译码指令从内存中取出两个数字并存储结果，会访问4个页面，导致4次页面错误。但由于参考的局部性，这种痛苦程度会减小。 按需分页需要硬件支持，包括带有有效位无效位的页表和用于交换的二级存储(交换设备)。 在缺页异常时，需要重置指令指针，重新启动进程。 Stages in Demand Paging (worse case) 需求页面的最坏情况下的步骤如下：\n中断到操作系统。 保存用户寄存器和进程状态。 确定中断是一个页面故障。 检查页面引用是否合法，并确定页面在磁盘上的位置。 从磁盘向一个空闲帧发出读取请求： ① 在此设备队列中等待读取请求得到服务。 ② 等待设备查找和/或延迟时间。 ③ 开始将页面传输到空闲帧。 在等待期间，将CPU分配给其他用户。 从磁盘输入/输出子系统接收中断(I/O完成)。 保存其他用户的寄存器和进程状态。 确定中断来自磁盘。 修改页表和其他表，以显示页面现在在内存中。 准备好，等待CPU再次分配给此进程。 恢复用户寄存器，进程状态和新页表，然后继续中断的指令。 Performance of Demand Paging 有效访问时间EAT=(1-p)×memory access time+p×page fault service time\nCopy-on-write COW(Copy-on-Write)允许父进程和子进程在内存中共享相同的页面。只有当一个进程修改共享页面时，才会进行页面复制。这可以更高效地进行进程创建，因为只需要复制修改过的页面。只需要标记可以修改的页面为COW即可。\n空闲页面通常从一个空闲页面池中分配。池中应该总是有空的页面帧，以便快速执行按需页面替换。在分配页面之前，通常会使用零填充技术，将页面清零，擦除其之前的内容。 vfork()不使用写时复制技术。它通过挂起父进程并让子进程使用父进程的地址空间来实现高效的进程创建。 如果子进程修改了父进程的地址空间中的任何页面，这些修改在父进程恢复时将可见。 vfork()的设计是让子进程立即调用exec()函数。它是一种非常高效的进程创建方法，有时用于实现UNIX命令行shell接口。\nPage Replacement 页面替换是因为进程页面和内核/I/O缓冲区等都需要使用内存空间。 需要决定为进程页面、内核和I/O缓冲区等分配多少内存空间。 可以为I/O缓冲区预留一个固定的内存百分比。也可以让用户进程和I/O子系统竞争使用全部内存。 如果内存中没有空闲页面，可以终止用户进程、交换进程或者进行页面替换。 页面替换可以提高内存利用率，让更多进程并发执行，对用户透明。 Basic Page Replacement 基本页面替换算法包括以下步骤：\n在磁盘上查找所需页面的位置。 找到一个空闲页面帧： 如果有一个空闲页面帧，就使用它。 如果没有空闲页面帧，使用页面替换算法选择一个牺牲页面帧。 将牺牲页面帧写入磁盘，如果脏页面，还需要更改页面和页面帧表。 将所需页面读入到刚释放的页面帧中。 更新页面和页面帧表。 通过重新启动引起中断的指令，继续执行进程。 现在可能需要2次页面传输(1次出栈和1次进栈)，增加了有效访问时间。 当发生页面替换，例如将内存中的 page0 替换为 page1 时，操作系统需要执行以下步骤来更新页表和内存：\n选择替换页面：首先，操作系统使用页面置换算法（如 LRU、FIFO、时钟算法等）来选择一个要被替换出内存的页面。假设 page0 被选中。 检查替换页面的状态： 如果 page0 被修改过（脏页面），操作系统需要将它的内容写回到辅助存储（如硬盘）。这确保了修改被保存，以便将来再次访问时可以从辅助存储中重新加载。 如果 page0 未被修改（干净页面），可以直接将其从内存中移除，因为辅助存储上已有其最新副本。 更新页表： 修改 page0 对应的页表项，将其有效-无效位设置为无效（i）。这表明 page0 不再位于物理内存中。 为 page1 创建或更新相应的页表项，包括指向新分配的物理帧的帧号，并将其有效-无效位设置为有效（v）。 将新页面调入内存： 将 page1 从辅助存储读取到刚刚释放的帧中。这个过程可能涉及到磁盘的I/O操作。 重置访问控制信息：对于新调入内存的 page1，可能需要重置或更新与其相关的访问控制信息，如使用频率、最近访问时间等，这些信息常用于页面置换算法。 重新执行指令：最后，操作系统将控制权返回给导致缺页异常的程序，允许它重试原本失败的内存访问操作。由于 page1 现在已经在内存中，该操作应能够成功执行。 整个过程中，操作系统确保了内存中的数据与辅助存储之间的一致性，并通过页表项的更新保持了虚拟地址到物理地址映射的准确性。这样，进程就可以无缝地继续运行，即使其内存页面发生了替换。\n使用修改位(dirty bit)可以减少页面传输的开销。修改位用于表示页面自从上次加载到内存后是否被修改过。只有修改过的页面才会被写入磁盘。页面替换完成了逻辑内存和物理内存的分离。大容量的虚拟内存可以在较小的物理内存上提供。如果没有按需页面替换，一个进程的所有页面仍然必须驻留在物理内存中。\n帧分配算法决定了每个进程应该获得多少帧以及当发生缺页时应该替换哪些帧。页面替换算法希望在首次访问和再次访问时都能获得最低的缺页率，被替换的页面应该是未来最不可能被引用的页面。页面替换算法旨在获得页面故障的最小数量。评估页面替换算法的方法是，在特定的内存引用序列上运行算法，并计算该序列上的页面故障数量。\nreference strings FIFO (First-In-First-Out) Algorithm 先进先出\nBelady’s anomaly证明了在使用先入先出(FIFO)页面替换算法时，增加页面帧数量反而可能导致更多缺页中断。例如，对于参考字符串3,2,1,0,3,2,4,3,2,1,0,4,3槽，总共获得9次缺页中断，但如果增加槽数到4，则总共获得10次缺页中断。\nOptimal Algorithm 替换将来最长时间没被使用的。\nLeast Recently Used Algorithm 选择最长时间未被访问的页面进行替换。\nLRU implementation LRU(Least Recently Used)页面置换算法的实现需要硬件支持，主要问题是确定各个页面最后一次被使用的顺序。每个页面都包含一个计数器和时间使用字段，CPU需要增加一个逻辑时钟或计数器，每次内存访问时都会增加该计数器的值。每次访问页面时，会将计数器的值复制到页表中该页面的时间使用字段。当需要替换页面时，会查看各个计数器的值，选择具有最小时间值的页面进行替换。\n页面置换算法的实现可以使用栈来维护一个页面号码的双链表。当页面被引用时，将其移动到栈顶；不需要搜索替换页面，LRU页面总是在栈底。\nLRU Approximation Algorithms LRU 需要特殊硬件并且仍然缓慢。\n为每个页面条目关联一个比特，初始设置为0。\n当页面被引用时，由硬件将该比特置为1。\n替换值为0的页面条目(如果存在的话)。\n问题：我们不知道页面的顺序。\n每个页面在内存中的表中关联一个8位的字节。\n在定期的定时器中断中，操作系统将每个页面的引用位移入8位字节的最高位，将其他位右移1位并丢弃最低位。\n每个8位字节包含过去8个时间段中页面使用的状态。\n数值最低的页面是LRU页面，可以被替换。\nSecond chance 算法是一个FIFO页面置换算法的变种，它需要额外的参考位(reference bit)来跟踪每个页面的最近访问时间。当需要替换一个页面时，如果该页面最近被访问过(参考位为1)，则不替换该页面，而是将下一个页面(按时钟顺序)替换出去。这样可以减少页面替换的次数，提高效率。\nEnhanced Second-Chance算法考虑了参考位和修改位，将每个页面分为四个类别：\n(0,0) 既未被最近访问也未被修改的页面，是最理想的替换对象。 (0,1) 未被最近访问但已被修改的页面，在替换前需要先写回磁盘。 (1,0) 最近被访问但内容未被修改的页面，很可能很快会被再次访问。 (1,1) 最近被访问且内容已被修改的页面，在替换前需要先写回磁盘。 根据页面所属类别，从最低的非空类别中遇到的第一个页面开始替换。可能需要多次搜索环形队列。 Counting-based page replacement 算法通过为每个页面维护一个引用计数器来统计页面被访问的次数。 LFU (Least Frequently Used) 算法根据计数器的值选择引用次数最少的页面进行替换。 MFU (Most Frequently Used) 算法则选择引用次数最多的页面进行替换，认为引用次数最多的页面最有可能正在被使用。 这两种算法都不太常见，因为它们需要为每个页面维护引用计数器，增加了实现的复杂性。\nPage-Buffering Algorithm 该算法维护一个空闲帧的池子。当发生页面错误时，先选择一个受害帧，然后在受害帧被写出之前，将所需页面读入池中的一个空闲帧。当受害帧稍后被写出时，其帧被添加到空闲帧池中。可能还会维护一个被修改页面的列表。每当分页设备空闲时，选择一个被修改的页面并将其写入磁盘，然后重置其修改位。还可能保持一个空闲帧的池子，但要记住每个帧中有哪个页面。如果在该帧被重用之前需要旧页面，可以直接从空闲帧池中重用该页面。\nAllocation of Frames 操作系统中每个进程需要的最小页面数。\n这个需求根据进程使用的指令类型和内存寻址方式而变化。例如，仅使用单一内存地址指令的进程至少需要两个帧，而允许一级间接寻址的进程至少需要三个帧。特定指令，如PDP-11上的移动指令或IBM 370上的MVC指令，可能需要六页，因为它们复杂并可能涉及间接引用。该部分还提到了两种主要的帧分配方案：固定分配和优先级分配。这些分配方法确保了内存的有效使用，避免浪费。\nFixed Allocation 等量分配：例如，如果有93个帧和5个进程，每个进程分配18个帧，剩余的3个帧用作空闲帧缓冲池。 比例分配：根据每个进程的大小分配可用内存。具体来说，每个进程的虚拟内存大小为si，总虚拟内存为S（所有si之和）。每个进程的分配比例（ai）是其虚拟内存大小（si）除以总虚拟内存（S），乘以总帧数（m）。每个进程的分配数（ai）调整为大于其最小帧数的整数，且总和不超过m。分配可能根据多程序级别而变化。 Priority Allocation 使用基于优先级而非大小的比例分配方案，或者结合大小和优先级来进行分配。\n这种分配是动态的，随着多程序级别和进程大小的变化而变化。\n如果进程 P i 发生页面错误，选择替换它的某个帧。局部替换是从优先级较低的进程中选择替换一个帧。全局替换则是从整个系统范围内选择替换一个帧。\nGlobal vs. Local replacement 全局替换（Global Replacement）和局部替换（Local Replacement）是操作系统中页面替换策略的两种不同方法，它们用于决定当发生页面错误（Page Fault）时，应该从内存中移除哪个页面以便为新页面腾出空间。\n全局替换 (Global Replacement): 在全局替换策略中，当某个进程需要替换页面时，它可以从整个系统的内存帧中选择一个页面进行替换。这意味着一个进程可能会取代（或“偷取”）另一个进程的内存页面。 这种方法由操作系统来管理，它维护一个所有空闲帧的列表。当发生页面错误时，操作系统会从这个列表中选择一个页面来替换。 优点是可以提高系统吞吐量（即整个系统的效率和性能），因为它可以更灵活地分配和管理内存资源。 缺点是单个进程可能无法有效控制自己的页面错误率，因为它的页面可能被其他进程所替换。 局部替换 (Local Replacement): 局部替换策略限制页面替换仅在发生页面错误的那个进程的内存帧中进行。这意味着进程只能替换属于自己的页面。 在这种策略下，每个进程的页面错误完全由该进程自己的分页行为决定，不受其他进程的影响。 优点是进程对自己的内存管理有更大的控制权，可以更好地优化自己的页面错误率。 缺点是可能导致整体系统吞吐量降低，因为内存资源分配可能不如全局替换那样灵活和高效。 Thrashing Thrashing Thrashing(过度换页)是指当一个进程没有足够数量的页面时，页面故障率非常高。每次页面故障需要获取页面，替换现有的页面，但很快需要替换回原来的页面，这会导致：\n低CPU利用率，因为大部分时间都在进行页面替换 操作系统认为需要增加多进程的程度 向系统中添加另一个进程 当一个进程花费大部分时间在页面替换而不是执行时，就说明该进程处于过度换页状态。要避免过度换页，必须为进程分配足够数量的页面。 thrashing的发生是因为：\n进程的局部性大小(locality size)大于总内存大小(total memory size)。 使用了局部(或优先级)页面替换算法，这可以限制抖动的影响。 为了防止抖动，必须为进程提供它需要的所有页面。 如何知道进程需要多少页面？\n通过查看进程实际上使用的页面数量来确定。 进程执行的局部性模型是：\n局部性：一组正在一起使用的页面。 进程从一个局部性迁移到另一个局部性。 局部性可能重叠。 Working-Set Model 工作集窗口大小Δ: 这是衡量工作集大小的一个关键参数，表示在一定数量的页面引用中考虑的页面集合。例如，如果Δ是10,000，那么工作集包括最近10,000个页面引用。 工作集（Working Set）: 它是在最近Δ个页面引用中出现的那些页面的集合。这反映了一个进程在最近一段时间内的内存使用情况。 WSSi（进程Pi的工作集大小）: 这是指在特定时刻进程Pi的工作集中页面的数量。这个数字随时间变化，因为进程的内存需求可能会增加或减少。 工作集大小的准确性与Δ的选择有关: 如果Δ设置得太小，可能无法准确反映进程的内存需求；如果设置得太大，可能会过度估计所需的内存。理想的Δ值应该能够合理反映进程的实际内存使用模式。 总工作集大小D: 它是所有进程工作集大小的总和，用于近似表示程序的局部性（即内存访问的局限性）。如果D超过了系统中可用的内存帧数量m，可能会导致频繁的页面调度和内存抖动，就需要挂起一个进程。难点在于持续跟踪工作集。 跟踪工作集的方法：通过定期中断和维护页面访问位来跟踪工作集。这种方法有助于识别哪些页面属于当前的工作集，但可能无法精确反映快速变化的工作集。 使用定时器定期中断，例如每隔5000时间单位中断一次。 为每个页面维护两个内存位，一个用于记录页面最近一次被访问的时间，一个用于记录页面是否在工作集中。 在定时器中断时，将所有页面的访问时间位清零，并将工作集中的页面的访问时间位置1。 根据页面访问时间位判断页面是否在工作集中。 改进方法: 通过增加历史位数量和提高定时器中断频率，可以更准确地跟踪页面的工作集。这有助于操作系统更有效地管理内存，减少页面错误和提高系统性能。 Page-Fault Frequency Scheme Page-Fault Frequency Scheme是一种更直接的工作集模型替代方法。 它通过建立一个可接受的页面故障率，并使用局部替换策略来控制页面故障频率。如果实际的页面故障率过低，进程会丢失一个页面框；如果实际的页面故障率过高，进程会增加一个页面框。选择一个进程，将其交换到外部存储设备。\nMemory-mapped file Memory-mapped files(内存映射文件)通过将磁盘块映射到内存页中来简化并加速文件访问。文件初始化时使用按需调页，将文件系统中的一个页大小的文件块装入物理帧。后续的读写操作都被视为普通的内存访问。当数据被写入内存时，会在页缓存扫描脏页时或者文件关闭时才写入磁盘。\n一些操作系统(例如Solaris)选择通过特定的系统调用(如mmap())将文件映射到内存，而一些操作系统则通过特定的系统调用(如mmap())将文件映射到内核地址空间。这使得进程可以像访问内存一样访问文件，而不需要通过标准的I/O操作(open(), read(), write(), close())。这种方式利用了高效的内存管理子系统。\nMemory-mapped files允许多个进程同时映射同一个文件，从而在内存中共享该文件的页面。\nCOW(Copy-on-Write)可以用于读/写非共享页面。它允许进程以只读模式共享文件，但每个进程都可以对其修改的数据保留自己的副本。 内存映射文件可以用于共享内存。\nMemory-mapped I/O是将内存地址映射到设备寄存器，通过读写这些内存地址来在CPU和设备之间传输数据。这种方式适用于响应时间较快的设备，如视频控制器。它也可以用于其他设备，如串口和并口，用于连接调制解调器和打印机到计算机。通过这种方式，CPU通过读写几个设备寄存器(I/O端口)来与这些设备进行数据传输。\nAllocating Kernel Memory 内核内存与用户内存不同，它通常从一个不同的空闲内存池中分配，而不是和普通用户模式进程使用的内存池相同。原因有两点：\n内核请求不同大小的数据结构内存，有些小于一个页面的大小。 一些内核内存需要是连续的，例如用于设备I/O。某些硬件设备需要直接与物理内存交互，可能需要连续的内存页面。 内核内存分配使用Buddy System伙伴系统和Slab allocation两种方式。\nBuddy System 伙伴系统(Buddy System)将内存从一个固定大小的内存段中分配，该内存段由物理上连续的页面组成。 伙伴系统使用2的幂次方大小的分配器。 内存以2的幂次方大小的单元分配。 请求大小向上取2的下一个最高幂次方。 整个可用的内存空间被看作是一个大小为2U的单一块。 如果请求大小在2U-1和2U之间，则整个块被分配。 否则，块被分成两个大小相等的伙伴块。 进程继续，直到生成一个最小大小为s的块。\nSlab Allocation 将物理内存划分为固定大小的内存块，称为slab。 将多个slab组成一个缓存(cache)。 为每个内核数据结构(如进程控制块PCB)创建一个单独的缓存。 在创建缓存时，先将缓存填充一些初始化的空对象。 当需要使用该内核数据结构时，从缓存中分配一个对象(实例)并标记为已使用。 当缓存中的对象都标记为已使用时，需要分配新的slab来扩展缓存。 该分配方式可以避免内存碎片，同时可以快速地满足内存请求。 Other considerations Prepaging Prepaging是为了减少进程启动或者换出进程重新启动时产生的大量缺页中断。它通过提前将进程需要的页面加载到内存中来实现。如果预加载的页面没有被使用，就会浪费I/O和内存资源。预加载页面有一定的优势，需要比较使用预加载页面的成本和处理相应缺页中断的成本，来判断是否使用预加载页面。例如，如果预加载S个页面，实际上只使用了Sa个页面(0\u0026lt;a\u0026lt;1)，那么预加载S个页面的成本是否小于处理S(1-a)个不必要的缺页中断的成本。如果a接近1，预加载就更有优势。\nPage Size 页面表的大小：每个活跃进程都需要一个自己的页面表副本，所以较大的页面大小是可取的。 碎片化：为了最小化内部碎片化，需要较小的页面大小。 I/O开销：I/O时间主要由搜索时间和延迟时间组成，而传输时间通常较小。为了最小化I/O时间，需要较大的页面大小。 局部性：较小的页面大小可以改善局部性，减少总的I/O。但是为了最小化页面错误，需要较大的页面大小。 页面大小通常在4KB到4MB之间选择。 所以页面大小需要在减小碎片化和I/O开销与提高局部性和减少页面错误之间做权衡。 TLB Reach TLB Reach指的是从TLB(Translation Lookaside Buffer)可以访问的内存范围。 TLB Reach = (TLB Size) x (Page Size) 理想情况下，每个进程的工作集应该存储在TLB中。否则，页面错误率会很高，进程会在页表中花费大量时间而不是TLB中解析内存引用。 增加TLB Reach的方法包括：\n增加Page Size，但这可能会导致碎片化增加，因为不是所有应用程序都需要大Page Size。 提供多种Page Size，这可以让需要大Page Size的应用程序使用它们，而不会增加碎片化。 Inverted Page Tables Inverted Page Tables的目的是减少跟踪虚拟到物理地址转换所需的物理内存。它使用一个表项来跟踪每个物理帧中的虚拟内存页，表项由进程ID和页面号索引。当发生页面错误时，还需要其他信息，例如每个虚拟页的位置和页面数量。必须为每个进程保留一个外部页面表，根据需要进行页面换入和换出。页面错误现在可能需要生成另一个页面错误来换入需要的页面表。\nProgram Structure 仔细选择数据结构和编程结构可以提高局部性，从而降低缺页错误率和工作集中的页面数量。例如，栈具有很好的局部性，因为访问总是从栈顶开始。而散列表则设计成散布引用，产生较差的局部性。编译器和加载器对页面管理有很大影响。将代码和数据分离并生成可重入代码意味着代码页可以只读，永远不会被修改。加载器可以避免将程序段放在跨页面边界位置。经常相互调用的程序段可以打包到同一页面中。\nI/O interlock 考虑挂起的I/O操作：\n用于设备I/O的内存页必须被锁定，防止被页面替换算法选中用于淘汰。 不允许直接对用户内存执行I/O操作。 数据在系统内存和用户内存之间进行复制。 I/O操作只在系统内存和I/O设备之间进行。 允许将页面锁定到内存中：\n每个帧都关联一个锁定位。 被锁定的页面不能被替换。 当I/O完成后，页面解锁。 页面固定来锁定到内存中：\n操作系统内核的部分或全部被锁定在内存中。 用户进程可能需要将页面锁定到内存中。 考虑到具有需求分页、优先级调度和全局替换的系统： 低优先级进程L发生缺页。 操作系统选择一个替换帧，并调入所需页面。 然后，L进入就绪队列，可能长时间不被选中。 当L等待时，高优先级进程H发生缺页。 寻找替换页面时，可能是L刚调入的页面—它是干净的，且长时间未使用。 使用锁定位来防止新调入页面的替换，直到至少被使用一次：\n当页面被选为替换对象时，其锁定位被打开。 锁定保持到引起缺页的进程再次被调度。 大多数操作系统都提供系统调用，允许应用请求将其逻辑地址空间的一部分固定。\n危险性：锁定位可能被打开但永远不关闭。\n被锁定的帧变得无法使用。 ","date":"2023-12-25T19:54:47Z","permalink":"https://www.xxx.blog/post/6-main-memory-and-virtual-memory/","title":"6 Main Memory And Virtual Memory"},{"content":"Deadlocks System Model Resource types：系统中有多种资源类型，包括 CPU、内存空间、文件、I/O 设备（如打印机等）。 资源可以分为物理资源和逻辑资源。 physical resources：preemptive resources，如 CPU、内存；non-preemptive resources，如打印机。 logical resources：temporary resources, known as consumable resources 资源实例：每个资源类型都有若干个实例。 进程如何使用资源：每个进程根据其需求请求、使用和释放资源。 system table：系统表记录了每个资源的状态（自由或分配），以及若资源分配给哪个进程。 请求、使用和释放：进程在需要资源时发起请求，获得资源后进行使用，并在完成任务后释放资源。 Deadlock Characterization 死锁特征是指一组进程在运行过程中，由于资源争用导致的一种特殊状态，即这些进程都在等待对方释放资源，从而导致进程无法继续执行。\n死锁的特征主要包括以下几点：\n互斥性：至少有两个进程在争夺同一资源，且至少有一个进程已经持有了该资源。 请求与等待：进程请求获取它所需要的资源，但该资源已被其他进程占用，因此请求进程处于等待状态。 不可剥夺性：已分配给进程的资源在未被该进程释放前，其他进程无法强行占用。 循环等待：存在一个进程链，每个进程都在等待下一个进程所持有的资源。 当以上特征同时满足时，系统就容易出现死锁现象。理解死锁特征有助于分析和预防死锁的发生，从而确保系统资源的合理分配和进程的正常运行。 Resource-Allocation Graph 资源分配图是一种用于描述多个进程在请求和分配资源过程中的关系图表。 在资源分配图中，每个进程用一个节点表示，每条边表示一个进程请求或分配一个资源。\n节点V：图表中的节点代表进程。每个节点包含当前进程已经分配的资源数量以及尚未请求的资源数量。 P表示进程 R表示资源 边E：图表中的边表示进程之间的资源请求关系。边有两种类型： 请求边request edge：表示一个进程可能请求另一个进程所持有的资源。请求边用虚线表示。 分配边assignment edge：表示一个进程已经分配了某个资源。分配边用实线表示。 循环：在资源分配图中，如果存在一个进程链，每个进程都在等待下一个进程所持有的资源，那么就形成了循环等待。循环等待是导致死锁的一个关键条件。 循环在资源分配图中起着关键作用，可以用来判断系统是否会发生死锁。当循环中每个资源类型只有一个实例时，系统必然会发生死锁。而当循环中的资源类型有多个实例时，虽然死锁的可能性较高，但并非必然发生死锁。 安全状态与不安全状态： 安全状态是指不存在循环等待的情况下，系统可以分配资源给进程而不会导致死锁。 不安全状态是指存在循环等待，系统分配资源可能导致死锁的情况。 通过检查资源分配图中的循环等待，系统可以确定哪些资源分配是安全的，哪些是不安全的。在不安全情况下，系统可以采取措施推迟进程的资源分配，直到资源请求不会导致死锁。 Methods for Handling Deadlocks 死锁预防 Deadlock-prevention：通过制定严格的资源请求顺序，预先避免死锁的发生。例如，为所有资源类型设定一个全局排序，并要求进程按照资源编号的升序请求资源。 死锁避免 Deadlock-avoidance：在系统运行过程中，通过检测潜在的死锁情况并采取措施避免它们。例如，使用银行家算法（Banker Algorithm）来预先分配资源，确保不会发生资源请求冲突。 允许系统进入死锁状态，检测到死锁后进行恢复（Deadlock Detection and Recovery）： 检测：通过一定的算法和策略检测到系统中的死锁情况。 恢复：当死锁发生时，通过终止进程、抢占资源或回滚进程状态等方法解除死锁。 忽略问题（Deadlock Ignoration）：假装死锁在系统中永远不会发生。大多数操作系统（包括 UNIX 和 Windows）都采用这种方法。 Deadlock Prevention 互斥性（Mutual Exclusion）是指对于不可共享的资源，进程之间需要相互排斥，确保同一时间只有一个进程可以使用该资源；而对于可共享的资源，则不需要互斥性。 持有等待（Hold and Wait）意味着进程在请求新资源时，不能持有其他资源。 这里提供了两种持有等待的策略： 进程在开始执行前，需要请求并分配所有所需资源。但这种方法的缺点是资源利用率低。 只在进程没有资源时才请求资源（先释放资源）。但这种方法的缺点是可能导致进程饥饿（starvation）。 不预先分配资源（No Preemption）。 该策略有两种实现方式： 当一个进程请求资源时，其已经持有的资源会被抢占。进程必须在没有资源的情况下等待。 如果一个持有资源的进程请求一个无法立即分配的资源，那么它将释放当前持有的所有资源。 被抢占的资源会被添加到进程等待的资源列表中。 进程在持有资源的情况下等待，但持有的资源可能会被其他请求这些资源的进程抢占。 这种策略通常适用于状态容易保存和恢复的资源，如 CPU 寄存器和内存空间。 循环等待（Circular Wait）。该策略要求对所有资源类型进行 total 排序，并规定每个进程按资源类型请求的顺序递增。 每个资源的排序位置由 F(Ri) 确定。 该策略有两种实现方式： 进程可以请求资源类型 Rj 的实例，条件是 F(Rj) \u0026gt; F(Ri)。如果需要多个相同资源类型的实例，进程必须一次请求所有实例。 每当进程请求资源类型 Rj 的实例时，它需要释放任何 F(Ri) ≥ F(Rj) 的资源。 这样可以确保系统在资源分配时遵循一定的顺序，从而降低死锁的可能性。 Deadlock Avoidance 每个进程声明可能需要的每种资源的最大数量。 死锁避免算法动态检查资源分配状态，以防止循环等待条件出现。 资源分配状态包括可用资源、已分配资源和进程的最大需求。\nSafe State 安全状态（Safe State）是指在系统中，所有进程都能够继续执行，且不会发生死锁的状态。在安全状态下，系统的资源分配满足以下条件：\n对于每个进程 Pi，其尚未请求到的资源可以通过当前可用的资源加上所有进程 Pj（其中 j\u0026lt;i）已持有的资源来满足。 如果某个进程需要的资源暂时不可用，那么该进程需要等待，直到所有进程 Pj 完成任务。 当一个进程完成任务后，它释放已持有的资源，然后继续执行下一个任务。 Resource-Allocation Graph Algorithm 资源分配图算法被用来检测系统是否处于安全状态，以避免死锁的发生。 该算法主要应用于单实例资源分配系统，通过分析资源分配图，判断资源分配是否会导致死锁。\n创建一个资源分配图，其中节点表示进程，边表示进程对资源的请求，框里点的个数表示资源个数。 使用深度优先搜索（DFS）或广度优先搜索（BFS）算法检测图中是否存在循环。 如果no circle，说明系统处于安全状态，一定没有死锁，可以进行资源分配。 如果找到循环，说明系统处于不安全状态，此时进程必须等待其他进程释放资源以避免死锁。 如果每个资源类型只有一个实例，并且这个实例被循环中的进程所持有，那么就会发生死锁。 如果循环中涉及到的每个资源类型都有多个实例，那么可能会发生死锁。 在这种情况下，尽管图中存在循环，这表明至少有一个进程在等待另一个进程释放资源，但由于每个资源类型有多个实例，因此理论上，如果循环中的进程能够获取到它们需要的资源的一个替代实例，那么死锁可以避免。因此，循环是死锁存在的必要条件，但不是充分条件。即使存在循环，只要资源分配得当，死锁是可以避免的。 \u0026ldquo;一个实例\u0026quot;通常指的是一种特定类型的资源的单个副本。假设有一个资源类型是“打印机”，那么系统中可能会有多台打印机。\n在资源分配图算法中，进程请求资源的过程如下：\n进程 Pi 请求资源 Rj。 检查将 Pi → Rj 转换为 Rj → Pi 是否会导致图中的循环。 如果没有导致循环，则允许资源分配，进程继续执行；否则，进程 Pi 需要等待。 Banker’s Algorithm 银行家算法（Banker\u0026rsquo;s Algorithm），它适用于多个实例的资源分配系统。进程需要在事先声明它们可能需要的每种资源的最大数量。当进程请求一组资源时，系统必须检查分配这些资源是否会使得系统处于安全状态。如果可以，则分配资源；否则，进程必须等待其他进程释放足够的资源。当进程获得所有所需资源后，它必须在有限的时间内归还这些资源。 银行家算法所需的数据结构:\nn：表示进程的数量。 m：表示资源类型的数量。 以下是数据结构的具体组成部分： Available：一个长度为 m 的向量。如果 Available[j] = k，意味着有 k 个 Rj 类型的资源可用。 Max：一个 n×m 的矩阵。如果 Max[i, j] = k，表示进程 Pi 最多可能请求 k 个 Rj 类型的资源。 Allocation：一个 n×m 的矩阵。如果 Allocation[i, j] = k，说明进程 Pi 目前分配了 k 个 Rj 类型的资源。 Need：一个 n×m 的矩阵。如果 Need[i, j] = k，表示进程 Pi 可能还需要 k 个 Rj 类型的资源来完成任务。 Need[i, j] 的计算公式为：Need[i, j] = Max[i, j] - Allocation[i, j]。 向量 X 和 Y，长度都是 n。X≤Y 表示向量 X 中的每个元素都小于或等于向量 Y 中的对应元素。也就是说，对于所有的 i=1，2，\u0026hellip;，n，都有 X[i]≤Y[i]。 矩阵 allocution 和 need 的每一行都可以看作是一个向量，分别被称为 $allocution_i$ 和 $need_i$。其中： $Allocation_i$ 表示当前分配给进程 Pi 的资源。 $Need_i$ 表示进程 Pi 可能还需要完成的任务所需的额外资源。 Safety Algorithm Safety Algorithm 的主要步骤：\n初始化：设置 Work 向量为可用资源，Finish 向量为长度为 n 的 vector，初始状态下，所有进程的 Finish 变量都为 false。 寻找一个索引 i，满足以下条件： a. Finish[i] 为 false b. Needi ≤ Work 如果找不到这样的 i，则执行步骤 4。 分配资源：将分配给进程 Pi 的资源添加到 Work 向量中，并将 Finish[i] 设置为 true。然后返回步骤 2。 检查系统状态：如果所有进程的 Finish[i] 都为 true，则系统处于安全状态。 Resource-Request Algorithm 【资源请求算法】（Resource-Request Algorithm）是一种在操作系统中处理资源分配和死锁问题的一种方法。该算法主要涉及到进程在请求资源时，如何判断和处理请求是否会影响系统的安全性。 在资源请求算法中，有以下几个关键点：\n每个进程都有一个请求向量（request vector），用于表示该进程所需的各种资源类型及其数量。 当一个进程请求某个资源时，系统需要检查该请求是否符合以下条件：\na. 请求的资源数量不超过进程所需的最大资源数量。\nb. 请求资源后，系统仍然处于安全状态。 系统通过检查进程的请求向量和当前系统中的可用资源，来判断请求是否可以被满足。如果满足条件，系统将为进程分配资源；否则，进程需要等待其他进程释放足够的资源。 进程在获得所需资源后，需要在有限时间内释放这些资源，以避免资源锁定现象。 资源请求算法的主要目的是确保系统在分配资源时始终保持安全状态，避免死锁的发生。通过进程提交资源请求，系统可以动态地检查资源分配状态，以便在满足进程需求的同时，确保系统资源的有效分配。这种算法有助于维护系统的稳定性和安全性，从而提高操作系统的性能。 Example of Banker’s Algorithm\nDeadlock Detection Single Instance of Each Resource Type 死锁等价于wait-for graph有环\nSeveral Instances of a Resource Type 可用资源（Available）：一个长度为m的向量，用来表示每种类型资源的可用数量。在进程需要资源时，这个向量会动态变化，以反映当前系统内每种资源的剩余数量。 分配（Allocation）：一个n×m的矩阵，用来定义当前分配给每个进程的每种类型资源的数量。矩阵的每一行代表了对应进程所分配到的资源类型和数量。 请求（Request）：一个n×m的矩阵，表示每个进程当前的资源请求。如果Request[i, j] = k，那么进程Pi正在请求k个资源类型Rj的实例。这个矩阵帮助系统了解各个进程还需要哪些资源，以便进行相应的分配。 在分配和请求矩阵中，每一行都可以被视为一个向量，分别称为Allocation i和Request i，这样可以更方便地表示和引用每个进程的分配和请求情况。\nDetection Algorithm Example of Detection Algorithm Detection-Algorithm Usage 何时以及多久调用一次死锁检测算法取决于以下几个因素：\n死锁多久可能发生一次？ 需要回滚多少个进程？ 对于每个不相关的循环，都需要一个回滚。 死锁只有在某个进程提出了一个不能立即满足的请求时才会发生。\n每当有资源分配的请求不能立即被满足时，就调用死锁检测算法。 这样做可能会在计算时间上产生相当大的开销。因此，可以定义一个时间间隔，比如每小时调用一次算法，或者当CPU利用率低于40%时调用。 如果随意调用检测算法，资源图（resource graph）中可能会有许多循环，这样我们就无法判断是哪个死锁进程“导致了”死锁。因此，需要合理地安排死锁检测的频率，以确保能够有效地识别和处理死锁，同时又不至于过度增加系统的开销。\nRecovery from Deadlock 当系统中存在死锁时：\n告知操作员，手动处理死锁。或者让系统自动从死锁中恢复。 为了打破死锁：\n终止一个或多个进程。 预占有一些资源，从死锁的进程中的一个或多个进程中。 在处理死锁时，需要考虑以下问题：\n成本：终止进程或抢占资源可能会带来一定的成本，比如重新启动进程的开销，或者可能导致系统性能下降。 规则：需要有一套明确的规则来决定如何识别和打破死锁，比如银行家算法就是一种常用的避免死锁的算法。 公平：在抢占资源时，需要考虑公平性问题，确保不会对任何进程造成不公平的待遇。 为了预防死锁，可以制定以下规则：\n资源分配规则：确保资源的分配不会导致循环等待条件的发生。 进程调度规则：合理安排进程的执行顺序，避免多个进程因为资源竞争而相互等待。 死锁检测和恢复机制：定期检测系统是否存在死锁，并在发现死锁时采取恢复措施，比如终止或抢占资源。 Process Termination 为了通过终止进程来消除死锁：\n终止所有死锁的进程。 逐个终止进程，直到死锁循环被消除。 系统会回收所有分配给已终止进程的资源。那么，我们应该按照什么顺序选择一个进程来终止呢？这里涉及到成本考虑：\n进程的优先级。 进程已经计算了多长时间，以及还需要多长时间才能完成。 进程已经使用了多少资源，以及是什么类型的资源。 进程完成还需要多少更多的资源。 需要终止多少个进程。 进程是交互式的还是批处理的？ Resource Preemption 连续从进程预占一些资源，并将这些资源分配给其他进程，直到打破死锁循环。选择一个牺牲品——哪些资源和哪些进程应该被预占？\n最小化成本。 回滚——将进程恢复到某个安全状态，并从该状态重新启动。 总体回滚：终止进程，然后重新启动它。 饥饿——同一个进程可能总是被选为牺牲品。 在成本因素中包括回滚的次数。 在选择牺牲品时，需要考虑以下因素来最小化成本：\n优先级：通常，优先级较低的进程更容易被选为牺牲品。 资源使用情况：已经占用较多资源的进程可能更容易导致死锁，因此可能被选为牺牲品。 进程的状态：如果进程处于一个可以安全回滚的状态，那么它可能被选为牺牲品。 回滚的代价：如果一个进程需要频繁回滚，那么它的成本可能较高，因此可能被选为牺牲品。 为了避免饥饿现象，即同一个进程总是被选为牺牲品，可以采取一些策略，比如轮流选择牺牲品，或者在选择牺牲品时考虑进程的公平性。 在考虑成本时，需要将回滚的次数作为一个重要因素。如果一个进程经常因为死锁而需要回滚，那么它的总体成本可能会很高，因此在选择牺牲品时需要考虑这一情况。 Combined Approach to Deadlock Handling 综合方法处理死锁：\n预防（Prevention） 避免（Avoidance） 检测（Detection） 将三种基本方法结合起来，允许针对系统中每种资源使用最优方法。\n将资源划分为层次结构化的类别。 在每个类别内使用最合适的死锁处理技术。 期末考计算题 根据资源、进程间的请求关系，画出Resource-Allocation Graph 根据资源分配图分析死锁出现的资源条件，或避免死锁的资源条件 Deadlock Avoidance 当每类资源只有一个资源实例，利用Resource-Allocation Graph Algorithm判断有无死锁/系统是否安全 当资源可有多个资源实例时，利用Banker Algorithm判断系统是否安全?(无死锁?), 进程的资源请求是否be granted Deadlock Detecting 当每类资源只有一个资源实例，利用waiting graph判断有无死锁? 当资源可有多个资源实例时，利用deadlock detecting algorithm 判断有死锁? ","date":"2023-10-21T21:27:13Z","permalink":"https://www.xxx.blog/post/5-deadlocks/","title":"5  Deadlocks"},{"content":"Process Synchronization Background Bounded-Buffer Procedure-Consumer Problem Bounded-Buffer Procedure-Consumer Problem（有界缓冲程序-消费者问题）是一个经典的并发编程问题，通常用于展示多进程/多线程同步和互斥的概念。问题的背景通常是一个有界缓冲区，其中生产者生产项目并将其放入缓冲区，而消费者则从缓冲区中取出项目并进行处理。\n以下是问题的要点和解决方法：\n问题描述：\n有一个固定大小的缓冲区，可以容纳有限数量的项目。 生产者进程生产项目并尝试将其放入缓冲区。 消费者进程从缓冲区中取出项目并进行处理。 缓冲区在满时不允许生产者继续生产，当缓冲区为空时不允许消费者继续消费。 解决方法： 问题通常通过使用互斥锁（mutex）和条件变量（condition variable）来解决。这些是线程同步的工具，用于确保生产者和消费者之间的正确互斥操作。\n互斥锁：用于保护共享缓冲区，以确保在任何时刻只有一个线程可以访问它。 条件变量：用于通知其他线程缓冲区的状态，如是否为空或已满。 解决方法的关键点：\n当缓冲区满时，生产者会等待，直到有空间可用。 当缓冲区为空时，消费者会等待，直到有项目可用。 当生产者放置项目或消费者取出项目后，它们会通知其他等待的线程。 这样，通过互斥锁和条件变量的协同作用，可以实现生产者和消费者之间的正确同步，确保没有数据竞争或死锁。\nThe Critical-Section Problem The Critical-Section Problem（临界区问题）是并发编程中的一个经典问题，通常用于展示如何实现多个进程或线程之间的互斥访问共享资源。问题的核心是多个进程（或线程）需要同时访问共享资源，但要确保它们不会在同一时间访问该资源，以避免数据竞争和不一致性。\n概念：\n同步：指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。 互斥：当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。 问题描述：\n多个进程或线程需要访问一个共享资源，如共享内存区域、全局变量或文件。 任何时刻，只允许一个进程/线程访问共享资源，其他进程/线程必须等待。 进程/线程必须在进入临界区（临界区是访问共享资源的代码段）之前获得访问权限，然后在退出临界区后释放访问权限。 解决方法： 问题通常通过使用互斥锁（mutex）和信号量（semaphore）等同步工具来解决。这些工具用于确保只有一个进程/线程可以进入临界区，而其他进程/线程必须等待。\n临界区资源访问过程：\nEntry Section 进程发送请求以获取许可或锁，以指示其希望进入临界区域。 检查是否可进入临界区 Critical Section 临界部分通常包括需要保护的关键代码，以确保数据一致性。 Exit Section 在退出部分，进程释放许可或锁，以允许其他进程进入临界区域。 进程也可以执行一些清理操作或更新共享数据。 Remainder Section 在完成退出部分后，进程可以执行其余下部分的代码，这些代码通常不需要互斥保护。 Solution must satisfy three requirements\n互斥 同一时刻只能有一个进程在其关键部分执行。 空闲让进 进展性确保如果当前没有进程在其关键部分执行，而有些进程希望进入其关键部分，那么选择下一个进入关键部分的进程不应无限期地被延迟。 有限等待 有界等待对其他进程在允许一个进程请求进入其关键部分并在该请求获得批准之前进入其关键部分的次数设置了限制。 这一要求旨在防止其他进程不断地超越某个进程，确保进程执行的公平性。 竞争条件： 竞争条件是指多个进程或线程试图同时访问共享资源，可能导致数据不一致或其他问题。在操作系统中，一些潜在的竞争条件包括管理文件、内存分配、进程列表维护以及中断处理等方面。\n抢占式和非抢占式： 处理竞争条件的方法取决于操作系统是否支持抢占。 抢占式操作系统允许内核模式下的进程被抢占，这可能导致在多处理器系统中难以设计，因为两个内核模式进程可能在不同处理器上同时运行。 非抢占式操作系统在内核模式下一直运行，直到它退出内核模式、阻塞或自愿放弃 CPU。这种情况下，内核模式下几乎没有竞争条件。 Peterson’s Solution Peterson 算法是基于双线程互斥访问的LockOne与LockTwo算法而来。LockOne算法使用一个 flag 布尔数组，LockTwo 使用一个 turn的整型量，都实现了互斥，但是都存在死锁的可能。Peterson 算法把这两种算法结合起来，完美地用软件实现了双线程互斥问题。\n首先，我们来看看下面这段代码：\nPi进程： flag[i] = True; while(flag[j]); critical section; flag[i] = False; remainder section; Pj进程： flag[j] = True; while(flag[i]); critical section; flag[j] = False; remainder section; 以上是用来实现两个进程互斥访问临界区的两端代码，我们可以这样来理解这两段代码，其中flag[i]表示进程Pi表示想要进入临界区，while(flag[j])可以理解为Pi在自己进临界区之前，先问问Pj是否想要进入临界区，如果Pj想进的话它就等待（Pi品德高尚）；类似的，Pj也是同样的。双方互相谦让的结果是，最终两个进程谁也进不了临界区。（可以想象这样一个生活场景，两个人同时想进屋，结果在门口谦让了了半天，过了很久都没进去）\nPeterson算法就是在上面代码的基础之上，又引入了一个变量turn，打破了这种因为谦让而导致“饥饿”的现象。下面我们先来看看Peterson算法的代码：\nPi进程： flag[i] = True; turn = j; while(flag[j] \u0026amp;\u0026amp; turn == j); critical section; flag[i] = False; remainder section; Pj进程： flag[j] = True; turn = i; while(flag[i] \u0026amp;\u0026amp; turn == i); critical section; flag[j] = False; remainder section; 怎么理解变量turn呢？可以将turn变量理解成轮到谁进入临界区了。举个例子：turn = i，表示轮到Pi进入临界区。那么上面这个代码就可以理解为：首先，Pi想进入临界区（flag[i] = True），然后，还是和前面的代码一样，Pi会先把进入临界区的机会让给Pj（turn = j），同样地，当Pj想进入临界区时，也会将进入临界区的权利先让给Pi。紧接着，变量turn的作用就显现出来了，当Pj把进入临界区的机会又让给Pi的时候（注意：这是发生在Pi将进入临界区的优先权让给Pj之后），Pi这次就会直接进入临界区。就不会再次出现一直互相谦让，最终导致均无法进入临界区的情况了。\n关于为什么当进入临界区的权利（即turn = i）又回到Pi手里时，Pi会直接进入临界区的分析？我们可以分析一下Pi能够成功进入临界区的条件（即：while(flag[j] \u0026amp;\u0026amp; turn == j)语句）： 总的分为以下两种情况：\nPj不想进入临界区（flag[j] = False） 当Pj不想进入临界区时，自然也就不存在Pi和Pj冲突的情况，Pi当然就直接进入临界区。 Pj想进入临界区（flag[j] = True） 当Pj想进入临界区，又分为以下两种情况： 当 turn = i turn = i说明当前轮到i进入临界区了 ，这个时候i就直接进入临界区了，不再谦让。（其实这个挺合理的，根据Peterson算法的代码我们不难发现因为turn的值是根据先后想要进入临界区的顺序排列的） 当 turn != i turn != i 说明当前轮到i进入临界区了没有轮到Pi进入临界区，Pi自然需要等待。 仅过上面的分析，我们就不难理解，当Pi和Pj经过一轮谦让之后，就会直接根据turn的值（即：该轮到谁进临界区了）来直接决定谁该进入临界区。现在回过头回顾整个算法，其实我们会发现，Peterson算法的思想会更贴近于生活中的真实情况，大家一般都是略微谦让一下，然后直奔主题，难道不是吗？哈哈\n*Bakery Algorithm 面包店算法为n个进程的临界区问题提供了一种解决方案。在进入临界区之前，每个进程都会接收到一个编号。持有最小编号的进程首先进入临界区。如果两个进程Pi和Pj接收到相同的编号，那么比较它们的进程ID：如果i\u0026lt;j，则Pi先被服务；否则Pj先被服务。编号方案始终按枚举的递增顺序生成编号，例如1, 2, 3, 3, 3, 3, 4, 5等等。\n这里的“\u0026lt;”表示字典顺序（票号，进程ID号）。如果(a, b)\u0026lt;(c, d)，那么要么是a\u0026lt;c，要么在a=c的情况下b\u0026lt;d。max(a0, …, an-1)是一个数字k，满足对于所有i = 0, …, n – 1，k≥ai。\nShared data boolean choosing[n];//false int number[n]; //0 Pi while (1) { choosing[i] = true; // Pi is taking a number number[i] = max(number[0], number[1], …, number [n–1])+1; //排队取号 choosing[i] = false; // end of number taking for (j = 0; j \u0026lt; n; j++) { while (choosing[j]) ; while ((number[j] != 0) \u0026amp;\u0026amp; ((number[j], j)\u0026lt;(number[i], i)); //排队等待 } critical section number[i] = 0; remainder section } Synchronization Hardware Synchronization Hardware 许多系统提供硬件支持以保护临界区代码。\n禁用中断disable interrupts 在单处理器系统中，当前正在执行的代码可以在不被抢占的情况下执行。而在多处理器系统中，这种做法效率太低，时间成本很高。这也会影响系统时钟的精度，特别是当时钟的更新是通过中断来完成的。 锁（Lock）：一个简单的工具，用于实现互斥。 进程在进入临界区之前必须获取一个锁。 当进程退出临界区时，它会释放锁，使其他进程能够进入。 atomic hardware instructions 现代计算机提供特殊的原子硬件指令，这些指令是不可中断的。 原子操作（Atomic） 意味着操作过程不会被中断。 例如，TestAndSet() 指令用于测试内存单元的值并设置新的值。 Swap() 指令用于交换两个内存单元的内容。 这些原子硬件指令可以在多线程或多进程的情况下，用来保护临界区代码，确保多个执行单元在同时访问共享资源时不会发生竞争条件。这些原子指令提供了一种有效的方式来执行互斥操作，而无需禁用中断或使用锁。\nSolution using TestAndSet() 使用 TestAndSet() 来解决临界区问题的解决方案如下：\nShared data: boolean lock = FALSE; Process Pi while(TRUE) { while (TestAndSet(\u0026amp;lock)); critical section lock = FALSE; remainder section } 共享数据：boolean lock = FALSE;，lock 是一个布尔变量，初始值为 FALSE。 进程 Pi： 进入一个无限循环，表示一直在运行。 在进入临界区之前，使用 TestAndSet(\u0026amp;lock) 来测试并设置 lock，如果 lock 的值为 TRUE，则继续等待，直到 lock 变为 FALSE。 一旦获得了 lock，进入临界区执行临界区代码。 执行完临界区后，将 lock 设置为 FALSE，表示离开了临界区。 最后，执行剩余部分。 这个解决方案使用 TestAndSet() 指令来确保在一个时刻只有一个进程能够进入临界区，其他进程必须等待。这样，它满足了互斥性的要求。\nSolution using Swap() 使用 Swap() 来解决临界区问题的解决方案如下：\nShared data: boolean lock = FALSE; Process Pi while(TRUE) { key = TRUE; while (key == TRUE) Swap (\u0026amp;lock, \u0026amp;key); critical section lock = FALSE; remainder section } 共享数据：boolean lock = FALSE;，lock 是一个布尔变量，初始值为 FALSE。 进程 Pi： 进入一个无限循环，表示一直在运行。 首先将 key 设置为 TRUE。 在进入临界区之前，使用 Swap(\u0026amp;lock, \u0026amp;key) 将 lock 和 key 互换，如果 lock 的值是 TRUE，那么 key 的值将变成 TRUE，表示继续等待。如果 lock 的值是 FALSE，那么 key 的值将变成 FALSE，表示进入临界区。 一旦获得了锁，进入临界区执行临界区代码。 执行完临界区后，将 lock 设置为 FALSE，表示离开了临界区。 最后，执行剩余部分。 这个解决方案使用 Swap() 指令来确保在一个时刻只有一个进程能够进入临界区，其他进程必须等待。这样，它满足了互斥性的要求。\nMutual Exclusion Machine Instructions 优势：\n适用于任意数量的进程，无论是在单处理器还是在共享主内存的多处理器系统上。 简单，易于验证。 可用于支持多个临界区。 劣势：\nBusy-waiting会占用处理器时间，这可能会导致资源的浪费。 可能出现starvation情况，当一个进程离开临界区并且有多个进程在等待时。 deadlock：如果一个优先级较低的进程拥有临界区，而一个优先级较高的进程需要进入临界区，那么高优先级的进程将获得处理器，但它只是等待临界区。 Revised Solution Using TestAndSet() 经过修订的使用TestAndSet()的解决方案如下：\nShared data(initialized to FALSE) : boolean lock; boolean waiting[n]; Process Pi while (TRUE) { waiting[i] = TRUE; key = TRUE; while (waiting[i] \u0026amp;\u0026amp; key) key = TestAndSet(\u0026amp;lock); waiting[i] = FALSE; // critical section j = (i + 1) % n; while ((j != i) \u0026amp;\u0026amp; !waiting[j]) j = (j + 1) % n; if (j == i) lock = FALSE; else waiting[j] = FALSE; // remainder section } 共享数据（初始化为FALSE）：\nboolean lock; // 用于表示临界区是否被锁定 boolean waiting[n]; // 用于表示每个进程是否在等待 这是使用TestAndSet()进行修订的解决方案，以实现多个进程之间的互斥。当进程需要访问临界区时，它首先等待其他进程完成，然后尝试使用TestAndSet()获取锁。在进入临界区后，它会检查是否有其他进程在等待，如果没有，就释放锁；否则，将等待标志设置为FALSE，以允许其他进程尝试获取锁。这有助于确保只有一个进程可以同时进入临界区。\nMutex Locks 以前的硬件解决方案复杂且通常不易被程序员所使用，操作系统设计者通过编写软件工具来解决关键段问题。最为简单的解决方案是互斥锁（又称互斥机制）。 保护关键段的方法是：首先获取（acquire）锁，然后释放（release）锁。 采用一个布尔变量available来表示锁的状态，用以判断锁是否可用。 acquire()和release()锁的操作必须是原子性的，通常通过硬件原子指令来实现原子性操作。 然而，这种解决方案需要忙等待，即在获取锁时，线程需要不断尝试直到锁可用。因此，这种锁被称为自旋锁（spinlock）。自旋锁通常在多处理器系统中使用，以解决多个处理器同时访问共享资源的问题。\nacquire() { while (!available) ; /* busy wait */ available = false; } release() { available = true; } Semaphores 信号量（Semaphore）是一种用于进程同步的工具，它提供了比互斥锁更复杂的方法。与互斥锁不同，信号量不需要busy waiting。 信号量是一个特殊的变量，通常用整数来表示，可以初始化为非负数。它只能通过两个不可分割的操作来访问：\nwait(S)：等待操作，用于获取信号量，操作会减小信号量的值。S\u0026ndash; signal(S)：信号操作，用于释放信号量，操作会增加信号量的值。S++ 这两个操作是不可中断的，它们在执行过程中不会被中断。 信号量用于实现进程同步和互斥，它可以帮助控制多个进程之间的访问共享资源的顺序。 Semaphore usage 信号量的使用可以分为两种主要类型：二进制信号量和计数信号量。\nBinary Semaphore 整数值只能在 0 和 1 之间取值。 通常用于互斥控制，类似于互斥锁（Mutex Lock）。 一个进程可以通过 wait(S) 操作获取二进制信号量，使其值变为 0，表示资源已被占用。 通过 signal(S) 操作释放二进制信号量，使其值变为 1，表示资源可用。 Counting Semaphore 整数值可以在一个不受限制的范围内取值。 通常用于控制对一组有限数量资源的访问。 计数信号量的初始值通常设置为资源的可用数量。 当一个进程希望使用资源时，它执行 wait() 操作，减小信号量的值。 当一个进程释放资源时，它执行 signal() 操作，增加信号量的值。 当计数信号量的值降至 0 时，表示所有资源都被使用，此后希望使用资源的进程将会被阻塞，直到计数信号量的值再次大于 0。 为了确保 wait() 和 signal() 操作的原子性：\n在单处理器系统中，通常的做法是在执行这些操作时禁止（抑制）中断。这样可以防止进程在执行这些操作时被中断，从而保证了操作的原子性。\n在多处理器系统中，禁止中断并不是一个可行的解决方案，因为即使在一个处理器上禁止了中断，其他处理器上的进程仍然可以执行这些操作。因此，需要使用锁定技术来确保操作的原子性。一个常见的锁定技术是使用自旋锁（spinlocks），它会让进程在尝试获取锁时循环检查锁是否可用，而不是放弃处理器的控制权。 计数信号量可用于控制对共享资源的并发访问，确保资源在同一时刻不被过多的进程使用。\n在解决临界区问题时，信号量可以用来协调多个进程的访问。下面是一个关于 n 个进程的临界区问题的示例，以及如何使用信号量来同步它们的执行：\nCritical Section of n Processes Shared data: semaphore mutex; // 初始值为 1 Process Pi: while (true) { wait(mutex); // 临界区代码 signal(mutex); // 剩余部分代码 } 在此示例中，有 n 个进程（P1, P2, \u0026hellip;, Pn），它们共享一个信号量 mutex，它的初始值为 1。每个进程在进入临界区之前都会执行 wait(mutex) 操作，以等待获取信号量。当一个进程完成临界区的操作后，它会执行 signal(mutex) 操作，释放信号量，允许其他进程进入临界区。\n这种方式可以确保在同一时刻只有一个进程能够进入临界区，从而避免了竞争条件。但需要注意的是，如果某个进程在等待获取信号量时，它会处于忙等待状态，这可能会浪费 CPU 资源。这种类型的信号量也被称为自旋锁（spinlock），因为进程在等待锁时会自旋（忙等待）。\n此外，示例中的 n 可以是任意正整数，表示有多少个进程需要协调访问临界区。\n在信号量的实现中，可以使用等待队列来避免忙等待。信号量可以被定义为一个 C 结构，每个信号量具有以下属性：\n一个整数值，表示信号量的计数。 一个进程列表（等待队列），用于存储等待获取信号量的进程。 信号量操作包括：\nblock(): 当一个进程调用此操作时，它会被放置到适当的等待队列中，表示它正在等待获取信号量。 wakeup(P): 当需要释放信号量时，可以从等待队列中选择一个等待的进程，并将其移至就绪队列，以便它可以继续执行。 这种方式允许进程在等待信号量时不会浪费 CPU 资源，因为它们不需要忙等待。相反，它们会进入等待队列，直到信号量可用，然后才会被移至就绪队列。\n这种信号量的实现方式更高效，特别适用于多进程协同工作的情况，以避免资源竞争和提高系统的整体性能。\n这是一个使用等待队列的信号量实现，其中包括 wait 和 signal 操作。以下是这两个操作的伪代码示例：\nwait 操作:\nwait(semaphore *S) { S-\u0026gt;value--; // 减少信号量值 if (S-\u0026gt;value \u0026lt; 0) { // 如果信号量值小于零，表示资源不可用，将当前进程加入等待队列并阻塞 add this process to S-\u0026gt;List; block(); // 阻塞当前进程 } } signal 操作:\nsignal(semaphore *S) { S-\u0026gt;value++; // 增加信号量值 if (S-\u0026gt;value \u0026lt;= 0) { // 如果信号量值不小于零，表示有等待的进程，唤醒其中一个 remove a process P from S-\u0026gt;List; wakeup(P); // 唤醒一个等待的进程 } } 这种实现方式可以确保在资源不可用时，等待的进程不会浪费 CPU 资源，而是会被阻塞，直到资源可用。一旦资源可用，信号量会唤醒一个等待的进程，使其可以继续执行。这有助于避免忙等待，提高系统的效率和性能。\n这个信号量实现采用了等待队列，以确保没有两个进程可以同时执行相同信号量上的 wait() 和 signal() 操作。为了避免竞态条件，必须确保这两个操作在临界区内执行。\n具体实现的方式取决于系统的特性：\n在单处理器系统中，可以通过禁用中断来防止进程切换，从而实现临界区的互斥。 在多处理器系统中，需要使用锁定技术，如自旋锁（spinlocks），以确保 wait() 和 signal() 操作在同一信号量上不会同时执行。 虽然这种实现方式并没有完全消除忙等待，但它将忙等待限制在 wait() 和 signal() 操作的关键部分。由于这两个操作的实现代码很短（通常不超过10条指令），因此关键部分很少被占用，因此忙等待发生得很少。\n这种方法允许系统高效地等待资源的可用性，同时尽量减少不必要的忙等待。这有助于提高系统性能和效率。\n问题：死锁和饥饿\n死锁：指两个或多个进程无限期地等待一个只能由等待中的进程中的一个触发的事件。死锁是并发系统中的一种严重问题。\n示例：假设有两个信号量S和Q，它们都被初始化为1。\nP0 P1 wait (S); wait (Q); wait (Q); wait (S); … … signal (Q); signal (S); signal (S); signal (Q); 在这个示例中，P0和P1都试图以相反的顺序等待S和Q，这可能导致死锁。\n饥饿：饥饿是指进程无限期地被阻塞。这种情况下，进程可能永远无法从其挂起的信号量队列中被移除。饥饿可能导致一些进程无法获得所需的资源，从而降低系统性能。\n示例：一个使用LIFO（后进先出）队列的信号量可能导致某些进程永远无法获得资源，因为它们总是排在队列的末尾。\n这些问题是在并发编程中需要小心处理的关键问题。解决方法包括使用适当的算法和数据结构，以及在设计时考虑进程的优先级和资源分配策略，以避免死锁和饥饿的发生。\nPriority Inversion 定义：优先级反转是指在多任务系统中，当一个具有较低优先级的任务持有一个较高优先级任务所需的资源时，可能导致高优先级任务受阻的情况。 例子： 假设有三个进程，分别为L、M和H： H（高优先级）需要资源R，而L（低优先级）正在使用该资源。因此，H必须等待L完成对R的使用。 在此时，M（中等优先级）可以运行，并抢占了L的执行。 此时，由于M的运行，L被抢占，导致H等待更长时间才能获得对R的访问。这种情况称为优先级反转，因为高优先级的任务被低优先级的任务所阻塞。 solution：优先级继承协议priority-inheritance protocol 当一个任务（例如L）持有一个资源（例如R）时，任何试图访问这个资源的任务都会继承该任务的优先级（例如H的优先级）。 在上述例子中，L在使用R期间临时继承了H的优先级，以确保H不会被低优先级的M所阻塞。 一旦任务完成对资源的使用，它的优先级就会恢复到原始值。 Classic Problems of Synchronization The Bounded-Buffer Problem 有界缓冲区问题 假设缓冲池由 n 个缓冲区组成，每个缓冲区可以容纳一个项目。 共享数据包括三个信号量：mutex、empty 和 full。 初始状态如下：\nmutex = 1：互斥信号量，确保每次只有一个进程能够进入临界区。 empty = n：表示空缓冲区的数量，初始时所有缓冲区都是空的。 full = 0：表示已满缓冲区的数量，初始时没有缓冲区是满的。 有界缓冲区问题的解决方案通常包括生产者和消费者两个进程。生产者负责将产品放入缓冲区，而消费者从中获取产品。这里的代码示例描述了生产者和消费者的基本循环：\n公有信号量-互斥\n私有信号量-同步\nThe Readers-Writers Problem 竞争：读-写、写-写 共享：读-读\n有两个经典的读者-写者问题：\n第一个读者-写者问题（读者优先）：\n只有读取内容的读者和可以更新内容的写者。 读者可以同时访问共享对象。 写者具有独占访问共享对象的权限。 在这个问题中，没有读者会一直等待，除非有一个写者已经获得了访问共享对象的权限。 写者可能会饥饿，即等待时间较长。 rw-mutex是读写的互斥信号量，mutex_r是控制读者数量的信号量。 先等能控制读者数量的时候，如果有个读者进程出现，就会让read_count的数量++，如果是第一个读者，要等rw_mutex信号量为1的时候才能进行下一步。 当最后一个读者读完了，要把rw_mutex信号量释放\n第二个读者-写者问题（写者优先）：\n一旦写者准备好，它将尽快执行写入。 如果有一个写者正在等待访问共享对象，那么新的读者将无法开始阅读。 在这个问题中，读者可能会饥饿，因为一旦写者准备好，读者将无法访问共享对象。 The Dining-Philosophers Problem 这是著名的\u0026quot;哲学家就餐问题\u0026quot;（Dining Philosophers Problem）的示例，通常用于说明并发编程中的同步和资源分配问题。在这个问题中，有五位哲学家坐在一张圆形餐桌周围，每位哲学家面前放着一只筷子。他们交替地思考（thinking）和进餐（eating），但只有在同时拿到两只筷子时才能进餐。解决这个问题需要协调哲学家的活动，以避免死锁和竞态条件。\n在这个示例中，semaphore chopstick[5] 是五个信号量，代表五只筷子。每位哲学家都需要拿起两只相邻筷子才能吃饭。解决方案的核心是确保一位哲学家在拿筷子时不会与其邻居发生竞争。\n哲学家的活动循环包括以下部分：\n思考（thinking）：哲学家在思考时不需要资源，因此直接进入思考状态。 饥饿（hunger）：哲学家想要进餐，但必须获取两只筷子。他们通过等待两只相邻筷子的信号量来表示他们的饥饿。 进餐（eating）：当哲学家拿到两只筷子后，他们可以进餐。进餐后，他们释放筷子。 semaphore chopstick[5]={1,1,1,1,1}; //Pi while(1){ hunger wait(chopstick[i]); wait(chopstick[(i+1)%5]); eating signal(chopstick[i]); signal(chopstick[(i+1)%5]); thinking } solution1 最多4个人吃饭，至少有一只筷子多出来 增加一个count信号量\nsemaphore chopstick[5]={1,1,1,1,1}; semaphore count=4; //Pi while(1){ hunger wait(count); wait(chopstick[i]); wait(chopstick[(i+1)%5]); eating signal(chopstick[i]); signal(chopstick[(i+1)%5]); signal(count); thinking } solution2 奇数拿左边，偶数拿右边 如果拿不到就吃不上，等下次再拿\nsemaphore chopstick[5]={1,1,1,1,1}; //Pi while(1){ hunger if(i%2==1){ wait(chopstick[i]); wait(chopstick[(i+1)%5]); }else{ wait(chopstick[(i+1)%5]); wait(chopstick[i]); } eating signal(chopstick[i]); signal(chopstick[(i+1)%5]); thinking } Monitors Define Monitor Monitors（管程）是一种高级同步构造，用于在并发进程之间安全共享抽象数据类型。Monitor是一个软件模块，通常用于控制对共享资源的访问，以避免竞态条件和确保数据的一致性。\n局部数据变量: 这些变量仅限于Monitor内部的过程访问。 进程入口: 进程通过调用Monitor中的某个过程来进入。 互斥执行: 任何时候，Monitor内只允许一个进程执行。 一个Monitor的概念示意图如下：\n+------------------------+ | Monitor | | | | Data Variables | | | | Procedures | | | | Condition Variables| | | +------------------------+ 上面的示意图展示了一个监视器的基本结构。监视器内部包括以下主要组成部分：\n数据变量（Data Variables）：这些是局部数据变量，只能由Monitor内的过程访问。它们用于存储Monitor所管理的共享数据。 过程（Procedures）：这些是Monitor内定义的过程，通常用于对共享数据进行操作。只有进入Monitor的进程才能调用这些过程。 条件变量（Condition Variables）：条件变量是一种用于等待和通知的机制。它们允许进程在满足某些条件之前等待，然后在条件满足时被通知继续执行。条件变量通常与等待（wait）和通知（signal）操作相关联。 Condition Variable 条件变量（Condition Variable）是管程（Monitor）内的一个重要组成部分，用于实现进程的等待和通知机制。条件变量通常与等待（wait）和通知（signal）操作相关联。\n声明条件变量：在monitor内，你可以声明一个或多个条件变量condition x, y; wait() 操作：调用此操作的进程将被挂起（suspended），直到另一个进程调用x.signal(); signal() 操作：恢复（resumes）一个被挂起的进程。如果没有进程被挂起，则signal操作没有任何效果。 条件变量和相关操作使监视器内的进程能够更灵活地协同工作，等待特定条件的满足，并在条件满足时得到通知。这有助于避免忙等待（busy waiting）和提高系统的效率。不同编程语言和操作系统可能会提供不同的条件变量实现，但它们的基本概念是相似的。\n","date":"2023-10-21T21:19:31Z","permalink":"https://www.xxx.blog/post/4-process-synchronization/","title":"4 Process Synchronization"},{"content":"CPU Scheduling Basic Concepts The objective of multiprogramming is to have some process running at all times. To maximize CPU utilization. 多程序调度目标：最大化 CPU 利用率 CPU-I/O burst 周期 CPU burst 分布\nCPU Scheduler CPU调度器（Scheduler）的主要任务是从内存中准备执行的进程中选择一个，并将CPU分配给其中一个进程。 CPU调度决策可能在以下情况下发生：\n进程终止。 进程从运行状态切换到等待状态。 进程从运行状态切换到就绪状态。 进程从等待状态切换到就绪状态。 这些情况导致了CPU调度器重新选择下一个要执行的进程，以确保CPU资源得到有效利用。 Decision Mode 决策模式是关于操作系统中CPU调度方式的两种主要类型：\n非抢占式（Nonpreemptive）： 一旦进程进入运行状态，它将一直运行，直到终止或因I/O操作而阻塞自己。 一旦CPU被分配给一个进程，该进程将一直保持CPU，直到它释放CPU（要么因终止，要么切换到等待状态）。 非抢占式调度可能导致一个进程长时间独占处理器。 抢占式（Preemptive）： 当前运行的进程可能会被操作系统中断并移动到就绪状态。 抢占式调度允许更好的服务，因为任何一个进程不能长时间占用处理器。 抢占式调度有时可能会导致竞争条件，尤其当数据被多个进程共享时。 抢占式调度允许操作系统随时暂停正在执行的进程，以便分配CPU时间给其他进程，这有助于确保公平地共享CPU资源。非抢占式调度则在分配CPU时较为保守，只有在进程主动释放CPU时才会切换。 Dispatcher 进程调度器，它是操作系统中的一个关键模块，负责分配和调度 CPU 时间片给各个就绪状态的进程。 Dispatcher 的主要功能如下：\n控制 CPU：Dispatcher 负责将 CPU 控制权交给选定的进程。在操作系统中，有一个短期调度器（也称为 Dispatcher）负责在就绪队列中的进程之间分配 CPU 时间片。 切换上下文：当 CPU 控制权发生变化时，Dispatcher 负责在各个进程之间切换上下文。这包括保存当前进程的状态，加载下一个进程的状态，以及将 CPU 执行环境切换到下一个进程。 进程切换：Dispatcher 负责实现进程之间的切换。当一个进程完成执行或者主动让出 CPU 时，Dispatcher 会选取下一个就绪进程并将其投入执行。 调度 latency：Dispatcher 决定了进程切换所需的时间，即调度 latency。这是 Dispatcher 停止一个进程并开始执行另一个进程所需的时间。 优先级调度：Dispatcher 还负责根据进程的优先级进行调度。优先级较高的进程更容易获得 CPU 时间片，以确保系统资源得到合理分配。 总之，Dispatcher 是操作系统中的核心模块，负责管理 CPU 时间片分配和进程调度。它确保系统资源得到高效利用，同时确保进程能够在合适的时机获得执行。 Scheduling Criteria 调度准则 是指用于评估和选择调度算法的标准或指标。这些准则通常用于衡量操作系统中进程调度器的性能和效率。 调度准则可以分为两类：性能相关和性能无关。\n性能相关：这类准则关注的是调度算法在提高系统性能方面的表现，主要包括以下几个方面： CPU 利用率：尽量让 CPU 保持繁忙，提高系统资源利用率。 吞吐量：衡量单位时间内完成进程数量的表现。 周转时间（Turnaround Time）：从进程提交到完成执行所花费的时间。 等待时间：进程在就绪队列中等待 CPU 分配的时间。 响应时间：从提交请求到产生第一个响应的时间（对于时间共享环境）。 性能无关：这类准则主要关注调度算法的公平性和可预测性，包括以下几个方面： 公平性：确保各个进程能够公平地获得 CPU 资源。 截止日期（Deadline）：确保关键任务在规定的时间内完成。 系统导向：通过优化系统整体性能，提高系统的稳定性和可靠性。 在选择调度算法时，需要根据具体场景和需求来权衡这些准则的相对重要性。常见的调度算法评估方法包括确定性建模、排队论、模拟和实现等。根据这些评估结果，可以选择最适合特定系统的调度算法。 Scheduling Algorithms First-Come, First-Served (FCFS) Scheduling 先来先服务调度算法。在这种算法中，每个进程加入就绪队列，形成一个先进先出的队列。当当前进程执行结束时，选择就绪队列中the oldest的进程继续执行。FCFS 算法是非抢占式的，即当前进程在执行过程中不会被其他进程中断。\nShortest-Job-First (SJF) Scheduling 短作业优先调度算法。SJF 算法根据进程的预计下一个 CPU burst 时间来设置进程的优先级，优先级越高的进程越有可能被调度执行。SJF 算法可以分为抢占式和非抢占式两种，其中非抢占式算法只是在进程到达时将其放入队列末尾，不会中断当前进程。\nPrediction of the Length of the Next CPU Burst 由于下一个 CPU burst 的实际长度是不确定的，所以我们只能对其进行估计。预测可以通过使用之前 CPU burst 的长度，采用指数平均法来实现。 具体计算公式如下： 下一次 CPU burst 预测长度 = α * 上一次 CPU burst 实际长度 + (1 - α) * 指数平均法预测长度 其中，α 是一个在 0 到 1 之间的参数，表示预测权重。当α接近 1 时，表示更倾向于选择上一次 CPU burst 的实际长度；当α接近 0 时，表示更倾向于选择指数平均法预测的长度。\nPriority Scheduling 优先级调度算法。这种算法根据进程的优先级来决定调度顺序，优先级高的进程优先执行。（通常数字越小优先级越高）优先级可以根据进程的性质（如交互式进程、批量进程等）或进程的 burst 时间来设置。优先级调度可以是抢占式的，也可以是非抢占式的。\n静态优先级、非抢占式调度 静态优先级、抢占式调度 优先级调度算法会导致饥饿问题，解决办法是随着时间的增长优先级提高。\nRound Robin (RR) Scheduling 轮转调度算法。RR 算法为每个进程分配一个固定的时间片，进程按照顺序轮流执行。当一个进程的时间片用完后，将其放回队列末尾，继续下一个进程执行。RR 算法保证了每个进程都能得到公平的 CPU 时间片，但可能导致较长作业长时间无法执行。\nExample of RR with Time Quantum=20\n在就绪队列中有 n 个进程，时间片为 q 的情况下，每个进程将获得 CPU 时间的 1/n，且每个进程等待时间不会超过 (n-1)q。 性能取决于时间片的大小：\n如果时间片 q 非常大（无限大），那么将实现先来先服务（FCFS）调度算法； 如果时间片 q 非常小，那么将导致大量上下文切换； 为了避免过高的时间片切换开销，时间片 q 必须相对于上下文切换较大。 总之，合适的时间片大小对于 CPU 调度性能至关重要。时间片过大或过小都会导致性能下降。因此，在实际应用中，需要根据系统实际情况和需求来设置合适的时间片大小。 Multilevel Queue Scheduling 多级队列调度算法。这种算法将进程分为多个队列，根据进程的性质和优先级将它们放入相应的队列。每个队列都有自己的调度算法，如前台进程使用 RR 算法，后台进程使用 FCFS 算法。多级队列调度可以在不同队列之间实现抢占式或非抢占式调度。\nMultilevel Feedback Queue Scheduling 多级反馈队列调度算法。这种算法在多级队列的基础上，根据进程的执行情况和反馈信息调整进程的优先级。进程可以在队列之间流动，根据优先级和反馈信息进行调度。这种算法旨在平衡系统性能和资源利用率，实现公平和高效的调度。\n如果一个进程使用太多的 CPU 时间，它将被移动到较低优先级的队列。\n将I/O绑定和交互式进程留在较高优先级的队列中。 如果一个进程在较低优先级的队列中等待太久，它可能被移动到更高优先级的队列。\n这种老化方式防止了饥饿现象。 Three queues：\nQ0 \u0026ndash; 最高优先级 \u0026ndash; 时间片为 8 毫秒\nQ1 \u0026ndash; 较低优先级 \u0026ndash; 时间片为 16 毫秒\nQ2 \u0026ndash; 最低优先级 \u0026ndash; FCFS\n多级反馈队列调度器由以下参数定义：\n队列的数量。\n每个队列的调度算法。\n确定何时将进程升级到更高优先级队列的方法。\n确定何时将进程降级到更低优先级队列的方法。\n确定进程在需要服务时进入哪个队列的方法。\nHighest Response-Ratio Next Scheduling 最高响应比优先调度是一种非抢占式调度算法，它综合考虑了进程的等待时间和 CPU burst 时间。响应比是指进程完成任务所需的响应时间与任务执行时间的比值。响应比越高，说明进程完成任务的速度越快，因此优先级越高。 在该算法中，系统会实时计算每个进程的响应比，并选择响应比最高的进程进行调度。这种算法旨在优化系统的响应时间，提高用户满意度。然而，该算法的缺点是计算响应比的过程较为复杂，会带来一定的系统开销。\nResponse-Ratio ： R=(W+T)/T=1+W/T W：waiting time in ready queue T：CPU-burst time\nMultiple-Processor Scheduling 多处理器系统的分类：\na. 松耦合多处理器（Loosely coupled multiprocessor）：每个处理器具有自己的内存和 I/O 通道。这种结构中的处理器之间相互独立，互不干扰。\nb. 紧耦合多处理器（Tightly coupled multiprocessing）：处理器共享主内存。这种结构中的处理器在执行任务时需要更多的协作和同步。\nc. 功能专业化处理器：如 I/O 处理器，这种处理器专门负责处理 I/O 操作，由主处理器控制。 homogeneous 处理器：在多处理器系统中，任何可用的处理器都可以运行队列中的任何进程。这意味着系统中的所有处理器具有相同的性能和功能。 Heterogeneous 系统：在这种系统中，只有为特定处理器指令集编译的程序才能在该处理器上运行。这意味着系统中的处理器具有不同的指令集和性能。\nApproaches to Multiple-Processor Scheduling Asymmetric multiprocessing（非对称多处理器）和 Symmetric multiprocessing（对称多处理器）是两种不同的多处理器调度方式。 在非对称多处理器系统中，有一个主处理器负责处理所有的调度决策、I/O 处理和其他系统活动。其他从处理器仅执行用户代码。主处理器访问系统数据结构，从而减少了数据共享的需求。从处理器向主处理器发送服务请求。这种方法的缺点是，如果主处理器出现故障，整个系统将受到影响；此外，主处理器可能会成为性能瓶颈。 在对称多处理器（SMP）系统中，架构是对等的，操作系统可以在任何处理器上执行。每个处理器都可以自行调度。准备队列有两种方式：一是每个处理器拥有自己的私有准备队列；二是共享一个公共准备队列。使用私有队列时，可以为主处理器提供专用短期队列，但可能会导致负载不平衡。使用公共队列时，需要确保两个处理器不会选择相同的进程，并且进程不会从队列中丢失。\nProcessor Affinity 处理器亲和力（Processor Affinity）\n非统一内存访问（NUMA，Non-Uniform Memory Access）\n处理器亲和力是指操作系统将进程分配给特定处理器的能力。在这个过程中，操作系统尽量让一个进程在同一处理器上运行，但并不保证一定实现。这主要是为了提高系统的性能和资源利用率。 非统一内存访问（NUMA）是一种现象，指的是 CPU 对内存的不同部分访问速度不同。通常，这种情况出现在含有 CPU 和内存板的系统中。在这种系统中，一个主板上的 CPU 访问该主板上的内存速度要比访问其他主板上的内存速度快。\nLoad balancing 负载均衡是指在 SMP（对称多处理器）系统中，保持工作负载在所有处理器上均匀分布。 负载均衡仅在每个处理器都有自己的准备队列（private ready queue）的系统中才有必要。 负载均衡有两种方法：\n推迁移（Push migration）：特定任务周期性地检查每个处理器的负载，如果存在负载不平衡，将从负载过重的处理器上将进程推到空闲或较不繁忙的处理器上。 拉迁移（Pull migration）：空闲处理器从繁忙的处理器中拉取等待的任务。 然而，负载均衡往往抵消了处理器亲和性（processor affinity）的优点。 Multiprocessor Thread Scheduling 负载分享（Load sharing）：在这种策略下，进程不会被分配到特定的处理器上。这意味着处理器会在多个进程之间共享，以实现更高的资源利用率。 组调度（Gang scheduling）：这种策略是指一组相关的线程同时在一组处理器上运行。这种方法可以提高程序的执行效率，特别是当这些线程之间存在很强的相关性时。 专用处理器分配（Dedicated processor assignment）：在这种策略下，线程被分配到特定的处理器上。这种方法可以确保每个线程都能获得固定的处理器资源，从而提高程序的执行效率。 动态调度（Dynamic scheduling）：这种策略是指在程序执行过程中，可以动态地改变线程的数量。这使得系统可以根据当前的系统负载和资源状况，灵活地调整线程数量，以实现更高的资源利用率。 总的来说，这段内容主要介绍了多处理器线程调度的一些基本概念和策略，以及如何根据不同的需求和场景选择合适的调度方法。这些策略可以提高系统的资源利用率、执行效率，并确保程序的正常运行。 Thread Scheduling 线程是独立于进程其他部分执行的，一个应用程序可以是一组合作的线程，在相同的地址空间中并行执行。线程在不同的处理器上运行可以带来性能的显著提升。线程可以分为内核级线程和用户级线程，内核级线程由操作系统调度，用户级线程由线程库管理，内核无法感知到它们。要在一台 CPU 上运行，用户级线程最终必须映射到相关的内核级线程，这个映射可能是间接的，可能使用轻量级进程（LWP）。\n竞争范围（Contention Scope）包括进程竞争范围（PCS）和系统竞争范围（SCS）。在 PCS 中，线程库将用户级线程调度到可用的 LWP 上。CPU 的竞争仅在同一进程的线程之间进行。在 SCS 中，内核决定将哪个内核级线程调度到 CPU 上。CPU 与 SCS 的竞争发生在系统中的所有线程之间。\n线程调度包括局部调度（PCS）和全局调度（SCS）。局部调度指的是进程竞争范围，采用 m:1 和 m:n 模型。全局调度指的是系统竞争范围，采用 1:1 模型。Pthread 调度 API 允许在创建线程时指定 PCS 或 SCS。在实现多对多模型的系统中，PTHREAD_SCOPE_PROCESS 策略将用户级线程调度到可用的 LWP 上，线程库维护 LWP 的数量。PTHREAD_SCOPE_SYSTEM 策略将为每个用户级线程创建并绑定一个 LWP，实际上将线程映射为一对一策略。操作系统可能会限制这些选项，例如 Linux 和 Mac OS X 仅允许 PTHREAD_SCOPE_SYSTEM。\nOperating System Examples Linux Scheduling Linux调度算法，是Linux操作系统中用于分配CPU资源的进程调度策略。其核心目标是公平、高效地为各进程分配CPU时间片，以实现最大的系统资源利用率。\n1. 任务优先级\n任务的优先级与其数值成反比。 实时任务：优先级为0-99，拥有较高的优先级。 非实时任务：优先级为100-140，拥有较低的优先级。 2. 时间共享 (100-140)\n优先给予具有最多积分的进程CPU时间片。 定时器中断发生时，进程积分逐渐减少。 积分为0时，切换至另一进程。 所有进程积分归零时，重新分配积分。 3. 实时调度 (0-99)\n符合Posix.1b标准的软实时调度。 先来先服务（FCFS） 循环轮转（RR） 总是优先执行最高优先级的进程。 4. 任务优先级的类别\n实时任务：分配固定的静态优先级，因需满足严格的时间限制。 其他任务：动态优先级，由其\u0026quot;nice\u0026quot;值（相对优先级）决定，取值范围为-20到19。值越低，优先级越高。调度时根据此优先级确定。 5. 优先级索引的任务列表\n该列表根据任务优先级排序，存放所有就绪状态的任务。 高优先级任务优先执行，保证关键和实时任务获得足够资源。 低优先级任务在资源充裕时得以执行，以保证系统的公平与效率。 调度器会按照此列表优先级，从高到低地选择并执行任务。 Windows Scheduling 基于优先级的抢先式调度\n调度器：调度器即为分派器。\n线程的运行状态：\n遭遇阻塞。 时间片用完。 被高优先级的线程抢占。 线程终止。 实时线程与非实时线程：实时线程可以抢占非实时线程。\n优先级方案：\n共有32个优先级。 变量类的优先级范围是1-15，实时类的优先级范围是16-31。 优先级0被分配给内存管理线程。 多级队列：每个优先级都有一个对应的队列。\n无可运行线程时的状态：如果没有可运行的线程，系统会运行空闲线程。\nWindows XP的优先级制度\n线程的优先级：每个线程的优先级都是基于其优先级类和相对优先级来决定的。 进程的优先级通常设为NORMAL_PRIORITY_CLASS。 线程的初始优先级通常是进程的基础优先级。 时间片用尽时的处理：当时间片用尽时，线程的优先级会被降低，但绝不会低于基础优先级；当线程从等待操作恢复时，其优先级会被提高。 Solaris Scheduling 基于优先级的线程调度\n相同优先级的处理方式：当线程具有相同的优先级时，采用循环轮转（RR，Round Robin）方式进行调度。\n线程分类：每个线程都属于以下六个类别中的一个：\n时间共享（Time Sharing, TS） 交互式（Interactive, IA） 实时（Real Time, RT） 系统（System, SYS） 公平共享（Fair Share, FSS） 固定优先级（Fixed Priority, FP） 每类特点：在每个类别中，都有不同的优先级和调度算法。\n默认调度类别：对于进程，其默认的调度类别是时间共享。\nAlgorithm Evaluation 度量标准： CPU利用率：这是一个度量CPU活跃程度的指标，通常表示为百分比。理想情况下，我们希望CPU保持高效的利用，但同时也要确保它不会过载。 响应时间：表示从请求提交到收到第一个响应所需的时间。对于交互式系统或实时系统，响应时间是一个关键指标。 吞吐量：在单位时间内完成的任务数量。对于批处理系统或高性能计算系统，吞吐量是一个重要指标。 度量标准的相对重要性： CPU利用率的最大化：但要在一个限制下，即响应时间的最大值不能超过1秒。这意味着，尽管我们希望CPU尽可能多地被利用，但我们也希望系统的响应时间保持在用户可以接受的范围内。 吞吐量的最大化：但要满足一个条件，即周转时间（从任务提交到任务完成的总时间）与任务的总执行时间成线性关系。这意味着，随着任务执行时间的增加，周转时间也会按相同的比例增加，从而确保系统的公平性。 Deterministic modeling 这段内容主要介绍了确定性建模（Deterministic modeling）的概念。确定性建模是一种针对特定预先确定的工作负载（workload）来评估调度算法性能的方法。在这种方法中，系统会对每种算法在工作负载下的性能进行定义。 举一个例子来说明，假设我们有以下的工作负载：\nFCFS（First-Come-First-Serve，先来先服务）算法 SJF（Shortest Job First，最短作业优先）算法 RR（Round Robin，轮转）算法，其中队列长度为 10 接下来，我们需要比较这三种算法的平均等待时间。 进程的 burst time（执行时间）如下： P1:10 P2:29 P3:3 P4:7 P5:12 计算每种算法的平均等待时间： FCFS：((0+10+39+42+49)/5)=28 SJF：((10+32+0+3+20)/5)=13 RR：((0+32+20+23+40)/5)=23 通过这个例子，我们可以看到不同调度算法在同一工作负载下的性能表现。在这个案例中，FCFS、SJF 和 RR 算法的平均等待时间分别为 28、13 和 23。 Queuing models 排队模型（Queuing models）是一种用于描述系统中进程等待服务的模型。在这个模型中，关键的概念是进程到达时间分布、服务时间分布以及进程队列的类型。 排队模型的主要目的是分析系统在给定资源限制下的性能表现，例如计算平均等待时间、响应时间等指标。在排队模型中，通常会考虑以下几个方面： 进程到达时间分布：这是指进程在系统中的到达时间是如何分布的。常见的到达时间分布有泊松分布、均匀分布等。 服务时间分布：这是指进程在获得 CPU 资源后执行的时间分布。常见的服务时间分布有指数分布、均匀分布等。 进程队列类型：根据系统中的进程队列类型，排队模型可以分为单队列模型和多队列模型。在单队列模型中，所有进程按照到达顺序排队等待服务；而在多队列模型中，进程会被分为多个队列，每个队列有自己的服务规则。 通过对这些参数进行建模，可以分析不同调度算法在特定系统负载下的性能表现。排队模型有助于我们了解系统在不同条件下的响应时间、吞吐量等性能指标，从而为系统优化提供依据。\nSimulations 模拟（Simulations）在评估 CPU 调度算法性能中的应用。模拟是指通过编写计算机系统的模型来进行实验，以评估不同调度算法的性能。 在模拟过程中，主要涉及以下几个方面：\n编程模型：模拟过程中需要编写计算机系统的软件数据结构，这是系统的主要组成部分。 变量：模拟中使用的一个关键变量是时钟（clock），它可以表示时间的推移。 性能统计：在模拟执行过程中，会收集和打印表明算法性能的统计数据。 数据生成：模拟所需的数据可以通过随机数生成器（random-number generator）来生成。 分布定义：模拟中的数据分布可以通过数学方式或经验方式（empirically）定义。 分布驱动模拟：但由于实际系统中连续事件之间的关系，分布驱动的模拟可能存在一定的不准确性。 这段内容主要介绍了模拟仿真在评估 CPU 调度算法性能时的优势。它与队列模型相比，具有更高的准确性。 simulations，即模拟仿真，是一种通过程序构建计算机系统模型的方式，用于评估不同调度算法的性能。在模拟过程中，钟（clock）被作为一个变量，用以表示时间的推移。通过模拟，可以收集表明算法性能的统计数据。 与之相比，队列模型（queueing models）的限制在于它们是基于固定的概率分布和系统参数进行建模的，而这些参数可能在实际运行过程中发生变化。模拟仿真则更灵活，可以生成不同分布的数据来驱动仿真，从而更准确地反映实际情况。 模拟仿真的数据可以通过以下方式收集：\n随机数生成器（random number generator）：根据设定的概率生成不同的事件序列。 数学或经验定义的分布（distributions defined mathematically or empirically）：根据实际情况设定进程到达、执行时间和完成时间的分布。 轨迹带（trace tapes）：记录实际系统中真实事件的序列。 通过这些数据，可以对不同的调度算法进行性能评估。从而为 CPU 调度算法的选择和优化提供依据。 Implementation Implementation 部分指的是将实际的调度算法在现实系统中进行评估。这个过程需要在现实操作系统的环境下运行，以便更好地了解算法的性能和适用性。 在实施过程中，主要面临以下困难： 成本问题：实施算法不仅需要编写算法代码和修改操作系统以支持它，以及其所需的数据结构，还需要考虑用户对不断变化的操作系统的反应。这可能导致额外的成本支出。 环境变化：环境变化不仅来自于新程序的编写和问题类型的变化，而且还可能是调度器性能的结果。这使得调度算法在现实系统中的实施变得更加困难，因为需要不断地调整和优化算法以适应不断变化的环境。\n","date":"2023-10-21T21:12:53Z","permalink":"https://www.xxx.blog/post/3-cpu-scheduling/","title":"3 CPU Scheduling"},{"content":"2 Processes And Threads Process Concept 进程是执行中的程序。 程序是存储在磁盘上的可执行文件。 当可执行文件加载到内存中时，程序成为进程。\n一个进程包括：\n程序代码，称为文本部分。 数据部分，包含全局变量。 进程控制块（PCB） 进程映像=代码段+数据段+PCB，进程映像是静态的，进程是动态的； 进程是进程映像/进程实体的运行过程，是系统进行资源分配和调度的一个独立单位； 进程控制块PCB是存放进程的管理和控制信息的数据结构，进程控制块PCB是进程存在的唯一标志（类似于身份证）； 所谓创建进程实质上就是创建进程映像中的PCB，撤销进程实质上是撤销进程的PCB；\n进程的执行必须按顺序进行。进程就是一个程序的运行时，包含了一些权限控制。 进程之间不共享数据，每个进程有自己独立的地址空间，一个进程至少包含一个或多个线程；\n一个进程本身可以是其他代码的执行环境，例如JVM 可执行的Java程序在Java虚拟机（JVM）中执行。 JVM作为一个进程执行： 解释加载的Java代码 代表该代码采取行动（通过本机机器指令）。 例如，java程序：命令java将JVM作为普通进程运行。JVM执行Java程序。 Process State 随着进程的执行，它会改变状态。一个进程可能处于以下状态之一：\nnew：进程正在被创建。 running：正在执行指令。 waiting：进程正在等待某个事件发生。 ready：进程等待被分配到处理器。 terminated：进程已经执行完成。 在任何给定时间，每个处理器上只能运行一个进程，但有许多进程可能处于就绪和等待状态。\nProcess Control Block(PCB) 每个进程都由一个 PCB（进程控制块）表示，也被称为进程控制块。PCB是进程存在的唯一标志！ PCB 包含与每个进程相关的信息：\n进程状态 程序计数器 CPU 寄存器 CPU 调度信息 - 优先级、调度队列指针 内存管理信息 账户信息 - 使用的 CPU 时间量，自启动以来经过的时钟时间，时间限制，帐户号码等 I/O 状态信息 - 分配给进程的 I/O 设备列表，打开文件列表等 进程号 - 标识符，例如：该进程的标识符，其父进程的标识符，用户标识符等。 PID是操作系统中的进程标识符，操作系统中每打开一个程序都会创建一个进程ID也就是PID，在运行时每个进程有唯一的PID编号，进程终止后PID标识符会被系统回收利用； CPU Switch From Process to Process 进程的地址空间 地址空间分为物理地址空间(内存、磁盘)和虚拟地址空间；\n因为操作系统的缘故，对一个进程/程序来说似乎独占所有硬件资源，一般一个进程会分为如下几个段，其中堆向上生长，栈向下生长（注意这里的地址空间是虚拟地址空间，之后也会讲，分段常用于用户视图）\nProcess Feature 进程的基本特征是对比单个程序的顺序执行提出的，也是对进程管理提出的基本要求：\n动态性：进程具有一定的生命周期，是动态产生、变化和消亡； 并发性：指多个进程实体同时存于内存中，能在一段时间内同时运行； 独立性：指进程实体是一个能够独立运行、独立获得资源和独立接受调度的基本单位； 异步性：进程按照各自独立的、不可预知的速度向前推进，为了避免异步，在操作系统中必须配置相应的进程同步机制； 结构性：结构上看，进程实体是由程序段、数据段以及进程控制块三部分组成；\nWhen to Switch a Process 时钟中断（Clock interrupt）: 进程已经执行了最大允许的时间片。\nI/O 中断（I/O interrupt）: 处理内存错误时，可能需要将虚拟内存中的数据载入主内存。\n陷阱（Trap）: 当发生错误时，可能会导致进程进入终止/退出状态。\n系统调用（System call）: 例如，文件打开等操作。\nProcess Scheduling 多道程序设计的目标是最大化CPU利用率。通过在多个进程之间频繁切换CPU，使用户感觉好像它们都在同时运行。分时共享的目标则是让用户在程序运行时与之互动。\n进程调度程序负责选择一个可用的进程在CPU上执行。在单处理器系统上，由于硬件资源的限制，最多只能运行一个进程。其余的进程将不得不等待，直到CPU空闲并可以重新调度它们。\n通过合理的进程调度和时间分配，多道程序设计和分时共享可以有效地提高系统的整体性能和用户满意度。\nCPU管理的最终结构概括为操作系统启动多个进程，并能够在多个进程之间调度/切换，从而实现CPU高效管理；\n（1）在操作系统中现在有三个进程，其PID分别是1、2、3；\n（2）现在正在执行的是2号进程；\n（3）进程1执行到53地址处停了下来，进程3执行到250地址处停了下来，进程1停下来的原因是进程1用完了时间片，进程3停下来的原因是进程3要等到磁盘读写完成；\n（4）进程1和进程3停下来的执行现场分别存放在各自的PCB中；\n（5）操作系统通过这些PCB可以感知、了解并控制各个进程，操作系统对进程的管理关键在于对这些PCB的管理；\n多进程视图是操作系统的核心视图.操作系统在从开机启动到最后关机的全部运行过程中都要围绕这个多进程视图工作；\n一个进程执行完毕以后可以调用exit（）来退出自己，但shell不会调用exit（）退出自己，除非关机。因此shell进程会一直执行，不断创建新的进程，并用这些新进程完成各种各样的任务。在操作系统最终关机时，会将系统中所有进程杀死；\n编写操作系统中的进程管理模块，需要做到以下两点：\n从上层用户角度想象系统中的多个进程，要在头脑里形成这样的画面，操作系统里有多个进程，每个进程各司其职，要做新的工作就会在系统中创建出的新进程等； 从下层系统内核角度感知和控制系统中的多个进程； Scheduling Queues 作业队列 - 系统中的所有进程集合。\n就绪队列 - 驻留在主存储器中、准备好等待执行的所有进程的集合。\n通常存储为链表。\n头部包含指向列表中第一个和最后一个PCB的指针。\n设备队列 - 等待I/O设备的进程列表。每个设备都有自己的设备队列。\nRepresentation of Process Scheduling Schedulers Long-term scheduler (or job scheduler)选择哪些进程应该被带入就绪队列。 Short-term scheduler (or CPU scheduler)选择下一个应该执行哪个进程并分配CPU。\n主要区别：执行频率。\n短期调度器被调用频率非常高（毫秒）（调度器必须快）。 长期调度器被调用频率非常低（调度器可能很慢）（秒，分钟）（调度器必须快）。 长期调度器控制多道程序的程度，即在内存中的进程数。\n进程可以分为以下两种：\nI/O密集型进程（I/O-bound process）：花费大量时间进行I/O操作而不是计算，存在许多短暂的CPU突发。 计算密集型进程（CPU-bound process）：花费大量时间进行计算；很少有非常长的CPU突发。选择好的进程组合。 如果所有进程都是I/O密集型的，准备队列将几乎总是空的，CPU调度程序几乎没有工作要做。如果所有进程都是计算密集型的，I/O等待队列将几乎总是空的，设备将无法使用。\n短期调度（Short-term Scheduling）\n目的：短期调度，也称为CPU调度，主要负责决定哪个就绪进程应该被分配CPU时间。 频率：这种类型的调度发生得非常频繁，通常以毫秒级别计算。 调度对象：它关注的是处于就绪队列中的进程或线程。 特点： 快速和频繁：因为必须频繁地做出决策，所以短期调度算法需要非常快速和高效。 决定进程执行顺序：它负责选择下一个将使用CPU的进程。 中期调度（Medium-term Scheduling）\n目的：中期调度主要负责调整系统的多道程序程度，通过实施进程的挂起和唤醒来控制系统的负载。 频率：这种调度发生的频率低于短期调度，但比长期调度更频繁。 调度对象：它主要处理已经开始执行但暂时被挂起的进程。 特点： 内存管理：中期调度常常与内存管理相关联，如页面置换算法。 减少负载：通过将进程移出或移入就绪队列来减少系统负载。 长期调度（Long-term Scheduling）\n目的：长期调度，也称为作业调度，负责决定哪些进程应从作业池中移入就绪队列。 频率：这种调度发生得较不频繁，通常以秒或更长的时间间隔计算。 调度对象：它涉及决定哪些新进程被引入内存的就绪队列。 特点： 影响系统的多道程序程度：长期调度决定了系统中同时运行的进程数。 性能和资源利用率：它影响整体系统性能和资源的利用率。 Medium-Term Scheduling 该进程被中程调度程序交换出去，存储在磁盘上，稍后又被交换进来。\nMedium-Term Scheduling（中期调度）的主要作用是避免某些进程长时间等待。当一个进程在等待I/O操作完成时，它会被移至I/O等待队列。如果进程在等待过程中被换出（swapped out），则它将被存储在磁盘上，并在稍后被换入（swapped in）由中期调度器进行操作。这样，当CPU执行速度超过I/O操作速度时，所有进程都可以等待I/O操作完成，从而释放更多的内存空间。在等待期间，进程的状态变为“交换等待”（swapped waiting）。\nSwapped/Suspended Processes 处理器的速度通常比I/O设备快，因此在某些情况下，所有的进程都可能在等待I/O操作。为了释放更多内存，这些进程会被交换到磁盘上。\n等待状态被转换为“swapped waiting”，表示进程已被交换到磁盘上。在这个过程中，还引入了两种新的状态：\n\u0026ldquo;swapped waiting\u0026rdquo;（挂起等待/阻塞）：表示进程已被交换到磁盘，正在等待某些事件的发生。 \u0026ldquo;swapped ready\u0026rdquo;（挂起就绪）：表示进程已准备好执行，但仍然位于磁盘上，等待被交换回内存执行。 Reasons for Process swapped out 进程被换出的原因有多种，包括：\n在多道程序环境下，系统会根据优先级、CPU时间片、内存使用情况等因素来调度进程，如果一个进程在等待I/O操作（例如磁盘读写），或者它的优先级低于其他进程，那么它可能会被暂时换出，以便其他进程可以继续执行。 当CPU切换到另一个进程时，系统需要保存旧进程的状态并加载新进程的保存状态，这个过程被称为上下文切换。如果系统频繁地进行上下文切换，那么每个进程可能会被短暂地暂停并被换出，以便其他进程可以执行。 在内存不足时，系统会将一些进程暂时换出到磁盘上，以便为其他进程腾出空间。 在某些情况下，父进程可能会希望暂停其子进程的执行，以检查或修改被暂停的进程，或者协调多个进程的活动。这可以通过将子进程换出到磁盘来实现。 操作系统需要释放足够的内存来引入其他进程，如果当前没有足够的内存，那么一些进程可能会被暂停并被换出到磁盘上。 进程可能由于其他原因被换出，例如它已经完成了它的任务或者出现了错误。 Context Switch 当CPU切换到另一个进程时，需要进行上下文切换（Context Switch）。这是指系统必须保存当前进程的状态，并加载下一个进程的保存状态。这个过程包括保存处理器状态，包括程序计数器和其它寄存器，更新PCB以及内存管理数据结构，并恢复选定进程的上下文。这个过程是纯开销，系统在切换过程中并不执行任何有用的工作。上下文切换的时间取决于很多因素，包括系统的设计和进程的性质。在多任务处理中，上下文切换是很重要的，它使得各个进程可以共享CPU资源，并且可以有效地管理系统的运行。\n上下文在进程的 PCB 中表示。\n当 CPU 切换到另一个进程时，系统必须保存旧进程的状态并加载新进程的已保存状态。这被称为上下文切换。\n上下文切换包括以下步骤：\n保存处理器的上下文，包括程序计数器和其他寄存器。 更新当前正在运行的进程的 PCB。 将 PCB 移动到适当的队列 - 就绪队列或等待队列。 选择另一个进程执行（调度）。 更新所选进程的 PCB。 更新内存管理数据结构。 恢复所选进程的上下文。 上下文切换时间是纯粹的开销，系统在切换期间不执行有用的工作。上下文切换时间取决于硬件支持。\n多进程视图工作的核心是多个进程之间的来回切换，这也是并发的基本含义，操作系统实现多进程视图需要解决如下两点：\n什么时候切换； 具体如何切换； 切换的时机就是当CPU出现空闲的时候，这种空闲点也被称为调度点，调度点可以是当前进程在执行过程中产生的如exit()，也可以是操作系统强行加入的如进程分配的时间片耗尽；\n//一个调度点的实例代码 某个进程{ 启动磁盘写； pCur.state=\u0026lsquo;W\u0026rsquo;;//将进程状态修改为阻塞态 将pCur放在DiskWaitQueue;//pCur就是用于保存 “CPU中当前进程执行现场” 的PCB结构，当然它就是当前进程的PCB，便于将来能够切换回当前进程 schedule();//调用schedule函数完成进程切换 }\n操作系统调用函数schedule()实现切换，其实现原理如下：\n从就绪队列中选出下一个进程的PCB，我们称为pNew； 用PCB结构pNew中存放的执行现场去替换CPU中的PC、AX等寄存器； 为了能够切换回当前进程，切换之前还应将CPU中的“当前进程执行现场”保存在当前进程的PCB结构中，该PCB结构我们称为pCur； 这其中如何选择pNew需要精心设计算法，如果只是简单的选择就绪队列首部的进程作为下一个进程，这样公平但是对于某些应当需要优先执行的进程来说非常致命；\n简单给出schedule函数的基本代码结构\nschedule(){ pNew=getNext(ReadyQueue); switch_to(pCur,pNew); } switch_to(pCur,pNew){ //保存当前进程的PCB结构 pCur.ax=CPU.ax; pCur.bx=CPU.bx; \u0026hellip; //用pNew中的执行现场替换CPU中的寄存器 CPU.ax=pNew.ax; CPU.bx=pNew.bx; }\n进程的组织 要论述操作系统是如何实现多进程视图（前面已经给出过图示）的，第一步要解决的问题就是在计算机中如何组织多个进程；\n操作系统管理进程的关键就是管理进程对应的PCB数据结构，所以很容易就能想到，组织多个进程就是用合适的数据结构来管理这些PCB；\nPCB之间存在简单的线性关系，简单而高效的方式就是将这些PCB组织成队列，并且在管理进程时需要区分进程位于哪个队列，根据进程状态概念可以分类描述操作系统中的进程：\n运行态：当前占有CPU、正在执行的进程状态； 就绪态：一个进程具备所有可执行的条件，只要获得了CPU就能开始执行； 阻塞态：也称为睡眠态或等待态，指进程缺少某些条件（比如磁盘正在读写、打印机忙等），即使分配了CPU也无法执行的状态； 基于单CPU的背景，因此只有一个CPU意味着只会有一个处于运行态的进程，多个阻塞队列（多种等待事件），一个就绪队列（都在等待CPU），故形成下图所示多进程基本组织方式\n上图类似于一张合照，是某一时刻下多个进程在操作系统中的样子，当然利用进程状态还可以描述一个进程在其执行过程中的演化过程（该过程常被称为进程的生存周期）\n进程隔离 尽管多个进程同时在内存中交替执行可以提高CPU的使用效率，但是同时在内存中的多个进程也会相互影响（比如某个进程把另一个进程的内存地址给修改了）；\n解决上述问题的办法就是使用地址隔离\n进程操作的地址并不是真的物理内存地址，而是通过一个映射表对应到一个真实的物理地址，这也是需要用GDT表和页表来翻译CS:EIP的根本原因；\n操作系统给每个进程分配的真实的内存区域是只属于该进程的、互相不重叠的，就算进程1和进程2同时访问的地址是100，但是通过映射表后访问的真实地址其实是2100和1100；\nOperations on Processes Process Creation 允许一个进程创建另一个进程，此时创建者称为父进程，被创建的进程称为子进程： 子进程可以继承父进程所拥有的资源； 子进程被撤销的时候需要将从父进程那里获得的资源归还给父进程； 撤销父进程必须同时撤销其所有的子进程；\n创建一个新进程的过程：\n为新进程分配唯一的PID并申请一个空白的PCB，若PCB申请失败则创建失败； 为新进程的程序和数据以及用户栈分配必要的内存空间，若资源不足不会导致创建失败，而是处于阻塞态等待内存资源； 初始化PCB，主要包括初始化标志信息、初始化处理机状态信息以及初始化处理机控制信息、进程优先级等； 若就绪队列能够接纳新进程则将新进程插入就绪队列等待被调度运行； 进程创建的原因\n提交批处理作业 用户登录 创建以提供打印等服务的目的 进程创建另一个进程 创建进程涉及以下步骤：\n为进程分配一个唯一的进程标识符，通常是一个整数。 为进程分配内存空间。 初始化进程控制块（PCB）。 建立适当的链接，例如将新进程添加到用于调度队列的链接列表中。 创建或扩展其他数据结构，以维护相关信息，例如维护一个账户文件。 处理资源共享，这涉及确定新进程与其父进程之间共享的资源，可以有不同的模式，如父进程和子进程共享所有资源、子进程共享父进程的一部分资源、或父进程和子进程之间不共享任何资源。 当创建一个进程时，通常会传递初始化数据，这些数据可能从父进程传递给子进程，以便子进程能够正确初始化。 在进程创建方面，有一些执行和地址空间的选择：\n执行方面，有两种可能性： 父进程和子进程并发执行。 父进程等待，直到其一些或全部子进程终止。 地址空间方面，有两种可能性： 子进程是父进程的副本，它们共享相同的地址空间。 子进程有一个程序加载到它自己的地址空间中，独立于父进程。 在UNIX系统中，每个进程都由其进程标识符（PID）唯一标识，可以通过系统调用fork创建新进程。在创建子进程后，可以使用exec系统调用将子进程的内存空间替换为新程序，实现程序的更改。这些机制允许UNIX系统创建和管理进程，支持各种并发和应用程序切换操作。\nProcess Termination 引起进程终止的事件有：\n正常结束：表示进程的任务完成并准备退出运行； 异常结束：进程运行过程中发生异常导致程序无法继续运行； 外界干预：进程因为外界的请求而终止运行； 撤销原语如下：\n1.根据被终止进程的标识符检索PCB，从中读出该进程的状态； 2.若被终止的进程处于执行状态则立即终止该进程的执行，将处理机的资源分配给其他进程； 3.若该进程有子孙进程则将其所有子孙进程终止； 4.将该进程拥有的全部资源归还给其父进程或操作系统； 5.将该PCB从所在队列删除；\n进程终止的原因可以有很多，包括但不限于：\n正常完成：进程成功完成其任务。 超出时间限制：进程运行时间超过了设定的最大限制。 内存不足：进程需要的内存资源不可用。 边界违规：进程试图访问超出其分配边界的内存。 保护错误：例如，尝试向只读文件写入。 算术错误：进程执行的数学运算导致错误。 时间超出：进程等待某个事件的时间超过了指定的最大等待时间。 I/O 失败：例如，尝试打开一个不存在的文件。 无效指令：当尝试执行非法或无效的指令时发生。 特权指令：尝试执行只有特权进程才能执行的指令。 数据滥用：例如，类型错误。 操作系统干预：当操作系统介入处理进程问题，如解决死锁时。 父进程终止：子进程会在其父进程终止时终止。 这些是可能导致进程终止的各种情况，操作系统会根据不同的终止原因采取适当的处理措施。\n进程终止可以由多种方式触发：\n进程执行完最后一条语句，然后请求操作系统删除它（通过 exit）。\n进程将数据输出给父进程，然后等待父进程的确认（通过 wait）。\n操作系统会释放进程占用的资源，包括内存和其他系统资源。\n此外，父进程也可以由多种原因来终止其子进程的执行，例如：\n子进程占用的资源超出了分配的限额。 子进程执行的任务不再需要。 父进程本身终止。 需要注意的是，如果一个父进程终止，操作系统通常不允许其子进程继续运行，这可以防止子进程在没有父进程的情况下执行。因此，通常由操作系统来处理子进程的终止。\n进程的阻塞和唤醒 进程的阻塞是进程自身的一种主动行为，只有处于运行状态的进程才可能转换为阻塞态，阻塞原语的执行过程如下：\n1.找到将要被阻塞进程的PID对应的PCB； 2.若该进程为运行态则保护其现场并将其状态转换为阻塞态； 3.把该PCB插入相应事件的等待队列，将处理机资源调度给其他就绪进程；\n当被阻塞进程需要的资源到达，由相关进程调用唤醒原语，将等待该事件的进程唤醒，唤醒原语如下：\n1.在该事件的等待队列中找到相应进程的PCB； 2.将其从等待队列中移出，并置其状态为就绪态； 3.把该PCB插入就绪队列，等待调度程序调度；\n注意：Block 原语和Wakeup 原语是一对作用刚好相反的原语，必须成对使用。Block原语是由被阻塞进程自我调用实现的，而Wakeup原语则是由一个与被唤醒进程合作或被其他相关的进程调用实现的；\nInterprocess Communication 独立进程（Independent process）不能影响或被另一个进程的执行所影响。\n协作进程（Cooperating process）可以影响或被另一个进程的执行所影响。进程协作的优点包括：\n信息共享：允许进程之间共享数据和信息，从而实现协同工作。 计算加速：多个进程协同工作可以加速计算和任务的完成。 模块化：将系统划分为多个协作的模块或进程，使系统更易于管理和维护。 方便性：允许不同的进程协同执行各自的任务，从而提高系统的灵活性和效率。 进程协作通常可以使用两种基本模型来实现：\n共享内存（Shared-memory）：多个进程可以访问相同的内存空间，从中读取和写入数据，以实现协同工作。允许进程之间以最大的速度和便利进行通信。 消息传递（Message passing）：进程之间通过发送和接收消息来进行通信，以协同执行任务。这种方式更加分离，进程之间互相独立。 数据交换的方式：消息传递适用于需要交换较少数据的情况，因为它不需要考虑数据冲突。每个进程可以将消息发送给其他进程，实现数据交换。 跨计算机通信：消息传递更容易在不同计算机之间实现，因为它允许进程在不同计算机上发送和接收消息，适用于分布式系统和网络通信。 Shared-memory systems 在通信的进程之间存在一块可直接访问的共享空间，通过对这片共享空间进行写/读操作实现进程之间的信息交换。 在对共享空间进行写/读操作时，需要使用同步互斥工具（如P操作、V操作），对共享空间的写/读进行控制。 共享存储又分为两种： 低级方式的共享是基于数据结构的共享； 高级方式的共享则是基于存储区的共享。 操作系统只负责为通信进程提供可共享使用的存储空间和同步互斥工具，而数据交换则由用户自己安排读/写指令完成。 注意，进程空间一般都是独立的，进程运行期间一般不能访问其他进程的空间，想让两个进程共享空间，必须通过特殊的系统调用实现，而进程内的线程是自然共享进程空间的。 Message-passing systems 在消息传递系统中，进程间的数据交换以格式化的消息（Message） 为单位。若通信的进程之间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信。 进程通过系统提供的发送消息和接收消息两个原语进行数据交换。这种方式隐藏了通信实现细节，使通信过程对用户透明，简化了通信程序的设计，是当前应用最广泛的进程间通信机制。 在微内核操作系统中，微内核与服务器之间的通信就采用了消息传递机制。由于该机制能很好地支持多处理机系统、分布式系统和计算机网络，因此也成为这些领域最主要的通信工具。\n消息传递的基本结构:\n发送消息：send(message) 接收消息：receive(message) 当进程P和Q需要通信时，它们需要：\n建立一个用于连接它们的通信链路。 使用send和receive操作来交换消息。 通信链路的实现包括逻辑方面和物理方面：\n逻辑方面：涉及逻辑属性，例如通信链路的属性。 物理方面：可能涉及共享内存或硬件互连等物理元素。 1）直接通信方式。发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息。\n直接通信中的命名问题包括以下内容：\n进程必须显式地为对方命名： send(P, message)：向进程P发送消息。 receive(Q, message)：从进程Q接收消息。 通信链路的属性： 通信链路是自动建立的。 一个通信链路与恰好一个进程对相关联。 每对通信进程之间存在恰好一个通信链路。 通信链路可以是单向的，但通常是双向的。 寻址的不对称性：receive(id, message)会导致定义的进程模块的可重用性受限。 2)间接通信方式。发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息。 这种中间实体一般称为信箱（也称为端口）。该通信方式广泛应用于计算机网络中。\n特点： 每个邮箱都有唯一的标识符（id）。 进程只有在共享同一个邮箱的情况下才能进行通信。 通信的原语包括： send(A, message)：将消息发送到邮箱A。 receive(A, message)：从邮箱A接收消息。 通信链路的属性包括： 链路只有在进程共享一个邮箱时才会建立。 一个链路可以与多个进程相关联。 每对进程可以共享多个通信链路。 链路可以是单向的或双向的。 多进程共享邮箱的通信难题： 当多个进程共享一个邮箱，例如进程P1、P2和P3共享邮箱A时，如果P1使用send(A, message)发送消息到邮箱A，实际的接收者成为了一个问题。 为此，存在几种可能的解决方案： 允许一个链路与多个进程相关联：例如，消息可以被发送到与此链路相关联的任一进程。 限制同时接收的进程：只允许一个进程执行receive()操作，确保只有特定进程接收到消息。 系统随机选择接收者：系统选择一个接收者，但会通知发送者哪个进程接收了消息。这种方式需要进一步同步和协调，但为发送者和接收者提供了关于消息交付状态的明确信息。 邮箱的所有权： 邮箱可以由特定的进程拥有，或者由操作系统独立地拥有。 进程拥有的邮箱：此邮箱的所有者是唯一可以通过它接收消息的进程。而其他进程可以发送消息到这个邮箱。 操作系统拥有的邮箱：此类邮箱是独立的，不属于任何特定进程。进程可以通过操作系统提供的机制对邮箱执行一系列操作，如创建、发送/接收消息以及删除。 消息传递的同步性： 消息传递可能是同步的（阻塞）或异步的（非阻塞）。 阻塞消息传递： 发送方阻塞：直到消息被接收。 接收方阻塞：直到消息可用。 非阻塞消息传递： 发送方：发送消息后继续执行其他操作。 接收方：无论消息是否可用，都会立即检索。 消息队列缓冲： 消息队列是与通信链路相关的，并有三种可能的缓冲方式： 零容量：没有消息缓存。发送方必须等待接收方准备好会合。 有界容量：队列具有固定的大小，例如n条消息。当队列满时，发送方必须等待。 无界容量：队列大小是无限的，所以发送方无需等待，可以随时发送消息。 Producer-Consumer Problem 协作进程中的常见范例是生产者-消费者问题，其中一个生产者进程生成信息，而一个消费者进程获取并使用该信息。\nShared-memory 定义：使用一个共同的内存区域或缓冲区，该区域可以由生产者写入数据，并由消费者读取和消费数据。\n主要有两种类型的缓冲区：\n无界缓冲区（unbounded-buffer）：不对缓冲区的大小设定实际限制，可以不断地存储项目。 有界缓冲区（bounded-buffer）：假定缓冲区有一个固定的大小，即缓冲区中可以存储的项目数量有限。 不论使用哪种缓冲区类型，生产者和消费者之间需要进行同步。这确保生产者不会在缓冲区已满时添加数据，也确保消费者不会从空的缓冲区中读取数据。\n关于同步：在多进程环境中，由于调度和执行顺序是不确定的，可能会导致数据不一致或其他错误。因此，引入了临界区的概念，确保在给定时间内只有一个进程可以访问共享资源或数据。\nPipe 管道是一种在进程间进行通信的方法。它允许一个进程的输出成为另一个进程的输入。\n定义：管道是一个通信机制，允许一个进程向管道的一端写入数据，而另一个进程从另一端读取数据。 特性： 数据在管道中是先进先出的。 如果管道为空，读进程会被阻塞，直到有数据可读。 如果管道已满，写进程会被阻塞，直到有空间可写。 管道在Linux中通常有一个固定的大小（例如，4KB）。当管道满时，写操作会被阻塞。当管道空时，读操作会被阻塞。 管道可以用于父子进程间的通信。一个进程可以创建一个管道，并将其传递给其子进程。 通常，管道只支持单向通信。要进行双向通信，可能需要两个管道。 注意：从管道读取的数据是一次性的。一旦数据被读取，它就从管道中删除了。\nExample of IPC Systems POSIX shared memory\nMessage passing in the Mach operating system\nWindows\nCommunication in Client-Server Systems Sockets 套接字（Socket）\n套接字是用于通信的端点。\n它是 IP 地址与端口号的组合。例如，套接字 161.25.19.8:1625 指的是主机 161.25.19.8 上的端口 1625。\n通信是在一对套接字之间进行的。\n所有低于 1024 的端口都被认为是众所周知的，可以用来实现标准服务。\n例如，FTP 服务器监听端口 21，telnet 服务器监听端口 23，Web 或 HTTP 服务器监听端口 80。\n当客户端进程发起连接请求时，它会由其主机计算机分配一个端口（大于 1024）。\nSocket通信是一种常见且高效的分布式进程通信方式。它是一种低级通信形式，允许在分布式进程之间交换未经结构化的字节流。在Socket通信中，所有的连接必须是唯一的。\nRemote Procedure Calls (RPC) 远程过程调用（RPC）是一种抽象的过程调用方法，用于在网络系统上的进程之间进行通信。通过RPC，交换的消息是结构良好的。\n每个消息都是发送到远程系统上某个端口的RPC守护进程。每个消息包含要执行的函数标识符和要传递给该函数的参数。然后按照请求执行该函数，并将任何输出以单独的消息发送回请求者。\n端口是消息数据包的起始处的一个数字。系统拥有一个网络地址，但可以在该地址内有多个不同的端口，以区分支持的多个网络服务。如果远程进程需要某项服务，它会将消息地址定向到适当的端口。RPC的语义允许客户端以与本地调用过程相同的方式调用远程主机上的过程。\n为此，客户端提供了一个存根（stub），作为服务器上实际过程的客户端代理。客户端存根用于定位服务器上的端口，对参数进行编组，并向服务器发送消息。服务器端存根接收此消息，解包编组的参数，并在服务器上执行过程。返回值使用相同的技术传递回客户端。\n数据的表示在不同机器上可能是不同的，因此需要一种机器无关的数据表示方式，如外部数据表示（XDR）。客户端将机器相关数据转换为XDR，服务器将XDR数据解组并转换为机器相关表示。\n调用的语义为“仅一次”——将时间戳附加到每条消息，服务器必须保留其已经处理的消息的所有时间戳历史记录，以确保不会处理重复消息。还有“正好一次”——服务器向客户端发送确认消息，确保消息的唯一性。\n绑定信息可以预先确定，即使用固定端口地址，也可以通过约会机制进行动态绑定，根据需要绑定端口。\nRemote Method Invocation (RMI, Java) RMI（远程方法调用）是类似于RPC的Java机制，允许一个机器上的Java程序调用远程对象的方法。\nRMI使用存根（stubs）和骨架（skeletons）来实现远程对象，因此对于客户端和服务器来说，远程方法是透明的。存根是远程对象的代理，位于客户端。骨架负责解组参数并在服务器上调用所需的方法。\nRMI有关参数传递行为的规则如下：\n如果已经编组的参数是本地对象，它们将使用对象序列化技术进行复制传递。 如果参数也是远程对象，它们将通过引用传递。 如果要将本地对象作为参数传递给远程对象，它们必须实现java.io.Serializable接口。 Threads Threads 线程，也称为轻量级进程（LWP），是CPU利用的基本单位。\n包括线程ID、程序计数器、寄存器集合和堆栈。 与属于同一进程的其他线程共享其代码段、数据段和其他操作系统资源，如打开的文件和信号。 引入进程之后，进程是资源（除CPU外的系统资源）分配的单位，内核级线程是处理器调度和分配的单位。 线程本身不具有资源，它可以共享所属进程的全部资源 一个线程可以创建和撤销另一个线程，同一进程中的多个线程之间可以并发执行。 线程与进程的比较：\n调度 在同一进程中，线程的切换不会引起进程切换。但从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。 资源 线程不拥有系统资源（仅有一点必不可少、能保证独立运行的资源），但线程可以访问其隶属进程的系统资源 独立性 每个进程都拥有独立的地址空间和资源，除了共享全局变量，不允许其他进程访问。某进程中的线程对其他进程不可见。同一进程中的不同线程是为了提高并发性及进行相互之间的合作而创建的，它们共享进程的地址空间和资源。 系统开销 由于一个进程内部有多个线程，若线程的切换发生在同一个进程内部，则只需要很少的时空开销。 由于同一进程内的多个线程共享进程的地址空间，因此这些线程之间的同步与通信非常容易实现。 支持多处理机系统 可以将进程中的多个线程分配到多个处理机上执行。 线程的属性\n每个线程都应有一个唯一的标识符和一个线程控制块，线程控制块记录了线程执行的寄存器和栈等现场状态。 不同的线程可以执行相同的程序，即同一个服务程序被不同的用户调用时，操作系统把它们创建成不同的线程。 Thread States 线程的三种基本状态：Running, ready, waiting\n与线程状态变化相关的操作包括：\nSpawn：创建另一个线程 Block、Unblock：阻塞或解除阻塞线程 Finish：释放寄存器上下文和堆栈资源 Multicore Programming 多核编程是一种允许系统同时执行多个任务的编程方法。并行性意味着系统能够同时执行多个任务，而并发性则支持多个任务同时取得进展。在单处理器/核心系统中，调度程序提供并发性。CPU设计者通过添加硬件来提高线程性能，以提高系统性能。\nMultithreading Models 用户级线程，在内核之上支持，无需内核支持而由用户程序管理。 所有线程管理由应用程序完成。内核不知道线程的存在。用户线程是在内核之上支持的，由用户级别的线程库实现。该库提供线程的创建、调度和管理支持，无需内核的支持。 在用户级线程中，有关线程管理(创建、撤销和切换等)的所有工作都由应用程序在用户空间中完成，内核意识不到线程的存在。应用程序可以通过使用线程库设计成多线程程序。通常，应用程序从单线程开始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生例程创建一个在相同进程中运行的新线程。 三种主要的线程库： POSIX Pthreads Win32 线程 Java 线程 内核线程，由操作系统直接支持和管理。 最终，用户线程和内核线程之间必须存在关系。 受操作系统直接支持。内核在内核空间中执行线程的创建、调度和管理。内核维护进程和线程的上下文信息。 在操作系统中，无论是系统进程还是用户进程，都是在操作系统内核的支持下运行的，与内核紧密相关。内核级线程同样也是在内核的支持下运行的，线程管理的所有工作也是在内核空间内实现的。内核空间也为每个内核级线程设置一个线程控制块，内核根据该控制块感知某线程的存在，并对其加以控制。图2.5(b)说明了内核级线程的实现方式。 这种实现方式的优点如下：①能发挥多处理机的优势，内核能同时调度同一进程中的多个线程并行执行。②如果进程中的一个线程被阻塞，内核可以调度该进程中的其他线程占用处理机，也可运行其他进程中的线程。③内核支持线程具有很小的数据结构和堆栈，线程切换比较快、开销小。④内核本身也可采用多线程技术，可以提高系统的执行速度和效率。 这种实现方式的缺点如下：同一进程中的线程切换，需要从用户态转到核心态进行，系统开销较大。这是因为用户进程的线程在用户态运行，而线程调度和管理是在内核实现的。 调度是以线程为基础进行的。支持内核线程的系统示例包括Windows XP/2000、Solaris、Linux、Tru64 UNIX和Mac OS X。 有三种常见的线程实现类型： 多对一（Many-to-One） 在单个内核线程映射到多个用户级线程。线程管理在用户空间中完成。如果一个线程执行了一个阻塞的系统调用，整个进程会被阻塞。在多处理器上，多个线程无法并行运行，因为每次只能有一个线程访问内核。这种模型适用于不支持内核线程的系统，但目前很少有系统使用这种模型。例如，Solaris 2中提供的Solaris Green Threads是一个可用于Solaris的线程库，还有GNU Portable Threads。 一对一（One-to-One） 在这种模型中，每个用户级线程都映射到一个内核线程。当一个线程执行一个阻塞的系统调用时，允许另一个线程运行。这允许多个线程在多处理器上并行运行。创建一个用户线程需要创建相应的内核线程。系统支持的线程数量受到限制。使用这种模型的 系统包括Windows、Linux以及Solaris 9及更高版本。 多对多（Many-to-Many） 这种模型允许许多用户级线程映射到许多内核线程。操作系统可以创建足够数量的内核线程。当一个线程执行一个阻塞的系统调用时，内核可以调度另一个线程进行执行。支持这种模型的系统示例包括Solaris 9之前的版本以及具有ThreadFiber包的Windows。 这三种模型之间的比较如下： Many-to-One模型允许开发人员创建任意数量的用户线程，但无法实现真正的并发，因为内核一次只能调度一个线程。 One-to-One模型允许更大的并发性，但开发人员必须小心，不要在应用程序中创建过多的线程。 Many-to-Many模型允许开发人员创建必要数量的用户线程，而相应的内核线程可以在多处理器上并行运行。 这些模型的选择取决于应用程序的性质和运行环境。Many-to-Many模型通常提供最大的灵活性和性能，因为它允许更好的并发性和利用多处理器系统的优势。但是，开发人员必须小心管理线程的数量，以避免过多的开销。 Threads Libraries 线程库（Thread Libraries）提供了程序员创建和管理线程的API。有两种主要的实现方式：\n在用户空间提供一个完全不依赖内核支持的库。所有的代码和数据结构都存在于用户空间中。 实现一个在操作系统直接支持的内核级库。所有的代码和数据结构都存在于内核空间中。 主要的线程库包括： POSIX Pthreads：一种通用的线程库，支持多个操作系统，包括Linux和Unix系统。 Win32：Windows操作系统上的线程库。 Java：Java编程语言内置的线程支持。 这些库允许程序员轻松地创建、管理和同步线程，从而实现多线程应用程序。不同的操作系统和编程语言可能提供不同的线程库来满足特定需求。 在多线程编程中，全局数据（Global Data）和局部数据（Local Data）之间存在不同的访问规则：\n对于POSIX和Windows线程，在全局范围声明的数据将在同一进程中的所有线程之间共享。这意味着多个线程可以访问和修改这些全局数据。 Java没有全局数据的概念，因此访问共享数据必须在线程之间进行显式安排。在Java中，局部数据通常存储在栈上，因为每个线程都有自己的栈，所以局部数据的每个线程都有一份拷贝。 创建多个线程的一般策略包括异步线程和同步线程：\n异步线程（Asynchronous Threading）：在这种策略中，一旦父线程创建了子线程，父线程就会继续执行，使得父线程和子线程同时执行。这种策略通常用于多线程服务器等场景。 同步线程（Synchronous Threading）：在这种策略中，父线程会等待子线程完成其任务后再继续执行。这种策略用于需要等待子线程结果的场景。 同步线程（Synchronous Threading）是一种策略，当父线程创建一个或多个子线程后，必须等待所有子线程终止后才能继续执行。这被称为\u0026quot;fork-join\u0026quot;策略。 在同步线程策略中，由父线程创建的各个子线程会并发执行工作，但父线程必须等待这些工作完成后才能继续执行。一旦每个线程完成了它的工作，它就会终止并与其父线程合并（join）。只有在所有子线程都已合并后，父线程才能恢复执行。 通常，同步线程涉及大量线程之间的数据共享。例如，父线程可能会合并其各个子线程计算的结果。 这种策略适用于需要等待子线程完成工作并收集结果的情况。 Threading Issues fork() 和 exec() 系统调用的问题。 当一个程序中的线程调用 fork() 时，新的进程会复制所有线程还是只有一个线程？ ・ 如果一个线程调用 fork()，那么新进程会复制所有线程。\n・ 新的进程只复制发起 fork() 系统调用的那个线程。 如果 fork() 后立即调用 exec()，那么只复制调用线程是合适的。 ・ 如果一个线程调用 exec()，那么指定参数中的程序将替换整个进程，包括所有线程。\n・ 如果分离的进程在 fork() 后没有调用 exec()，那么分离的进程应复制所有线程。 这段内容主要阐述了在操作系统中，当程序创建新进程时，如何处理线程的复制问题。根据不同的情况，新进程会复制所有线程或仅复制发起 fork() 的线程。同时，当新进程调用 exec() 时，会替换整个进程的所有线程。如果新进程没有立即调用 exec()，那么需要复制所有线程。这是因为操作系统在处理进程创建和线程复制时，需要确保进程和线程的资源正确分配和执行路径。\nthread cancellation 线程取消是指在线程完成之前终止线程的过程。线程取消主要有两种场景：异步取消和延迟取消。 异步取消：当一个线程立即终止目标线程时，这种方式就是异步取消。在这种方式下，终止线程的操作是立即发生的，不需要等待目标线程执行到某个取消点。 延迟取消：在这种场景下，目标线程会定期检查是否需要终止。当满足取消条件时，线程才会被终止。这种方式相对于异步取消，更加灵活，但需要线程自身具备检查和处理取消的机制。 线程取消的困难之处在于，当线程被取消时，可能正在执行的任务没有完成，或者正在占用资源。为了解决这个问题，操作系统和线程库通常提供了一种机制，使线程能够在被取消时释放资源并进行清理工作。 在 Pthreads 库中，线程取消是通过 pthread_cancel() 函数实现的。该函数请求终止指定线程，但实际的终止取决于线程的状态。线程可以设置自己的取消状态和类型，也可以在运行过程中检查是否需要终止。默认情况下，线程的取消类型是延迟取消，即线程在达到取消点时才会被终止。在 Linux 系统中，线程取消是通过信号处理的机制实现的。 这段内容主要讲述了线程取消的相关知识。在线程取消中，Pthread 库提供了一个用于取消线程的函数：pthread_cancel（tid）。 ◼ 当调用 pthread_cancel（tid）时，请求取消线程。但实际的取消操作取决于线程的状态： • 线程可以通过 API 设置其取消状态和类型。\n• 如果线程禁用了取消功能，那么取消操作将一直保持待处理状态，直到线程启用它。 ◼ Pthread 库的默认取消类型是延迟取消。 • 只有在线程达到取消点时，才会发生取消。\n• 取消点可以通过调用 pthread_testcancel() 函数来创建。\n• 当取消点被触发时，清理处理程序将被调用，以释放资源。 ◼ 在 Linux 系统中，线程取消是通过信号处理的机制实现的。 综上所述，这段内容主要介绍了线程取消的原理和方法，以及 Pthread 库在线程取消过程中的作用。线程取消分为异步取消和延迟取消，其中延迟取消是默认方式。在线程达到取消点时，线程将被取消，并执行清理处理程序以释放资源。在 Linux 系统中，线程取消是通过信号处理的机制实现的。\nsignal handling 【信号处理】（Signal handling）是操作系统中用于处理进程接收到的信号的过程。信号是一种用于通知进程某个特定事件已发生的方式。这些事件可能包括硬件信号（如内存访问错误、除以零等，）、软件信号（如终止进程的特定键盘操作，如 Ctrl+C）以及其他各种事件。 信号处理的主要目的是让进程在接收到信号后能够采取相应的措施。信号处理可以分为两类：同步信号处理和异步信号处理。\n同步信号处理：同步信号是由进程自身的行为引发的，例如非法内存访问或除以零等操作。这类信号会直接传递给引发该信号的进程。当同步信号发生时，进程必须处理该信号。 异步信号处理：异步信号是由进程外部的事件引发的，如终止进程的特定键盘操作。这类信号会传递给正在运行的进程。与同步信号不同，异步信号的处理方式取决于信号类型和进程的配置。有些异步信号需要发送给所有线程，如 Ctrl+C；而有些信号只发送给非阻塞信号的线程。 在多线程程序中，信号处理需要确保信号传递给应该处理的线程。信号处理的方法取决于信号类型。同步信号需要传递给生成该信号的线程，而某些异步信号需要发送给所有线程，或者仅发送给非阻塞信号的线程。某些 UNIX 版本的多线程允许线程指定它接受哪些信号并阻塞哪些信号。 thread pools 【线程池】（Thread pools）是一种用于管理和管理线程的技术。其核心思想是在程序启动时创建一批线程，并将它们放入一个池中等待分配任务。当服务器接收到请求时，它会从线程池中唤醒一个线程，将请求传递给它进行处理。线程处理完请求后，会返回线程池等待下一次分配任务。如果线程池中没有可用的线程，服务器会等待直到有线程空闲为止。 线程池的优点主要有以下几点：\n通常比等待创建新线程更快地服务请求。 允许将应用程序中的线程数量与线程池的大小绑定。 提高系统资源利用率，降低上下文切换的开销。 总之，线程池有助于提高程序的运行效率，特别是在处理大量并发请求的场景中。 thread-specific data 【线程特定数据】（Thread-specific data）是指在多线程程序中，每个线程都有自己的数据副本，这些数据与其他线程中的数据相互独立。线程特定数据允许每个线程拥有自己的数据副本，以便在并发环境下实现数据隔离，避免数据冲突和竞争条件。 线程特定数据的主要优点如下：\n提高程序的并发性能，因为每个线程可以独立地处理任务，而无需等待其他线程完成操作。 降低数据竞争和同步开销，因为每个线程都有自己的数据副本，从而减少了锁和其他同步原语的使用。 使线程能够更好地协同工作，因为每个线程可以独立地处理任务，并根据需要共享结果。 线程特定数据与本地变量、静态数据有所不同： 本地变量：本地变量仅在单个函数调用期间可见，而在多线程环境下，不同线程之间的本地变量是相互独立的。 静态数据：静态数据在程序运行期间始终保持不变，可以被所有线程共享。然而，在多线程环境下，静态数据可能引发竞争条件和死锁等问题。 总之，线程特定数据是一种在多线程程序中管理和保护数据的方法，有助于提高程序的性能和稳定性。 Scheduler Activations 【调度器激活】（Scheduler Activations）是一种在操作系统中实现线程与内核之间通信的方法。它允许用户线程库与内核线程之间进行交互，以便内核能够通知应用程序关于某些事件的信息。调度器激活在多线程应用程序中发挥着重要作用，因为它提供了一种机制，使应用程序能够在适当的时候接收内核的通知并进行相应的处理。 调度器激活的主要特点如下：\n提供了一种用户线程与内核线程之间通信的机制。 内核可以通过调度器激活向应用程序通知特定事件，如信号、时间戳等。 用户线程库可以处理内核通知，并在适当的时候执行相应的操作。 调度器激活通常使用轻量级进程（Lightweight Process，LWP）作为用户线程与内核线程之间的中介。 在 openEuler 操作系统中，线程的实现采用了 1:1 模型，其线程库是 NPTL（Native POSIX Thread Library）。openEuler 的进程和线程在地址空间中的布局采用了类似的方式，即一个进程由一个线程组及其共享的资源组成。当应用程序中的一个线程即将阻塞时，内核会向该线程发送一个调度器激活，通知应用程序分配一个新的轻量级进程。然后，应用程序在这个新的轻量级进程中运行一个调度器激活处理程序，用于处理阻塞线程的状态保存和重新调度等操作。 总之，调度器激活是操作系统中实现线程与内核之间通信的一种重要机制，它有助于提高多线程应用程序的性能和稳定性。 ","date":"2023-10-21T20:54:29Z","permalink":"https://www.xxx.blog/post/2-processes-and-threads/","title":"2 Processes And Threads"},{"content":"1 Introduction Computer System Components\n可以计算机系统分成三个基本组成部分：底层的计算机硬件、中间层的操作系统以及上层的计算机应用程序，操作系统属于承上启下的中间层，所以它在计算机系统中的地位和作用尤为重要。\n操作系统是计算机系统中最基本的系统软件；\nWhat Operating Systems do? User view System view resource allocator control program Defining Operating Systems Kernel（nucleus）内核\nOS is the one program running at all times on the computer.(all else being system programs and application programs) Portion of operating system that is in main memory. 常驻内存 Contains most-frequently used functions.频繁使用 操作系统是计算机系统中的一个系统软件，是一些程序模块的集合，它们能以尽量有效、合理的方式组织和管理计算机的软硬件资源，合理地组织计算机的工作流程，控制程序的执行，向用户提供各种服务功能\n操作系统是安装在计算机硬件之上的一层软件；操作系统之上可以安装各种应用程序软件； 用户可以通过应用程序软件来间接使用操作系统，也可以直接使用操作系统，但通常都是通过操作系统来最终使用计算机硬件的； 直接使用操作系统：让用户通过编写程序来调用操作系统提供的系统接口从而进入操作系统。 用户通过系统接口进入操作系统后使用计算机硬件，即用户必须“穿过”操作系统才能使用计算机硬件； 操作系统管理计算机硬件，目的是让用户对计算机硬件的使用更加简便，也更加高效； Operating System Feature 操作系统是一种系统软件，操作系统的基本特征包括并发、共享、虚拟和异步\nConcurrence 并发是指两个或多个事件在同一时间间隔内发生。操作系统的并发性是指计算机系统中同时存在多个运行的程序，因此它具有处理和调度多个程序同时执行的能力。\n引入进程的目的是使程序能并发执行。\nQ：并发和并行的区别？ A： 并发：同一时间间隔 并行：同一时刻 基于单处理机的背景，实际上每个时刻仅能有一道程序执行，在一段时间内，宏观上有多道程序在同时执行，微观上这些程序仍然是分时交替执行的 —— 操作系统的并发性是通过分时得以实现的；\n而并行性需要有相关硬件的支持，要么是多流水线，要么是多处理机硬件；\nSharing 共享也就是资源共享，是指系统中的资源可供内存中多个并发执行的进程共同使用，共享可分为以下两种资源共享方式： 互斥共享方式：规定在一段时间内只允许一个进程访问资源，将在一段时间内只允许一个进程访问的资源成为临界资源或独占资源； 同时访问方式：“同时”通常是指宏观上的，微观上这些进程可能是交替地对资源进行访问，即“分时共享”；\nVirtual 虚拟是指将一个物理上的实体变为若干逻辑上的对应物； 操作系统利用了多种虚拟技术来实现虚拟处理器、虚拟内存和虚拟外部设备等： 利用多道程序设计技术把一个物理上的CPU虚拟为多个逻辑上的CPU（即分时使用一个处理器），称为虚拟处理器； 将用户感受到的存储器称为虚拟存储器（实际存储器我们编程的时候根本接触不到）； 简单来说，操作系统的虚拟技术可以归纳为：时分复用技术（处理器的分时共享）和空分复用技术（虚拟存储器）\nAsynchronism 异步是指由于资源有限，进程的执行不是一贯到底的，而是以不可预知的速度向前推进。\n异步是在多道程序环境下允许多个程序并发执行极有可能导致的进程与时间有关的错误。\nOperating-System Function fundamental management modules：进程管理、存储器管理、设备管理以及文件系统\nDevice Management The device management module is responsible for managing all the hardware devices of the computer. This includes monitoring the status of hardware devices, installing and configuring device drivers, and handling input/output operations.\nDevice Management in an operating system primarily encompasses the following functions:\nBuffer Management: Buffer management is crucial for handling input/output operations efficiently. It involves temporarily storing data in a buffer while it is being transferred between two places, such as between a device and the main memory. This process helps in managing the speed differences between the devices and the CPU. Device Allocation: Device allocation refers to the allocation of various hardware resources to different processes or users. The operating system must manage the allocation of devices in a way that optimizes their usage while avoiding conflicts and ensuring fair access for all processes. Device Handling: Device handling involves managing the actual operation of the hardware devices. This includes interpreting commands, initiating operations, and monitoring the status of devices. The operating system communicates with device drivers, which are specific to each hardware device, to perform these operations. Virtual Devices: The concept of virtual devices involves abstracting the physical hardware into a more manageable form. This allows the operating system to provide more flexible and efficient device management by presenting hardware resources as virtual devices, which can be easier to manage and share among multiple processes. Process Management A process is a program in execution 进程在执行过程中需要分配资源，当进程完成任务或终止时，需要回收其占用的资源，以便其他进程可以使用。 单线程进程有一个程序计数器（PC, Program Counter），用于指定下一条要执行的指令位置；多线程进程具有多个线程，每个线程都有一个独立的PC。 计算机系统可以在一个或多个 CPU 上并发运行多个进程，以提高系统性能。 操作系统在与进程管理相关的活动中负责以下任务：\n创建和删除用户和系统进程 挂起和恢复进程 提供进程同步的机制 提供进程通信的机制 提供死锁处理的机制 Memory Management CPU 能够直接寻址和访问的唯一大型存储设备是内存。 内存管理负责管理内存中存储的内容，从而提高 CPU 利用率和计算机响应用户的速度。 内存管理活动包括以下几个方面： 跟踪当前正在使用内存的部分以及使用者。 决定将哪些进程和数据移入和移出内存。 根据需要分配和释放内存空间。 Storage Management 操作系统为信息存储提供了uniform, logical view，使得用户和程序能够以更加简洁的方式处理存储设备。 操作系统将物理存储介质抽象为逻辑存储单元，即文件。这种抽象使得用户可以忽略底层物理存储细节，更容易地管理和操作数据。 每种存储介质都由特定的设备控制，如磁盘驱动器、磁带驱动器等。这些设备具有不同的属性，如访问速度、容量、数据传输速率以及访问方法（顺序或随机）。 File-System Management 文件通常组织成目录。 大多数系统具有访问控制来确定谁可以访问什么。\n操作系统的活动包括：\n创建和删除文件 创建和删除目录以组织文件 支持用于操作文件和目录的基本操作 将文件映射到辅助存储设备 备份文件到稳定的（非易失性）存储介质。 Mass-Storage Management 通常，磁盘用于存储无法容纳在主内存中的数据，或者需要在较长时间内保留的数据。\n操作系统在磁盘管理方面的活动包括：\n空闲空间管理 存储分配 磁盘调度 计算机操作的整体速度高度依赖于磁盘子系统及其算法。\n某些存储设备不必很快，三级存储包括光盘、磁带。 存储介质可能是WORM（只写一次，多次读取）或RW（可读写）。 虽然对系统性能不是至关重要的，但仍然需要进行管理，包括挂载和卸载、分配和释放，以及将数据从二级存储迁移到三级存储。\nCaching 缓存旨在将正在使用的信息从较慢的存储复制到较快的存储中，以提高数据处理速度。 缓存应用于多个计算机层次，包括硬件、操作系统和软件。主内存被视为辅助存储的最后一级缓存。 系统在访问数据前会首先检查缓存，若信息已存在，则直接从缓存中获取；若不存在，则将数据复制到缓存并在其中使用。 由于缓存容量有限，缓存管理策略（如数据替换算法）和设计决策（如缓存大小）至关重要。\n具体类型如下： 磁盘缓存（Disk Cache）： 利用主内存的一部分作为缓冲区，临时存储磁盘数据。 磁盘写入时进行聚类，预计会再次被引用的数据可以从软件缓存中快速检索，避免从磁盘缓慢读取。 缓存内存（Cache Memory）： 对操作系统不可见，由硬件直接管理。 提高内存速度，缓解处理器速度与内存速度之间的差距。 作为处理器的高速存储区域，提高数据访问效率。 Operating-System Structure Uniprogramming Uniprogramming（单道批处理系统）是一种计算机操作系统的早期模式，其中在计算机系统上一次只能执行一个程序。这种模式通常是单任务操作系统的基础，它允许计算机执行一个程序，直到该程序完成或发生错误。一旦程序执行完毕，用户可以手动或通过重启系统来加载和执行下一个程序。\nUniprogramming的特点包括：\n单道性： 计算机一次只能执行一个程序。 简单性： 由于只有一个程序在运行，Uniprogramming系统相对简单，不需要复杂的任务调度或多任务管理机制。 顺序性： 资源（如内存和CPU时间）完全由当前运行的程序占用，而其他程序必须等待。 Uniprogramming有一些明显的局限性。最显著的是效率问题，因为计算机在执行一个程序时，其他程序无法运行，导致资源利用率低下。此外，用户体验也受到影响，因为用户必须等待一个程序完成后才能运行下一个程序。 这包括：\n性能低下： 由于Uniprogramming一次只能执行一个程序，因此性能有限，计算机不能同时处理多个任务，导致了性能低下的问题。 I/O速度慢： 输入/输出操作的速度较慢，因为计算机必须等待I/O指令完成后才能继续执行。这意味着I/O操作会阻塞其他计算任务的执行。 Multiprogramming 保持CPU和I/O设备始终繁忙： 多道程序设计旨在最大程度地利用计算机资源，以确保CPU和I/O设备在任何给定时间都保持繁忙状态，以提高系统的性能和资源利用率。 组织作业以保持CPU繁忙： 多道程序设计将不同的作业（包括代码和数据）组织在系统中，以确保CPU始终有一个作业可供执行，从而减少CPU空闲时间。 内存中的作业子集： 系统中只保留了作业的一个子集（通常是部分作业）在内存中，以便它们可以立即被执行。 作业调度： 作业调度是多道程序设计的一部分，它选择要在CPU上运行的作业。作业调度算法根据不同的策略选择下一个要执行的作业。 等待I/O时切换作业： 当一个作业需要等待I/O操作完成时，操作系统会将CPU的控制权切换到另一个可执行的作业，以充分利用CPU时间，而不让CPU处于空闲状态。 两个程序的多道程序设计： 这是多道程序设计的一种特定情况，其中只有两个程序同时存在在内存中，操作系统可以根据需要在这两个程序之间切换，以确保CPU忙碌。 多道程序设计的核心思想是在系统中同时运行多个作业，以减少计算机资源的浪费，提高性能和响应速度。这种方法允许计算机在一个作业等待I/O操作的时候，执行另一个可执行的作业，从而最大化了资源的利用率。\nTime sharing systems 时间共享和交互式计算：时间共享系统通过频繁地在不同作业之间切换CPU，使得多个程序能够似乎同时运行，为用户提供交互式的体验。分时技术，是指把处理器的运行时间分成很短的时间片，按时间片轮流把处理器分配给各联机作业使用。 系统响应和进程： 快速响应：为了维持交互性，系统的响应时间必须很短，最好小于1秒。 多进程：每个用户在系统中都有至少一个或多个正在运行的程序，这些程序称为进程。 CPU调度和资源管理： 当多个进程同时请求CPU时，需要一个调度机制来决定哪个进程应该获得CPU。 不所有进程都能完全装入内存。当内存不足时，某些进程会被移到磁盘上，需要时再被调入内存。这种操作称为交换，由交换程序（Swapper）执行。 虚拟内存允许不完全在内存中的进程执行，提高了内存的使用效率。 多用户系统和在线通信： 多个用户可以同时使用计算机并运行自己的程序。 用户可以通过终端与系统实时通信，发送命令和接收响应。 与传统的从外部设备（如卡片阅读机）获取指令不同，现代操作系统直接从用户键盘获取指令。 在线系统的可用性：在线系统必须始终可用，以供用户随时访问数据和代码。 Real-time operating system 实时操作系统与一般的操作系统相比，最大的特色就是“实时性”，如果有一个任务需要执行，实时操作系统会马上（在较短时间内）执行该任务，不会有较长的延时。\n经常用作专用应用中的控制设备，例如控制科学实验、医学成像系统、工业控制系统以及某些显示系统。 具有明确固定的时间约束。 必须在定义的约束内完成处理，否则系统将失败。 实时系统有两类： 硬实时系统 目标：保证关键任务及时完成。 次要存储有限或不存在，数据存储在短期内存或只读内存（ROM）中。 与时间共享系统冲突，不被通用操作系统支持。 软实时系统 关键实时任务优先于其他任务，并保持该优先级直到完成。 缺乏截止时间支持，在工业控制或机器人技术中应用受限。 在需要高级操作系统功能的应用中有用（例如多媒体、虚拟现实、科学项目）。 Operating-System Operations Modern operating systems are interrupt driven. Interrupt driven by hardware Software error or request creates exception or trap Division by zero, request for operating system service Other process problems include infinite loop, processes modifying each other or the operating system Dual-mode operation Dual-mode operation allows OS to protect itself and other system components.\nuser mode and kernel mode 两种操作模式： User mode：代表用户执行，主要用于普通应用程序的运行。 Kernel mode：代表操作系统执行，用于处理操作系统内核及相关功能。 内核组成部分： 硬件密切相关的模块：时钟管理、中断处理等。 运行频率较高的程序：进程管理、设备管理等。 操作系统内核主要包括以下几个方面： 时钟管理：计算机最关键的设备，系统管理依赖于时钟。 中断机制：现代操作系统靠中断驱动。 原语Atomic Operation：特殊程序，运行具有原子性。 数据结构管理：操作系统需对系统中的数据结构进行有效管理，包括进程管理、存储器管理、设备管理等。 在用户态和核心态发生的事件 核心态 系统调用 中断 输入输出指令会引起中断 操作系统会完成：提供中断服务、初始化中断向量表、保存中断屏蔽字 时钟 置时钟指令只能在核心态运行 用户态 用户程序在用户态下使用特权指令引起的中断叫访管中断 访管仅在用户态执行 用户态到核心态的转换是通过硬件完成的 用户设计程序时，使用系统调用命令，该命令经过编译之后，形成若干参数和陷入（trap）指令。\nImplementation of Dual-mode operation 双模态是由操作系统和硬件一起实现的，硬件主要实现下面的功能：\n特权指令 特权指令：只能在 CPU 处于内核态时执行，具有较高的权限，可以访问和控制系统的硬件资源。 特权指令包括危险的指令，如 I/O 指令、置中断指令、存取用于内存保护的寄存器等。 为了防止用户程序对系统造成破坏，特权指令不允许用户直接执行，操作系统提供了接口（称为系统调用）来协助用户执行特权指令。 （系统调用命令工作在内核态） 非特权指令：在 CPU 的 user 态和 kernel 态下执行，主要访问用户的地址空间，权限较低。 非特权指令允许用户直接使用，主要访问用户的地址空间，不能直接访问系统中的软硬件资源。 非特权指令在用户程序中广泛应用，用于实现程序的控制逻辑、数据计算和存储等操作。 操作系统在内存中划分用户态内存和内核态内存，并设置各自的特权级别。内核态内存特权级别较高，用于操作系统及其组件的运行；用户态内存特权级别较低，用于用户程序的运行。 用户程序在访问内存时，CPU 会进行特权级检查。当用户程序试图访问特权级别高于自身的内存区域时，CPU 会拒绝执行该指令，从而实现操作系统的保护机制。 特权级检查通过 CPU 提供的特权环机制实现。特权环是一种硬件机制，用于在执行指令时进行特权级检查，以确保程序在适当的权限级别下运行。 特权级检查涉及两个重要数值：当前特权级（CPL）和描述符特权级（DPL）。CPL 表示当前执行指令的特权级，DPL 表示目标内存区域的特权级，二者用于判断程序是否具有访问目标内存的权限。 内存保护 保证物理地址与虚拟地址隔离，现代操作系统采用分页法。分页法涉及虚拟地址到物理地址的转换，由硬件（CPU 中的 MMU）执行映射，操作系统决定映射策略，页表存储在内存中。 时间片中断 一个让操作系统重新获取CPU控制权的方式。 在定时器中断后，操作系统安排另一个进程（可能是被中断的同一个进程）运行。 为了防止无限循环或进程占用过多资源，操作系统使用计时器，在特定时间后设置中断，不断递减计数器以追踪时间，并在计数器归零时产生中断，从而使操作系统能够重新获得控制权或终止超出分配时间的程序，同时确保修改计时器内容的指令是特权且安全的。 上下文切换 当一个进程被替换并由另一个进程取代时，系统保存当前进程的状态并加载新进程的状态。 Interruption When an interrupt or fault occurs hardware switches to kernel mode. 中断是唯一让用户态切换到核心态的方式； 核心态转换为用户态只需要修改程序状态字PSW的标志位（通过执行特权指令来修改）； 发生中断或异常时，运行用户态的CPU会立即进入核心态，这是通过硬件实现的（一位寄存器0表示核心态、1表示用户态）\nDefining Interruption 中断也称外中断（外设请求、人工干预），指来自CPU执行指令以外的事件发生（I/O中断、时钟中断），这一类中断通常是与当前指令执行无关的事件； 访管中断，又称软件中断或自愿中断，是一种由用户程序在运行过程中主动请求操作系统提供服务而引发的中断。 访管在用户态使用。 外部中断：也称为硬件中断，是由外部设备或硬件信号引发的中断。例如，I/O 设备完成数据传输、硬件故障、计时器到期等。外部中断通常使用中断向量表中的中断向量来处理。 处理外部中断时，应由操作系统保存通用寄存器里的内容。 定时器产生时钟中断时，由时钟中断服务程序更新的部分是内核中时钟变量的值、当前进程占用的CPU时间、当前进程在时间片内剩余执行时间。 异常也称内中断（例外、陷入），指来自CPU执行指令内部的事件（程序非法操作码、地址越界），对异常的处理通常依赖当前程序的运行现场，且异常不能被屏蔽，一旦出现应当立即处理； 开中断（Enabling Interrupts）：这是指允许中断信号被处理的状态。当系统处于“开中断”状态时，如果出现中断信号，CPU将响应这个信号，并根据中断的类型执行相应的中断处理程序。这是计算机正常操作时的常态，因为它允许系统对如输入/输出请求、硬件故障等事件做出及时响应。\n关中断（Disabling Interrupts）：这是指暂时屏蔽或禁止中断信号的状态。在“关中断”状态下，即使有中断信号产生，CPU也不会对其进行处理。这通常用于保护关键的代码段不被中断，例如在操作系统内核执行一些关键任务时，可能会暂时关中断，以保证任务的连续性和数据的一致性。完成这些关键任务后，系统通常会重新开启中断。\nComputer-System Organization Computer-System Operation 在计算机系统中，CPU 与 I/O 设备可以同时执行任务，实现高效的数据传输。设备控制器负责管理特定类型的设备，并具备本地缓冲区。CPU 负责在主内存与本地缓冲区之间传输数据，而 I/O 操作则从设备到控制器本地缓冲区进行。当设备控制器完成操作时，它会通过引发中断通知 CPU，从而实现顺畅的数据处理和设备控制。这种机制使得计算机系统能够在处理数据和控制设备时保持高效和稳定。\nInterrupt Timeline \u0026ldquo;Interrupt Timeline\u0026rdquo;（中断时间线）通常指的是计算机系统中的中断事件序列，记录了中断的发生时间和处理时间。在操作系统和计算机体系结构中，中断是一种用于处理异步事件的机制，例如硬件故障、外部设备的输入、定时器事件等。中断允许计算机系统在正常执行的过程中响应和处理这些事件，而不需要等待或轮询。\nInterrupt Timeline包括以下关键元素：\n中断源：表示引发中断事件的来源，例如硬件故障、I/O设备请求、时钟中断等。 中断请求时间：指中断事件发生的确切时间戳。 中断处理时间：指操作系统或处理器开始处理中断事件的时间戳。这包括了操作系统的中断服务例程或中断处理程序的执行时间。 中断完成时间：指整个中断处理过程完成的时间戳。这包括了中断服务例程的执行以及可能的上下文切换。 Storage Structure Main memory \u0026ndash; only large storage area that the processor can access directly. Secondary storage \u0026ndash; extension of main memory that provides large nonvolatile storage capacity. Magnetic disks \u0026ndash; rigid metal or glass platters covered with magnetic recording material. Disk surface is logically divided into tracks, which are subdivided into sectors. The disk controller determines the logical interaction between the device and the computer. Magnetic tapes \u0026ndash; used for backup, for storage of infrequently used information. Storage Hierarchy Storage systems organized in hierarchy. Speed Cost Volatility Volatile storage loses its contents when the power to the device is removed. Principle of design a computer memory system： uses only as much expensive memory as necessary. provides as much inexpensive, nonvolatile memory as possible. Storage-Device Hierarchy I/O Structure Programmed I/O\nInterrupt-Driven I/O\nSynchronous I/O\nAsynchronous I/O\nDMA\nI/O通道控制方式\nI/O operation 设备控制器 device controller Local buffer storage A set of special-purpose registers Moving data between device and its local buffer storage. 设备控制器是一种硬件组件，用于管理特定类型的外部设备（如磁盘驱动器、键盘、鼠标等）。它包括一组特殊用途的寄存器，用于控制设备的操作和状态。设备控制器还包括本地缓冲存储，用于在设备和计算机之间传输数据。 设备驱动程序 device driver One for each device controller. Presents a uniform interface to the device. 设备驱动程序是用于与设备控制器通信的软件组件。每种设备控制器都有一个相应的设备驱动程序。设备驱动程序提供了一个统一的接口，以便操作系统可以与不同类型的设备进行交互。 I/O 操作 I/O operation ：I/O 操作是指计算机系统与外部设备之间的数据传输和交互过程。它包括以下步骤： Device driver loads registers within the controller. 设备驱动程序加载设备控制器内的寄存器，以配置设备的操作。 Device controller examines the contents of the registers to determine what action to take. 设备控制器检查寄存器的内容，以确定应采取什么操作。 Device controller starts the transfer of data between the device and its local buffer. 设备控制器开始在设备和其本地缓冲存储之间传输数据。 Once done, device controller sets its status, or informs the driver via an interrupt. 一旦完成数据传输，设备控制器设置其状态，或者通过中断通知设备驱动程序。 Device driver returns control to the OS, with data if \u0026lsquo;read\u0026rsquo;. 设备驱动程序将控制返回给操作系统，如果是“读”操作，可能会将读取的数据一并返回。 Modern Computer System high-end systems use switch architecture. multiple components can talk to other components concurrently, rather than competing for cycles on a shared bus. 在计算机系统中，高端系统采用了一种称为\u0026quot;交换架构\u0026quot;的设计。这种设计允许多个系统组件同时相互通信，而不是竞争共享总线周期。在传统的计算机架构中，多个组件（如CPU、内存、输入/输出设备）必须通过共享总线来访问系统资源，这可能会导致资源争用和性能瓶颈。而交换架构允许各个组件之间以更高效的方式进行通信，从而提高了系统的并发性和性能。\n在交换架构中，不同组件之间可以直接建立点对点的连接，而无需通过共享总线进行通信。这种架构通常使用交换网络或高速互连来实现，允许组件之间并行传输数据，提供更大的带宽和更低的延迟。这对于高性能计算、大规模服务器和数据中心等需要处理大量数据并进行高度并发处理的应用非常重要。\nProtection and Security 保护：操作系统中的保护机制控制进程或用户对系统资源的访问，确保资源的安全使用和访问控制。 安全：操作系统需要抵御内部和外部攻击，包括拒绝服务、蠕虫、病毒、身份盗窃和服务盗用等安全威胁。 访问控制：操作系统规定用户对系统的访问权限，以确定用户能够执行的操作。 信息流控制：操作系统控制数据在系统内的流动以及传递给用户的方式。 认证：证明访问控制和信息流控制是否按照规范执行的过程。 系统首先区分用户，以确定谁可以执行什么操作。用户标识（用户 ID、安全 ID）包括用户名和相关编号，每个用户有一个。 用户 ID 与用户的所有文件和进程相关联，以确定访问控制。组标识符（组 ID）允许定义一组用户，并进行管理，然后也与每个进程和文件相关联。 特权提升：操作系统允许用户切换到具有更多权限的有效 ID，以便执行需要更高权限的操作。 Operating-System Structures Operating System Services 操作系统提供了一个程序执行的环境，并向程序和用户提供各种服务。\n操作系统提供一组服务，旨在满足用户的需求，包括以下功能：\n用户界面 (UI)： 操作系统提供不同类型的用户界面，以便用户与计算机系统交互。这包括命令行界面 (CLI)，批处理界面，图形用户界面 (GUI) 等。用户可以通过这些界面执行命令、操作文件和访问系统功能。 程序执行： 操作系统负责加载程序到内存并执行它。它可以正常或异常地终止程序的执行，以指示是否发生了错误。 I/O 操作： 操作系统管理输入/输出操作，允许用户访问磁盘上的文件，输出到打印机或屏幕等。这包括文件的读写、目录的创建和删除、文件搜索、权限管理等。 文件系统操作： 操作系统支持对文件和目录的操作，包括读取和写入文件，创建和删除文件和目录，搜索文件，列出文件信息以及权限管理。 通信： 进程可以在同一台计算机上或在网络上的不同计算机之间交换信息。这可以通过共享内存、消息传递等方式实现。 错误检测： 操作系统能够检测硬件、I/O 设备或用户程序中可能发生的错误。对于每种类型的错误，操作系统应采取适当的措施以确保计算的正确性和一致性。 调试功能： 操作系统提供调试工具，以帮助用户和程序员高效地使用系统。这些工具可以用于识别和解决程序中的错误，从而提高系统的可靠性和稳定性。 操作系统还具备一组功能，旨在通过资源共享来确保系统自身的高效运行，这包括以下方面：\n资源分配： 当多个用户或多个作业同时运行时，必须为它们分配资源。不同类型的资源需要不同的分配策略，例如 CPU 时间、主内存、文件存储等。某些资源可能需要特殊的分配代码，而其他资源可能使用通用的请求和释放代码，例如 I/O 设备。 记账（Accounting）： 记账是跟踪用户使用了多少以及什么类型的计算机资源的过程。这有助于了解资源的使用情况，以便进行资源管理和计费。 保护和安全性： 多用户或网络化计算机系统中存储的信息的所有者可能希望控制该信息的使用。同时运行的进程不应相互干扰。保护涉及确保对系统资源的所有访问都受到控制。系统的安全性要求用户进行身份验证，并扩展到保护外部 I/O 设备免受非法访问尝试的攻击。如果要保护和确保系统的安全性，必须在整个系统中采取预防措施。 操作系统提供的服务分为面向客户（命令接口）和面向编程人员（系统调用）。\n命令接口：用户通过这些操作命令来组织和控制作业的执行。 命令行界面（CLI）和图形用户界面（GUI）属于命令接口 根据控制方式的不同，命令接口可分为两类： 脱机控制接口：也称为批处理命令接口，适用于批处理系统，由一组作业控制命令组成。 联机控制接口：也称为交互式命令接口，适用于分时或实时系统。用户可以与操作系统进行实时交互，操作系统根据用户的指令实时执行任务。 程序接口： 程序接口指的是操作系统提供给程序员的所有编程接口，包括但不限于系统调用。它还可以包括应用程序接口（APIs）、库函数、框架等。 编程人员使用这些接口请求操作系统服务，实际上就是系统调用。当我们说“程序接口是编程人员用来请求操作系统服务的，实际上就是系统调用”的时候，我们是在强调系统调用作为程序接口的一个核心和最直接的部分。 User Operating System Interface Command Interpreter (CLI) 命令解释程序（Command Interpreter）是用户与操作系统之间的接口。它负责解释用户输入的命令并将其传达给操作系统执行。命令解释程序可以以不同的方式实现，取决于操作系统的设计和类型：\n内核中实现（例如 MS-DOS）： 在某些操作系统中，命令解释程序可以直接内置在内核中，这使得它更加紧密地与操作系统集成。 由系统程序实现（例如 Windows / UNIX）： 在其他操作系统中，命令解释程序是作为系统程序运行的，不在内核中。这种设计允许更灵活地扩展和定制命令解释程序。 Shell（例如 UNIX / Linux）： 在类UNIX系统中，通常使用一个称为\u0026quot;Shell\u0026quot;的特殊程序来充当命令解释程序。不同的Shell可以有不同的特性和功能，例如Bourne Shell、C Shell等。 命令解释程序的主要职责是接收用户输入的命令并执行它。命令可以通过两种方式来实现：\n内置命令（例如 MS-DOS）： 一些命令解释程序支持内置命令，这意味着某些命令的实现是直接嵌入到命令解释程序中的。这些命令通常执行速度快，但无法轻松扩展或添加新功能。 系统程序（例如 UNIX）： 在其他系统中，大多数命令是通过系统程序来实现的，这些程序可以独立于命令解释程序进行开发和维护。这种方法使得添加新功能和扩展系统功能变得更加容易，因为不需要修改命令解释程序本身。 Graphical User Interface (GUI) 图形用户界面（Graphical User Interface，GUI）是一种用户友好的桌面元喻界面，通常使用鼠标、键盘和显示器来与计算机进行交互。GUI的特点包括：\n图标表示文件、程序和操作： GUI使用图标来代表不同的文件、程序、操作等，使用户可以通过可视化方式来管理和执行任务。 鼠标操作： 用户可以使用鼠标来点击、拖动、右键单击等与界面中的对象互动，触发不同的操作和功能。 提供信息和选项： 用户可以通过鼠标操作来获取对象的信息，查看选项，执行功能，等等。 文件夹结构： GUI通常使用文件夹（也称为目录）来组织文件和数据，用户可以打开文件夹以查看其中的内容，这个操作通常被称为\u0026quot;打开目录\u0026quot;。 GUI的概念最早在20世纪70年代初由帕洛阿尔托研究中心（Xerox PARC）发明。现代操作系统通常提供了CLI和GUI两种接口，以满足不同用户的需求。一些相关的系统和信息包括：\nMicrosoft Windows： Windows操作系统使用GUI界面，但也包含了命令行界面（CLI）。 Apple Mac OS X： Mac OS X使用名为\u0026quot;Aqua\u0026quot;的GUI界面，底层采用UNIX内核，并提供了多种不同的shell来满足不同的需求。 Unix和Linux： Unix和Linux系统通常提供CLI界面，并可选择性地提供GUI界面，例如Common Desktop Environment（CDE）、KDE Desktop Environment和GNOME GNU Desktop等。 System Calls 系统调用是操作系统提供的接口，允许应用程序与底层硬件和文件系统交互。\n系统调用按照功能可分为以下几类：\n设备管理：完成设备的请求、释放和启动等功能。 文件管理：完成文件的读、写、创建和删除等功能。 进程控制：完成进程的创建、撤销、阻塞和唤醒等功能。 进程通信：完成进程之间的消息传递或信号传递等功能。 内存管理：完成内存的分配、回收以及获取作业占用内存区大小和始址等功能。 操作系统内核程序负责处理系统调用，运行在核心态。大多数应用程序通过高级应用程序接口（API）而不是直接的系统调用来访问操作系统的功能。API 提供了一组可供程序员使用的函数，简化了与操作系统交互的过程。操作系统通常使用高级编程语言（如 C/C++）编写，并通过库（如 libc）提供 API，使程序员能够更轻松地访问和利用操作系统的功能。这提高了应用程序的开发和维护效率，同时降低了底层系统调用的复杂性。\n库函数与系统调用的区别和联系: 库函数是语言或应用程序的一部分，可以运行在用户空间中。而系统调用是操作系统的一部分，是内核为用户提供的程序接口，运行在内核空间中，而且许多库函数都会使用系统调用来实现功能。未使用系统调用的库函数，其执行效率通常要比系统调用的高。因为使用系统调用时，需要上下文的切换及状态的转换（由用户态转向核心态）。\nSystem Call Implementation 运行时支持系统（run-time support system）提供了一个系统调用接口，它作为与系统调用的连接。 这个接口通常包含在与编译器一起提供的库中，这些库中内置了一组函数。 通常，每个系统调用都与一个数字相关联，系统调用接口维护一个表，根据这些数字进行索引。\n系统调用接口的功能包括：\n拦截API中的函数调用。 调用操作系统中所需的系统调用。 返回系统调用的状态以及任何返回值。 调用者无需了解系统调用的实现方式，或者在执行期间它执行了什么操作。 他们只需要遵守API，并理解作为结果操作系统将执行的操作。 API隐藏了程序员不需要了解的大部分操作系统接口的细节，这些细节由运行时支持库进行管理。\nSystem Call Parameter Passing 通常，传递给操作系统的信息通常不仅仅是所需的系统调用的标识。所需的信息类型和数量因操作系统和调用而异。\n有三种常见的方法用于将参数传递给操作系统：\nRegisters，最简单的方法。 Memory block，参数存储在内存中的块或表中，块的地址作为参数传递给寄存器（Linux 和 Solaris 采用这种方法）。 Stack，程序将参数推送到栈上，由操作系统从栈上弹出。 Types of System Calls Process control 进程控制 结束、中止、加载和执行进程：用于管理进程的创建和终止。 创建进程、终止进程：用于创建和终止进程。 获取进程属性、设置进程属性：用于获取和设置进程的属性信息。 等待时间、等待事件、信号事件：用于处理等待时间、事件和信号的操作。 分配和释放内存：用于管理内存的分配和释放。 内存转储：在发生错误时将内存内容转储到文件中，以进行故障诊断。 调试器：用于识别和调试程序中的错误，支持单步执行和监视程序的执行。 锁：用于管理多个进程之间对共享数据的访问，以确保数据的一致性和互斥访问。 fork、exec、wait 和 exit 这四个系统调用是和进程有关的最为重要的四个系统调用：\nfork 用来创建进程； exec 从磁盘上载入并执行某个可执行程序； exit 是进程自己退出时要调用的函数； wait 调用的进程会等到子进程退出时才继续执行。 fork fork 系统调用的函数原型定义为：\nint fork(); 这个函数没有参数，调用该函数的进程会再创建一个进程，新创建的进程是原进程的子进程。两个进程都从 fork() 这个地方继续往下执行，并且执行“同样”的代码。但是父进程执行 fork() 会返回子进程的ID，而子进程调用 fork() 会返回0。父子进程正是通过对这个返回值的判断（用if语句）来决定分别执行哪段代码。\nexec exec() 系统调用的功能是在当前进程中执行一段新程序，进程的PID保持不变。可以这样形象地理解，一个进程就像一个壳子，在这个壳子里可以装各种可执行代码。fork() 创建了这个壳子，并且将父进程的代码装在这个壳子中执行，而 exec() 是用一个磁盘上的可执行程序（exec() 的参数告诉操作系统是哪个可执行程序）替换了这个壳子里原有的内容。\nexec() 函数分为两类，分别以 execl 和 execv 开头，其函数原型定义如下：\nvoid execl(const char* filepath, const char* arg1, char* arg2, …); void execlp(const char* filename, const char* argl, char* arg2, …); void execv(const char* filepath, char* argv[]); void execvp(const char* filename, char* argv[]); 这些函数基本上一样，只是 execl 中对应可执行程序入口函数的参数，即其中的 arg1、arg2 等，是一个一个列举出来的，而 execv 是将这些参数组织成一个数组告诉操作系统的。\nexit exit() 系统调用用来终止一个进程，在进程中可以显式调用 exit 来终止自己，也可以隐式调用 exit。操作系统在编译 main() 函数时，当遇到 main() 函数的最后一个 } 时会“塞入”一个 exit。\nexit() 函数的原型定义为：\nvoid exit(int status); exit 中的参数 status 是退出进程返回给其父进程的退出码。同时，退出的进程会向其父进程发送一个 SIGCHILD 信号，一个进程执行 wait 系统调用时就会\n暂停自己的执行来等待这个信号。所以 wait 和 exit 合在一起可以完成这样一种进程之间的同步合作：父进程启动了一个子进程，调用 wait 等待子进程执行完毕；子进程执行完毕以后调用 exit 给父进程发送一个信号 SIGCHILD，父进程被唤醒继续执行。\nwait wait 系统调用的函数原型定义为：\nint wait(int *stat_addr); 其返回值是 exit 子进程的PID，stat_addr 是进程中定义的一个变量，用于存放子进程调用 exit 时的退出码，即 exit 系统调用的参数 status。\nFile management 创建文件（Create file）: 用于创建新的文件，分配必要的存储空间和初始化文件属性。 删除文件（Delete file）: 用于移除现有文件，释放其占用的存储空间，并更新文件系统的记录。 打开文件（Open）: 用于打开一个文件以进行读取、写入或其他操作。在文件打开时，操作系统通常会在内部维护一个文件描述符或句柄。 关闭文件（Close）: 在文件操作完成后，关闭文件以释放操作系统维护的资源和句柄。 读取文件（Read）: 用于从文件中读取数据到内存中。 写入文件（Write）: 将内存中的数据写入到文件中。 重新定位文件指针（Reposition）: 改变文件读写操作的当前位置，例如移动到文件的特定位置开始读写操作。 获取文件属性（Get file attributes）: 用于查询文件的属性信息，如大小、创建时间、修改时间、权限等。 设置文件属性（Set file attributes）: 允许修改文件的属性，如更改文件权限、修改时间戳等。 Device management 请求设备（Request Device）: 用于请求使用特定设备，如磁盘驱动器、打印机等。 释放设备（Release Device）: 用于释放先前请求的设备，使其可供其他进程或任务使用。 读取设备（Read Device）: 用于从设备读取数据，如从硬盘读取数据或从键盘接收输入。 写入设备（Write Device）: 将数据写入设备，例如向硬盘写入数据或向显示器发送数据。 重新定位设备指针（Reposition Device Pointer）: 用于移动设备指针到不同位置，如改变磁盘读写头的位置。 获取设备属性（Get Device Attributes）: 用于获取设备的属性信息，如设备类型、状态、配置参数等。 设置设备属性（Set Device Attributes）: 用于设置设备的属性，如配置参数、状态等。 逻辑附加或分离设备（Logical Attach/Detach Device）: 将设备逻辑连接或分离到系统中，以便程序可以访问它。 库函数 printf 和 scanf\nprintf:\n用于格式化输出，将数据显示到控制台或其他输出设备。 函数原型：void printf(const char* format, ...); 例如：printf(\u0026quot;ID:%d\u0026quot;, 3); 会在屏幕上显示 ID:3。 scanf:\n用于格式化输入，从键盘或其他输入设备读取数据。 函数原型：void scanf(const char* format, ...); 例如：scanf(\u0026quot;ID:%d\u0026quot;, \u0026amp;id); 会从用户输入中读取一个整数并存储在变量 id 中。 注意：printf 和 scanf 是标准库函数，不是系统调用。它们在内部可能依赖于系统调用如 write 和 read 来实现对设备的“写”和“读”操作。库函数提供了比系统调用更高级的抽象，使得程序员可以更容易地进行输入输出操作。\nQ：库函数和系统调用的区别在哪里？\nA：系统调用是最底层的应用，是面向硬件的。而库函数的调用是面向开发的，相当于应用程序的API接口； 各个操作系统的系统调用是不同的，因此系统调用一般是没有跨操作系统的可移植性，而库函数的移植性良好； 库函数属于过程调用，调用开销小；系统调用需要在用户空间和内核上下文环境切换，开销较大； 库函数调用函数库中的一段程序，这段程序最终还是通过系统调用来实现的；系统调用调用的是系统内核的服务；\nCommunications 消息传递模型（Message-Passing Model）： 在消息传递模型中，进程通过操作系统提供的进程间通信（IPC）机制来交换信息。这种模型涉及创建和删除通信连接，以及通过发送和接收消息来进行通信。进程可以使用系统调用来发送消息给其他进程，同时也需要相应的系统调用来接收消息。这种模型通常用于实现进程间的协作和数据传输。 共享内存模型（Shared-Memory Model）： 在共享内存模型中，进程使用映射内存的系统调用来访问其他进程拥有的内存区域。这允许多个进程在相同的内存区域中读取和写入数据，从而实现了共享数据。进程可以使用系统调用来附加或分离共享内存区域，以便其他进程可以访问它。这种模型通常用于实现高效的数据共享和协作。 Information maintenance 系统调用概述 获取时间或日期（Get Time or Date）:\n用于获取当前系统时间或日期。 通常返回时间和日期的详细信息，如年、月、日、小时、分钟、秒等。 设置时间或日期（Set Time or Date）:\n允许设置或修改系统的当前时间和日期。 这通常是一个受保护的操作，可能需要管理员权限或特殊权限。 获取系统数据（Get System Data）:\n用于获取操作系统的各种数据，如系统性能、资源利用率、配置设置等。 设置系统数据（Set System Data）:\n用于修改系统设置或配置。 这些更改可能影响系统的整体行为或性能，通常需要特定权限。 获取进程、文件或设备属性（Get Process, File, or Device Attributes）:\n用于查询进程、文件或设备的特定属性，如进程状态、文件大小、设备类型等。 设置进程、文件或设备属性（Set Process, File, or Device Attributes）:\n允许修改进程、文件或设备的属性。 这可能包括更改进程优先级、修改文件权限、调整设备配置等。 Protection 控制资源访问（Control Access to Resources）:\n涉及限制对文件、设备、网络资源等的访问。 通常基于用户身份、组成员资格或角色来实现。 获取和设置权限（Get and Set Permissions）:\n用于查询或修改文件、目录或其他系统资源的访问权限。 权限可以包括读取、写入、执行等操作的允许或禁止。 允许和拒绝用户访问（Allow and Deny User Access）:\n用于授权特定用户或用户组访问资源，或者拒绝他们的访问请求。 这涉及到用户账户的管理和权限分配。 System Programs 系统程序是计算机操作系统中的一组程序，用于提供各种服务和功能。\n文件管理：\n创建、删除、复制、重命名、打印、导出、列出文件和目录。 状态信息：\n一些系统程序可以获取系统信息，如日期、时间、可用内存、磁盘空间和用户数量。 其他系统程序提供详细的性能、日志记录和调试信息，通常将输出格式化并显示在终端或其他输出设备上。 一些系统实现了注册表，用于存储和检索配置信息。 文件修改：\n文本编辑器用于创建和修改文件，而特殊命令可搜索文件内容或进行文本转换。 编程语言支持：\n编译器、汇编程序、调试器和解释器有时会提供编程语言支持。 程序加载和执行：\n包括绝对装载程序、可重定位装载程序、链接编辑器和覆盖加载程序等。 还包括用于高级语言和机器语言的调试系统。 通信：\n提供创建进程、用户和计算机系统之间虚拟连接的机制。 允许用户将消息发送到其他用户的屏幕、浏览网页、发送电子邮件、远程登录、在不同机器之间传输文件等。 系统实用程序/应用程序：\n由用户运行，通常不被视为操作系统的一部分。 可通过命令行、鼠标点击或手指触摸等方式启动。 例如，Web浏览器、文字处理器、电子表格、数据库系统、编译器、统计分析软件和游戏等。 后台服务：\n在系统启动时启动，一些在系统启动后终止，一些在系统启动到关机期间一直运行。 提供诸如磁盘检查、进程调度、错误日志记录、打印等功能。 在用户上下文中运行，而非内核上下文中。 通常被称为服务、子系统或守护程序。 Operating System Design and Implementation 操作系统的设计与实现是一个复杂的任务，没有一个“完美”的解决方案，但一些方法已被证明是成功的。不同操作系统的内部结构可以有很大的差异。\n目标与规格定义：\n操作系统的设计首先需要明确定义目标和规格。这些目标受到硬件选择、系统类型（批处理、分时、实时、单用户或多用户、分布式等）的影响。 难以规定的要求：\n操作系统的需求难以精确定义，因为它们需要满足多方面的用户和系统目标。 用户目标包括方便使用、易学易用、可靠、安全和高效。 系统目标包括易于设计、实现和维护、灵活、可靠、无错误和高效。 规定和设计操作系统是软件工程的高度创造性任务。 策略与机制分离：\n重要原则是将策略与机制分离。 策略是关于“做什么”的问题，而机制是关于“如何做”的问题。 分离策略和机制是一个非常重要的原则，它允许在以后更改策略决策时具有最大的灵活性。 例如，设置时间片长度和给予某些类型的程序优先级就是策略和机制分离的例子。 Unix和Windows的调度策略就是这种分离的例子。 多种编程语言的使用：\n操作系统的实现通常包含多种编程语言的混合使用。 较低层次的部分可能使用汇编语言编写，主体部分通常使用C语言编写。 系统程序可能使用C、C++以及脚本语言（如PERL、Python、Shell脚本）编写。 使用更高级别的语言使操作系统更容易移植到不同的硬件平台，但可能会导致性能较差和存储需求较大。 模拟（Emulation）：\n模拟允许操作系统在非本机硬件上运行。 模拟可以通过模拟硬件或虚拟机来实现。 这样的模拟可以提高操作系统在不同平台上的可移植性。 操作系统性能的提升：\n提高操作系统性能的主要方法包括改进数据结构和算法。 仅有少量代码对于高性能至关重要，包括中断处理程序、I/O管理、内存管理和CPU调度器。 写好并正确运行后，可以识别性能瓶颈的关键例程，然后将其替换为汇编语言等效代码以提高性能。 Operating System Structure 简单结构 Simple structure MS-DOS MS-DOS（Microsoft Disk Operating System）是为了在最小的空间内提供最大功能而编写的操作系统。它存在一些结构上的不足：\n缺乏模块化分割： MS-DOS没有被精心分割为模块化的组件。这意味着其功能没有被很好地分离和隔离，而是被混杂在一起，这使得系统的维护和扩展变得更加困难。\n接口和功能的分离问题： MS-DOS中，接口和功能的分离程度较低。这意味着不同功能的代码没有被清晰地分隔开，这可能导致代码的不稳定性和难以维护。\n受限于硬件： MS-DOS在某种程度上受到了硬件的限制。例如，它最初是设计用于Intel 8088处理器，这个处理器缺乏一些现代操作系统所需的功能，比如双模式（用户模式和内核模式）和硬件保护机制。\n因此，MS-DOS虽然在其时间内非常重要，但由于结构上的不足，它在面对较新的硬件和复杂的任务时变得不够灵活。这促使了后来的操作系统设计采用更模块化、分层的方法，以提高系统的稳定性和可维护性。\nOriginal UNIX 原始的UNIX操作系统在结构上较为有限，这主要是由硬件功能的限制所决定的。它由两个可分离的部分组成：\n系统程序： 这部分包括用户可以运行的各种应用程序，如文本编辑器、编译器等。系统程序构成了用户与操作系统交互的一部分。\n内核： 内核是操作系统的核心部分，位于系统的最底层。内核被分为一系列接口和设备驱动程序，包括系统调用接口、文件系统、CPU调度、内存管理等功能。内核位于系统调用接口以下，位于物理硬件之上，它为系统提供了基本的操作系统功能。\nUNIX操作系统的API（应用程序编程接口）是通过系统调用定义的，而通常可用的系统程序则构成了用户界面。这种结构使得用户可以运行各种程序，而内核负责管理硬件和提供系统服务。\n需要注意的是，原始的UNIX操作系统的结构相对简单，这是因为它诞生于较早的计算机时代，当时的硬件功能和资源有限。后来的UNIX变种和其他操作系统采用了更模块化和层次化的结构，以适应更复杂的硬件和应用需求。\n分层结构 Layered Approach 操作系统可以分解成多个层次（或称为层级），每一层建立在较低层次之上。这些层次构成了操作系统的层次结构，其中最底层（第0层）是硬件，而最高层（第N层）是用户界面。\n在这种层次结构中，每个操作系统层次都表示一个抽象对象，由数据和可以操作这些数据的函数组成。模块化设计使得每一层次都可以使用较低层次的函数和服务，以构建更高层次的功能。\n这种结构使系统各部分相互隔离，降低复杂性，更易于维护和扩展。主要优点是简化系统设计和开发，降低错误风险，更容易扩展和维护，有助于管理复杂性。\n将操作系统视为一系列层次结构是一种有助于管理系统复杂性的方法。这个方法的主要思想是将系统的功能和组件分解为多个层次，每个层次负责执行相关的功能，同时依赖于较低层次的功能来完成更基本的操作。这种分解有以下主要优势：\n主要优势：\n构建和调试的简单性：通过将系统划分为多个层次，每个层次有明确定义的功能，使得系统的构建和调试变得更加简单。每个层次都可以独立开发和测试，减少了复杂性。 设计和实施的简化：层次结构化方法有助于将系统的设计和实施任务分解为更小的、可管理的子问题。这种分解有助于管理复杂性，使整个过程更加清晰。 主要困难：\n层次的仔细定义：确定每个层次的功能和接口需要仔细的定义。不同层次之间的依赖性和接口必须清晰明确，以确保系统的正确运行。 复杂性的分层结构：在一些情况下，分层结构可能导致复杂性的增加，尤其是在处理诸如磁盘驱动器和内存管理等关键组件时。这可能需要更复杂的协作和通信。 在操作系统中，将其视为一系列层次结构可以帮助管理系统的复杂性，但这种方法可能不如其他结构类型高效。在这种分层结构中，每个层次负责一组相关的功能，而每个系统调用必须经过多个层次才能达到硬件层面，这可能会导致性能开销。以下是有关这一点的详细信息：\n效率较低：这种分层结构可能导致系统调用的效率较低。当执行系统调用时，它必须经过多个层次，每个层次可能需要对参数进行修改、传递数据等。这会增加系统调用的开销。\n举例：考虑执行I/O操作的情况。当应用程序执行I/O操作时，它会触发系统调用，该系统调用被传递到I/O层次。然后，I/O层次可能需要与内存管理层次和CPU调度层次进行通信，最终数据被传递给硬件执行。这些多次通信和数据传递可能导致性能下降。\n宏内核（Monolithic Kernel）：在宏内核结构中，整个核心操作系统运行在内核空间和监管者模式下。这种结构通常没有明确的层次结构，所有功能都在一个单一的内核中实现。这可能会导致较低的模块化和较高的性能，但也可能增加维护的复杂性。\n总的来说，分层结构虽然有助于管理系统复杂性，但可能在性能方面存在一些开销。不同的操作系统采用不同的设计方法，以在性能和复杂性之间取得平衡。对于某些用途，如实时系统，可能更倾向于采用更紧凑的内核结构，而对于通用用途的操作系统，可能更愿意牺牲一些性能以获得更好的可维护性和可扩展性。\n微内核结构 Microkernels 微内核（Microkernel）是一种操作系统设计结构，旨在将操作系统的基本功能模块化，并将尽可能多的功能移到用户空间，以提高系统的模块性、灵活性和可维护性。以下是有关微内核的一些关键概念和优点：\n基本功能： 微内核包含操作系统的基本功能，如内存管理、CPU调度和进程间通信（IPC）。这些功能通常被认为是不可或缺的，但微内核试图将其他功能从内核中分离出来。\n用户空间服务： 微内核将额外的服务移到用户空间中，这些服务可以在用户空间中运行并与客户程序通信。客户程序可以使用这些服务来执行特定任务，而无需直接涉及内核。这提高了系统的可定制性和灵活性。\n通信方式： 微内核系统通常使用消息传递来实现客户程序和用户空间服务之间的通信。消息传递允许客户程序发送请求或数据给服务，并通过消息响应来执行相应的操作。\n优点： 微内核结构的主要优点包括：\n模块化：它允许操作系统的各个部分相对独立地开发和维护，减少了模块之间的相互影响，提高了可维护性。 灵活性：新的服务可以相对容易地添加到用户空间，而不必更改整个内核，提供了更大的可配置性和扩展性。 安全性和可靠性：微内核的模块化设计使得每个模块都可以进行严格测试，如果一个服务出现问题，不会影响整个操作系统的稳定性。 然而，微内核结构可能会导致一定的性能开销，因为消息传递和用户空间切换可能比在内核中执行相同功能更慢。因此，在对性能要求非常高的应用程序中，可能会选择其他内核结构。不同的操作系统采用不同的内核结构，以满足其设计目标和需求。\n微内核结构的劣势在于性能可能受到一定的影响，主要表现在以下方面：\n系统功能开销增加： 使用微内核结构会引入更多的系统功能开销，例如消息传递和用户空间切换。这些额外的开销可能会导致性能下降，特别是在对性能要求非常高的应用程序中。\n性能历史问题： 一个明显的例子是Windows NT操作系统的性能历史。最初的Windows NT 1.0采用了分层微内核组织，导致性能较低，与Windows 95相比表现不佳。随后的Windows NT 4.0部分改进了性能问题，将某些层次从用户空间移到内核空间，并更加紧密地集成它们。然而，随着Windows XP的设计，Windows的架构变得更加单片化，不再典型的微内核结构。\n大内核和微内核 大内核系统将操作系统的主要功能模块都作为一个紧密联系的整体运行在核心态，从而为应用提供高性能的系统服务；由于复杂的交互关系使得层次之间的界限极其模糊，定义清晰的层次间接口非常困难； 微内核将内核中最基本的功能保留在内核，将那些不需要在核心态执行的功能移到用户态执行；微内核结构最大的问题是性能问题，需要频繁在核心态与用户态之间进行切换； 模块化结构 Modules 现代许多操作系统采用可加载的内核模块。内核包含一组核心组件，并通过模块动态链接其他服务，可以在启动时或运行时进行。这种方法在现代UNIX的实现中非常常见，例如Solaris、Linux和Mac OS X，以及Windows。以下是有关可加载内核模块的一些关键概念：\n常见性： 可加载内核模块在现代操作系统中广泛采用，尤其是在UNIX系列操作系统中。\n面向对象的方法： 可加载内核模块采用面向对象的方法。每个核心组件都是独立的模块，它们之间使用已知接口进行通信。\n模块化： 每个核心组件都是可加载的，可以根据需要在内核中加载。这增加了系统的可扩展性和定制性。\n受保护接口： 每个核心组件都有定义的受保护接口，确保安全性和隔离性。\n更高的灵活性： 与微内核结构相似，可加载内核模块具有更高的灵活性，因为任何模块都可以调用其他模块，而不必通过消息传递来进行通信。\n更高的效率： 相对于一些其他结构，可加载内核模块通常更加高效，因为模块之间的通信无需调用消息传递，从而减少了开销。\n总的来说，可加载内核模块是一种在现代操作系统中广泛采用的内核结构，它融合了模块化、面向对象和高效的设计原则，以提供更大的灵活性和可扩展性。\nVirtual Machines 操作系统虚拟化：\n通过CPU调度和虚拟内存，操作系统为多个进程创造了在各自处理器上执行以及拥有自己虚拟内存的幻觉。 物理计算机的资源被共享来创建虚拟机。 虚拟机将分层方法推向逻辑极限，将硬件和操作系统内核视为硬件层。 虚拟机提供与裸机硬件相同的接口，允许操作系统作为其他操作系统内的应用程序运行。 虚拟机管理器（VMM）提供虚拟化服务，支持本机编译的客户操作系统运行在本机编译的宿主操作系统上。 在源CPU类型与目标类型不同的情况下，使用模拟，如 \u0026ldquo;Rosetta\u0026rdquo; 允许IBM CPU编译的应用程序在Intel CPU上运行。 虚拟机特性：\n提供了对系统资源的完全保护。 每个虚拟机与所有其他虚拟机隔离，不允许直接共享资源。 系统的开发和测试可在虚拟机上进行，不干扰正常系统操作。 虚拟机的普及解决了系统兼容性问题，但实现复杂，需提供与底层机器完全相同的副本。 虚拟化方法：\n第一类虚拟化：类似操作系统，运行在裸机上，提供多道程序功能，向上层提供若干台虚拟机，每台都是裸机硬件的精确复制品。支持不同操作系统的运行。 第二类虚拟化：依赖于宿主操作系统分配和调度资源，伪装成具有CPU和设备的完整计算机。如VMware Workstation。客户操作系统安装在虚拟磁盘上。 虚拟化应用：\nWeb主机领域中虚拟化十分流行，提供了成本效益高的解决方案，如“云”主机。 第一类虚拟化也称为裸金属架构，第二类称为寄居架构。 Operating System Generation 操作系统生成 操作系统的生成是一个定制化和配置过程，用以确保操作系统能够在特定的计算机硬件上运行。\n针对特定硬件的设计：\n操作系统被设计为能够在某一类计算机硬件上运行。 需要对每个具体的计算机站点进行详细配置。 系统生成程序（SYSGEN）：\nSYSGEN 程序用于获取硬件系统的特定配置信息。 这些信息帮助操作系统更好地理解并适应当前的硬件环境。 系统生成的方法：\n修改操作系统源代码：根据具体硬件需求调整操作系统的源代码副本。 预编译库选择：从预编译的库中创建表格并选择适合的模块。 表格驱动系统：创建适当的表格以描述系统配置，系统完全由这些表格驱动。 执行时选择：系统在运行时根据这些表格进行配置选择和调整。 System Boot 操作系统引导过程 操作系统引导是计算机启动和加载操作系统的一系列过程。这个过程涉及多个步骤，确保硬件和软件正确地协同工作，从而启动计算机系统。以下是引导过程的详细步骤：\n激活CPU:\nCPU被激活并读取ROM中的引导程序（Boot Program）。 将指令寄存器设置为BIOS（基本输入输出系统）的第一条指令，开始执行BIOS。 硬件自检:\nBIOS启动后，首先进行硬件自检（POST - Power-On Self Test）。 检查硬件是否存在故障，如有故障，主板会发出警告声，启动中止。 若无故障，屏幕显示CPU、内存、硬盘等硬件信息。 加载操作系统所在的硬盘:\nBIOS读取Boot Sequence（启动顺序），这通常保存在CMOS中，或通过用户交互设置。 控制权传递给启动顺序中排在第一位的存储设备。 CPU将该存储设备的引导扇区内容加载到内存中。 加载主引导记录（MBR）:\n主引导记录（MBR）位于硬盘的第一个扇区。 MBR包含特定标识符，区分引导硬盘和非引导硬盘。 MBR的作用是告诉CPU去哪个主分区找操作系统。 扫描硬盘分区表，加载活动分区:\nMBR包含硬盘分区表，该表区分活动分区和非活动分区。 MBR扫描分区表，识别含有操作系统的硬盘活动分区。 找到活动分区后，开始加载，将控制权交给该分区。 加载分区引导记录（PBR）:\n读取活动分区的第一个扇区，即分区引导记录（PBR）。 PBR的作用是找到并激活用于引导操作系统的程序（如启动管理器）。 加载启动管理器:\n分区引导记录搜索并加载活动分区中的启动管理器。 加载操作系统:\n启动管理器进一步加载操作系统，完成引导过程。 这个过程是操作系统启动和运行的基础，确保了从硬件的初始化到操作系统完全加载的顺利进行。\n","date":"2023-09-12T09:26:35Z","permalink":"https://www.xxx.blog/post/1-introduction/","title":"1 Introduction"}]