[{"content":"主要概念 （1）客户服务器（C/S）：传统的网络应用采用的通信模型，服务器向客户提供资源和服务，服务器程序先运行，等待客户的请求；通信由客户发起，服务器收到请求之后，将需要的资源返回给客户。\n（2）P2P：对等模型，两个网络应用程序（Peer，对等体）在通信时没有严格的客户和服务器的区分，每一个 Peer 既有客户的功能也有服务器的功能。\n（3）解析器：DNS 的客户端程序，发送域名请求给本地 DNS 服务器。\n（4）递归解析：本地名字服务器向上级名字服务器发送查询请求，上级服务器转发给更上一级服务器，到达根服务器之后再向下转发，直至请求转发给权威名字服务器；查询结果再反向依次转发给本地名字服务器的过程。\n（5）迭代解析：本地名字服务器向上级名字服务器发送查询请求，上级名字服务器返回更上一级名字服务器的 IP 地址，以此类推，每一次查询请求均由本地名字服务器发送，直至请求权威服务器的过程。\n（6）MIME（多用途因特网邮件扩展）：为邮件头和 HTTP 消息头提供了内容类型扩展，以支持除纯文本之外的其它数据类型，包括图像、音频、视频、压缩文件等。\n（7）浏览器：WWW 的客户端程序，除了 HTTP，还支持 FTP、Email 等协议。\n（8）Webmail: 用户使用浏览器和 HTTP 协议与邮件服务器通信，收发邮件\n（9）统一资源定位符 URL：URL：protocol://domain_name:port/item_name\n（10）HTTP 操作过程\n（11）持久连接：HTTP1.1 的功能，在一个 TCP 连接上传输一个网页中的多个文件，所有文件传输完之后再关闭连接。\n网络应用模型 C/S 客户和服务器是指通信中所涉及的两个应用进程。 客户/服务器方式所描述的是进程之间服务和被服务的关系。 客户是服务请求方，服务器是服务提供方。 服务器总是处于运行状态，并等待客户的服务请求。服务器具有固定端口号（例如HTTP服务器的默认端口号为80)，而运行服务器的主机也具有固定的IP地址。 C/S方式是因特网上传统的、同时也是最成熟的方式，很多我们熟悉的网络应用采用的都是C/S方式。包括万维网WWW、电子邮件、文件传输FTP等。 基于C/S方式的应用服务通常是服务集中型的，即应用服务集中在网络中比客户计算机少得多的服务器计算机上。 由于一台服务器计算机要为多个客户机提供服务，在C/S应用中，常会出现服务器计算机跟不上众多客户机请求的情况。 为此，在C/S应用中，常用计算机群集（或服务器场）构建一个强大的虚拟服务器。 P2P 在P2P方式中，没有固定的服务请求者和服务提供者，分布在网络边缘各端系统中的应用进程是对等的，被称为对等方。对等方相互之间直接通信，每个对等方既是服务的请求者，又是服务的提供者。\n目前，在因特网上流行的P2P应用主要包括P2P文件共享即时通信、P2P流媒体、分布式存储等。\n基于P2P的应用是服务分散型的，因为服务不是集中在少数几个服务器计算机中，而是分散在大量对等计算机中，这些计算机并不为服务提供商所有，而是为个人控制的桌面计算机和笔记本电脑，它们通常位于住宅、校园和办公室中。\nP2P方式的最突出特性之一就是它的可扩展性。因为系统每增加一个对等方，不仅增加的是服务的请求者，同时也增加了服务的提供者，系统性能不会因规模的增大而降低。\nP2P方式具有成本上的优势，因为它通常不需要庞大的服务器设施和服务器带宽。为了降低成本，服务提供商对于将P2P方式用于应用的兴趣越来越大。\nDNS DNS 基本概念 DNS目标：实现域名和IP地址之间的映射（转换） 分层的域名空间、分布式数据库 域名的规定 Client（解析器）请求本地域名服务器（UDP，端口53） 本地名字服务器请求其他服务器（最终到权威域名服务器） 迭代解析（因特网普遍采用） 递归解析 DNS目标很简单，但实现系统庞大而复杂 具有高效率（缓存机制）和可靠性（镜像、辅助域名服务器） 安全性：DNSSEC DNS的特点 分层命名空间：主机具有按层次组织的组合名称。 分布式数据库：DNS可以在组织内进行细分，并且可以有任意层级（最大深度为128）。 Hierarchical namespace 命名策略：名称按从叶子到根的路径结构化，由点分隔。每个区域对应于负责该部分层次结构的管理机构。 Resource Records（资源记录） 资源记录（Resource Records）是DNS中的基本数据单元，用于存储和传输有关域名和其关联信息的记录。每个域名可以有一个或多个资源记录。\n资源记录包含以下信息：\nOwner（所有者）：资源记录所属的域名。 Type（类型）：指定该资源记录的类型，决定了记录中存储的信息的含义。常见的类型包括： A：主机地址记录，将域名映射到IPv4地址。 AAAA：主机地址记录，将域名映射到IPv6地址。 CNAME：规范名称记录，指定域名的规范名称（别名）。 MX：邮件交换记录，指定接收该域名邮件的邮件服务器。 NS：域名服务器记录，指定该域名的授权域名服务器。 SOA：权威起始记录，指定该域名的起始授权服务器。 TXT：文本记录，用于存储任意文本信息。 SRV：服务记录，指定提供特定服务的服务器的位置。 Class（类）：指定协议族的类型，通常为IN（Internet系统）。 TTL（生存时间）：指定缓存资源记录的有效时间，以秒为单位。过期后，客户端需要重新查询以获取最新的记录。 Data（数据）：根据资源记录的类型，存储特定类型的信息。例如，A记录中存储IPv4地址，MX记录中存储邮件服务器的优先级和域名。 DNS客户端（解析器） DNS客户端，也被称为解析器，通常是安装在用户设备上（如PC、手机或任何需要连接到Internet的设备）的软件。这个客户端的任务是向DNS服务器发出查询，请求将一个网站的域名（例如www.example.com）转换为与之对应的IP地址。这就像是在问，“请告诉我这个网站的精确位置”。\n浏览器、电子邮件客户端、手机应用等都有内置的DNS解析器。解析器首先在本地缓存和“hosts”文件中查找IP地址，如果找不到，则向本地的DNS服务器（通常是由互联网服务提供商或企业IT部门设定的）发出查询请求。\nDNS服务器 DNS服务器是互联网的关键组件之一，其任务是响应来自解析器的查询，将域名解析为对应的IP地址，并将这个IP地址返回给请求者。\nDNS服务器是分层次和分布式的，这是为了提高效率和可靠性。当你的设备发出DNS查询请求时，以下是常见的处理流程：\n本地DNS服务器（Local DNS Server）： 这是查询的起点。本地DNS服务器一般由你的ISP（互联网服务提供商）或企业IT部门运营。当用户设备发出DNS查询请求时，请求首先会发送到本地DNS服务器。如果本地DNS服务器缓存中已经有对应的记录，它会直接返回结果。否则，本地DNS服务器会代理用户，将查询请求发送到更高级的DNS服务器。\n根DNS服务器（Root DNS Server）： 如果本地DNS服务器无法解析查询请求，请求就会发送到根DNS服务器。根DNS服务器位于DNS的最顶层，是互联网上的13组服务器之一。根服务器没有具体的记录信息，但它知道所有顶级域（如.com、.org、.net等）的DNS服务器的信息。它会将查询指向对应的顶级域的DNS服务器。\n顶级域DNS服务器（Top-Level Domain, TLD, DNS Server）： 这个层级的服务器管理顶级域下的所有二级域名。例如，.com TLD服务器就负责管理所有以.com结尾的二级域名的记录。当这个服务器收到查询请求，它会指向对应的二级域名的权威DNS服务器。\n权威DNS服务器（Authoritative DNS Server）： 权威DNS服务器是负责特定二级域名的服务器。比如，example.com的权威DNS服务器就负责管理所有以example.com结尾的子域名，比如www.example.com或mail.example.com。这个服务器拥有真正的、权威的DNS记录，当收到查询请求时，它会返回对应的IP地址。\nDNS查表 递归查询： 递归查询是DNS客户端（解析器）向DNS服务器发出的一种请求，要求DNS服务器负责完成整个解析过程并返回最终的解析结果。 迭代查询： 迭代查询是DNS客户端向DNS服务器发出的一种请求，要求DNS服务器返回一个指向下一级服务器的响应，而不是直接提供解析结果。 DNS 缓存 为了提高DNS的查询效率，并减轻根域名服务器的负荷和减少因特网上的DNS查询报文数量，在域名服务器中广泛地使用了高速缓存（cache）。\n高速缓存用来存放最近查询过的域名以及从何处获得域名映射信息的记录。\nTLD服务器通常被本地域名服务器缓存，因此根域名服务器很少被访问。\n不但在本地域名服务器中需要高速缓存，在用户主机中也很需要。许多用户主机在启动时从本地域名服务器下载域名和P地址的全部数据库，维护存放自己最近使用的域名的高速缓存，并且只在从缓存中找不到域名时才向域名服务器查询。\nMail：SMTP/POP3/IMAP 目标：用户之间的异步数据传输\n邮件格式\n基本邮件格式(IMF)只支持ASCII（英文） MIME:扩展邮件头，支持多种数据类型、多种语言、邮件 内包含多部分（附件）\n邮件传输协议(Client/Server)\n发送邮件协议：SMTP 接收邮件协议：POP3,IMAP4(功能更强，更复杂) Webmail\n用户使用浏览器和HTTP协议与邮件服务器通信，收发邮件 邮件服务器之间使用SMTP发送邮件 安全性：PGP,SMIME\n电子邮件系统的结构 UA (User Agent) end-user mail program Interface between the end users and the email servers E.g,outlook,foxmail,… Mail Server Responsible for transmitting/receiving emails and reporting status information about mail transferring to the mail sender Both a client and a server Email protocols SMTP:used for sending an email POP3:used for receiving an email 电子邮件地址 DNS地址格式：mailboxname@domain\n每个电子邮件地址在互联网上是唯一\nInternet 邮件格式 Message envelop：\u0026ldquo;信封\u0026quot;是一个抽象的概念，用于描述邮件从源地址到目的地址的传输信息。这些信息通常不包含在邮件本身的头部或正文中，而是在邮件传输过程中由邮件服务器和协议生成和管理的。 Message connect:互联网电子邮件采用的是RFC 5322标准定义的邮件格式。 邮件头（Headers） From：发件人的邮件地址。 To：主要收件人的邮件地址。 Cc（Carbon Copy）：抄送给其他人的邮件地址。 Bcc（Blind Carbon Copy）：密送给其他人的邮件地址，被隐藏在邮件中。 Subject：邮件的主题或标题。 Date：邮件发送的日期和时间。 Reply-To：回复邮件的地址。 MIME-Version：邮件使用的MIME（Multipurpose Internet Mail Extensions）版本。 Content-Type：邮件正文的类型和编码方式。 Content-Disposition：附件的处理方式。 空行（Blank Line）：邮件头和正文之间需要有一个空行作为分隔。 邮件正文（Body）：邮件的实际内容，可以包括文本、图片、附件等多种格式。 MIME MIME（Multipurpose Internet Mail Extensions）是一种用于多部分多媒体电子邮件的扩展标准。它扩展了传统的纯文本电子邮件，允许在邮件中包含多种类型的媒体内容，如图像、音频、视频等。\nMIME通过引入额外的邮件头字段来定义邮件的内容类型。常见的邮件头字段包括：\nMIME-Version：标识使用的MIME版本。 Content-Description：描述邮件的可读字符串。 Content-Id：邮件内容的唯一标识符。 Content-Transfer-Encoding：指定邮件在传输时的编码方式，用于处理二进制数据。 Content-Type：指定邮件内容的类型和子类型，如文本（text）、图像（image）、音频（audio）、视频（video）、应用程序（application）等。 MIME支持多部分消息内容类型，其中每个部分都有自己的类型和编码方式。这使得邮件能够以多种格式呈现，并支持包含附件等复杂的内容结构。\n使用MIME，可以使用现有的邮件程序和协议发送MIME消息。它已经被广泛使用，并成为互联网上电子邮件的标准。\nMIME还定义了各种内容类型和子类型，以适应不同类型的媒体内容。例如，text/plain表示纯文本，image/gif表示GIF格式的静态图像，audio/basic表示基本音频，video/mpeg表示MPEG格式的视频等。这些类型和子类型允许邮件接收者正确解释和显示邮件中的内容。\n增加了5个新的邮件首部字段，这些字段提供了有关邮件主体的信息。\n定义了许多邮件内容的格式，对多媒体电子邮件的表示方法进行了标准化。\n定义了传送编码，可对任何内容格式进行转换，而不会被邮件系统改变。\n实际上，MIME不仅仅用于SMTP,也用于后来的同样面向ASCII:字符的HTTP。\nSTMP 简单邮件传输协议（Simple Mail Transfer Protocol，SMTP）用于在用户代理（UA）和邮件服务器之间以及邮件服务器之间传输邮件消息。\nSMTP服务器监听25号端口。 SMTP客户端建立与该端口的TCP连接。 如果消息无法传递，最终将返回给发送者包含无法传递的消息的错误报告的第一部分。\nSMTP服务器始终处于开启和监听状态，通过TCP的25端口进行通信。 SMTP服务器负责接收并存储用户的入站邮件。 SMTP是一种简单的ASCII协议。\n邮件系统由文件系统和SMTP组成。用户通过SMTP客户端将邮件消息发送到SMTP服务器，SMTP服务器负责将邮件传递到目标服务器或目标用户的邮箱。MTA（Mail Transfer Agent，邮件传输代理）是使用SMTP的邮件服务器。\nPOP和IMAP WWW:HTTP 目标：将分布在互联网不同设备上的资源组织起来。 WWW体系结构 超链接：超文本、超媒体 Web客户（浏览器）和Web服务器 URL:protocol://domain_name:port/item_name Web页面：静态页面(HTML),动态页面，活动页面 超文本传输协议(HTTP) Client/Server,同步数据传输 over TCP,port80 HTTP操作：TCP连接，HTTP请求报文和响应报文 HTTP1.0\u0026amp;1.1:持久连接、流水线请求 概念 www 万维网采用客户端/服务器模式，其中浏览器程序充当客户端。 客户端和服务器通过HTTP（超文本传输协议）进行交互。 万维网文档使用URL（统一资源定位符）进行定位。 万维网文档采用HTML（超文本标记语言）编写。 搜索引擎使用户能够方便地找到所需的信息。 浏览器 一个应用程序作为用户与网络的接口，用于获取来自Web服务器的信息（网页）并将信息显示给用户。当用户点击超链接时，浏览器会确定链接的URL和网页名称（例如www.abc.com/example.html），然后向DNS请求www.abc.com的IP地址。浏览器建立与返回的IP地址的TCP连接，并发送一个HTTP请求，请求页面 /example.html ，并获取嵌入的图像。浏览器显示 /example.html 中的所有文本和图像，并在完成后释放TCP连接。 Web 服务器 Web服务器存储一组Web文档，并通过向浏览器发送文档副本来响应请求。服务器的工作循环包括以下步骤： 接受来自客户端（浏览器）的TCP连接。 获取页面的路径，即所请求文件的名称。 获取文件（从磁盘上）。 将文件的内容发送给客户端。 释放TCP连接。 这些步骤循环进行，以响应浏览器的请求并向客户端提供所请求的Web文档。 web文档（web page） 静态网页(static web page)： 存储在文件中，内容不可更改。 页面内容在创建后不会发生变化，呈现给用户的是固定的信息。 动态网页(dynamic web page)： 每当服务器接收到请求时可以根据需求进行更改。 页面内容是在服务器端根据请求生成的，通常是通过服务器上的程序输出，如脚本语言(script)。 活动网页(active web page)： 在文档加载到浏览器后，页面可以根据用户的操作进行更改。 页面内容是在客户端生成的，通过在浏览器中运行的计算机程序（例如Java）实现。 这种类型的页面常常包含交互性和动态功能，用户可以与页面进行互动并触发特定事件。 URL 默认：协议http；端口80；路径index.html protocol://domain_name:port/item_name HTTP HTTP介绍 HTTP 是一个应用层协议，它使用 TCP 连接进行可靠的传送\nHTTP定义了浏览器（即万维网客户进程）怎样向万维网服务器请求万维网文档，以及万维网服务器怎样把万维网文档传送给浏览器。\n每个万维网网点都有一个服务器进程，它不断地监听 TCP 的端口 80，以便发现是否有浏览器向它发出连接建立请求。\n一旦监听到连接建立请求并建立了 TCP 连接之后，浏览器就向万维网服务器发出浏览某个页面的请求，服务器接着就返回所请求的页面作为响应。\n最后，TCP 连接就被释放了。\nHTTP/1.0\u0026amp;HTTP/1.1 HTTP/1.0 停等 非持续连接：每次浏览器要请求一个文件都要与服务器建立TCP连接，当收到响应后就立即关闭连接。 每请求一个文档就要有两倍的RTT的开销。若一个网页上有很多引用对象（例如图片等），那么请求每一个对象都需要花费2RTT的时间。 为了减小时延，浏览器通常会建立多个并行的TCP连接同时请求多个对象。但是，这会大量占用www服务器的资源，特别是www服务器往往要同时服务于大量客户的请求，这会使其负担很重。 HTTP/1.1 持续连接：万维网服务器在发送响应后仍然保持这条连接，使同一个客户（浏览器）和该服务器可以继续在这条连接上传送后续的HTTP请求报文和响应报文。这并不局限于传送同一个页面上引用的对象，而是只要这些文档都在同一个服务器上就行。 为了进一步提高效率，HTTP/1.1的持续连接还可以使用流水线方式工作，即浏览器在收到HTTP的响应报文之前就能够连续发送多个请求报文。 HTTP报文格式 HTTP是面向文本的，其报文中的每一个字段都是一些ASCII码串，并且每个字段的长度都是不确定的。\ncookies Cookie是一种对无状态的HTTP进行状态化的技术。\n缓存和代理服务器 万维网缓存又称为Web缓存(Web Cache),可位于客户机，也可位于中间系统上，位于中间系统上的\nWeb缓存又称为代理服务器(Proxy Server).\nWeb缓存把最近的一些请求和响应暂存在本地磁盘中。当新请求到达时，若发现这个请求与暂时存放的请求相同，就返回暂存的响应，而不需要按URL的地址再次去因特网访问该资源。\n","date":"2024-01-23T21:03:54Z","permalink":"http://localhost:1313/post/6-%E5%BA%94%E7%94%A8%E5%B1%82/","title":"6 应用层"},{"content":"主要概念\n引入网络层的原因：消除网络层的不可靠性；提供源主机到端主机的可靠地，如实际使用网 络无关的信息传输；提高服务质量，进行差错检测。\n与网络层的区别：传输层提供应用进程间的逻辑通信，而网络层只是实现主机到主机之间通信\n传输层提供高效、可靠、高性价比的数据传输，独立于当前的物理层网络，是进程与进程间的通信\n算法 流量控制，拥塞控制 慢启动 启动速率很低，拥塞窗口初始值为1个最大报文段长度（MSS）。在达到阈 值或者发现丢包之前，拥塞窗口按指数级增长 注： cwnd: CongestionWindow AI 当拥塞窗口达到阈值时，按线性增长 MD 出现重发定时器超时，拥塞窗口降为最小值（1个MSS），阈值改为超时时刻的拥塞窗口值的一半，重新开始新的慢启动。 快速恢复 收到三个重复的ACK时，拥塞窗口降为当前窗口的一半，开始新的AI 最大最小公平性 (Max-Min Fairness) 基本含义：使得资源分配向量的最小分量的值最大，防止任何网络流被‘饿死’，同时在一定程度上尽可能增加每个流的速率。\n原则：一个信道上，在满足最小需求的前提下，各流尽量均分带宽；如果增加任何一个参与者（分量）的带宽，将导致其它的具有相同或者更少带宽的参与者（分量）的带宽下降，此时即满足了最大最小公平性\nIn Figure 6-20, suppose a new flow E is added that takes a path from R1 to R2 to R6. How does the max-min bandwidth allocation change for the five flows?\n习题8：在书图6-20（即下图）中，假设加入了一个新的流E，它的路径是从R1到R2、R2再到R6。请问对于5个流的最大－最小带宽分配有什么变化？\n解题思路：本题考查对于最大最小公平性原则的理解。在带宽分配中，如果增加任一个流的带宽，不会减少最小带宽需求的流的带宽，则该分配方式满足最大最小公平性原则。\n答：流A和E在R1-R2均分带宽。由于A不是占用带宽最小的流，从2/3降为1/2没有违反最大-最小公平性原则。\n在链路R1-R2上，A分配1/2带宽，在R2-R3上继续分配1/2带宽；\n在链路R1-R2上，E分配1/2带宽, 在R2-R6上继续分配1/2带宽；\n其他流（B、C、D）的带宽分配不变。\nTCP拥塞控制过程 慢启动，AIMD\n发送窗口=min(接收窗口，拥塞窗口)\n发生超时，则阈值＝超时时刻的拥塞窗口值/2\nNagle算法（发送端） 积累要发送的数据，一次尽可能发送较大的数据量（1个MSS） Clark算法（接收端） 等待空闲的接收缓冲区变大，只在有较大缓存（至少为1/2 MSS）时，才发送窗口更新通知 Jacobson算法 估计端到端环回时延RTT $$RTT_{估值}=\\alpha \\times RTT_{估值的历史值} + (1 - \\alpha) \\times RTT_{测量值}$$ 传输层协议 UDP 提供无连接、尽力而为的传输服务，采用校验和方式进行差错检测 ，不提供差错恢复功能。 UDP保留发送方和接收方之间的消息边界\n使用UDP的协议：DNS、DHCP、RIP等\n段头格式 校验和计算 TCP 提供面向连接的、可靠的字节流服务，不保证应用层的消息边界\n段格式 段头（20或更多字节）\n校验和 Provides extra reliability\nIt checksums the header, the data, and the conceptualpseudo-header\nPseudo-header: helps detect mis-delivered packets Checksum is mandatory(TCP中的校验和是必须支持的)\nOptions in Header MSS(Maximum Segment Size) 连接建立时协商 收发方向的MSS可以不同 Window scale 允许双方在连接开始时协商 最大可达 $$2^{30$$ 字节 Timestamp SACK 选择性确认 三步建立连接，四步释放连接 建立连接（客户端确认“服务器的确认”😀）\n释放连接（主动方等被动方的遗言，然后确认“被动方的确认”😀）\n","date":"2024-01-23T20:52:56Z","permalink":"http://localhost:1313/post/5-%E4%BC%A0%E8%BE%93%E5%B1%82/","title":"5 传输层"},{"content":"概念 网络层功能 网络层的任务是将源计算机发出的数据分组（数据报）经过适当的路径送到目的地计算机，从源端到目的端可能要经过若干中间节点。\n网络层是处理计算机网络中端到端数据传输的最低层。\n存储转发分组交换机制 一台主机要发送一个分组（数据报），那么它将分组传送给最近的路由器，该路由器或者在它自己的 LAN 上，或者在一条通向承运商的点到点链路上。该分组被存储在路由器上，一直到它完全到达路由器为止，所以路由器可以验证它的校验和。然后它被沿路转发到下一台路由器，直到到达目标主机为止，最后在目标主机上它被递交给相应的进程。\n网络层****传输的单位：分组\n向传输层提供的服务：虚电路和数据表 分组交换\n面向连接的虚电路服务 （Virtual Circuit approach） 发送方发送给接收方的所有分组都沿着同一条虚电路传送\n不是真正的物理连接\nVirtual Circuit Identidier（VIC）:标识虚电路的信号，要先建立虚连接\n无连接的数据报服务（Datagram approach） 发送方发送给接收方****的分组可能沿着不同路径传送\n无连接，每个包单独处理，没有真正的带宽分配\n对比的方面 虚电路 数据报 连接的建立 必须有 不要 目的站地址 仅在连接建立阶段使用，每个分组使用短的虚电路号 每个分组都有目的站的全地址 路由选择 在虚电路连接建立时进行，所有分组均按同一路由 每个分组独立选择路由 当路由器出故障 所有通过了出故障的路由器的虚电路均不能工作 出故障的路由器可能会丢失分组，一些路由可能会发生变化 分组的顺序 总是按发送顺序到达目的站 到达目的站时可能不按发送顺序 端到端的差错处理 由通信子网负责 由主机负责 端到端的流量控制 由通信子网负责 由主机负责 路由选择算法 最优化原则 如果路由器 J 是在从路由器 I 到路由器 K 的最优路径上，那么，从 J 到 K 的最优路径也必定沿着同样的路由路径。\n最短路径选择算法（Dijkstra 最短路由搜索算法） 扩散算法（Flooding）洪泛 在扩散法中，每一个入境分组将被路由器转发到除了它进来的那条路线之外的每一条输出线路上。\n由于扩散算法会产生大量的重复分组，需要改进扩散算法，避免重复的分组。\n收到包就转发\n距离矢量路由选择（Distance Vector Routing） DVR 是一种基于距离的基本路由协议，根据距离确定数据包的最佳路径。它使用简单的度量标准（如跳数）来计算最佳路径，并与邻居共享这些信息。\n每个路由器有一个路由表，更新表时只跟邻居交换。\n如果结点 i 的所有邻站都知道到结点j的最短距离，那么求结点 i 和结点 j 之间的最短距离就可以用结点 i 到每个邻站之间的距离分别加上该邻站到结点 j 的最短距离，然后再从得数中选择最小的一个。\n所有的节点都监听从其他节点传送来的路由选择更新信息，并在下列情况下更新它们的路由选择表：\nA. 被通告一条新的路径，该路由在本节点的路由表中部存在，此时本地系统加入这条新的路由；\nB. 通过发送来路由信息的节点有一条到达某个目的地的路由，该路由比当前使用的路由有较短的距离（较小的代价）。在这种情况下，就用经过发送路由信息的节点的新路由替换路由表中到达那个目的地的现有路由。\nC. 在本节点的现有路由表中为了到达某一目的地首先应前往的下一节点如果通告了一个较高的代价，就要使用这一新的代价更新从本节点前往同一目的地的代价。\n创建路由表 更新路由表 无穷计算（Count-to-infinity）问题：DVR 在得知更高效或更短路径（好消息）时会快速更新其路由表。然而，对于“坏消息”，如链路故障或更长路径，它的反应较慢。这种差异可能导致“无限计数”问题，其中路由器持续增加失效链路的跳数，导致路由环路和次优路由。\n好消息传得快，坏消息传得慢，导致了当路由信息发生变化时该变化未能及时地被所有路由器知道，而仍然可能在路由器之间进行传递 慢收敛是导致发生路由回路的根本问题 总结\n使用在 RIP （Routing Information Protocol）、Cisco EIGRP （Enhanced Interior Gateway Routing Protocol） RIP协议为应用层协议，使用UDP传送数据 改进：BGP-4 （Border Gateway Protocol）、IDRP （Inter-domain Routing Protocol） 距离值\u0026gt;=16意味着该网络不可达 链路状态路由选择（Link State Routing） 概念\n在链路状态路由中，每个路由器都将其邻接网络的信息共享给网络中的所有其他路由器。使用链路状态包（Link-State Packet，LSP）定义并发送最佳已知的网络拓扑。当网络发生变化时，信息会被共享。\n步骤\n发现邻居节点：每个路由器需要发现它的邻居，并知道他们的网络地址。这个过程通常是通过发送一种特殊的数据包，称为 HELLO 包，来实现的。HELLO 包可以在广播网络中广播，也可以在点对点网络中向邻居单播。当邻居收到 HELLO 包后，会回复一个确认包，告诉发送者它是谁。在这里，路由器的标识（Route IDs）必须是全球唯一的。另外，当两个或更多路由器通过局域网或其他多访问网络连接时，可以简化网络拓扑。 测量线路开销：路由器需要测量到每个邻居的延迟或成本。这个过程可以通过测量往返时间（使用 ECHO 包）和带宽来实现。在此过程中，可能需要考虑是否在测量延迟时考虑负载因素，因为这可能会导致路由表振荡，从而引发许多潜在问题。 创建链路状态分组：路由器需要构建一个链路状态分组（Link-State Packet，LSP），该包包含所有新学习到的信息：这个分组的内容包含了发送方的标识，以及是一个序列号（Seq）和年龄（Age），以及一个邻居列表。对于每个邻居，同时也要给出到这个邻居的延迟。这个过程可以定期进行，也可以在一些重大事件发生时进行，例如链路或邻居宕机、重新上线，或其属性发生显著变化。 序号是为了解决前面发生的浪费太多资源的问题，每发一包，序号加 1 年龄是为了解决路由器崩溃，序号发生错误等情况，每秒年龄减 1，减到 0 后丢弃 分发链路状态分组：路由器需要将 LSP 可靠地发送到网络中的所有其他路由器，而不仅仅是它的邻居。这个过程主要是通过洪泛法来实现的，以防止路由器之间线路的错误。所有的 LSP 都需要得到确认，以确保其正确送达。 计算新路由：一旦路由器积累了一整套 LSP，它就可以利用这些信息构造出整个网络拓扑图。然后，路由器可以运行 Dijkstra 的算法，根据这个网络拓扑图，计算出本节点到其他结点的最短路径。最后，这些计算结果可以被安装在路由表中，用于指导路由器的路由决策。 例子\n应用\n链路状态路由（Link State Routing）在多种网络协议中得到了采用和实现，主要包括以下两种：\nIS-IS（Intermediate System to Intermediate System）：这是一个开放性的路由协议，被设计出来主要用于路由交换机（routers）和交换机（switches）之间。IS-IS 协议支持多种网络层协议，如 DECnet，ISO CLNP，IP，AppleTalk，Novell NLSP （IPX）等。这种多协议支持的能力使得它在各种不同的网络环境中都能够工作。 OSPF（Open Shortest Path First）：OSPF 是在 IS-IS 之后设计的一种路由协议，它只为 IP 提供服务。这是一种用于互联网内部网络的路由协议，主要用于在自治系统内部进行路由选择。OSPF 能够动态地适应网络拓扑的改变，其基本思想是让路由器了解到整个网络的拓扑结构，然后用最短路径算法（如 Dijkstra 算法）计算出最佳路由。 两者都是基于链路状态的路由选择算法，但他们在具体的应用和支持的网络协议上有所不同。\n层次路由（Hierarchical Routing） 红线是原路由，绿线是新路由\nConsider a subnet with 720 routers.假设这里有 720 个路由器\nIf there is no hierarchy 不分层 720 routing table entries If the subnet is partitioned into 24 regions of 30 routers each （Total:53） 24 个区域，每个区域 30 个路由器 30 local entries 每个区域本地 30 个表 23 remote entries 其他区域的表 If a three-level hierarchy is chosen, with 8 clusters, each containing 9 regions of 10 routers (Total: 25) 10 entries for local routers 8 entries for routing to other regions within its own cluster 7 entries for distant clusters DVR 和 LSR 对比 DVR (Distance Vector Routing) LSR (Link State Routing) 分享的信息 目标网络和距离 网络拓扑（LSP） 分享对象 相邻路由器 网络中的所有路由器 分享频率 周期性 变化时 路由器知道的信息 距离，不包括路径拓扑 整个网络拓扑 是否有数至无穷的问题 有 没有 拥塞控制 概念\n当一个子网或子网的一部分中出现太多分组的时候，网络的性能开始下降。这种情况称之为拥塞，网络资源上有太多的分组时，将会导致网络性能下降，即对资源需求的总和大于可用资源。\n产生拥塞的原因\n包括低带宽线路、多个输入对应一个输出、节点缓冲容量小以及节点处理速度低。\n任何涉及等待或排队的系统都可能发生拥塞。如果数据包到达率高于数据包处理率，输入队列会变得越来越长。如果数据包离开率低于数据包处理率，输出队列会变得越来越长。\n拥塞控制的通用原则\n开环控制 是预防性技术，通过预先采取措施避免拥塞的发生。 确定何时接受新流量、何时丢弃分组及丢弃哪些分组 闭环控制 是反应性技术，一旦网络发生拥塞，就采取措施进行应对。 监视系统，检测拥塞发生的时间和地点，将信息传递到能采取行动的地方，然后调整系统运行以解决问题。 拥塞控制途径：增加资源和减少负载\n增加资源： 网络提供（Network Provisioning）：规划和调整网络，以适应业务负载的需求。通过增加带宽、增加路由器、改进网络拓扑等方式来增加网络资源，以减轻拥塞压力。 业务量感知的路由（Traffic Aware Routing）：在进行路由选择时，考虑网络负载的影响。根据网络拥塞的情况，选择路径以避免拥塞节点或拥塞链路，从而实现负载均衡和拥塞控制。 减少负载： 接纳控制（Admission Control）：仅适用于虚电路网络，当网络资源不足时，拒绝建立新的虚电路连接，以避免进一步加重网络负载。\n业务量减速（Traffic Throttling）：通过限制流量的速率来降低网络负载。\n可以使用抑制分组（choke packet）、逐跳反压（hop-by-hop backpressure）和显示拥塞通知（ECN）等技术来控制和调节流量。\nchoke packet\n检测拥塞： 链路利用率（utilization of the output links）：如果输出链路的利用率过高，那么可能存在网络拥塞的情况。 队列缓冲（buffering of queued packets inside the router）：如果路由器内部的数据包队列缓冲过多，那么可能存在网络拥塞的情况。 丢包数（number of packets that are lost due to insufficient buffering）：如果因为缓冲不足而丢失的数据包数量过多，那么可能存在网络拥塞的情况。 为了估算队列延迟，通常使用指数加权移动均值（Exponentially Weighted Moving Average， EWMA）算法。 通知源主机： 发送一个抑制分组（Choke Packet）给源主机，抑制分组中包含了原始数据包中的目标地址。 对原始数据包进行标记，以防止它产生更多的抑制分组。 为了避免增加网络负载，路由器可能会以低速率发送抑制分组。 源主机降速：源主机接收到抑制分组后，可能会根据分组中的信息调整发送到指定目标的数据流量。例如，源主机可能会将流量减少 x%（例如 50%）。这样就可以降低网络拥塞，提高网络的整体性能。 hop-by-hop backpressure\n它对经过的每一个跳点（也就是网络中的节点或路由器）都会产生影响。这种机制的主要目的是限制源节点向网络中发送过多的数据，从而减轻网络拥塞。 在逐跳反压机制中，当一个节点（如路由器）检测到网络拥塞时，它会向上游节点发送反压信号，通知上游节点降低发送数据的速率。这个过程会在每个经过的节点间重复，从而使得整个网络路径上的数据流量得到控制。 ECN（IP/TCP 会使用）\nECN 通过在 IP 数据包头部使用两个比特位来记录数据包是否经历了拥塞。\n当路由器检测到拥塞时，它会将传输的数据包的 ECN 字段设置为指示拥塞的标记。目的地主机会将这些标记作为明确的拥塞信号回传给发送方，在下一次回复数据包中将标记传递回去。\n负载掉落（Load Shedding）：当路由器的处理能力不足以处理所有到达的数据包时，可以选择丢弃部分数据包来减轻负载。\n可以使用不同的策略，如葡萄酒策略（丢新的）或牛奶策略（丢旧的），也可以采用随机早期检测（Random Early Detection/RED）算法，在缓冲区空间即将耗尽之前开始丢弃数据包。 RED：早点丢随机丢 RED 的目标是在拥塞出现之前就开始主动丢弃部分数据包，以促使发送方降低传输速率。通过采用随机丢包的方式，RED 可以实现一种分散拥塞的机制，避免了一次性丢弃大量数据包所带来的突发性拥塞。 当某条线路上的平均队列长度超过一个阈值时，该线路被认为是拥塞的，随机丢弃一小部分数据包。 路由器如何向源主机告知拥塞情况呢？路由器直接丢弃选择的数据包，受影响的发送方在没有收到确认时会注意到数据包的丢失。这是一种隐式通知。 源主机在收到丢失的数据包后会减缓其传输速率，以响应丢包情况。 服务质量 评价标准 Reliability Packet error rate 差错率 Packet loss rate 丢包率 Delay Jitter Bandwidth 流量整形 漏桶（leaky bucket）算法 桶满则数据丢失 每个主机连接到网络的接口中都包含一个漏桶，即含有一个有限长度的内部队列。如果当该队列满的时候，又有一个分组到来，那么该分组将被丢弃，亦即是，如果在一台主机上，队列中的分组数目已经达到了最大值，这是又有一个或者多个进程要发送分组，那么新发送的分组将被丢弃。 令牌桶（token bucket）算法 桶中保存的是令牌，每个令牌包含一定数量的字节的分组，令牌桶允许主机积累发送全，直至到达桶的最大尺寸，因而相对于漏桶，允许有一定的突发流量。 经过令牌桶之后的突发数据持续时间： 突发时间S，令牌桶容量B，令牌产生速率R，最大输出速率M MS=B+RS \u0026ndash;\u0026gt; S=B(M-R) 分组调度 公平排队（fair queueing） 路由器为每一条输出线路使用一组单独的队列，每个流一个队列。当一条线路空闲的时候，路由器轮流扫描这些队列，从下一个队列中取出第一个分组。使得所有的流量以相同的速率发送数据包 （缺陷：他给使用大数据包的主机比使用小数据包的主机提供了更多的带宽）。 加权的公平排队（weighted fair queueing） 通过不同的主机赋予不同的优先级进行加权调节，从而提高算法的效率。 网络互联 互联网络的分组转发 级联虚电路： 优点： 路由器预留缓冲区等资源，保证服务质量 分组按序号传输； 分组头短 缺点： 路由器需要大量内存，存储虚电路信息； 一旦发生拥塞，没有其它路由； 健壮性差：如果网络中有一个不可靠的数据报子网，级连虚电路很难实现。 无连接网络互联： 优点： 能够容忍拥塞，并能适应拥塞； 健壮性好； 可用于多种网络互连。 缺点： 长包头： 包不能保证按序号到达； 不能保证服务质量。 隧道技术 当源和目标主机位于相同类型的网络中，中间的网络属于不同类型时使用隧道方案。 互联网路由 互联网定义了两级路由算法：在每个网络内部使用的内部网关协议（interior gateway protocol）和在网络之间使用的外部网关协议exterior gateway protocol）。 自治系统（AS,Autonomous System） 自治系统：在单一的技术管理下的一组路由器，而这些路由器使用一种AS内部的路由选择协议和共同的度量以确定分组在该AS内的路由，同时还使用一种AS之间的路由选择协议用以确定分组在AS之间的路由。 现在对自治系统AS的定义是强调下面的事实：尽管一个AS使用了多种内部路由选择协议和度量，但重要的是一个AS对其他AS表现出的是一个单一的和一致的路由选择策略。 因特网有两大类路由选择协议 内部网关协议IGP（Interior Gateway Protocol）：即在一个自治系统内部使用的路由选择协议。目前这类路由选择协议使用得最多，如RIP和OSPF协议。 外部网关协议EGP（External Gateway Protocol）：若源站和目的站处在不同的自治系统中，当数据报传到一个自治系统的边界时，就需要使用一种协议将路由选择信息传递到另一个自治系统中。这样的协议就是外部网关协议EGP。在外部网关协议中目前使用最多的是BGP-4。 分段和重组 MTU：Maximum Transmission Unit 最大传输单元 Internet上的网络层 IPv4 每一台主机和每一个接口的唯一的 32 比特的标识符，点分十进制 x.x.x.x\nIPv4 Header 一个IP数据报由首部和数据两部分组成。\n首部的前一部分是固定长度，共20字节,是所有IP数据报必须具有的。在首部的固定部分的后面是一些可选字段，其长度是可变的。IP分组（数据报）结构如下图所示。IP首部的长度为20-60B。\n版本 (version) 字段 版本 (Version) 字段记录了数据报属于协议哪个版本。（ipv4 or ipv6）\nIHL 字段 由于头的长度不固定，所以头的 IHL 字段指明了头有多长（以4B为单位）。IHL 的最小值为 5，这表明头没有可选项。该 4 位字段的最大值为 15，把头的长度限制为最大 60 字节，因此选项 (Options) 字段最多为 40 字节。\n区分服务 (differentiated services) 字段 区分服务 (Differentiated services) 字段\n该字段最初称为服务类型 (Type of service)。它曾经并且仍然用来区分不同的服务种类。\n现在，前 6 位用来标记数据包的服务类别，我们在本章前面描述过的加速服务和确保服务：后 2 位用来携带显式拥塞通知信息，比如数据包是否经历了拥塞，我们在本章的拥塞控制部分描述了显式拥塞通知。\n总长度 (total length) 字段 总长度 (Total length) 字段包含了该数据报中的所有内容，即头和数据。最大长度是 65535 个字节。\n标识 (identification) 字段 标识 (Identification) 字段的用途是让目标主机确定一个新到达的分段属于哪一个数据报。\n同一个数据报的所有段包含同样的标识值。\nDF（Don\u0026rsquo;t Fragment）标志 DF=1 不能分段 MF（More Fragments）标志 进行分段且后面还有fragment MF=0 后面没有fragment MF=1 分段偏移量 (fragment offset) 字段 除了数据报的最后一个段以外，其他所有段的长度必须是 8 字节的倍数(单位为8B)\n例：IP 数据报分段 生存期 (time to live) 字段 生存期 (Time to live) 字段是一个用于限制数据包生存期的计数器。这里的计数单位最初设置为秒，因此最大的生存期为 255 秒。在每一跳上该计数器必须被递减，而且，当数据报在一台路由器上排队时间较长时，该计数器必须多倍递减。实际上，它只是跳计数器，当它递减到 0 时，数据包就被丢弃，并且路由器给数据包的源主机发回一个报警包。\n协议 (protocol) 字段 协议 (Protocol) 字段指明了该将它交给哪个传输进程。\nTCP 是6、 UDP 是17\n头校验和 (header checksum) 字段 头校验和 (Header checksum) 字段。校验算法的执行过程是这样的：当数据到达时，所有的 16 位（半字）累加起来，然后再取结果的补码。该算法的目的是到达数据包的头校验和计算结果应该为 0。这样的校验和对于检测数据包穿过网络时是否发生错误非常有用。请注意，在每一跳必须重新计算头校验和字段，因为至少有个字段总是不断在改变（即生存期字段），\n源地址和目标地址 源地址 (Source address) 字段和目标地址 (Destination address) 字段表示源网络接和日标网络接口的 P 地址。\n选项 (options) 字段 选项 (Options) 字段的设计意图是提供一种途径，允许后续版本协议包含一些原设计中没有出现的信息，以便实验人员尝试新的想法、避免为那些不常使用的信息分配头字段。\n严格源路由 严格源路由 (Strict source routing) 选项给出了从源到目标的完整路径，其形式是一系列 IP 地址。数据报必须严格地遵循这条路径向前传输。\n松散源路由 松散源路由 (Loose source routing) 选项要求该数据包穿越所指定的路由器列表，并且要求按照列表中的顺序前进；但是，在途中也允许经过其他路由器。\n记录路由 记录路由 (Record route) 选项告诉沿途的路由器，将自己的 IP 地址附加到可送字段中。\n时间戳 时间戳 (Timestamp) 选项类似于记录路由选项，只不过每个路由器除了记录自己的 32 位 IP 地址以外，还要记录一个 32 位时间戳\nIPv4 地址 分类编址的 ipv4 只有 A/B/C 类地址能分配 主机号全为 0：网络地址 主机号全为 1：广播地址 A：0 8 位网络号 最小网络号为 0，保留不指派 最大网络号为 127，作为本地环回测试，不指派 B：10 16 位网络号 最小网络号也是第一个可指派的网络号 128.0 网络地址为 128.0.0.0 最大网络号也是最后一个可指派的网络号 191.255 网络地址为 191.255.0.0 C：110 24 位网络号 最小网络号也是第一个可指派的网络号 192.0.0 网络地址为 192.0.0.0 最大网络号也是最后一个可指派的网络号 223.255.255 网络地址为 223.255.255.0 划分子网的 ipv4 从主机号借用若干位作为子网号 划分为三个子网后对外仍是一个网络 子网掩码 （IP 地址） AND （子网掩码） = 网络地址 默认子网掩码：未划分子网的情况下使用的子网掩码 无分类编址的 ipv4 CIDR：斜线记法 在斜线后面写上网络号所占的比特数 128.14.34.7/20 路由聚合 最长前缀匹配：若路由器查表转发分组时，发现有多条路由可选，则选择网络前缀最长的那条 （最小的子网） IPv4 地址的应用规划 给定一个 IPv4 地址块，如何将其划分成几个更小的地址块，并将这些地址块分配给互联网中不同网络，进而可以给各网络中的主机和路由器接口分配 IPv4 地址\n定长的子网掩码 FLSM（Fixed Length Subnet Mask）、 使用同一个子网掩码来划分子网 子网划分方式不灵活：只能划分出$$2^$$个子网（是从主机号部分借用的用来作为子网号的比特数量） 每个子网所分配的 1P 地址数量相同，容易造成 P 地址浪费。 变长的子网掩码 VLSM（Variable Length Subnet Mask） 使用不同的子网掩码来划分子网 子网划分方式灵活：可以按需分配 每个子网所分配的 P 地址数量可以不同，尽可能减少对 P 地址的浪费 NAT转换 NAT网络地址转换，它是一种把内部私有网络地址(IP地址)翻译成合法网络IP地址的技术。\n1)宽带共享解决IP地址匮乏问题\n简单地说，NAT就是在局域网内部网络中使用内部地址，而当内部节点要与外部网络进行通讯时，就在网关处，将内部地址替换成公用地址，从而在外部公网(internet)上正常使用，NAT可以使多台计算机共享Internet:连接，只申请一个合法IP地址，就把整个局域网中的计算机接入Internet中。这一功能很好地解决了公共IP地址紧缺的问题。\n2)提供安全防护\nNAT屏蔽了内部网络，所有内部网计算机对于公共网络来说是不可见的。内部地址（在内部网络中分配给节点的私有IP地址）只能在内部网络中使用，不能被路由转发，隐藏保护了内网的计算机。\nIP 数据报分组和转发过程 直接交付与间接交付 可以通过目的地址 IP 和源地址的****子网掩码进行逻辑与运算得到目的网络地址\n如果目的网络地址和源网络地址 相同，就是在同一个网络中，属于直接交付\n如果目的网络地址和源网络地址 不相同，就不在同一个网络中，属于间接交付，传输给主机所在网络的默认****网关（路由器），由默认网关帮忙转发。\n默认网关 为了使本网络中的主机能和其他网络中的主机进行通信，给其指定本网络的一个路由器的接口，由该路由器帮忙进行转发。所指定的路由器，也被称为默认****网关\n路由器查表转发过程 路由器收到 IP 数据报 检查 IP 数据报首部是否出错： 若出错，则直接丢弃该 IP 数据报并通告源主机 若没有出错，则进行转发 根据 IP 数据报的目的地址在路由表中查找匹配的条目： 若找到匹配的条目，则转发给条目中指示的下一跳 若找不到，则丢弃该数据报并通告源主机 假设 IP 数据报首部没有出错，路由器取出 IP 数据报首部各地址字段的值 如源地址和目的地址\n查表转发 逐条检查路由条目，将目的地址与路由条目中的地址掩码进行逻辑与运算得到目的网络地址，然后与路由条目中的目的网络进行比较，如果相同，则这条路由条目就是匹配的路由条目。\n按照它的下一条指示，图中所示的也就是接口 1 转发该 IP 数据报\n路由器隔离广播域 IPv6 IPv6 地址，冒分十六进制\n数据报：\n其他协议 ICMP ARP DHCP ","date":"2024-01-23T20:36:56Z","permalink":"http://localhost:1313/post/4-%E7%BD%91%E7%BB%9C%E5%B1%82/","title":"4 网络层"},{"content":"排序 插入排序 直接插入排序 void InsertSort(SqList \u0026amp;L) { for (i = 2; i \u0026lt;= L.length; i++) // n-1轮 if (LT(L.r[i].key,L.r[[i-1].key)) { // 比前面的小 L.r[0] = L.r[i]; L.r[i] = L.r[i - 1]; // 监视哨 for (j=i-2; L.r[0].key \u0026lt; L.r[[j].key; j--) //逐一比较 L.r[j + 1] = L.r[j]; // 向后移动一个位置 L.r[j + 1] = L.r[0]; // 插入 } } // InsertSort (1) 最好情况（初始正序）下：每趟操作只需1次比较，0次移动\n总比较次数= n-1次 总移动次数= 0次\n所以时间复杂度为O(n)\n(2) 最坏情况（初始逆序）下：即每一趟操作都要插入记录到最前面。\n[改进措施]\n折半插入排序 算法思想：将循环中每一次在区间 [1,i-1] 上为确定插入位置的顺序查找操作改为折半查找操作。 效果：减少关键字间的比较次数，移动次数不变。\n2-路插入排序 算法思想：设置与r同样大小的辅助空间d，将r[1]赋值给d[1]，将d看作循环向量。对于r[i] (2in)，若r[i]d[1]，则插入d[1]之后的有序序列中，反之则插入d[1]之前的有序序列中。(避免r[1]关键字最小/最大) 效果：减少记录的移动次数。\n表插入排序 算法思想：构造静态链表，用改变指针来代替移动记录操作 效果：减少记录的移动次数。\n希尔排序 先选取一个小于n的整数d[i]（称之为步长），然后把排序表中的n个记录分为d[i]个组，从第一个记录开始，间隔为d[i]的记录为同一组，各组内进行直接插入排序，一趟之后，间隔d[i]的记录有序，随着有序性的改善，减小步长di（排序子表变大），重复进行，直到di=1（全部记录成为一个排序表），使得间隔为1的记录有序，也就使整体达到了有序。\n步长为1时就是直接插入排序。\n交换排序 冒泡排序 void BubbleSort(SqList \u0026amp;L) { n = L.length; sorted = FALSE; for (i = 0; i \u0026lt; n - 1 \u0026amp;\u0026amp; (!sorted); i++) // 最多n-1趟 sorted = TRUE; for (j = 1; j \u0026lt; n - i; j++) // 对前n-i个相邻元素逐个两两相比 if (L.r[j].key \u0026gt; L.r[j + 1].key) { // 是否逆序 L.r[j]←→L.r[j + 1]; // 交换 sorted = FALSE; // 设置标志位，表明本趟有交换 } } } // BubbleSort [性能分析]\n[算法的改进] 每趟排序中，记录最后一次发生交换的位置 例：{54，32，16，55，103，727，834，1006} 双向交替扫描，改进数据不对称性： 上下，最重沉底；下上，最轻升顶。 例：{12，18，42，44，45，67，94，10}\n快速排序 快速排序是通过比较关键码、交换记录，以某个记录为界(该记录称为支点)，将待排序列分成两部分。一部分是关键码大于等于支点记录的，另一部分是关键码小于支点记录的关键码。\n我们将待排序列按关键码以支点记录分成两部分的过程，称为一次划分。\n对各部分不断划分，直到整个序列按关键码有序。\nint Partition(SqList \u0026amp;L，int low, int high) { L.r[0] = L.r[low]; // 将low记录移动到r[0] pivotkey = L.r[low].key; // low的key作为支点 while (low \u0026lt; high) { while (low \u0026lt; high \u0026amp;\u0026amp; L.r[high].key \u0026gt;= pivotkey) --high; // 从后向前，如果high对应的key大于等于支点，则跳过(--high) L.r[low] = L.r[high]; // high对应的key小于支点，将其移动到low里面 while (low \u0026lt; high \u0026amp;\u0026amp; L.r[low].key \u0026lt;= pivotkey) ++low; // 从后向前，如果low对应的key小于等于支点，则跳过(++low) L.r[high] = L.r[low]; } L.r[low] = L.r[0]; return low; } // Partition void QuickSort(SqList \u0026amp;L) // 对顺序表 L 进行快速排序 { QSort(L, 1, L.length); } // QuickSort void QSort(SqList \u0026amp;L，int low, int high) // 对顺序表 L中的子序列L.r[low..high] 进行快速排序 { if (low \u0026lt; high) { pivotloc = Partition(L, low, high); Qsort(L, low, pivotloc - 1); Qsort(L, pivotloc + 1, high) } } // QSort 时间效率：在n个记录的待排序列中，一次划分需要约有\u0026lt;=n次关键码比较，时效为O(n) 理想情况下：每次划分，正好将分成两个等长的子序列，则需要的排序趟数为\u0026lt;= log2n，故时间性能为O(nlog2n)。 最坏情况下（初始正序/逆序）:即每次划分只得到一个子序列时，时间效率为O(n2) 快速排序通常被认为是在同数量级O(nlog2n)的排序方法中平均性能最好的。 快速排序是一个不稳定的排序。\n快速排序是递归的，每层递归调用时的指针和参数均要用栈来存放，递归调用层次数与上述二叉树的深度一致。因而，存储开销在理想情况下为O(log2n)，即树的高度；在最坏情况下，即二叉树是一个单链，为O(n)。\n[算法的改进] 合理选择枢轴记录可改善性能。例如， 三者取中 随机产生\n选择排序 简单选择排序 void SelectSort(SqList \u0026amp;L) { for (i = 1; i \u0026lt; L.length; i++) // n-1趟 { j = i; for (k = i + 1; k \u0026lt;= L.length; k++) if (L.r[j].key \u0026gt; L.r[k].key) j = k; // 找到最小 if (i != j) L.r[i] ←→ L.r[j]; } } // SelectSort 简单选择排序的性能分析\n空间效率：仅用了一个辅助单元R[0]作为交换的中介。\n时间效率：简单选择排序移动记录的次数较少\n最好情况下移动0次\n最坏情况下，每趟排序都需要交换（即每趟需移动3次），共需移动3(n-1)次；\n关键码的比较次数与初始序列情况无关，第i趟需要比较n-i次，\n（n-1)+(n-2)+(n-3)+……+1=n(n-1)/2；\n所以算法的时间复杂度为O(n2）\n简单选择排序是一个不稳定的排序。\n​ 简单选择排序的思想简单，易于实现，但其时间性能没有优势，这是因为在每趟的选择中，没有把前面选择过程中的一些有用信息继承下来，因此每趟选择都是顺序的一一进行，如果某一趟的选择能够把前面有用的一些信息继承下来，则定会减少本趟的比较次数，提高排序效率\n树形选择排序 [性能] 除第一次外，每次都走了树的一条分支，故其时间复杂度为 O( n log2 n )。 [缺陷] 辅助空间较多；需与“最大值”进行多余的比较\n堆排序 堆特点：堆顶元素是整个序列中最大(或最小)的元素。 首先将排序表按关键码建成堆，堆顶元素就是最大元素（或最小），将其输出 再对剩下的n-1个元素建成堆，得到次大 (或次小)的元素。以此类推，直到进行n-1次后，排序结束，便得到一个按关键码有序的序列。称这个过程为堆排序。 因此，实现堆排序需解决两个问题：\n1. 如何将n个元素的排序序列按关键码建成堆（初始堆）； 2. 怎样将剩余的n-1个元素按其关键码调整为一个新堆![微信图片_20221221151937](https://picture2023-1309715649.cos.ap-beijing.myqcloud.com/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20221221151937.jpg) 算法思想：\n1 取出根元素，放在R[n]\n2 将剩下的n-1个元素重新调整为堆\n3 再取出根元素，放在R[n-1]，将剩下的元素再调整为堆\n4 如此反复，直到取尽堆中所有元素\n第二个问题的背景：\n​ 输出堆顶元素后，将堆底元素送入堆顶（或将堆顶元素与堆底元素交换），堆可能被破坏。\n破坏的情况仅是根结点和其左右孩子之间可能不满足堆的特性，而其左右子树仍然是局部的堆。\n调整方法：\n将根结点与左、右孩子中较小(大顶堆为较大)的进行交换。若与左孩子交换，则左子树堆可能被破坏，且仅左子树的根结点处不满足堆的性质；若与右孩子交换，则右子树堆可能被破坏，且仅右子树的根结点处不满足堆的性质。继续对不满足堆性质的子树进行上述操作，直到满足了堆性质或者到叶子结点，堆被建成。\n称这个自根结点到叶子结点的调整过程为筛选。\nvoid HeapAdjust(HeapType \u0026amp;H, int s, int m) { rc = H.r[s]; for (j = 2 * s; j \u0026lt;= m; j *= 2) { if (j \u0026lt; m \u0026amp;\u0026amp; H.r[j].key \u0026lt; H.r[j + 1].key) j++; // 若左小于右，j++ // 经过上步以后，j指向左右之中最大的那个 if (rc.key \u0026gt; H.r[j].key) break; // 父结点大于孩子中最大的那个 H.r[s] = H.r[j]; s = j; // 交换 } H.r[s] = rc; } // HeapAdjust void HeapSort(HeapType \u0026amp;H) { for (i = H.length / 2; i \u0026gt; 0; i--) HeapAdjust(H, i, H.length); //初始化堆 for (i = H.length; i \u0026gt; 1; i--){ H.r[1]←→H.r[i]; //将大顶元素拿出 HeapAdjust(H, 1, i - 1); //调整剩余部分 } } // HeapSort 归并排序 2-路归并的基本思想是：\n•只有1个元素的表总是有序的，所以将排序表R[1..n]，看作是n个长度为len=1的有序子表，对相邻的两个有序子表两两合并到R1[1..n]，使之生成表长len=2的有序表；\n•再进行两两合并到R[1..n]中，…，直到最后生成表长len=n的有序表。\n•这个过程需要「log2n」趟。\n可以看到这种结构很像一棵完全二叉树，本文的归并排序我们采用递归去实现（也可采用迭代的方式去实现)。分阶段可以理解为就是递归拆分子序列的过程，递归深度为log2n。\n归并排序的算法描述\n第一步：申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列\n第二步：设定两个指针，最初位置分别为两个已经排序序列的起始位置\n第三步：比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置\n重复步骤3直到某一指针超出序列尾，将另一序列剩下的所有元素直接复制到合并序列尾\n归并排序其实要做两件事：\n（1）“分解”——将序列每次折半划分（递归实现）\n（2）“合并”——将划分后的序列段两两合并后排序\nVoid Merge(RedType SR[], RedType \u0026amp;TR[], int i, int m, int n) // 将有序的SR[i..m] 和 SR[m+1..n]归并为有序的TR[i..n] { for (j = m + 1, k = i; i \u0026lt;= m \u0026amp;\u0026amp; j \u0026lt;= n; k++) { if (SR[i].key \u0026lt;= SR[j].key) TR[k] = SR[i++]; else TR[k] = SR[j++]; } if (i \u0026lt;= m) TR[k..n] = SR[i..m]; if (j \u0026lt;= n) TR[k..n] = SR[j..n]; } // Merge void MergeSort(SqList \u0026amp;L) // 将顺序表 L 进行归并排序 { Msort(L.r, L.r, 1, L.length) ; } // MergeSort void MSort(RedType SR[], RedType \u0026amp;TR1[], int s, int t) // 将 SR[s..t] 归并排序为 TR1[ s..t] { if (s == t) TR1[s] = SR[s]; // 结束条件 else { m = (S + t) / 2; // 将SR[s..t]分为SR[s..m]和SR[m+1..t] Msort(SR, TR2, s, m); // 将SR[s..m]归并为有序的TR2[s..m] Msort(SR, TR2, m + 1, t); // 将SR[m+1..t]归并为有序的TR2[m+1..t] Merge(TR2, TR1, s, m, t); // 将TR2[s..m]和TR2[m+1..t] 归并到TR1[s..t] } } // MSort 归并排序性能分析\n空间性能 需要一个与表等长的辅助元素数据空间，所以其空间复杂度为O(n) 时间性能 对n个元素的表，可以将n个元素看作叶子结点，若将两两归并生成的子表看作它们的父结点，则归并过程对应由叶向根生成一棵二叉树的过程，所以归并趟数约等于二叉树的高度，即O(log2n)，每趟归并需移动记录n次，故时间复杂度为O(nlog2n) 归并排序是一种稳定的排序方法\n基数排序 基数排序是一种借助于多关键码排序的思想，是将单关键码按基数分成“多关键码”进行排序的方法。通过多次的“分配”和“收集”来完成。\n多关键码排序按照从最主位关键码到最次位关键码或从最次位到最主位关键码的顺序逐次排序。\n方法1：最高位优先(Most Significant Digit first)法，简称MSD法\n先对花色排序，将其分为4个组，即梅花组、方块组、红心组、黑心组。再对每个组分别按面值进行排序，最后，将4个组连接起来即可。\n为得到排序结果，我们讨论两种排序方法。 方法2：最低位优先(Least Significant Digit first)法，简称LSD法. 先按13个面值给出13个编号组(2号，3号，\u0026hellip;，A号)，将牌按面值依次放入对应的编号组，分成13堆。再按花色给出4个编号组(梅花、方块、红心、黑心)，将2组中牌取出分别放入对应花色组，再将3组中牌取出分别放入对应花色组，……，这样，4个花色组中均按面值有序，然后，将4个花色组依次连接起来即可。\n[基数排序算法思想] 借鉴LSD法\n​ 设参加排序的序列为K={K1, K2,\u0026hellip;, Kn}，\n​ 其中Ki是d位rd进制的数，rd称为基数；\n​ d由所有元素中最长的一个元素的位数计量，\n​ $K_i = K_i^0 K_i^1\u0026hellip; K_i^{d-1}$\n​ 从低位到高位依次对Kj(j=d-1, d-2, \u0026hellip;, 0)根据基数分配，再按基数递增序收集，则可得有序序列。\n[例 ]\n(1) K={3621 0724 8385 0075 0514 7368 0008 }\nrd=10, d=4\n(2) K={Zhang Wang Li Zhao}\nrd=27, d=5\n#define MAX_NUM_OF_KEY 8 // 可容纳的最多子关键字个数 #define RADIX 10 // 关键字的基数rd #define MAX_SPACE 10000 // 记录空间可容纳的最多记录数 typedef struct { KeysType key[MAX_NUM_OF_KEY]; InfoType otheritem; int next; } SLCell; typedef struct { SLCell r[MAX_SPACE]; // r[0]为头结点 int keynum; // 实际划分的关键字位数d int recnum; // 实际记录数 } SLList; Typedef int ArrType[RADIX]; void RadixSort(SLList \u0026amp;L) { for (i = 0; i \u0026lt; L.recnum; i++) L.r[i].next = i + 1; L.r[L.recnum].next = 0; // 将L改造为静态链表 for (i = 0; i \u0026lt; L.keynum; i++) { // LSD,从最低位开始 Distribute(L.r, i, f, e); // 分配 Collect(L.r, i, f, e); // 收集 } } // RadixSort void Distribute(SLCell \u0026amp;r, int i, ArrType \u0026amp;f, ArrType \u0026amp;e) { for (j = 0; j \u0026lt; RADIX; j++) f[j] = 0; // 链队队头指向0 for (p = r[0].next; p; p = r[p].next) { j = ord(r[p].keys[i]); // 求记录中关键字的第i位的队列编号 if (!f[j]) f[j] = p; // 如果原来链队为空 else r[e[j]].next = p; // 原来链队不为空 e[j] = p; // 链队尾指针指向新加入的记录 } } // Distribute void Collect(SLCell \u0026amp;r, int i, ArrType \u0026amp;f, ArrType \u0026amp;e) { for (j = 0; !f[j]; j++) ; // 找第一个非空子队列 r[0].next = f[j]; t = e[j]; while (j \u0026lt; RADIX) { for (j++; j \u0026lt; RADIX - 1 \u0026amp;\u0026amp; !f[j]; j++) ; // 找下一个非空子队列 if (f[j]) { r[t].next = f[j]; t = e[j]; } // 链接 } r[t].next = 0; } // Collect [链式基数排序的性能分析]\n设记录数为n，关键字位数为d，基数为rd\n每一趟：分配O(n) 收集O(rd) d趟总计：O(d(n+rd))O(n) 通常d, rd均为常数\n辅助空间 n个指针域（游标）空间 队头指针数组f[0..rd-1]和队尾指针数组e[0..rd-1] 辅助空间复杂度：O(rd+n)\n排序方法比较 排序方法 最好时间 平均时间 最坏时间 辅助空间 稳定性 直接插入 O（n） O（n²） O（n²） O（1） √ 希尔 $O(n^{1.3})$ O（1） × 冒泡 O（n） O（n²） O（n²） O（1） √ 快速 O（nlog2n） O（n log 2n） O（n²） O（log2n） × 简单选择 O（n²） O（n²） O（n²） O（1） × 堆 O（n log2n） O（n log2n） O（n log2n） O（1） × 归并 O（n log2n） O（n log2n） O（nlog2n） O（n） √ 基数 O（d（rd+n）） O（d（rd+n）） O（d（rd+n）） O（rd+n） √ 按平均时间排序方法分为四类 O(n2)、O(nlogn)、O(n1+)、O(n) 快速排序是目前基于比较的内部排序中最好的方法 关键字随机分布时，快速排序的平均时间最短，堆排序次之，但后者所需的辅助空间少 当n较小时如(n\u0026lt;50)，可采用直接插入或简单选择排序，前者是稳定排序，但后者通常记录移动次数少于前者 当n较大时，应采用时间复杂度为O(nlogn)的排序方法(主要为快速排序和堆排序)或者基数排序的方法，但后者对关键字的结构有一定要求 当n较大时，为避免顺序存储时大量移动记录的时间开销，可考虑用链表作为存储结构（如插入排序、归并排序、基数排序）\n堆排序难于在链表上实现，可以采用地址排序的方法，之后再按辅助表的次序重排各记录 文件初态基本按正序排列时，应选用直接插入、冒泡或随机的快速排序 选择排序方法应综合考虑各种因素\n外部排序 ","date":"2024-01-22T13:38:09Z","permalink":"http://localhost:1313/post/8-%E6%8E%92%E5%BA%8F/","title":"8 排序"},{"content":"查找 概念和术语 查找表是一种以集合为逻辑结构，以查找为核心运算的数据结构。 查找指定某个值，在查找表中确定是否存在一个记录，该记录的关键字等于给定值。 关键字记录(数据元素)中的某个数据项的值。 主关键字 该关键字可以唯一地标识一个记录。 如学生花名册中的学号 次关键字 该关键字不能唯一标识一个记录。如学生花名册中的姓名\n查找表以集合为逻辑结构，因此数据元素之间是没有“关系”的，在实现时就不受“关系”的约束，根据实际应用去组织查找表，以提高查找的效率，常见的存储结构有：顺序结构、链式结构、索引结构、散列结构。\n基于在查找表中操作的不同，查找表又分为以下两种:\n静态查找表 对查找表的查找仅是以查询为目的，不改动查找表中的数据。\n动态查找表 查找过程中还会有插入、删除操作。\n查找成功 查找表中存在满足查找条件的记录。\n查找不成功 查找表中不存在满足查找条件的记录。\n内查找 整个查找过程都在内存中进行。\n外查找 在查找过程中需要访问外存。\n平均查找长度ASL（ Average Search Length ）——查找方法时效的度量\n​ 为确定记录在查找表中的位置，需将关键字和给定值比较次数的期望值。\n静态查找表 顺序表查找 int Search_Seq2(SSTable ST, KeyType key) {\tST.elem[0].key=key; //哨兵 for(i=ST.length; ST.elem[i].key!=key; i--)； return i; }//Search_Seq2 设置监视哨，查找时每一步不必检测位置是否越界，提高算法效率。 [性能分析]\n空间：一个辅助空间。\n时间：\n1)查找成功时的平均查找长度\n​ 设表中各记录查找概率相等\n$ASL_s(n)=\\sum_{i=1}^{n}P_{i} C_i =(1+2+ \u0026hellip; +n)/n =(n+1)/2$\n2)查找不成功时的平均查找长度 $ ASL_f =n+1$\n[算法特点]\n算法简单，对表中元素排列顺序无任何要求\nn很大时查找效率较低\n改进措施：非等概率查找时，可将查找概率高的记录尽量排在表前部。\n逐个查找的方法也可用于线性链表表示的静态查找表\n有序表查找（补充：跳表） 二分查找 int Search_Bin(SSTable ST, keytype key) { low = 1; high = ST.length; // 置区间初值 while (low \u0026lt;= high) { // 要点1：结束条件 mid = (low + high) / 2; // 要点2：mid计算 if (key == ST.elem[mid].key) return mid; // 找到待查元素 else if (key \u0026lt; ST.elem[mid].key) // 要点3：low和high更新 high = mid - 1; // 继续在前半区间进行查找 else low = mid + 1; // 继续在后半区间进行查找 } return 0; // 顺序表中不存在待查元素 } // Search_Bin 变体问题\n查找第一个值等于给定值的元素\nint Search_Bin(SSTable ST, keytype key) { low = 1; high = ST.length; while (low \u0026lt;= high) mid = (low + high) / 2; if (key == ST.elem[mid].key) { if (mid == 1 || ST.elem[mid - 1].key != key) return mid; else high = mid - 1 } else if (key \u0026lt; ST.elem[mid].key) high = mid - 1; else low = mid + 1; } return 0; // 顺序表中不存在待查元素 } // Search_Bin 查找最后一个值等于给定值的元素\n略\n查找第一个值大于或等于给定值的元素\nif (key \u0026lt;= ST.elem[mid].key) { if ((mid == 1 || key \u0026gt; ST.elem[mid - 1].key)) return mid; else high = mid - 1; } else { low = mid + 1; } 查找最后一个值小于或等于给定值的元素\n略\n1.折半查找和二叉排序树的时间性能分析：\n从查找过程看，二叉排序树与二分查找相似。就平均时间性能而言，二叉排序树上的查找和二分查找差不多，但不完全一致； 折半查找的性能分析可以用二叉判定树来衡量，平均查找长度和最大查找长度都是O（logn）； 二叉排序树的查找性能与数据的输入顺序有关，最好情况下的平均查找长度与折半查找相同，但最坏情况时，即形成单支树时，其查找长度为O(n)。 折半查找的判定树唯一，而二叉排序树不唯一，相同的关键字其插入顺序不同可能生成不同的二叉排序树。 2.就维护表的有序性而言，二叉排序树无需移动节点，只需修改指针即可完成插入和删除操作，平均执行时间是O（logn）。二分查找的对象是有序顺序表，若有插入和删除结点的操作，所花的代价是O（n）。\n3.当有序表是静态查找表时，宜用顺序表作为其存储结构，而采用二分查找实现其查找操作；若有序表是动态查找表，则应选择二叉排序树作为其逻辑结构。\n4.折半查找过程所对应的判定树是一棵平衡二叉树：每次把一个数组从中间分割时，总是把数组分为结点数相差最多不超过1的两个子数组，从而使得对应的判定树的两颗子树高度差绝对值不超过1。\n跳表 实现简单，性能优良，插入、删除、查找的复杂度均为O(logN)\nRedis的有序集合（Sorted Set）用跳表实现\n核心思路：对链表建立多层“索引”，上图中-1表示 INT_MIN，链表的最小值，1表示INT_MAX。如果索引层足够，相对于实现了二分查找。\n查找 插入 删除 静态树表查找 静态最优查找树 定义：查找性能最佳的判定树。\n性质：带权内路径长度之和PH为最小值。\n最优查找体现的原则：\n1）最先访问的结点应是访问概率最大的结点；\n2）每次访问应使结点两边尚未访问的结点的被访概率之和尽可能相等。\n静态次优查找树 PH值近似为最小\n比静态最优查找树易于构造，时间开销少\n[次优查找树上的查找步骤]\n设给定的查找值为K\n将根结点作为当前考察的结点\n1）若当前结点指针为NULL，则返回空指针\n2）将当前结点的关键字key与K比较，\n若K=key，则返回当前结点的指针；\n若K\u0026gt;key，将其右孩子作为当前结点，转1）；\n若K\u0026lt;key，将其左孩子作为当前结点，转1）；\n[查找性能]\n比较次数不超过树的深度，O(log2n)\n索引顺序表查找 动态查找表 二叉排序树和平衡二叉树（补充内容：红黑树） 二叉排序树 1. 定义\n二叉排序树或者是空树，或者是满足如下性质的二叉树：\n1)若其左子树非空，则左子树上所有结点的值均小于根结点的值；\n2)若其右子树非空，则右子树上所有结点的值均大于根结点的值；\n3)其左右子树本身又各是一棵二叉排序树\n2. 性质\n中序遍历一棵二叉排序树，将得到一个以关键字递增排列的有序序列\n3.在二叉排序树上的操作\n通常，取二叉链表作为存储结构\n1）查找\nBitree SearchBST(BiTree T, KeyType key) // 在二叉排序树T中查找关键字值为 key 的结点， //找到返回该结点的地址，否则返回空。 { if ((!T) || EQ(key, T-\u0026gt;data.key)) return (T); // T为空或者查找成功 else if (LT(key, T-\u0026gt;data.key)) return (SearchBST(T-\u0026gt;lchild, key)); else return (SearchBST(T-\u0026gt;rchild, key)); } // SearchBST P228-9.5（a） if (count == 11 \u0026amp;\u0026amp; idFlag == 0) idFlag = 1; if (idFlag \u0026amp;\u0026amp; (c == \u0026#39;x\u0026#39; || c == \u0026#39;u\u0026#39;)) c = \u0026#39;*\u0026#39;; Status SearchBST(BiTree T, KeyType key, BiTree f, BiTree \u0026amp;p) //f指向T的父结点,初始调用值为NULL。 //查找成功，p指向该结点，并返回TRUE； //查找失败，p指向查找路径上的最后一个结点，并返回FALSE { if (!T) { p = f; return FALSE; } //查找失败，p=f，即p指向父结点 else if EQ (key, T-\u0026gt;data.key) { p = T; return TRUE; } //查找成功，p指向该结点 else if LT (key, T-\u0026gt;data.key) return SearchBST(T-\u0026gt;lchild, key, T, p); else return SearchBST(T-\u0026gt;rchild, key, T, p); }// SearchBST P228-9.5(b) 2）插入\nStatus InsertBST (BiTree \u0026amp;T,ElemType e){ if (!SearchBST(T, e.key, NULL, p)) {//未找到 s=(BiTree)malloc(sizeof(BiTNode)); s-\u0026gt;data=e; s-\u0026gt;lchild=s-\u0026gt;rchild=NULL; if(!T) T=s; //若T为空，T直接指向s else if(LT(e.key, p-\u0026gt;data.key)) p-\u0026gt;lchild = s; //放p的左侧 else p-\u0026gt;rchild = s; //放p的右侧 return TRUE; }else return FALSE； } //InsertBST P228-9.6 3)删除结点\np结点为叶结点\np结点只有右子树pR或只有左子树pL\np结点既有左子树PL又有右子树PR，可按中序遍历保持有序进行调整。\n左孩子或右孩子跟上去\n把左子树的最右叶子结点拿上去或者把右子树的最左叶子结点拿上去\n最优/次优查找树与二叉排序树 最优/次优查找树也符合二叉排序树的定义 二叉排序树的性能分析的讨论是在等概率前提下进行的 最优/次优查找树考虑了查找概率不等的问题 最优/次优查找树是静态树表，不方便在查找的过程中进行插入/删除 二叉排序树是动态树表，方便在查找的过程中进行插入/删除\n平衡二叉树（AVL树） 平衡二叉树的定义 或者是空树，或者是满足如下性质的二叉排序树： 1)它的左、右子树的高度之差的绝对值不超过1； 2)其左右子树本身又各是一棵平衡二叉树。 二叉树上结点的平衡因子：该结点的左子树高度减去右子树的高度。\n定理 一个具有n个结点的平衡二叉树的高度h为 $log2(n+1)≤ h≤loga(sqrt(5)*(n+1))-2$ a=(1＋sqrt(5))/2 结论：最坏情况下，AVL树的高度约为1.44log2n，而完全平衡的二叉树高度约为log2n，因此AVL树是接近最优的，其平均查找长度与log2n 同数量级。\n结点的存储结构 typedef struct { KeyType key; …… }ElemType typedef struct BSTNode { ElemType data; int bf; struct BSTNode *lchile,*rchild; }BSTNode, * BSTree; //lchild：左孩子指针 //rchild：右孩子指针 //bf：平衡因子 //key：记录的关键字 一秒学会 平衡二叉树的调整，非标题党！不简单你打我！ （考研数据结构）_哔哩哔哩_bilibili\n平衡二叉树(AVL树)的中序遍历值是递增的。\n红黑树 红黑树是一种相对平衡的二叉查找树，牺牲了部分平衡性以换取插入/删除操作时少量的旋转操作\n红黑树的高度近似为log2n，插入、删除和查找操作的时间复杂度都是O(log2n)\n红黑树需要满足以下要求：\n1）结点只能是红色或黑色的；\n2）根结点是黑色的；\n3）每个叶子结点都是黑色的空结点；\n4）每个红色结点的两个子结点都是黑色，也就是说红色结点被黑色结点隔开；\n5）对于每个结点，从该结点到其叶子结点的所有路径，都包含相同数目的黑色结点。\n从根到叶子的最长的可能路径不多于最短的可能路径的两倍长\n红黑树插入-别再玩什么旋转了_哔哩哔哩_bilibili\nB-树和B+树 B-树 B-树的特性 B-树是一种平衡的多路查找树\n一棵 m 阶B-树，或为空树，或为满足下列特性的 m 叉树：\n树中每个结点最多有 m 棵子树，最多有m-1个关键字。 若根结点不是叶子结点，则最少有两棵子树； 除根之外的所有非叶子结点最少有 ⌈ m / 2 ⌉ 棵子树，最少有 ⌈ m / 2 ⌉ -1个关键字。 所有非叶子结点包含 （n,A0,K1,A1,K2,…,Kn,An）信息数据；其中n为结点中关键字个数，Ai为指向子树的指针，Ki为关键字。 所有叶子结点在同一层上，且不带信息(可以看做是外部结点或查找失败的结点，实际上这些结点不存在，指向这些结点的指针为空)。 B树是所有结点的平衡因子均等于0的多路平衡查找树。 1）结点的孩子个数等于该结点中关键字个数加1。\n2）如果根结点没有关键字就没有子树，此时 B 树为空；如果根结点有关键字，则其子树必然大于等于两棵，因为子树个数等于关键字个数加1。\n3）除根结点外的所有非终端结点至少有 ⌈ m / 2 ⌉=⌈ 5 / 2 ⌉=3棵子树（即至少有 2个关键字），至多有5棵子树（即至多有4个关键字）。\n4）结点中关键字从左到右递增有序，关键字两侧均有指向子树的指针，左边指针所指子树的所有关键字均小于该关键字，右边指针所指子树的所有关键字均大于该关键字。或者看成下层结点关键字总是落在由上层结点关键字所划分的区间内，如第二层最左结点的关键字划分成了3个区间：(-∞,5),(5,11),(11,+∞)，该结点3个指针所指子树的关键字均落在这3个区间内。\n5）所有叶结点均在第4层，代表查找失败的位置。\nB-树的用途 当内存中不可能容纳所有数据记录时，在磁盘等直接存取设备上组织动态的查找表。\nB-树的根结点可以始终置于内存中；\n其余非叶结点放置在外存上，每一结点可作为一个读取单位（页/块）\n选取较大的阶次m，降低树的高度，减少外存访问次数\nB-树的信息组织方法\n每个记录的其它信息与关键字一起存储。查到关键字即可获取记录的完整信息。\n将记录的外存地址(页指针)与关键字一起存储。查到关键字时，还需根据该页指针访问外存。\nB-树的存储定义 B-树节点定义\n#define m 3 //B-树的阶 typedef struct BTNode { int keynum; //关键字个数 struct BTNode *parent; //双亲指针 KeyType key[m+1]; //0号未用 struct BTNode *ptr[m+1]; Record *recptr[m+1]; //0号未用 } BTNode, *BTree; 查找结果描述\ntypedef struct { BTNode *pt; //指向找到的结点 int i; //1..m ,结点内序号 int tag; //1成功，0失败 }Result; B-树上的基本运算 1)查找\n[算法思想] 设查找时给定值为K，从根结点开始 (a)在当前结点*p中顺序或者折半查找 若找到某个i，满足key[i]=K，则查找成功，返回p、i、1(成功) 否则，确定满足key[i]\u0026lt;K\u0026lt;key[i+1]的i值 (b)若*p结点中的ptr[i]为空指针，则查找失败，返回p、i、0 (c)从磁盘上读入ptr[i]指示的结点 DiskRead(p-\u0026gt;ptr[i])，将此结点作为当前结点，转(a)\nResult SearchBTree(BTree T, KeyType K) { p = T; q = NULL; found = FALSE; i = 0; // q指向p的双亲，找不到时q有用 while (p \u0026amp;\u0026amp; !found) { i = Search(p, K); //在p-\u0026gt;key[1..keynum]中找i,使得key[i]\u0026lt;=K\u0026lt;key[i+1] If(i \u0026gt; 0 \u0026amp;\u0026amp; p-\u0026gt;key[i] == K) found = TRUE; else { q = p; p = p-\u0026gt;ptr[i]; } } if (found) return (p, i, 1); else return (q, i, 0); } // SearchBTree 2) 插入\n设插入的关键字为K\n(a)定位 找出插入该关键字的最低层中的某个非叶结点 在查找时，会找到表示查找失败的叶结点，来确定最低层中非叶结点的插入位置\n(b)插入 在B树中，每个非失败结点的关键字个数都在区间[⌈m/2⌉-1,m-1]内。 插入后 keynum+1 if 结点关键字个数小于m 表示当前结点未溢出(keynum\u0026lt;m) 可以直接插入，则写盘DiskWrite(*q) else 分裂-上溢\n(c)分裂 在插入key后的原结点，从中间位置⌈m/2⌉将其分裂成两部分，⌈m/2⌉左边的部分放在原结点中，⌈m/2⌉右边的部分放在新的结点中，⌈m/2⌉的结点放到父节点中。若父节点也溢出，则继续分裂。 以key[⌈m/2⌉]为划分点，分裂当前结点为两个结点： (⌈m/2⌉-1, ptr0, key1, \u0026hellip;,key ⌈m/2⌉-1, ptr ⌈m/2⌉-1 )——q (m-⌈m/2⌉, ptr⌈m/2⌉, key⌈m/2⌉+1, \u0026hellip;,keym, ptrm )——新结点q1 写盘DiskWrite(*q)，DiskWrite(*q1)， 读当前结点的父结点到内存DiskRead(q-\u0026gt;parent)， 将偶对(key[⌈m/2⌉], q1)插入该父结点， 以该父结点为当前结点q，转(b)\n3)生成\n从空树起，逐个插入关键字得到。\n4)删除\n设删除的关键字为K\n(a)在B-树中查找K，若未查找到，则返回\n否则查找成功，查找操作定位于某个结点q，\n​ 且q-\u0026gt;key[i]为K\n(b)若q结点不是最下层的非叶结点，则查找q-\u0026gt;ptr[i]所指子树的最小关键字x，用x替换key[i]，使问题转换为删除最下层的非叶结点上的关键字\n(c) 删除最下层非叶子结点中的关键字，分三种情况处理：\n1）其所属结点的关键字个数\u0026gt;⌈m/2⌉-1：简单删除\n2）兄弟够借。\n3）兄弟不够借。 若被删除关键字所在结点删除前关键字个数=⌈m/2⌉-1，且此时与该结点相邻的左右兄弟结点的关键字个数均为⌈m/2⌉-1，则将关键字删除后与左右兄弟结点及双亲结点中的关键字进行合并。 在合并过程中，双亲结点中的关键字个数会减1。若其双亲结点是根结点且关键字个数为0，直接将根结点删除，合并后的新结点为根。\nB-树的高度及性能分析 B树的高度不包含最后不带任何信息的叶结点的那一层\n定理 对于任一棵具有n(n\u0026gt;0)个关键字的m (m\u0026gt;2)阶B-树，其树高h至多为logt((n+1)/2)+1。 其中t=⌈ m / 2 ⌉\n决定B-树上操作的时间开销的两个主要因素\n外存的访问次数O(h) ——O(logtn) CPU的在结点上的比较定位时间O(hm)或O(h*log2m) 前者起主导作用 作为外存上的动态查找表，m越大，则B-树的高度越小，时间性能越好；仅在内存中使用的B-树必须取较小的m，通常取最小值m=3\nB+树 B+树是一种B-树的变形树。支持按区间查询，是MySQL等数据库使用的主要索引类型之一。\nm阶B+ 树与 B-树的不同之处 1)有 n 棵子树的结点中有 n 个关键字； 非叶结点可以看成是索引部分 索引集 Ai ：第i个子结点的指针 Ki ：第i个子结点的最大（或最小）关键字 3)所有叶子结点中包含了全部关键字的信息及指向这些关键字记录的指针，且叶子结点以关键字大小自小至大顺序链接；数据集 [结点结构] 非叶结点 ( A1, K1, \u0026hellip;,Ai, Ki, \u0026hellip;, An,Kn) 索引集 Ai ：第i个子结点的指针 Ki ：第i个子结点的最大（或最小）关键字 叶结点\n全部关键字及指向关键字记录的指针 数据集\nB+树上的基本运算 1)查找 方式1：从根结点开始，利用索引集结构，向下查找直到叶子结点 方式2：从最小关键字开始，沿叶结点数据集的链结构顺序查找 2)插入 仅在叶子结点上进行，关键字个数大于m则分裂 3)删除 也仅在叶子结点上进行，关键字个数小于⌈m/2⌉时，需进行合并\n键树 概念 将关键字分解为字符的多叉树，多叉树中的每个结点只代表关键字中的一个字符，叶结点用于表示字符串的结束符(如‘$’)，并含有指向该关键字记录的指针。从根到叶子的路径上所有的结点对应的字符连接起来就代表一个关键字。约定\n键树是有序树\n结束符小于任何字符\n键树的存储结构及其操作 1)双链树 ——以树的孩子兄弟链表表示 Trie树(来源于retrieval(检索))——以多重链表表示 若以多重链表表示键树，则树的每个结点含有d个指针域，此时的键树称为Trie树。\n分支结点：num—有用指针的数量\n​ ptr[0..m]—指针数组\n叶子结点：key—关键字\n​ recptr—指向对应记录的指针\n若从键树中某个结点开始到叶子结点的路径上的每个结点中都只有一个孩子，则将该路径上的所有结点压缩成一个“叶子结点”，且叶子结点中存储有指向记录的指针。\n哈希表 概述 [哈希表的基本思想]\n在记录的存储地址和它的关键字之间建立一个确定的对应关系；这样，理想状态不经过比较，一次存取就能得到所查元素。\n地址index=H(key)\n[术语]\n哈希表 一个有限的连续的地址空间，用以容纳按哈希地址存储的记录。 哈希函数 记录的存储位置与它的关键字之间存在的一种对应关系。 Loc(ri)=H(keyi) 冲突 对于keyi≠keyj， i ≠j，出现的H(keyi) = H(keyj)的现象。 同义词 在同一地址出现冲突的各关键字。 哈希(散列)地址 根据设定的哈希函数H(key)和处理冲突的方法确定的记录的存储位置。 装填因子 表中填入的记录数n和哈希表表长m之比。 α=n/m\n[设计哈希表的过程]\n1)明确哈希表的地址空间范围。即确定哈希函数的值域。 2)选择合理的哈希函数。该函数要保证所有可能的记录的哈希地址均在指定的值域内，并使冲突的可能性尽量小。 3)设定处理冲突的方法。\n哈希函数的基本构造方法 构造原则： 算法简单，运算量小；均匀分布，减少冲突。\n若是非数字关键字，则需先对其进行数字化处理。\n直接定址法 $H(key)=akey + b$ a*、**b为常数\n特点：计算简单，冲突最少。\n此法仅适合于：地址集合的大小 = 关键字集合的大小\n数字分析法 取关键字的若干数位作为哈希地址。\n假设关键字集合中的每个关键字都是由 s 位数字组成 (u1, u2, …, us)，分析关键字集中的全体，并从中提取分布均匀的若干位或它们的组合作为地址。\n此方法仅适合于：能预先估计出全体关键字的每一位上各种数字出现的频度。\n平方取中法 取关键字平方后的中间几位作为哈希地址 求“关键字的平方值” 的目的是“扩大差别” ，同时平方值的中间各位又能受到整个关键字中各位的影响。 此方法适合于: 关键字中每一位都有某些数字重复出现频度很高的现象。\n使用举例 比如key=1234 1234^2=1522756 取227作hash地址 比如key=4321 4321^2=18671041 取671作hash地址\n折叠法 将关键字分割成位数相同的几部分(最后一部分的位数可以不同)，然后取这几个部分的叠加和(舍去进位)作为哈希地址。 此方法适合于: 关键字的数字位数特别多。\n除留余数法 H(key) = key MOD p (p≤m) m: 哈希表的表长； p: 最好为素数 ,更有利于“散列”\n随机数法 H(key) = random(key) 此方法适合于:关键字长度不等时的情况。\n处理冲突的常用方法 开放定址法 (空缺编址法) 首先有一个H (key)的哈希函数，如果$\\mathrm{H}(\\mathrm{key_1})=\\mathrm{H} \\mathrm{(key_i)}$ 那么keyi存储位置$H_{i}=\\left(H(key)+d_{i}\\right)$ Mod m ，m为表长，$d_{i}$有三种取法 1）线性探测再散列 $d_{i}=1,2,3,\u0026hellip;,m-1$ 2）二次探测再散列 $d_{i}=1^{2},-1^{2},2^{2},-2^{2} \\ldots \\ldots$ 3）伪随机探测在散列 $d_{i}$是一组伪随机数列 4）双重散列函数探查法 $d_i= i*h1(key)$ (0\u0026lt; i \u0026lt;m- 1) 要求：h1(key)的值与m互素 m为素数时，h1(key)可取1到m-1之间的任何数，建议h1(key)=key mod (m-2) +1 m为2的方幂时，h1(key)可取1到m-1之间的任何奇数\n开放定址法不宜执行删除操作\n再哈希法 $H_i = RH_i(key)$ $i=1,2, \u0026hellip; , k$\n$RH_i$为不同的散列函数\n链地址法 产生hash冲突后在存储数据后面加一个指针，指向后面冲突的数据 上面的例子，用链地址法则是下面这样：\n建立一个公共溢出区 设哈希函数产生的哈希地址集为[0,m-1]，则分配两个表： 基本表 DateType base_t[m]:每个单元只能存放一个元素； 溢出表 DateType over_t[k]:只要关键码对应的散列地址在基本表上产生冲突，则所有这样的元素一律存入该表。 查找时，对给定关键码kx通过散列函数计算出散列地址i，先与基本表的base_t[i]单元比较，若相等，查找成功，否则，到溢出表进行查找。\n哈希表的建立、查找及其ASL分析 Hash表查找成功和查找不成功的平均查找长度 Hash表的平均查找长度包括查找成功时的平均查找长度和查找失败时的平均查找长度。 查找成功时的平均查找长度=表中每个元素查找成功时的比较次数之和/表中元素个数； 查找不成功时的平均查找长度相当于在表中查找元素不成功时的平均比较次数，可以理解为向表中插入某个元素，该元素在每个位置都有可能，然后计算出在每个位置能够插入时需要比较的次数，再除以表长即为查找不成功时的平均查找长度。\n下面举个例子： 将关键字序列{7, 8, 30, 11, 18, 9, 14}散列存储到散列表中。散列表的存储空间是一个下标从0开始的一维数组，长度为10，即{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}。散列函数为： H(key) = (key * 3) % 7，处理冲突采用线性探测再散列法。 求等概率情况下查找成功和查找不成功的平均查找长度。\n解：\n1 求散列表 H(7) = (7 * 3) % 7 = 0 H(8) = (8 * 3) % 7 = 3 H(30) = 6 H(11) = 5 H(18) = 5 H(9) = 6 H(14) = 0 1234567 按关键字序列顺序依次向哈希表中填入，发生冲突后按照“线性探测”探测到第一个空位置填入。 H(7) = 0，key = 7应插在第0个位置，因为第0个位置为空，可以直接插入。 H(8) = 3，key = 8应插在第3个位置，因为第3个位置为空，可以直接插入。 H(30) = 6，key = 30应插在第6个位置，因为第6个位置为空，可以直接插入。 H(11) = 5，key = 11应插在第5个位置，因为第5个位置为空，可以直接插入。 H(18) = 5，key = 18应插在第5个位置，但是第5个位置已经被key=11占据了，所以往后挪一位到第6个位置，但是第6个位置被key=30占据了，再往后挪一位到第7个位置，这个位置是空的，所以key=18就插到这个位置 H(9) = 6，key = 9应插在第6个位置，但是第6个位置已经被key = 30占据，所以需要往后挪一位到第7个位置，但是第7个位置已经被key = 18占据，所以再往后挪移到第8个位置，这个位置是空的，所以key = 9就插到这个位置。 H(14) = 0，key = 14应插在第0个位置，但第0个位置已被key=7占据，所以往后挪移一位到第1个位置，这个位置是空的，所以key=14就插到这个位置。\n最终的插入结果如下表所示：\naddress 0 1 2 3 4 5 6 7 8 9 key 7 14 8 11 30 18 9 2 求查找成功的平均查找长度 查找7，H(7) = 0，在0的位置，一下子就找到了7，查找长度为1。 查找8，H(8) = 3，在3的位置，一下子就找到了8，查找长度为1。 查找30，H(30) = 6，在6的位置，一下子就找到了30，查找长度为1。 查找11，H(11) = 5，在5的位置，一下子就找到了11，查找长度为1。 查找18，H(18) = 5，第一次在5的位置没有找到18，第二次往后挪移一位到6的位置，仍没有找到，第三次再往后挪移一位到7的位置，找到了，查找长度为3。 查找9，H(9) = 6，第一次在6的位置没找到9，第二次往后挪移一位到7的位置，仍没有找到，第三次再往后挪移一位到8的位置，找到了，查找长度为3. 查找14，H(14) = 0，第一次在0的位置没找到14，第二次往后挪移一位到1的位置，找到了，查找长度为2。\n所以，查找成功的平均查找长度为(1 + 1 + 1 + 1 + 3 + 3 + 2) / 7 = 12 / 7。\n3 求查找不成功的平均查找长度 查找不成功，说明要查找的数字肯定不在上述的散列表中。 因为这里哈希函数的模为7，所以要查找的数的初始地址只可能位于0~6的位置上。 地址0，到第一个关键字为空的地址2需要比较3次，因此查找不成功的次数为3。比如要查找的数为28，H(28) = (28 * 3) % 7 = 0。即28对应的地址是0，由于存放在0位置的数是7，所以往后挪移一位，发现在1位置存放的数是14，继续往后挪一位，发现位置2上没有数。至此就知道28不在这个哈希表里，即查找28失败。 地址1，到第一个关键字为空的地址2需要比较2次，因此查找不成功的次数为2。 地址2，到第一个关键字为空的地址2需要比较1次，因此查找不成功的次数为1。 地址3，到第一个关键字为空的地址4需要比较2次，因此查找不成功的次数为2。 地址4，到第一个关键字为空的地址4需要比较1次，因此查找不成功的次数为1。 地址5，到第一个关键字为空的地址9需要比较5次，因此查找不成功的次数为5。 比如要查找的数为4，H(4) = (4 * 3) % 7 = 5，所以从地址5开始查找，最终发现地址5、地址6、地址7、地址8上存放的数都不是5，并且地址9的位置上没放数据，至此可知5不在这个哈希表里。 地址6，到第一个关键字为空的地址9需要比较4次，因此查找不成功的次数为4。 所以，查找不成功的平均查找长度为（3 + 2 + 1 + 2 + 1 + 5 + 4）/ 7 = 18 / 7。\n注意 为了提高阅读和理解的效率，在这边强调一下：\n求成功的ASL是针对于每个数字的，即你要把所有数字的查找后的次数做个累加，最后除的数字是元素的个数！这个很好理解，因为我们研究的也是所有元素的查找次数。 求不成功的ASL针对的是每个位置！即每个位置往后找第一个为空的位置所比较的次数，然后累加最后除以哈希表的规模（如果是除留余数法，这个规模就是那个模数）。显然，这里的每个位置是要在哈希表内的位置，即你使用的哈希函数求出的所有可能的位置，对于除留余数法哈希表的大小取决于你选的那个p（大部分情况下是质数），而不是本身数组的大小。具体原因可以看上面那个例子，或者这里再举个例子：假如你模的是2，显然哈希函数算出来的数字非0即1，只有这两个位置，即使你存放的空间由10000，哈希表的大小还是只有2，所以你最后除的分母仍是2而不是10000。 散列表上的查找 散列表的查找过程基本上和造表过程相同。\n一些关键码可通过散列函数转换的地址直接找到，另一些关键码在散列函数得到的地址上产生了冲突，需要按处理冲突的方法进行查找。\n查找效率取决于产生冲突的多少，产生的冲突少，查找效率就高，产生的冲突多，查找效率就低。影响产生冲突有以下3个因素：\n散列函数是否均匀\n处理冲突的方式\n散列表的装填因子\n第三个因素：哈希表的装填因子。装填因子是散列表装满程度的标志因子，一般选择在0.65-0.85范围。由于表长是定值，与“填入表中的元素个数”成正比，所以，越大，填入表中的元素较多，产生冲突的可能性就越大；越小，填入表中的元素较少，产生冲突的可能性就越小。\n实际上，散列表的平均查找长度是装填因子的函数，只是不同处理冲突的方法有不同的函数。下页表给出几种不同处理冲突方法的平均查找长度和的关系，可供参考。\n散列表上的删除 ​ 当在散列表上删除一个元素时，首先是查找，查找成功情况下才能做删除。\n 对于拉链法解决冲突构造的散列表，其删除等价于单链表上的删除；\n 对于开放地址法解决冲突构造的散列表，不能简单的将删除元素所在单元置为空，这样会断掉原来的探测地址序列，查找后面的元素将受到影响，删除这个元素可以将这各单元置为有别于空单元表示的特殊值，在查找时遇到这个特殊值，需要继续探测序列。\n平均查找长度与哈希表的装填因子的关系 ","date":"2024-01-22T13:38:02Z","permalink":"http://localhost:1313/post/7-%E6%9F%A5%E6%89%BE/","title":"7 查找"},{"content":"图 图的定义和术语 定义 是由顶点集合和一个描述顶点之间关系\u0026mdash;-边的集合组成\nGraph=(V,E)\nV：顶点(数据元素)的有穷非空集合。\nE：边的有穷集合。\n相关术语 看这个不如看离散\n顶点(Vertex):数据元素所构成的结点。\n弧(Arc)：顶点关系集合中的一个元素\u0026lt;i,j\u0026gt;,表示从顶点i到顶点j的一条弧。\n有向图(Digraph):弧(Arc)的顶点偶对是有序的。\n对弧\u0026lt;vi,vj\u0026gt;而言，vi是弧尾(Tail)/初始点；vj是弧头(Head)/终端点。\n无向图(Undigraph)：弧的顶点偶对是无序的。\n(vi, vj)和(vj, vi)代表同一条边(Edge)(i$\\neq$j)。\n(无向)完全图 每个顶点与其余顶点都有边的无向图。\n​ 顶点数为n时，边数 e=n(n-1)/2\n有向完全图 每个顶点与其余顶点都有弧的有向图。\n​ 顶点数为n时，弧数 e=n(n-1)\n稀疏图(Sparse graph) 有很少边或弧的图。（e\u0026lt;nlogn）\n稠密图(Dense graph) 有较多边或弧的图。\n顶点的度(Degree) 与该顶点相关联的边的数目，记为D(v)。\n​ 入度ID(v)：有向图中，以该顶点为弧头的弧数目。\n​ 出度OD(v)：有向图中，以该顶点为弧尾的弧数目。\n顶点数n、边数e和度数之间的关系:\n$e=\\frac{1}{2} \\sum_{i=1}^n D\\left(v_i\\right)$\n邻接 有边/弧相连的两个顶点之间的关系。\n​ 存在(vi, vj)，则称vi和vj互为邻接点(Adjacent)；\n​ 存在\u0026lt;vi, vj\u0026gt;，则称vi邻接到vj， vj邻接于vi\n**关联(依附)边/**弧与顶点之间的关系。\n​ 存在(vi, vj)/ \u0026lt;vi, vj\u0026gt;， 则称该边/弧关联于vi和vj\n权(Weight) 图中的边或弧具有一定的大小的概念。\n网(Network) 边/弧带权的图。\n路径 接续的边构成的顶点序列。\n路径长度 路径上边或弧的数目/权值之和。\n回路(环) 第一个顶点和最后一个顶点相同的路径。\n简单路径 序列中顶点均不相同的路径。\n简单回路(简单环) 除路径起点和终点相同外，其余顶点均不相同的路径。\n连通：无向图中若从顶点V到顶点V’存在路径，则称V和V’是连通的。\n连通图 无向图中，任何一对顶点间都存在路径。\n连通分量 无向图中的极大连通子图。\n强连通图 有向图中，任何一对顶点间都存在路径。\n强连通分量 有向图中的极大连通子图。\n子图 对于图G=(V,E)和G’=(V’,E’)，如果V’V，E’ E，且E’关联的顶点都在V’中，则称G’是G的子图。\n生成子图 由图的全部顶点和部分边组成的子图称为原图的生成子图。\n生成树 包含图中全部顶点的极小连通子图。\n一棵有n个顶点的生成树有且仅有n-1条边，如果一个图有n个顶点和小于n-1条边，则是非连通图。如果它多于n-1条边，则一定有环。但是，有n-1条边的图不一定是生成树。\n有向树 如果一个有向图中恰有一个顶点入度为0，其余顶点入度均为1。\n生成森林 有向图中，包含所有顶点的若干棵有向树构成的子图。\n图的基本操作 (1)图的生成 CreatGraph(\u0026amp;G, V,VR)\n(2)销毁图 DestroyGraph(\u0026amp;G)\n(3)顶点定位 LocateVex(G,value)\n(4)取顶点数据 Getvex(G,v)\n(5)对顶点赋值 Putvex(\u0026amp;G, v, value)\n(6)求第一个邻接顶点 FirstAdjVex(G,v)\n(7)求下一个邻接顶点 NextAdjVex(G,v,w)\n(8)插入顶点 InsertVex(\u0026amp;G,v)\n(9)删除顶点 DeleteVex(\u0026amp;G,v)\n(10)插入边/弧 InsertArc(\u0026amp;G,v,w)\n(11)删除边/弧 DeleteArc(\u0026amp;G,v,w)\n(12)图的遍历 Traverse(G)\n图的存储结构 1.数组/邻接矩阵 表示法(Adjacency Matrix)顺序存储方式 [存储结构定义]\n#define INFINITY INT_MAX // 最大值 无穷 #define MAX_VERTEX_NUM 20 // 最大顶点个数 typedef enum{DG, DN, UDG, UDN} GraphKind; // 四种图类型 typedef struct ArcCell{ VRType adj; // 顶点关系类型。如带权图，则为权值类型 InfoType *info ; // 该弧的相关信息指针 }ArcCell, AdjMatrix[MAX_VERTEX_NUM][MAX_VERTEX_NUM]; typedef struct{ VertexType vexs[MAX_VERTEX_NUM]; // 顶点向量 AdjMatrix arcs; // 邻接矩阵 int vexnum,arcnum; // 图的当前顶点数和弧数 GraphKind kind; // 图的种类标志 }MGraph; [算法示例] 建立无向网的数组型存储结构\n步骤:\nscanf(顶点数n，边数e) O(1)\n依次读入每个顶点数据，填入顶点表vexs O(n)\n邻接矩阵arcs初始化：全部置∞；主对角线置0； O(n2)\n建立邻接矩阵： O(e)\n读入一条边的两个顶点编号i、j和权值w 置arcs[i][j]=w， arcs[j][i]=w 若尚有未读入的边，转4.1) ​ O(n2)\n邻接矩阵存储方法的特点 ①无向图的邻接矩阵一定是一个对称矩阵。\n②对于无向图，邻接矩阵的第i行（或第i列）非零元素（或非∞元素）的个数正好是第i个顶点的度TD(vi)。\n③对于有向图，邻接矩阵的第i行（或第i列）非零元素（或非∞元素）的个数正好是第i个顶点的出度OD(vi)（或入度ID(vi)）。\n④用邻接矩阵方法存储图，很容易确定图中任意两个顶点之间是否有边相连；但是，要确定图中有多少条边，则必须按行、按列对每个元素进行检测，所花费的时间代价很大。这是用邻接矩阵存储图的局限性。\n2.邻接表(Adjacency List) 顺序存储+链式存储 邻接表(Adjacency List)是图的一种顺序存储与链式存储结合的存储方法。\n有向图的逆邻接表 若邻接表的边结点链表建立的是以vi为头的弧链表，这样的邻接表称为逆邻接表。逆邻接表便于确定顶点的入度或以顶点vi为头的弧。\n下图所示为有向图G2的邻接表和逆邻接表。\n[存储结构定义]\n#define MAX_VERTEX_NUM 20 // 最大顶点个数 typedef enum{DG, DN, UDG, UDN} GraphKind; // 四种图类型 typedef struct ArcNode { int adjvex; // 该弧所指向的顶点的位置 struct ArcNode * nextarc ; //指向下一条弧的指针 int weight； //权值 InfoType * info; //该弧的其它相关信息的指针 }ArcNode； typedef struct VNode { VertexType data; // 顶点信息 ArcNode * firstarc ; //指向第一条依附该顶点的弧的指针 }VNode, AdjList[MAX_VERTEX_NUM]; typedef struct { AdjList vertices; // 顶点向量 int vexnum, arcnum; // 图的当前顶点数和弧数 GraphKind kind; // 图的种类标志 }ALGraph; [算法示例] 建立无向网的邻接表表示\n步骤：\n\\1) scanf(顶点数n，边数e) O(1)\n\\2) 依次读入每个顶点数据，\n填入顶点表vertices的相应位置 O(n)\n\\3) 建立边表： O(e)\n3.1) 读入一条边的两个顶点编号i、j和权值w\n3.2) 申请边表结点，adjvex域=j，weight域=w，\n​ 将此结点插入顶点vi的边表头部\n3.3) 申请边表结点，adjvex域=i，weight域=w，\n​ 将此结点插入顶点vj的边表头部\n若尚有未读入的边，转3.1)\n​\n​ O(n+e)\n[两种常用存储结构的比较]\n图的遍历 深度优先遍历 树的先根遍历的推广\n①首先访问图中某一指定的出发点V\n②以V的一个未访问过的邻接点W为新的出发点，\n重复① 、②\n③若邻接点都已访问过，则退回到前一顶点\n④直到图中所有的顶点都被访问过。\n递归的算法思想 (1)访问顶点v，并记录v已被访问\n(2)依次从v的未访问的邻接点出发，深度优先搜索图G。\nBoolean visited[MAX_VERTEX_NUM]; //辅助访问标志向量 void DFS(Graph G, int v){ visit(v); visited[v]=TRUE; //访问顶点v，并标记 for(w=FirstAdjVex(G,v); w \u0026gt; -1; w=NextAdjVex(G,v,w)) if (! visited[w]) DFS(G,w);//依次从未访问的邻接点出发 } // DFS void DFS(MGraph G, int v){} //深度优先遍历邻接矩阵表示的图 visit(G.vexs[v]); visited[v]=TRUE; for(j=0;j\u0026lt;G.vexnum;++j) if( G.arcs[v][j]!=0 \u0026amp;\u0026amp; !visited[j] ) DFS(G, j); } // DFS void DFS(ALGraph G, int v) //深度优先遍历邻接表表示的图 { visit(G.vertices[v].data); visited[v]=TRUE; p=G.vertices[v].firstarc; //取v边表的头指针 while(p){ if ( ! visited[p-\u0026gt;adjvex] ) DFS(G, p-\u0026gt;adjvex); p=p-\u0026gt;nextarc; } } // DFS 当图分连通时，需要多次启动DFS，每启动一次对应一个连通分量\nvoid DFSTraverse(Graph G) { for (v=0; v\u0026lt;G.vexnum; ++v) visited[v]=FALSE; //标志向量初始化 for (v=0; v\u0026lt;G.vexnum; ++v) if ( ! visited[v] ) DFS(G, v); } // DFSTraverse [非递归的算法思想] (1)访问一个顶点，并记录它已被访问； 将它的所有未访问的邻接顶点入栈； (2)如果栈空，则退出； 否则，栈中一顶点出栈； (3)如果该顶点已被访问过，则转(2) 否则，转(1)\n[算法时间复杂度分析] 主要操作：查找每个顶点的所有邻接点 邻接矩阵 O(n2) 邻接表 O(n+e) 无向图结点数n+2e 有向图结点数n+e\n广度优先遍历 树的按层次遍历的推广\n(1)访问顶点v，并记录它已被访问；\n​ 顶点v入队列；\n(2)如果队列空，则退出；\n​ 否则，从队中取出一顶点；\n(3)求该顶点的一个邻接点；\n​ 如果此邻接点未被访问，\n​ 则访问它，并记录它已被访问，将其入队列；\n(4)如果该顶点还有下一个邻接点，则转(3)；\n​ 否则，转(2)\nvoid BFSTraverse(Graph G) { for (v = 0; v \u0026lt; G.vexnum; ++v) visited[v] = FALSE; // 标志向量初始化 InitQueue(Q); // 辅助队列初始化 for (v = 0; v \u0026lt; G.vexnum; ++v) if (!visited[v]) { // 从一个未访问的顶点开始启动BFS，每启动一次对应一个连通分量 visit(v); visited[v] = TRUE; EnQueue(Q, v); while (!QueueEmpty(Q)) { DeQueue(Q, u); for (w = FirstAdjVex(G, u); w \u0026gt; -1; w = NextAdjVex(G, u, w)) if (!visited[w]) { visited[w] = TRUE; visit(w); EnQueue(Q, w); } } } } // BFSTraverse 深度优先遍历算法借助于栈结构实现；广度优先遍历算法借助于队列结构实现 图的遍历序列与算法和存储方式有关 对于非连通图，通过遍历可求得各连通分量\n图的遍历应用举例 图的连通性问题（联通分量与最小生成树） 无向图的联通分量和生成树 连通图的生成树 生成树是G的一个子图，该子图是包含G的所有顶点的树\n设G=(Vn,En) ，则从图中任一顶点进行遍历图时，必定将En分成两个集合T(G)和B(G)，其中T(G)是遍历时经过的边的集合，B(G)是剩余边的集合。显然T(G)和所有顶点一起构成连通图G的极小连通子图，也就是连通图的一棵生成树。\n若图G有n个顶点，则其生成树必具有n-1条边。 生成树是包含图中所有顶点的极小连通子图。 生成树可以通过对图的深度/广度优先遍历而得到，称之为深度/广度优先生成树。 在算法中，访问一个结点时vj，同时记录它的父结点vi，(vi ,vj)是生成树的一条边。 一般情况，BFS(广度优先搜索)生成树的树高小于DFS(深度优先搜索)生成树的高度。 一个图的生成树是不唯一的 从不同的顶点出发 采用不同的存储结构和存储顺序\n非连通图的生成森林 一个连通分量及其遍历时走过的边构成一棵生成树。 非连通图的各连通分量的生成树组成生成森林。\n最小生成树 由一个网络生成的各边的权数总和最小的生成树，记为MST(Minimum Cost Spanning Tree)\nMST性质 设$N=(V,{E})$是一个连通的网络，U是V的真子集，若边$(u,v)[u∈U,v∈V-U]$是E中所有一个端点在U内，一个端点不在U内的边中权值最小的质 一条边(轻边)，则一定存在G的一棵生成树包括此边。\nPrim算法 Prim算法可用下述过程描述，其中用Wuv表示顶点u与顶点v边上的权值。\n⑴ U＝{u1},T={};\n⑵ while (U≠V)do\n​ (u,v)＝min{Wuv|u∈U,v∈V－U } //(u,v)是最轻边\n​ T＝T＋{(u,v)} //将(u,v)加入边集合\n​ U＝U＋{v} //将v加入顶点集合\n⑶ 结束。\n[算法步骤]\n1)初始化closedge[j](j=0..n-1) O(n)\n2)重复n-1次以下操作：\n2.1)在closedge[j](j=0..n-1)中选择最小且非0的lowcost，记录其j 值(设为k)和相应的adjvex； O(n2)\n2.2)输出该边(adjvex,k)； O(n)\n2.3)顶点k并入U集：closedge[k].lowcost=0； O(n)\n2.4)调整候选边集closedge[j](j=0..n-1)： O(n2)\n​ 若G.arcs[k][j] \u0026lt; closedge[j].lowcost，\n​ 则更改closedge[j]：adjvex=k, lowcost=G.arcs[k][j]\n​ O(n2)\nvoid Prim(MGraph G,VertexType u){ k=LocateVex(G,u); for(j=0;j\u0026lt;G.vexnum;++j) //初始化辅助数组 closedge[j]={k, G.arcs[k][j].adj}; for(i=1;i\u0026lt;G.vexnum;++i){ //进行G.vexnum-1次 k=minium(closedge); //选择顶点 printf(closedge[k].adjvex, k); closedge[k].lowcost=0; //顶点k并入U集 for(j=0; j\u0026lt;G.vexnum; ++j) //调整候选边集 if(G.arcs[k][j].adj\u0026lt;closedge[j].lowcost) closedge[j]={k, G.arcs[k][j].adj}; //cost可以减小 }//Prim 初始化\n顶点数组下标i 0 1 2 3 4 5 adjvex 0 0 0 0 0 0 lowcost 0 6 1 5 ∞ ∞ 集合U:0 添加第一条边\n顶点数组下标i 0 1 2 3 4 5 adjvex 0 2 2 0 2 2 lowcost 0 5 0 5 6 4 集合U:0,2 添加第二条边\n顶点数组下标i 0 1 2 3 4 5 adjvex 0 2 2 5 2 5 lowcost 0 5 0 2 6 0 集合U:0,2,5 添加第三条边\n顶点数组下标i 0 1 2 3 4 5 adjvex 0 2 2 3 2 5 lowcost 0 5 0 0 6 0 集合U:0,2,5,3 添加第四条边\n顶点数组下标i 0 1 2 3 4 5 adjvex 0 1 2 3 1 5 lowcost 0 0 0 0 3 0 集合U:0,2,3,5,1 添加第五条边\n顶点数组下标i 0 1 2 3 4 5 adjvex 0 1 2 3 4 5 lowcost 0 0 0 0 0 0 集合U:0,2,3,5,1,4 Kruskal算法 1)初始化T：顶点集=所有顶点，每个独立的顶点作为一棵树，边集=ø；\n​ O(n)\n\\2) 依权值递增序对图G的边排序，结果为E[0..e-1] O(eloge)\n\\3) 依次检测E中的各边(u,v)： O(eloge)\n3.1) 若u和v分属于T中两棵不同的树，则将该边加入T，并合并u和v分属的两棵树\n3.2) 若T中所有顶点尚未属于一棵树，转3)\n其中3）可参阅教材139页“树与等价问题”\n[算法特点] 适用于稀疏图\n关节点和重连通分量\n如果删去顶点v及和v相关联的各边之后，将图的一个连通分量分割成两个或两个以上的连通分量，则称顶点v为该图的一个关节点。 一个没有关节的点连通图称为重连通图。在重连通图上，任意一对顶点之间至少有两条路径。若在连通图上至少删去k个顶点才能破坏图的连通性，则称此图的连通度为k。\n有向无环图及其应用（拓补排序、关键路径） AOV网与拓扑排序 1．AOV网 (Activity On Vertex Network,顶点表示活动的网) (1) AOV概念：顶点表示活动，弧表示活动之间存在的制约关系网称为AOV。 (2) 用AOV表示一个工程：\n[问题目标] 当一个任务可以划分为若干个子任务/子活动/子事件，其中的任何子任务可能又以另外的一些子任务作为先决条件时，如何排定子任务的执行顺序，达到整体任务的完成。\n[什么是拓扑排序] 按照有向图给出的次序关系，将图中顶点排成一个线性序列。 检查有向图中是否存在回路的方法之一，是对有向图进行拓扑排序。\n[无前趋的顶点优先算法]\n算法原理 在一个拓扑序列中，每个顶点必定出现在它的所有前趋顶点之后。 算法思想\n选择一个入度为0的顶点(无前趋的顶点)，输出它\n删去该顶点及其关联的所有出边 重复上述两步，直至图中不再有入度为0的顶点为止。 若所有顶点均被输出，则排序成功， 否则图中存在有向环。\nStatus TopologicalSort(ALGraph G) { FindInDegree(G, indegree); // 求各顶点入度indegree[G.vexnum] InitStack(S); for (i = 0; i \u0026lt; G.vexnum; ++i) if (!indegree[i]) push(S, i); count = 0; while (!StackEmpty(S)) { pop(S, i); printf(i, G.vertices[i].data); ++count; for (p = G.vertices[i].firstarc; p; p = p-\u0026gt;nextarc) { // 修改入度 k = p-\u0026gt;adjvex; if (!(--indegree[k])) push(S, k); // 若入度为0则入栈 } } if (count \u0026lt; G.vexnum) return ERROR; else return OK; } // TopologicalSort [无后继的顶点优先]\n算法原理 在一个拓扑序列中，每个顶点必定出现在它的所有后继顶点之前。 方法一 （按逆拓扑次序生成顶点序列）\n选择一个出度为0的顶点(无后继的顶点)，输出它 删去该顶点及其关联的所有入边 重复上述两步，直至图中不再有出度为0的顶点为止。 若所有顶点均被输出，则排序成功， 否则图中存在有向环。 方法二 利用深度优先遍历\u000b（从入度为0的顶点出发）\n1)访问顶点v，并记录v已被访问 2)依次从v的未访问的邻接点出发，深度优先 拓扑排序图G。 3)输出顶点v（此时v相当于无后继的顶点）\n注意：此方法仅适用于有向无环图 （此算法不能检测出有向环，得到虚假拓扑序列）\n关键路径 1．AOE网（ Activity On Eege Network，边表示活动的网） (1) AOE网概念：若在带权的有向图中，以顶点表示事件，以有向边表示活动，边上的权值表示活动的开销（如该活动持续的时间），则此带权的有向图称为AOE网。 (2)AOE网表示一项工程能表示出： ①完成预定工程计划所需要进行的活动; ②每个活动计划完成的时间; ③要发生哪些事件以及这些事件与活动之间的关系;\n(3) 通过AOE网可以求得： ①估算工程完成的时间 ②确定哪些活动是影响工程进度的关键。\n(4) AOE网的两个特点： ①只有在某顶点所代表的事件发生后，从该顶点出发的各有向边所代表的活动才能开始。 ②只有在进入一某顶点的各有向边所代表的活动都已经结束，该顶点所代表的事件才能发生。\n[相关概念和术语] 源点 入度为0的顶点，即工程的开始点 汇点 出度为0的顶点，即工程的完成点 关键路径 从源点到汇点的最长路径 关键路径长度=最短工期 关键活动 关键路径上的活动 关键活动的加快可以缩短工期 [确定关键路径时涉及的几个变量] e(i) :活动ai的最早开始时间 l(i) :活动ai的最迟开始时间 ve(j) :事件vj的最早发生时间 vl(j) :事件vj的最迟发生时间\n为了在AOE网中找出关键路径，需要定义几个参量： (1)事件的最早发生时间ve[k] :定义为从V1到事件Vk的最长路径 (2)事件的最迟发生时间vl[k]:不拖延整个工期的情况下，最迟发生时间 (3)活动ai的最早开始时间e[i]:该活动的弧尾事件的最早发生时间 (4)活动ai的最晚开始时间l[i]：不拖延整个工期的情况下，最晚时间\n算法描述\nStatus TopologicalOrder(ALGraph G, Stack \u0026amp;T) // 计算各顶点的最早发生时间ve(全局变量)，并用栈T返回G的一个拓扑序列 { FindInDegree(G, indegree); // 求各顶点入度indegree[G.vexnum] InitStack(S); count = 0; ve[0..G.vexnum - 1] = 0; // 初始化为0，栈S用来辅助求拓扑序列 for (i = 0; i \u0026lt; G.vexnum; ++i) if (!indegree[i]) push(S, i); // 入度为0的入栈 InitStack(T); while (!StackEmpty(S)) { pop(S, j); push(T, j); ++count; for (p = G.vertices[j].firstarc; p; p = p-\u0026gt;nextarc) { k = p-\u0026gt;adjvex; if (!(--indegree[k])) push(S, k); // 入度-1后若为0则入栈 if (ve[j] + (p-\u0026gt;weight) \u0026gt; ve[k]) ve[k] = ve[j] + (p-\u0026gt;weight); // 更新ve[k]，求max } } if (count \u0026lt; G.vexnum) return ERROR; else return OK; } // TopologicalOrder Status CriticalPath(ALGraph G) // G为有向网，输出G的各项关键活动 { if (!TopologicalOrder(G, T)) return ERROR; vl[0.. G.vexnum - 1] = ve[G.vexnum - 1]; while (!StackEmpty(T)) // 按拓扑逆序求各顶点的vl值 for (pop(T, j), p = G.vertices[j].firstarc; p; p = p-\u0026gt;nextarc) { k = p-\u0026gt;adjvex; if (vl[k] - (p-\u0026gt;weight) \u0026lt; vl[j]) vl[j] = vl[k] - (p-\u0026gt;weight); // 更新vl，求min } for (j = 0; j \u0026lt; G.vexnum; ++j) // 求各活动的ee、el和确定关键活动 for (p = G.vertices[j].firstarc; p; p = p-\u0026gt;nextarc) { k = p-\u0026gt;adjvex; dut = p-\u0026gt;weight; ee = ve[j]; el = vl[k] - dut; tag = (ee == el) ? ’*’ :’ ’; printf(j, k, dut, ee, el, tag); } } // CriticalPath 最短路径 Dijkstra算法 设源点为v0，求到其余各顶点的最短路径，记录权值\n再从v0邻接的顶点出发，寻找并更新最短路径。\n[教材189页算法7.15]\nvoid ShortestPath_DIJ(Mgraph G, int v0, PathMatrix \u0026amp;P, ShortPathTable \u0026amp;D) { for (v = 0; v \u0026lt; vexnum; v++) { final[v] = FALSE; D[v] = G.arcs[v0][v]; for (w = 0; w \u0026lt; vexnum; w++) P[v][w] = FALSE; if (D[v] \u0026lt; INFINITY) P[v][v0] = p[v][v] = TRUE; } D[v0] = 0; final[v0] = TRUE; for (i = 1; i \u0026lt; vexnum; i++) { min = INFINITY; for (w = 0; w \u0026lt; vexnum; w++) if (!final[w] \u0026amp;\u0026amp; D[w] \u0026lt; min) { k = w; min = D[w]; } final[k] = TRUE; /*考虑新加入的节点k */ for (w = 0; w \u0026lt; vexnum; w++) if (!final[w] \u0026amp;\u0026amp; (min + G.arcs[k][w] \u0026lt; D[w])) { D[w] = min + G.arcs[k][w]; P[w] = P[k]; P[w][w] = TRUE; } } } Floyd算法 每一对顶点之间的最短路径\nvoid ShortestPath_FLOYD1(Mgraph G, PathMatrix \u0026amp;Path, DistanceMatrix \u0026amp;D) { for (v = 0; v \u0026lt; n; v++) for (w = 0; w \u0026lt; n; w++) { D[v][w] = G.arcs[v][w]; // 初始化D(-1) path[v][w] = ; if (D[v][w] \u0026lt; INFINITY) path[v][w] = [v] + [w]; // 初始化直接路径 } for (k = 0; k \u0026lt; n; k++) // 依次引入中间顶点 for (v = 0; v \u0026lt; n; v++) for (w = 0; w \u0026lt; n; w++) if (D[v][k] + D[k][w] \u0026lt; D[v][w]) { // 如果经过中间点k能优化长度 D[v][w] = D[v][k] + D[k][w]; Path[v][w] = Path[v][k] + Path[k][w]; } } // ShortestPath_FLOYD1 void ShortestPath_FLOYD2(Mgraph G, PathMatrix \u0026amp;P, DistanceMatrix \u0026amp;D) // P[v][w][k]为TRUE，则从v到w的最短路径中含有k节点 // D[v][w]从v到w的最短路径的长度 { for (v = 0; v \u0026lt; n; v++) for (w = 0; w \u0026lt; n; w++) { D[v][w] = G.arcs[v][w]; for (k = 0; k \u0026lt; n; k++) p[v][w][k] = FALSE; if (D[v][w] \u0026lt; INFINITY) // 存在直接路径 P[v][w][v] = P[v][w][w] = TRUE; // 从v到w的路径中包括v和w } for (k = 0; k \u0026lt; n; k++) // 依次加入中间顶点 for (v = 0; v \u0026lt; n; v++) for (w = 0; w \u0026lt; n; w++) if (D[v][k] + D[k][w] \u0026lt; D[v][w]) { // 如果经过中间点k能优化长度 D[v][w] = D[v][k] + D[k][w]; for (i = 0; i \u0026lt; n; i++) P[v][w][i] = P[v][k][i] || P[k][w][i]; // v经k到w的路径包含的节点为v到k的路径节点 || k到w的路径节点 } } // ShortestPath_FLOYD2 P191-算法7.16 ","date":"2024-01-22T13:37:43Z","permalink":"http://localhost:1313/post/6-%E5%9B%BE/","title":"6 图"},{"content":"树 树 一个前驱，多个后继\n定义 树是一类重要的非线性数据结构，是以分支关系定义的层次结构\n树是由n（n\u0026gt;=0）个结点构成的有限集合T，非空树满足：\n1）有一个称之为根（root）的结点，根节点没有前驱节点\n2）除根以外的其余结点被分成m个互不相交的集合$T_1,T_2,\u0026hellip;,T_m$,其中每一个集合本身又是一棵树，称为子树。\n树的递归定义刻画了树的固有特性，即一棵非空树是由若干棵子树构成的，而子树又可由若干棵更小的子树构成。\n特点 ⑴树的根结点没有前驱结点，除根结点之外的所有结点有且只有一个前驱结点。\n⑵树中所有结点可以有零个或多个后继结点。\n基本术语 结点的度：结点拥有的子树数目\n树的度：树的各节点度的最大值\n叶子（终端）结点：度为0的结点\n分支（非终端）结点：度不为0的结点\n内部结点：除根结点之外的分支结点\n双亲与孩子（父与子）结点：结点的子树的根称为该结点的孩子，该结点称为孩子的双亲\n兄弟：属于同一双亲的孩子\n结点的祖先：从根到该结点所经分支上的所有结点。\n结点的子孙：该结点为根的子树中的任一结点。\n结点的层次：表示该结点在树中的相对位置。根为第一层，其它的结点依次下推；若某结点在第L层上，则其孩子在第L+1层上。\n树的深(高)度：树中结点的最大层次。\n有序树：树中各结点的子树从左至右是有次序的，不能互换。否则，称为无序树。\n路径长度：从树中某结点Ni出发，能够通过树中结点到达结点Nj，则称Ni到Nj存在一条路径，路径长度等于这两个结点之间的分支/边的个数。\n森林：是m(m³0)棵互不相交的树的集合。\n二叉树 定义 二叉树是n(n\u0026gt;=0)个结点的有限集合，它或为空树(n=0)，或由一个根结点和两棵互不相交的被分别称为根的左子树和根的右子树的二叉树组成。\n特点 定义是递归的\n0\u0026lt;=结点的度\u0026lt;=2\n是有序树\n二叉树的每个结点至多只有两棵子树，且子树有左右之分，其次序不能任意颠倒。\n满二叉树 如果一棵二叉树每一层的结点个数都达到了最大，这棵二叉树称为满二叉树。对于满二叉树，所有的分支结点都存在左子树和右子树，所有叶子都在最下面一层。一棵深度为k的满二叉树有$2^k-1$个结点\n完全二叉树 一棵深度为k的有n个结点的二叉树，对其结点按从上至下，从左到右的顺序进行编号，如果编号为i的结点与满二叉树中编号为i的结点在二叉树中的位置相同，则这棵二叉树称为完全二叉树。\n​ 完全二叉树的特点是叶子结点只能出现在最下层和次最下层，并且最下面一层上的结点都集中在该层最左边的若干位置上，至多只有最下面的两层上结点的度数可以小于2，满二叉树肯定是完全二叉树，而完全二叉树未必是满二叉树。\n二叉树的性质 性质1 二叉树的第i层上至多有$2^{i-1}$(i\u0026gt;=1)个结点。\n性质2 深度为k的二叉树至多有$2^k-1$个结点(k\u0026gt;=1)。\n性质3 对任何一棵二叉树T，如果其终端结点数为n0，度为2的结点数为n2 ，则n0 = n2 + 1。\n设一颗二叉树上叶子结点数为n0，单分支结点数为n1，双分支结点数为n2，则总结点数为：n0+n1+n2。\n而一颗二叉树中，所有结点的分支数（即度数）应等于单分支结点数加上双分支结点数的两倍，即总分支数=n1+2n2。\n由于二叉树中除了根结点以外，每个结点都有唯一的一个分支指向它，因此二叉树中：总分支数=总结点数-1。\n即n1+2n2=n0+n1+n2-1。即n0=n2+1。\n性质4 具有n个结点的完全二叉树的深度为 $⌊\\log_2n⌋+1$。\n假设深度为k，根据完全二叉树的定义和性质2可知，有$2^{k-1}-1\u0026lt; n\u0026lt;=2^k-1$且k是整数\n$k-1\u0026lt;=\\log_2n\u0026lt;k$\n$k-1=⌊\\log_2n⌋$\n性质5 一棵具有n个结点的完全二叉树(又称顺序二叉树)，对其结点按层从上至下(每层从左至右)进行1至n的编号，则对任一结点i(1\u0026lt;=i\u0026lt;=n)有： (1)若i\u0026gt;1，则i的双亲是$⌊i/2⌋$；若i=1，则i是根，无双亲。 (2)若2i\u0026lt;=n，则i的左孩子是2i；否则， i无左孩子。 (3)若2i+1\u0026lt;=n，则i的右孩子是2i+1；否则， i无右孩子。\n二叉树的存储结构 二叉树的顺序存储 所谓二叉树的顺序存储，是用一组连续的存储单元存放二叉树中的结点。一般是按照二叉树结点从上至下、从左到右的顺序存储。\n对于一般的二叉树，如果仍按从上至下和从左到右的顺序将树中的结点顺序存储在一维数组中，则数组元素下标之间的关系不能够反映二叉树中结点之间的逻辑关系，只有增添一些并不存在的空结点，使之成为一棵完全二叉树的形式，然后再用一维数组顺序存储。\n二叉树的顺序存储结构可描述为：\n#define MAXNODE 1024 //二叉树的最大结点树 typedef TElemType SqBiTree[MAXNODE]; //0号单元存放根结点 定义一个顺序存储的二叉树变量：SqBiTree bt;\n即将bt为含有MAXNODE个TElemType类型元素的一维数组。\n链式存储结构 用链来指示元素之间的逻辑关系，通常有二叉链表存储和三叉链表存储\n二叉链表存储 链表中每个结点有3个域组成，除了数据域外，还有两个指针域，分别给出该结点左孩子和右孩子所在的链结点的存储地址。\n下图(a)给出一棵二叉树的二叉链表存储表示。二叉链表也可以带头结点的方式存放，如图(b)所示。\ntypedef struct BiTNode{ TElemType data; struct BiTNode *lchild,*rchild;//左右孩子指针 }BiTNode,*BiTree; //定义一个指向二叉树的指针变量:BiTree t; 三叉链表存储 二叉链表存储可以直接找到结点的孩子结点，但不能直接找到其双亲结点，用三叉链表存储可以解决这一问题，给运算带来方便\n每个结点由四个域组成，具体结构为：\n下图给出一棵二叉树的三叉链表存储示意图\n二叉树的遍历 在二叉树的一些应用中，常常要求在树中查找具有某种特征的结点，或者对树中全部结点逐一进行某种处理。这就引入了遍历二叉树的问题，即如何按某条搜索路径巡访树中的每一个结点，使得每一个结点均被访问一次，而且仅被访问一次。\n遍历对线性结构是容易解决的，而二叉树是非线性的，因而需要寻找一种规律，以便使二叉树上的结点能排列在一个线性队列上，从而便于遍历。\n由二叉树的递归定义，二叉树的三个基本组成单元是：根结点、左子树和右子树。\n先序遍历 若二叉树为空，则空操作；否则\n（1）访问根结点；\n（2）先序遍历左子树；\n（3）先序遍历右子树。\nvoid PerOrderTraverse(BiTree T,Status(*Visit)(datatype)){ //初始条件：二叉树T存在，Visit是对结点操作的应用函数 //操作结果：先序递归遍历T，对每个结点调用函数Visit一次且仅一次 if(T){ Visit(T-\u0026gt;data);//访问根结点 PerOrderTraverse(T-\u0026gt;lchild,Visit);//再先序遍历左子树 PerOrderTraverse(T-\u0026gt;lchild,Visit);//最后先序遍历右子树 } } 预留很多空，按根左右的方式写\n本质上是写出了这棵树的上下顺序\n中序遍历 若二叉树为空，则空操作；否则\n（1）中序遍历左子树；\n（2）访问根结点；\n（3）中序遍历右子树。\nvoid InOrderTraverse(BiTree T,Status(*Visit)(datatype)){ //初始条件：二叉树T存在，Visit是对结点操作的应用函数 //操作结果：中序递归遍历T，对每个结点调用函数Visit一次且仅一次 if(T){ InOrderTraverse(T-\u0026gt;lchild,Visit);//先中序遍历左子树 Visit(T-\u0026gt;data);//访问根结点 InOrderTraverse(T-\u0026gt;rchild,Visit);//最后中序遍历右子树 } } 从左到右写这棵树，本质上是描述了这棵树的左右顺序\n后序遍历 若二叉树为空，则空操作；否则\n（1）后序遍历左子树；\n（2）后序遍历右子树；\n（3）访问根结点。\nvoid PostOrderTraverse(BiTree T,Status(*Visit)(datatype)){ //初始条件：二叉树T存在，Visit是对结点操作的应用函数 //操作结果：后序递归遍历T，对每个结点调用函数Visit一次且仅一次 if(T){ PostOrderTraverse(T-\u0026gt;lchild,Visit);//先后序遍历左子树 PostOrderTraverse(T-\u0026gt;rchild,Visit);//然后后序遍历右子树 Visit(T-\u0026gt;data);//最后访问根结点 } } 后序遍历：预留很多空，直接写左右根\n【一秒学会构建二叉树和遍历，非标题党！秒做!超级简单（考研数据结构）】https://www.bilibili.com/video/BV11d4y1s7hm?vd_source=18eb90919502cd446c859adbd8eafddc\n非递归方法实现二叉树的三种遍历 包络线 下图中所示的从根结点左外侧开始，由根结点右外侧结束的曲线，称其为该二叉树的包络线，二叉树的遍历是沿着该线路进行的。沿着该路线按△标记的结点读得的序列为先序序列，按*标记读得的序列为中序序列，按⊕标记读得的序列为后序序列。\n栈的使用 先序遍历是沿着包络线深入时遇到结点就访问；\n中序遍历是在从左子树返回时遇到结点访问；\n后序遍历是在从右子树返回时遇到结点访问\n按包络线行走的核心思路：\n从根结点开始沿左子树深入下去，当深入到最左端，无法再深入下去时，则返回，再逐一进入刚才深入时遇到结点的右子树，再进行深入和返回，直到最后从根结点的右子树返回到根结点为止。\n在这一过程中，返回结点的顺序如深入结点的顺序想法，即后深入先返回。符合“栈”结构的特点。\np是否为空\n​ 如果不为空，把p指向的结点地址入栈，然后p=p-\u0026gt;lchild\n​ 如果为空，出栈一个结点地址复制给p，然后p=p-\u0026gt;rchild\n如果结点地址入栈前访问该结点，则为先序遍历\n如果结点地址出栈后访问该结点，则为中序遍历\n中序遍历的非递归算法\n// 中序遍历的非递归算法 Status InOrderTraverse（BiTree T, Status(* Visit)(TElemType e)) { InitStack(S); p = T; // p指向根结点 while (p || !StackEmpty(S)) { // p不为空或者栈不为空 if (p) { Push(S, p); // p不为空入栈p的值 p = p-\u0026gt;lchild; // p指向之前指向结点的左孩子 } else { // p值为null，已经到了左下角 Pop(S, p); // 出栈，将值赋给p if (!Visit(p-\u0026gt;data)) return ERROR; // 访问p指向的结点 p = p-\u0026gt;rchild; } // else } // while return OK; } 队列方法实现二叉树的层次遍历 所谓二叉树的层次遍历，是指从二叉树的第一层（根结点）开始，从上至下逐层遍历，在同一层中，则按从左到右的顺序对结点逐个访问。对于下图所示的二叉树，按层次遍历所得到的结果序列为：\nA B C D E F G\n队列的使用 在进行层次遍历时，可设置一个队列结构，遍历从二叉树的根结点开始，首先将根结点指针入队列，然后从对头取出一个元素，每取一个元素，执行下面两个操作：\n⑴访问该元素所指结点；\n⑵若该元素所指结点的左、右孩子结点非空，则将该元素所指结点的左孩子指针和右孩子指针顺序入队。\n此过程不断进行，当队列为空时，二叉树的层次遍历结束。\nStatus LevelOrderTraverse(BiTree T, Status (*Visit)(TElemType e)) { if (T) { InitQueue(Q); EnQueue(Q, T); // 根结点的指针T入队列 while (!QueueEmpty(Q)) { DeQueue(Q, p); // 从队头取一个指针 if (!Visit(p-\u0026gt;data)) return ERROR; if (p-\u0026gt;lchild) EnQueue(Q, p-\u0026gt;lchild); if (p-\u0026gt;rchild) EnQueue(Q, p-\u0026gt;rchild); } } return OK; } // LevelOrderTraverse 二叉树遍历的应用 构造二叉树的二叉链表存储 构建一棵二叉树的二叉链表也是基于遍历的过程进行的。这里按照先序遍历的过程构建。\n首先建立二叉树带空指针的先序序列，依此作为构建时结点的输入顺序，如对于下图所示的二叉树，输入序列为：ABD0G000CE00F00（0表示空，为了简化问题，设数据元素的类型为字符型)。\n读入带空指针的先序序列构造二叉树，写法1，通过return返回二叉树指针\n读入带空指针的先序序列构造二叉树，写法2，通过引用返回二叉树指针\n读入带空指针的先序序列构造二叉树，写法3，传递指向指针的指针\n在二叉树中查找值为x的数据元素 统计给定二叉树中叶子结点的数目 由遍历序列恢复二叉树 最下面一排写中序遍历，竖着写先序遍历，根据这个表恢复二叉树\n从前面讨论的二叉树的遍历知道，任意一棵二叉树结点的先序序列和中序序列都是唯一的。\n1、依据遍历定义：\n由二叉树的先序序列和中序序列可唯一地确定该二叉树。\n由二叉树的后序序列和中序序列也可唯一地确定该二叉树。\n由二叉树的先序序列和后序序列不能唯一地确定该二叉树。\n2、分隔过程：\n已知一棵二叉树的先序序列与中序序列分别为： A B C D E F G H I ， B C A E D G H F I，试恢复该二叉树。\n线索二叉树 遍历二叉树实际上就是将树中所有结点排成一个线性序列（即非线性结构线性化）。在这样的线性序列中，除第一个结点外，每个结点有且仅有一个直接前驱结点；除最后一个结点外，每个结点有且仅有一个直接后继结点。\n然而，有时我们希望不进行遍历，就能很快找到某个结点在某种遍历下的直接前趋和后继。为此，就需要把每个结点的直接前趋和直接后继记录下来。\n线索二叉树分为：\n先序线索二叉树\n中序线索二叉树\n后序线索二叉树\n但二叉树的存储结构中并没有反映出前趋和后继信息。一个最简单的办法是在原来的二叉链表的每个结点中，再增加两个指针域fwd和bkwd，分别指向前趋和后继。这些指针被称为线索（thread），加了线索的二叉树叫做线索二叉树\n线索二叉树（先序） 上述做法存储效率较低.\n一个具有n个结点的二叉树若采用二叉链表存储结构，在2n个指针域中只有n－1个指针域是用来存储孩子结点的地址，而另外n＋1个指针域存放的都是NULL。\n例如下图：7个结点，14个指针域，6个指针域存储孩子结点地址，8个存放的是NULL.\n一个新的思路：\n是利用二叉树的二叉链表存储结构中的那些空指针域来指示前趋和后继。\n利用二叉链表的空指针域，存储指向该结点的前驱/后继(某种遍历方式下)结点的指针，方便二叉树的线性化使用。(n个结点的二叉树含有n+1空指针域)\n例如：可以利用某结点空的左指针域（lchild）指出该结点在某种遍历序列中的直接前驱结点的存储地址，利用结点空的右指针域（rchild）指出该结点在某种遍历序列中的直接后继结点的存储地址。对于那些非空的指针域，则仍然存放指向该结点左、右孩子的指针。这样，就得到了一棵线索二叉树。\n指向孩子的指针和线索都是地址，如何区别某结点的指针域内存放的是指针还是线索？方法是为每个结点增设两个标志位域ltag和rtag，令：\n线索二叉树的结点定义如下： typedef struct BiThrNode { datatype data; struct BiThrNode *lchild; struct BiThrNode *rchild; unsigned ltag; unsigned rtag; }BiThrNodeType, *BiThrTree; 线索二叉树的构建 由于线索化的实质是将二叉链表中的空指针改为指向前驱或后继的线索，而前驱或后继的信息只有在遍历时才能得到，因此线索化的过程即为在遍历过程中，访问结点的操作是检查当前结点的左、右指针域是否为空，如果为空，将它们改完指向前驱结点或后继结点的线索。\n为实现这一过程，设指针pre始终指向刚刚访问过的结点，即若指针p指向当前结点，则pre指向它的前驱，以便增设线索。\n二叉树中序线索化 Status InOrderThreading(BiThrTree \u0026amp;Thrt, BiThrTree T) // 中序遍历二叉树T并将其线索化，Thrt指向头结点 { if (!(Thrt = (BiThrTree)malloc(sizeof(BiThrNode)))) exit(OVERFLOW); // 构造头结点 Thrt-\u0026gt;LTag = Link; Thrt-\u0026gt;Rtag = Thread; // 构造头结点 Thrt-\u0026gt;rchild = Thrt; // 右指针回指 if (!T) Thrt-\u0026gt;lchild = Thrt; // 若二叉树空，左指针回指 else { Thrt-\u0026gt;lchild = T; // 头结点的左指针是根结点 pre = Thrt // 将头结点作为初始的pre InThreading(T); pre-\u0026gt;RTag = Thread; // 最后一个结点线索化 pre-\u0026gt;rchild = Thrt; // 最后一个结点的后续是头结点 Thrt-\u0026gt;rchild = pre; // 头结点的右指针执行最后一个结点 } return OK; } // InOrderThreading P134-6.6 void InThreading(BiThrTree p) { if (p) { InThreading(p-\u0026gt;lchild); // 左子树线索化 if (!p-\u0026gt;lchild) // 如果p没有左孩子 { p-\u0026gt;LTag = Thread; p-\u0026gt;lchild = pre; } // p结点存储前驱线索 if (!pre-\u0026gt;rchild) // 如果pre没有右孩子 { pre-\u0026gt;RTag = Thread; pre-\u0026gt;rchild = p; } // pre结点存储后继线索 pre = p; // 保持pre指向p的前驱 InThreading(p-\u0026gt;rchild); // 右子树线索化 } } // InThreading P135-6.7 Status InOrderTraverse_Thr(BiThrTree T, Status (*Visit)(TElemType e)) // T指向头结点，头结点的左指针指向根节点 // 中序遍历二叉线索树的非递归算法 { p = T-\u0026gt;lchild; // p指向根结点 while (p != T) { while (p-\u0026gt;LTag == Link) p = p-\u0026gt;lchild; // 找到最左下角结点，即接下来应该访问的第一个结点 if (!Visit(p-\u0026gt;data)) return ERROR; // 访问该结点 while (p-\u0026gt;Rtag == Thread \u0026amp;\u0026amp; p-\u0026gt;rchild != T) { // 如果右指针为线索且不为空，则p-\u0026gt;rchild即为后继 p = p-\u0026gt;rchild; Visit(p-\u0026gt;data); // 指向后继并访问 } // while p = p-\u0026gt;rchild; // p指向右子树根结点，下一步再去找左下角 } return OK; } // InOrderTraverse_Thr P134-6.5 最优二叉树 术语 结点权值: 和叶子结点对应的一个有某种意义的实数(Wi)\n结点带权路径长度 叶子结点的路径长度与该结点的权之积。\n树的路径长度 从树根到每一个叶子结点的路径长度之和。\n树的带权路径长度 树中所有叶子结点的带权路径长度之和。\n最优二叉树(哈夫曼树) 带权路径长度WPL最小的 二叉树。\n最优二叉树 在权值为w1,w2,…,wn的n个叶子所构成的所有二叉树中，带权路径长度最小的二叉树，称为最优二叉树(哈夫曼树) 。\n从前图可以看出，最优二叉树中，权值越大的叶子距离根越近。哈夫曼首先给出了构造最优二叉树的方法，故我们称其为哈夫曼算法\n建立哈夫曼树（最优二叉树）的方法 [基本思想] 使权大的结点靠近根。 (1)将给定权值从小到大排序成{w1,w2,…,wm}，生成一个森林F={T1,T2,…,Tm}，其中Ti是一个带权Wi的根结点，它的左右子树均空。\n(2)把F中根的权值最小的两棵二叉树T1和T2合并成一棵新的二叉树T： T的左子树是T1 ，右子树是T2 ，T的根的权值是T1、T2树根结点权值之和。\n(3)将T按权值大小加入F中，同时从F中删去T1和T2\n(4)重复(2)和(3)，直到F中只含一棵树为止，该树即为所求。\n赫夫曼树的存储结构 初始有n个叶子结点，则构造出的赫夫曼树(属于严格二叉树)共有2n-1个结点。\n用大小为2n的向量存储赫夫曼树—顺序存储。\ntypedef struct { unsigned int weight; unsigned int parent, lchild, rchild; }HTNode, *HuffmanTree; //动态分配存储空间 1)申请空间并初始化HT[1..2n-1]：\nweight=0, lchild=rchild=parent=0\n2)设置HT[1..n]的weight值\n1.在HT[1..i-1]中parent = 0的结点中选weight最小的两个结点HT[s1]和HT[s2]\n2.修改HT[s1]和HT[s2]的parent值： parent=i\n3.置HT[i]：weight=HT[s1].weight + HT[s2].weight ,lchild=s1, rchild=s2\n构造赫夫曼树的算法步骤 HuffmanTree HT;\n1)申请空间并初始化HT[1..2n-1]：\nweight=0, lchild=rchild=parent=0\n2)设置HT[1..n]的weight值\n3)进行以下n-1次合并，依次产生HT[i]，i=n+1..2n-1：\n3.1)在HT[1..i-1]中parent = 0的结点中选weight最小的两个结点HT[s1]和HT[s2]\n3.2)修改HT[s1]和HT[s2]的parent值： parent=i\n3.3)置HT[i]：weight=HT[s1].weight + HT[s2].weight , lchild=s1, rchild=s2\nvoid BuildHT(HuffmanTree \u0026amp;HT, int *w, int n) // w存放n个叶结点的权值(均\u0026gt;0)，构造赫夫曼树HT { if ( n\u0026lt;=1 ) { HT=NULL; return; } m=2*n-1; //计算总结点个数 HT=(HuffmanTree)malloc((m+1)sizeof(HTNode)); for (p=HT+1, i=1; i\u0026lt;=n; ++i, ++p, ++w) *p={*w,0,0,0}; //初始化 for (; i\u0026lt;=m; ++i, ++p) *p={0,0,0,0}; //后续结点初始化为0 for (i=n+1; i\u0026lt;=m; ++i) { //建赫夫曼树 Select(HT, i-1, s1, s2); //在HT[1..i-1]中选择parent为0且权值最小的两个结点 HT[s1].parent=i; HT[s2].parent=i; HT[i].lchild=s1; HT[i].rchild=s2; HT[i].weight=HT[s1].weight+HT[s2].weight; } }//BuildHT 哈夫曼树的应用 最佳判定树\n哈夫曼编码：用于通信和数据传送中字符的二进制编码，可以使电文编码总长度最短。\n设需要编码的字符集合为{d1，d2，…，dn}，它们在电文中出现的次数或频率集合为{w1，w2，…，wn}，以d1，d2，…，dn作为叶结点，w1，w2，…，wn作为它们的权值，构造一棵哈夫曼树。\n赫夫曼编码是不等长编码\n赫夫曼编码是前缀编码，即任一字符的编码都不是另一字符编码的前缀\n赫夫曼编码树中没有度为1的结点。若叶子结点的个数为n，则赫夫曼编码树的结点总数为 2n-1\n发送过程：根据由赫夫曼树得到的编码表送出字符数据\n接收过程：按左0、右1的规定，从根结点走到一个叶结点，完成一个字符的译码。反复此过程，直到接收数据结束\n赫夫曼编码表的存储结构 void HuffmanCoding(HuffmanTree HT, int n, HuffmanCode \u0026amp;HC) // 求赫夫曼树HT的n个字符的赫夫曼编码HC { HC=(HuffmanCode)malloc((n+1)*sizeof(char *)); cd=(char *) malloc(n*sizeof(char)) ; //分配编码的工作空间 cd[n-1]=‘\\0’; for (i=1; i\u0026lt;=n; ++i) { //为每个字符求编码 start=n-1; for (c=i, f=HT[i].parent; f!=0; c=f, f=HT[f].parent ) //f是c的父节点 if (HT[f].lchild==c) cd[--start]=‘0’;// 若c是f的左孩子，记录编码0 else cd[--start]=“1”; //否则为右孩子，记录编码1 HC[i]= (char *)malloc((n-start)*size(char)); //申请存储第i个字符编码的空间 strcopy(HC[i], \u0026amp;cd[start]); //从临时工作空间cd拷贝到HC[i] } free(cd); }//HuffmanCoding #include\u0026lt;iostream\u0026gt; #include\u0026lt;string\u0026gt; using namespace std; struct Node { double weight; string ch; string code; int lchild, rchild, parent; }; void Select(Node huffTree[], int *a, int *b, int n)//找权值最小的两个a和b { int i; double weight = 0; //找最小的数 for (i = 0; i \u0026lt;n; i++) { if (huffTree[i].parent != -1) //判断节点是否已经选过 continue; else { if (weight == 0) { weight = huffTree[i].weight; *a = i; } else { if (huffTree[i].weight \u0026lt; weight) { weight = huffTree[i].weight; *a = i; } } } } weight = 0; //找第二小的数 for (i = 0; i \u0026lt; n; i++) { if (huffTree[i].parent != -1 || (i == *a))//排除已选过的数 continue; else { if (weight == 0) { weight = huffTree[i].weight; *b = i; } else { if (huffTree[i].weight \u0026lt; weight) { weight = huffTree[i].weight; *b = i; } } } } int temp; if (huffTree[*a].lchild \u0026lt; huffTree[*b].lchild) //小的数放左边 { temp = *a; *a = *b; *b = temp; } } void Huff_Tree(Node huffTree[], int w[], string ch[], int n) { for (int i = 0; i \u0026lt; 2 * n - 1; i++) //初始过程 { huffTree[i].parent = -1; huffTree[i].lchild = -1; huffTree[i].rchild = -1; huffTree[i].code = \u0026#34;\u0026#34;; } for (int i = 0; i \u0026lt; n; i++) { huffTree[i].weight = w[i]; huffTree[i].ch = ch[i]; } for (int k = n; k \u0026lt; 2 * n - 1; k++) { int i1 = 0; int i2 = 0; Select(huffTree, \u0026amp;i1, \u0026amp;i2, k); //将i1，i2节点合成节点k huffTree[i1].parent = k; huffTree[i2].parent = k; huffTree[k].weight = huffTree[i1].weight + huffTree[i2].weight; huffTree[k].lchild = i1; huffTree[k].rchild = i2; } } void Huff_Code(Node huffTree[], int n) { int i, j, k; string s = \u0026#34;\u0026#34;; for (i = 0; i \u0026lt; n; i++) { s = \u0026#34;\u0026#34;; j = i; while (huffTree[j].parent != -1) //从叶子往上找到根节点 { k = huffTree[j].parent; if (j == huffTree[k].lchild) //如果是根的左孩子，则记为0 { s = s + \u0026#34;0\u0026#34;; } else { s = s + \u0026#34;1\u0026#34;; } j = huffTree[j].parent; } cout \u0026lt;\u0026lt; \u0026#34;字符 \u0026#34; \u0026lt;\u0026lt; huffTree[i].ch \u0026lt;\u0026lt; \u0026#34; 的编码：\u0026#34;; for (int l = s.size() - 1; l \u0026gt;= 0; l--) { cout \u0026lt;\u0026lt; s[l]; huffTree[i].code += s[l]; //保存编码 } cout \u0026lt;\u0026lt; endl; } } string Huff_Decode(Node huffTree[], int n,string s) { cout \u0026lt;\u0026lt; \u0026#34;解码后为：\u0026#34;; string temp = \u0026#34;\u0026#34;,str=\u0026#34;\u0026#34;;//保存解码后的字符串 for (int i = 0; i \u0026lt; s.size(); i++) { temp = temp + s[i]; for (int j = 0; j \u0026lt; n; j++) { if (temp == huffTree[j].code) { str=str+ huffTree[j].ch; temp = \u0026#34;\u0026#34;; break; } else if (i == s.size()-1\u0026amp;\u0026amp;j==n-1\u0026amp;\u0026amp;temp!=\u0026#34;\u0026#34;)//全部遍历后没有 { str= \u0026#34;解码错误！\u0026#34;; } } } return str; } int main() { //编码过程 const int n=5; Node huffTree[2 * n]; string str[] = { \u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;}; int w[] = { 30, 30, 5, 20, 15 }; Huff_Tree(huffTree, w, str, n); Huff_Code(huffTree, n); //解码过程 string s; cout \u0026lt;\u0026lt; \u0026#34;输入编码：\u0026#34;; cin \u0026gt;\u0026gt; s; cout \u0026lt;\u0026lt; Huff_Decode(huffTree, n, s)\u0026lt;\u0026lt; endl;; system(\u0026#34;pause\u0026#34;); return 0; } 树和森林 树的四种表示方法 (1)直观表示法\n​ 树的直观表示法就是以倒着的分支树的形式表示，下图就是一棵树的直观表示。其特点就是对树的逻辑结构的描述非常直观。是数据结构中最常用的树的描述方法。\n(2)嵌套集合表示法\n(3)凹入表示法\n(4)广义表表示法\n(A(B(D,E(H,I),F),C(G)))\n森林 是m(m\u0026gt;=0)棵互不相交的树的集合\n树的存储 1．双亲链表存储方法 #define MAXNODE 1024 //树中结点的最大个数，可根据实际情况进行修改 typedef struct { datatype data; int parent; } PNode; PNode t[MAXNODE]; 下图所示为树的双亲表示。图中用parent域的值为-1表示该结点无双亲结点，即该结点是一个根结点。\n对于实现Parent(t，x)操作和Root(x)操作很方便，但若求某结点的孩子结点时，则需查询整个数组。\n2．指向孩子的链表存储方法 多重链表法 令每个结点包括一个结点信息域和多个指针域，每个指针域指向该结点的一个孩子结点，通过各个指针域值反映出树中各结点之间的逻辑关系。常称为多重链表法。\n在一棵树中，各结点的度数各异，因此结点的指针域个数的设置有两种方法\n1）每个结点指针域的个数等于该结点的度数\n2）每个结点指针域的个数等于树的度数\n方法1)虽然在一定程度上节约存储空间，但由于树中各结点是不同构的，操作不易实现，所以很少采用。\n方法2）各结点是同构的操作方便，但浪费存储空间。\ntypedef struct TreeNode{ datatype data; struct TreeNode * son[MAXSON]; }MSNode 孩子链表表示法 (查找孩子方便，查找双亲比较困难) 树中每一个元素对应一个结点，结点中有两部分信息，一是其本身的数据信息，二是其孩子链表的头指针，即将每个数据元素的孩子们链接成一个孩子链表。\n3．双亲孩子链表存储方法\n将双亲表示法和孩子链表法想结合，在孩子链表存储的基础上，其主结点又加上了其双亲的静态指针。\n4．孩子兄弟链表存储方法\n树中每个元素对应一个结点，每个结点除其信息域外，有两个指针域，分别指向该结点的第一个孩子结点和下一个兄弟结点。\ntypedef struct csnode { datatype data; struct csnode* lchild; struct csnode* nextsibling; }SNode; 树与二叉树的转换 树、森林与二叉树的转换_Raise的博客-CSDN博客_二叉树森林\n​ 从树的孩子兄弟表示法可以看到，如果设定一定规则，就可用二叉树结构表示树和森林，这样，对树的操作实现就可以借助二叉树存储，利用二叉树上的操作来实现。\n​ 在树或森林与二叉树之间有一个一一对应关系。任何一个树或森林可唯一对应到一棵二叉树；反之，任何一棵二叉树也能唯一地对应到一个树或森林。\n树转换为二叉树 森林转换为二叉树 二叉树到树、森林的转换 树和森林的遍历 二叉树和树的应用示例 void trial(int i, int n) { // 进入本函数时，前i-1已放置好，现在从i行选择合适的位置 if ( i\u0026gt;n ) 输出棋盘的当前布局; //已经摆满n个棋子 else for ( j=1; j\u0026lt;=n; ++j ) { 在第i行第j列放一个棋子； if (当前布局合法) trial(i+1, n); //放下一行 移走第i行第j列的棋子; } }//trial 八皇后问题调用： trial(1,8)\n","date":"2024-01-22T13:37:31Z","permalink":"http://localhost:1313/post/5-%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%A0%91/","title":"5 树与二叉树"},{"content":"串 串的概念和基本操作 串的概念 串（字符串）：是由零个或多个字符组成的有限序列。 记作：s =“a1a2…an” (n\u0026gt;=0) 串是特殊的线性表，数据元素是单个字符。\n相对于一般的线性结构的特点：\n结构简单，规模庞大，元素重复率高\n模式匹配（查找）操作：模式检测、模式定位、模式计数等\ns =“a1a2…an” (n³0)\ns 是串名，用引号引起来的字符序列是串的值，$a_i$可以是字母、数字、空格、其他字符。引号本身不属于串的内容。$a_i$(1\u0026lt;=i\u0026lt;=n)是一个任意字符，它称为串的元素，是构成串的基本单位，i是它在整个串中的序号。\nn为串的长度，表示串中所包含的字符个数，当n=0时，称为空串,通常记为f 。\n基本术语 子串和主串：串中任意个连续的字符组成的子序列称为该串的子串。包含子串的串称为主串。\n串相等：两个串长度相等，且对应位置的字符都相等。\n空串和空白串：空串不包含任何字符,表示为f；空白串由一个或多个空格组成，如‘ ’。\n子串的位置：子串的第一个字符在主串中的序号称为子串的位置。\n例：abcdpqrst cdp子串在主串中的位置为3\n串的表示和实现 定长顺序存储表示 用一组地址连续的存储单元存储串值中的字符序列，可以定长来指明最大的字符个数，也叫定长串。如：\n#define MAXSIZE 256 ​ char s[MAXSIZE]; 则字符串中的字符个数不能超过256。\n三种标识串实际长度的方法：\n1）类似顺序表，用一个变量curlen来指向最后一个字符的存储下标，这种方式可以直接得到串的长度：s.curlen+1\n2）在串尾存储一个特殊字符来作为终结符\n3）用s[0]存放串的实际长度，串值存放在s[1]~s[MAXSIZE-1]\nStatus Concat(SString \u0026amp;T,SString S1,SString S2){ //用T返回串s1和s2联接而成的新串 //uncut表示是否截断，未截断TRUE，截断为FALSE if(S1[0]+S2[0]\u0026lt;=MAXSTRLEN){ T[1..S1[0]]=S1[1..S1[0]]; T[S1[0]+1..S1[0]+S2[0]]=S2[1..S2[0]]; T[0]=S1[0]+S2[0]; uncut=TRUE; } else if (S1[0]\u0026lt;MAXSTRLEN) { T[1..S1[0]] = S1[1..S1[0]]; T[s1[0]+1..MAXSTRLEN] = S2[1..MAXSTRLEN-S1[0]]; T[0]= MAXSTRLEN; uncut=FALSE; } else { T[0..MAXSTRLEN]= S1[0..MAXSTRLEN]; uncut= FALSE; } return uncut; }// Concat Status SubString(SString \u0026amp;Sub, SString S, int pos, int len) //用Sub返回串S从第pos个字符起长度为len的子串 { if ( (pos\u0026lt;1 || pos \u0026gt;S[0] || len\u0026lt;0 || len \u0026gt; S[0]-pos+1 ) return ERROR; Sub[1..len]= S[pos..pos+len-1]; Sub[0]= len return OK; } // SubString int StrCompare(SString S, SString T) // S\u0026gt;T,返回值\u0026gt;0；S=T，返回0；S\u0026lt;T，返回值\u0026lt; 0 { for (i=1; i\u0026lt;=S[0] \u0026amp;\u0026amp; i\u0026lt;=T[0]; i++){//逐个字符进行比较 if (S[i] != T[i] ) return(S[i] - T[i] ); } return S[0]-T[0] } // StrCompare 堆分配存储表示 动态分配串值存储空间，避免定长结构的截断现象。\n[存储定义]\ntypedef struct { char *ch; //串空间基址，按串长申请 int length; //串长度 }HString; [基本操作实现示例]\nint StrCompare(HString S, HString T) // S\u0026gt;T,返回值\u0026gt;0；S=T，返回0；S\u0026lt;T，返回值\u0026lt; 0 { for (i = 0; i \u0026lt; S.length \u0026amp;\u0026amp; i \u0026lt; T.length; i++) { if (S.ch[i] != T.ch[i]) return S.ch[i] - T.ch[i]; } return S.length - T.length; } // StrCompare Status Concat(HString \u0026amp;T, HString S1, HString S2) //返回串S1和S2联接而成的新串T { if (T.ch) free(T.ch); //释放T原有空间 if ( ! (T.ch=(char *)malloc((S1.length+S2.length)* sizeof(char)))) exit(OVERFLOW); T.length=S1.length+S2.length; T.ch[0..s1.length-1]=S1.ch[0..s1.length-1]; T.ch[S1.length.. T.length-1]=S2.ch[0..S2.length-1]; return OK; } // Concat Status SubString(HString \u0026amp;Sub, HString S, int pos, int len) //求串S从第pos个字符起长度为len的子串Sub { if ( (pos\u0026lt;1 || pos \u0026gt;S.length || len\u0026lt;0 || len \u0026gt; S.length-pos+1 ) return ERROR; if (Sub.ch) free(Sub.ch); if ( !len ) { Sub.ch=NULL; Sub.length=0; } else { if ( !(Sub.ch=(char *)malloc(len* sizeof(char)))) exit(OVERFLOW); Sub.ch[0..len-1]=S.ch[pos-1..pos+len-2]; Sub.length=len; } return OK; } // SubString 块链存储表示 #define CHUNKSIZE 4 //由用户定义块大小 typedef struct Chunk { char ch[CHUNKSIZE]; struct Chunk * next; }Chunk; typedef struct { Chunk * head， * tail; //串的、尾头指针 int curlen; //串的当前长度 }LString; 串的模式匹配 模式匹配的应用\n网站上搜索新闻\n在文档中搜索一个单词\n定义\n子串定位操作称为串的模式匹配 模式匹配函数\nIndex(S,T,pos) 返回子串T在主串S中第pos个字符之后第一次出现的位置，不存在，返回0. KMP算法 KMP算法主要是通过消除主串指针的回溯来提高匹配的效率。\n简单模式匹配算法性能较低的根源：主串指针回溯是不必要的\n改进思路：尽量跳过一些不必要的比较\n主串S：S[0]中储存字符串的长度\nnext数组（k的计算） 当j等于1时，k=0；否则分析j前面的部分，看有没有正序x位和倒序x位相同的情况，如果没有这种情况k=1，如果有多于一种，则k等于x的最大值+1\nnext数组修正 当T[j]=T[next[j]]时，需要将next[j]修正为next[next[j]]， 依次类推\n代码 int Index_KMP(SString S,SString T,int pos){ i=pos;j=1; while(i\u0026lt;=S[0]\u0026amp;\u0026amp;j\u0026lt;=T[0]){ if(j==0||S[i]==T[j]){ ++i;++j;//继续比较后继字符 }else{ j=next[j]; } } if(j\u0026gt;T[0]) return i-T[0]; else return 0; } 串应用示例\u0026ndash;文本编辑 ","date":"2024-01-22T13:30:51Z","permalink":"http://localhost:1313/post/4-%E4%B8%B2/","title":"4 串"},{"content":"数据链路层的功能 数据链路层的功能：\n向网络层提供一个定义良好的服务接口。 处理传输错误。 调节数据流，确保慢速的接收方不会被快速的发送方淹没。 为了实现这些目标，数据链路层从网络层获得数据包，然后将这些数据包封装成帧 (frame) 以便传输。每个帧包含一个帧头、一个有效载荷（用于存放数据包）以及一个帧尾。\n基本术语：\n结点(node)：\n网络中的主机（host）和路由器（router）称为结点\n链路（Link）\n两个结点之间的点到点的线路段\n数据链路（Data Link）\n协议+链路，在不可靠的物理链路上实现可靠的传输\n端到端（end to end）\n从源结点（source node）到目的结点 （ destinationnode）的通信路径（path），可能由多个链路组成\n提供给网络层的服务：\n无确认的无连接服务：是指源机器向目标机器发送独立的帧，目标机器并不对这些帧进行确认。\n有确认的无连接服务：当向网络层提供这种服务时，数据链路层仍然没有使用逻辑连接，但其发送的每一帧都需要单独确认。\n面向连接的服务：采用这种服务，源机器和目标机器在传输任何数据之前要建立一个连接。连接上发送的每一帧都被编号，数据链路层确保发出的每个帧都会真正被接收方收到。它还保证每个帧只被接收一次，并且所有的帧都将按正确的顺序被接收。\n数据链路层使用的信道\n点对点信道，使用一对一的通信方式。 PPP 协议则是目前使用报广泛的点对点协议。 广播信道，这种信道上连接的主机很多，使用一对多的广播通信方式。采用共享广播信 道的有线局域网普遍使用 CSMA/CD 协议，而无线局域网则使用 CSMA/CA 协议。 封装成帧与透明传输 透明传输：在数据链路层传输时，所传输的数据在数据链路层没有任何的阻挡，接收方所收到的数据和发送方发送的数据没有任何差别，也就是说，数据链路层对其传输的数据帧是完全透明的。\n封装成帧是指在一段数据的前后分别添加首部和尾部构成帧。\n帧是数据链路层的数据传送单元。\n帧长=帧的数据部分长度+首部和尾部的长度。\n首部和尾部中含有很多控制信息，它们的一个重要作用是确定帧的界限，即帧定界。\n接收方能从接收到的二进制比特流中区分出帧的 起始与终止，即帧同步。\n字符计数法Character Count 利用头部中的一个字段来标识该帧中的字符数。\n字节填充法Byte Stuffing 让每个用一些特殊的字节作为开始和结朿。这些特殊字节通常都相同，称为标志字节 (flag byte)，作为帧的起始和结束分界符。\n零比特填充法Bit Stuffing 每个帧的开始和结束由一个特殊的比特模式，01111110 或十六进制 0x7E 标记。这种模式是一个标志字节。每当发送方的数据链路层在数据中遇到连续五个 1，它便自动在输出的比特流中填入一个比特 0。这种比特填充类似于字节填充，在数据字段的标志字节之前插入一个转义字节到出境字符流中。\n违规编码法Physical Layer Coding Violations 在物理层进行比特编码时，常采用违规编码法。例如，曼彻斯特编码方法将数据比特 “1\u0026quot; 编码成“高－低“电平对，将数据比特 ”O\u0026quot; 编码成“低－高“电平对，而“高－高“电平对和“低 －低“电平对在数据比特中是违规的（即没有采用），因此可借用这些违规编码序列来定界帧的起始和终止。局域网 IEEE 802 标准就采用了这种方法。违规编码法不采用任何填充技术便能实现数 据的透明传输，但只适用千采用冗余编码的特殊编码环境。\n差错检测和纠正 通常利用编码技术进行差错控制，主要有两类：自动重传请求 (ARQ)和前向纠错(FEC) 。\n在 ARQ方式中，当接收方检测到差错时，就设法通知发送方重发，直到收到正确的数据为止。在 FEC 方式中，接收方不但能发现差错，而且能确定错误的位置并加以纠正。因此，差错控制又可分为检错编码和纠错编码。\n检错编码 奇偶校验码 缺点：只能检验奇数位出错情况\n奇检验码：附加一个检验位后，码长为 n 的码字中 1 的个数为奇数。 偶检验码：附加一个检验位后，码长为 n 的码字中 1 的个数为偶数。 循环冗余码CRC （1）发送方：待校验数据补充r个0之后，对生成多项式进行模2除法，余数（r位）即为校验信息\n（2）接收方：待校验数据和校验信息一起，对生成多项式进行模2除法，余数不为0即认为有错\nCRC 的性能：\n所有的一位错误都将被检测到 可以捕捉到所有包含奇数个位变反的错误情形 带 r 个校验位的多项式编码可以检测到所有长度小于等于 r 的突发错误 如果突发错误的长度为 r+1，这样一个不正确的帧被当做有效帧接收的概率是$\\frac 1 {2^{r-1}}$ 同样可以证明，当一个长度大于 r+1 位的突发错误发生时，或者几个短突发错误发生时，一个坏帧被当做有效帧通过检测的概率为$\\frac 1 {2^{r}}$ 纠错编码 最常见的纠错编码是海明码。\n流量控制和可靠传输机制 乌托邦式的单工协议 单工协议即数据只能单向传输。这个协议假设信道永远不会丢失或损坏帧，接收方的处理能力足够快，缓冲区足够大。发送程序无限循环，接受程序响应事件，协议1中不包含流量控制和纠错功能。\nStop-and-Wait Protocol 无错信道上的单工停等协议 发送方的速度如果过快，接收方会被淹没，除了增强接收方的处理能力，可以让接收方给发送方发送反馈，发送方收到后才可以发送下一帧。发送程序无限循环并等待接收方确认，接受程序响应事件后发送确认帧。\n有错信道上的单工停等协议 有错信道上传输数据需要增加校验，接收方仅在数据正确时发送确认帧。但在确认帧丢失的情况下（超时），发送方将重发。接收方难以判断帧是重发还是新发，因此帧前加上序号以区分。重复的帧也会收到确认帧，以便发送方决策。\n超时重传 分组丢失：发送方发送分组，接收方没有收到分组，那么接收方不会发出确认，只要发送方过一段时间没有收到确认，就认为刚才的分组丢了，那么发送方就会再次发送。 确认丢失：发送方发送成功，接收方接收成功，确认分组也被发送，但是分组丢失，那么到了等待时间，发送方没有收到确认，又会发送分组过去，此时接收方前面已经收到了分组，那么此时接收方要做的事就是:丢弃分组,重新发送确认。 传送延迟：发送方发送成功，接收方接收成功，确认分组也被发送，没有丢失，但是由于传输太慢，等到了发送方设置的时间，发送方又会重新发送分组，此时接收方要做的事情：丢弃分组，重新发送确认.。发送方如果收到两个或者多个确认，就停止发送，丢弃其他确认。 差错控制 ARQ（自动请求重传）实现差错控制\n如果正确的接收，那么接受方会发送一个ACK帧给发送方 如果发送方没有收到接受方回复的ACK帧，那么发送方会设置计时器并重新发送传输帧 为了确保正确性，必须对框架和ACK进行编号\n接收机需要区分重传（由于丢失ACK或提前定时器）和新帧，对于停等协议，2个数字（使用1位）就足够了。 信道利用率 $$ \\alpha = \\frac {t_{prop}} {t_{frame}} = \\frac {Distance/Speed Of Signal} {Frame Size/Bit rate} $$\n$$ U=\\frac {t_{frame}} {2t_{prop}+t_{frame}}=\\frac 1 {2\\alpha +1} $$\nSliding Window Protocol 滑动窗口的概念 所有滑动窗口协议的本质是在任何时刻发送方总是维持着一组序号，分别对应于允许它发送的帧。我们称这些帧落在发送窗口 (sending window) 内。类似地，接收方也维持着一个接收窗口 (receiving window)，对应于一组允许它接受的帧。\n发送方窗口内的序号代表了那些可以被发送的帧，或者那些已经被发送但还没有被确认的帧。任何时候当有新的数据包从网络层到来时，它被赋予窗口中的下一个最高序号，并且窗口的上边界前移一格。当收到一个确认时，窗口的下边界也前移一格。按照这种方法发送窗口持续地维持了一系列未被确认的帧。\n接收方数据链路层的窗口对应于它可以接受的帧。任何落在窗口内的帧被放入接收方的缓冲区。当收到一个帧，而且其序号等于窗口下边界时，接收方将它传递给网络层，并将整个窗口向前移动 1 个位置。任何落在窗口外面的帧都将被丢弃。在所有情况下，接收方都要生成一个确认并返回给发送方，以便发送方知道该如何处理。\n滑动窗口协议的特点 只有接受窗口向前移动的时候，发送窗口才会向前移动 从滑动窗口的概念来看，停止等待协议、回退N协议和选择重传协议只不过是发送窗口和接受窗口的大小不同 停止等待协议：发送窗口和接受窗口大小都是1 后退N协议:发送窗口\u0026gt;1,接收窗口大小为1 选择重传协议:发送窗口\u0026gt;1,接受窗口大小\u0026gt;1 当接收窗口大小为1的时候可以保证有序的被接收 数据链路层中，传输过程中滑动窗口的大小是固定的 可靠的传输机制 捎带确认(piggy backing)：数据帧携带一个ACK帧 超时重传：在发送某个数据帧之后，就开启一个计时器，开始计时，一旦超过某段时间还没有收到确认帧，就重新发送该数据帧 自动重传请求ARQ：接受方请求发送方重新发送出错的数据帧来恢复出错的帧，传统的自动重传分三种\n停止等待ARQ 后退ARQ 选择性重传ARQ 窗口开的够大的时候，帧在线路上可以连续的流动，因此又称连续的ARQ协议 一位滑动窗口协议 发送窗口=接收窗口=1，其实就是停等协议。\n回退N帧协议GBN 发送窗口的大小\u0026gt;1，接收窗口的大小=1 接收端发现某一帧发生差错时，直接丢弃所有后续的帧，对丢弃帧不发送确认 数据链路层除了接收应该递交给网络层的下一帧之外，拒绝接收其它任何帧 发送方最终会超时，将按顺序重传所有未被确认的帧，即从最初受损或丢失的那一帧开始 接收端接收帧的顺序和发送端发出帧的顺序相同 窗口大小的选择\n用n表示序号字段长度；$2^n$表示发送端可发送帧的序号个数 发送窗口尺寸w应为$2^n-1$ 任何时候，可以发送的帧的最大个数不能等同于序号空间的大小。对回退 n 协议，可发送的帧最多为 MAX_SEQ 个，即使存在 MAX_SEQ+1 个不同的序号（分别为 0、1、2、\u0026hellip;MAX_SEQ)。 适用情况\n回退n帧协议，如果错误率较低时，工作的很好 但错误率较高时，就会浪费大量的带宽在重传上 累计确认\n当 n 号帧的确认到达，n-1 号帧、n-2 号帧等都会自动被确认。这种类型的确认称为累计确认 (cumulative acknowledgement)。\n计时器\n因为协议 5 有多个未被确认的帧，所以逻辑上它需要多个计时器，即每一个未被确认的帧都需要一个计时器\n选择重传协议SR 接收方的数据链路层存储坏帧之后的所有正确的帧，当发送方得知某个帧出错时，只是重传此坏帧，而不是所有的后继帧 在这个协议中，发送方和接收方都维持一个可接收序列号的窗口 接收窗口的大小\u0026gt;1，并为窗口中的每个序列号都提供一个缓冲区，每个缓冲区用一位判断其是否为空 当某一帧到达时，接收方检查其序列号，看其是否落在窗口内 如果落在窗口内且从未接收过，就接收并存储 接收到的此帧保存在数据链路层，而不交给网络层，直到比它序列号小的所有帧都按次序已交给了网络层，此帧才能提交给网络层 选择重传协议的窗口大小\n窗口大小应为\nWs+Wr\u0026lt;=2^n | Ws\u0026gt;=Wr | Ws,Wr\u0026lt;=2^(n-1) 一般情况下发送窗口和接收窗口都取$2^{n-1}$\n这个问题的本质在于：当接收方向前移动它的窗口后，新的有效序号范围与老的序号范围有重叠。因此，后续的一批帧可能是重复的帧（如果所有的确认都丢失了），也可能是新的帧（如果所有的确认都接收到了）。可怜的接收方根本无法区分这两种情形。\n解决这个难题的办法是确保接收方向前移动窗口之后，新窗口与老窗口的序号没有重叠。为了保证没有重叠，窗口的最大尺寸应该不超过序号空间的一半，\n无论如何，接收方不可能接受序号低于窗口下界的帧，也不可能接受序号高于窗口上界的帧。因此，所需要的缓冲区的数量等于窗口的大小，而不是序号的范围。\n出于同样的原因，需要的计时器数量等同于缓冲区的数量，而不是序号空间的大小。\n实际上，每个缓冲区都有一个相关联的计时器。当计时器超时，缓冲区的内容就要被重传\nNAK\n当接收方有理由怀疑出现了错误时，它就给发送方返回一个否定确认 (NAK) 帧。这样的帧实际上是一个重传请求，在 NAK 中指定了要重传的帧。在两种情况下，接收方要特别注意：接收到一个受损的帧，或者到达的帧并非是自己所期望的（可能出现丢帧错误）。为了避免多次请求重传同一个丢失帧，接收方应该记录下对于某一帧是否已经发送过 NAK。\n信道利用率/帧序号计算 信道利用率 帧发送时间$$t_f$$、单向传播时延$$t_p$$、发送窗口大小$$W_T$$ $$\\alpha=\\frac{t_p}{t_f}$$ $$t_f=\\frac{帧长}{信道速率}$$ 信道利用率$$U=\\frac{W_T}{1+2a}=\\frac{W_Tt_f}{t_f+2t_p+t_{确认}（一般忽略）}$$ U=100% $$W\\geq1+2a$$ U\u0026lt;100% $$W\u0026lt;1+2a$$ 采用捎带应答时，信道利用率$$U=\\frac{W_T}{2+2a}$$ U=100% $$W\\geq2+2a$$ U\u0026lt;100% $$W\u0026lt;2+2a$$ 信道利用率$$U=\\frac{L_1}{L_1+L_2+2×t×v}$$ L1:发送帧长 L2:确认帧长 t:单向传播时延 v:传输速率 帧序号计算 第一个总用时$$t_总=t_f+2*t_p+t_{确认}$$ 计算可发多少个 $$x=\\frac{t_总}{t}$$ 计算最小帧序号 n GBN:$$x\u0026lt;2^n-1$$ SR:$$x\u0026lt;2^{n-1}$$ 介质访问控制 https://aye10032.gitbook.io/computernetwork/di-san-zhang-shu-ju-lian-lu-ceng/3.5-jie-zhi-fang-wen-kong-zhi\n静态分配信道 将使用介质的每个设备与来自同一信道上的其他设备的通信隔开，把时域和频域资源合理分配给网络上的设备。\nFDM 频分多路复用 每个信号有自己独立的带宽，信号在通信的过程中自始自终都占用这个频带，在同样的时间占用不同的带宽频率 不用于数字，只用于模拟信号 TDM 时分多路复用 时分多路复用TDM，信道分割的方法是信号占用的时间，将使用复用的各路信号在时间上互不重叠，在传输时把时间分成小的时隙，每一时隙由复用的一个信号占用 不会发生碰撞 STDM 统计时分复用 是改进的时分复用技术，它可以提高信道的利用率。集中器使用这个方法。 统计时分复用技术使用STDM帧来传送复用数据，但每一个STDM帧中的时隙数小于或等于连接在集中器上的用户数，因此STDM帧不是固定分配时隙，而是按需动态分配时隙，由于用户占用的时隙并不是周期性地被使用，所以在每个时隙中还必须有用户的地址信息，这是统计时分复用必须要有的不可避免的开销。 各用户有了数据就随时发往集中器的输入缓存，然后集中器按照一定顺序依次扫描用户是否输入，把缓存中的输入数据放到 STDM 帧中，没有数据的缓存就跳过去，当一个帧的数据放满了才发送出去。 WDM 波分多路复用 使用一根光纤来同时传输多个光载波信号 用于光信号 CDM 码分多路复用 CDM与前几钟技术不同，它既共享信道的频率，也共享时间，是一种真正的动态复用技术，其原理是每比特时间被分成m个更短的时间槽，称为码片（Chip），通常情况下每比特有64或128个码片，每个站点（通道）被指定一个唯一的m位的代码或码片序列。当发送1时站点就发送码片序列，发送0时就发送码片序列的反码。当两个或多个站点同时发送时，各路数据在信道中被线形相加。为了从信道中分离出各路信号，要求各个站点的码片序列是相互正交的 Java\\C\\Python\\PHP(规格化内积/正交) 均匀分割 动态分配信道 有效数据率\u0026amp;CSMA/CD工作过程，例题：\n以太网最短帧长：使最短帧发送时间不少于2τ，以便发送站点能够在发送完毕之前检测到冲突\nALOHA 纯ALOHA想发就发，不监听，不按时间槽发送，随机重发如果发生冲突，接收方在就会检测出差错,然后不予确认，发送方在一定时间内收不到确认就判断发生冲突。等待超时后就会重发数据帧。两个帧时内无冲突概率 $$e^{-2G}$$吞吐量： $$S=G*e^{-2G}$$ G=0.5 时，最好的信道利用率为 18.4%（G 每帧时的平均帧数）\n时隙S-ALOHA只在时隙开始才能发送把时间分成若干个相同的时间片，所有用户在时间片开始时刻同步接入网络信道若发生冲突，那么等到时间槽开始才能发，无冲突的概率为 $$e^{-G}$$，G=1 时效率最高位 36.8% ，效率是纯ALOHA的两倍\nCSMA（Carrier Sense Multiple Access ）载波侦听多路访问协议，发送前先侦听缺点：如果发生冲突，都需要将已经出错的数据帧发送给接受方，造成资源的浪费 1 坚持忙时一直监听，空闲就发\n非坚持busy不发，随机时间后检测\np 坚持Idle 下 p发送，1-p不发busy等待下一个时间槽空闲后随机发\nCSMA/CD（碰撞检测） 先听再发，边发边听，碰撞停止，随机延发（二进制退避） （半双工）以太网使用，使用 CSMA 协议，有线 二进制退避算法 确定基本退避（推迟)时间为争用期2τ 数据发送方最长需要一个往返传播时延的时间（2t）才可以了解自己的数据有没有和其他的数据帧冲突。 只要经过2t时间还没有检测到碰撞，就能肯定这次发送不会发生碰撞。这段时间称为争用期 定义参数k，它等于重传次数，但k不超过10 k=min[重传次数，10] 当重传次数不超过10时，k等于重传次数 当重传次数大于10时，k就不再增大而一直等于10。 从离散的整数集合$$[0,1,2^k-1]$$中随机取出一个数r， 重传时间$$T=r*2τ$$ 当重传达16次仍不能成功时，认为此帧永远无法正确发出，抛弃此帧并向高层报告出错。 最短有效帧长$$L=2τ*带宽$$ MACA（Multiple Access with Collision Avoidance） （A） 首先给B发送一个RTS帧（包含了随后将要发送的数据帧的长度）。\n（B） B用一个CTS帧作为应答（包含了随后将要发送的数据帧的长度，复制）。\n（C） C只听到了A发出的RTS，但没有听到B发出的CTS，只要它没有干扰CTS，那么在数据帧传送过程中，它可以自由地发送任何信息。\n（D） D听不到RTS帧，但是听到了CTS帧。只要听到了CTS帧，这意味着它与一个将要接收数据帧的站离得很近，所以，它就延缓发送任何信息直到那个帧如期传送完毕。\n（E） 站E听到了这两条控制消息，与D一样在数据帧完成之前它必须保持安静。\nCSMA/CA CS：载波侦听/监听，每一个站在发送数据之前以及发送数据时都要检测一下总线上是否有其他计算机在发送数据。\nMA：多点接入，表示许多计算机以多点接入的方式连接在一根总线上。\nCD：碰撞检测（冲突检测)，边发送边监听，通过适配器边发送数据边检测信道上信号电压的变化情况，以便判断自己在发送数据时其他站是否也在发送数据。\n基于MACA进行了改进，在802.11标准定义，能解决隐藏终端问题，但不能解决暴露终端问题\n半双工网络/无线网 RTS：请求发送控制帧 CTS：允许发送控制帧-\u0026gt;明确发送许可，指示其它站点不要发送 过程： 在发送数据前，先检查信道是否空闲 信道空闲： 发出RTS（RTS包括发射端的地址、接收端的地址、下一份数据将持续发送的时间等信息）。 接收端收到RTS后会发出响应CTS。 发送端收到CTS后，开始发送数据帧（同时预约信道:发送方告知其他站点自己要传多久数据) 信道忙：等待信道空闲。 当接受方接收到其他发送方发送RTS后，因为已经建立过通信了，所以就不会响应其他发送方的RTS，这样就可以避免信号发生干扰。 接受方使用CRC循环检验码判断接受的数据是否出错。没有出错返回ACK响应. 发送方收到ACK就可以进行下一个数据帧的发送，若没有则一直重传至规定重发次数为止(采用二进制指数退避算法来确定随机的推迟时间）。 终端问题 隐藏终端问题 A和C向B传送数据，若A开始发送，C监听不到A的传输，C认为它可以向B传输数据，导致在B处产生冲突，因此，需要一个MAC协议来防止冲突的发生 暴露终端问题 B先向A发送，此时C监听到有一个传输正在进行，认为它不能向D发送数据，因此，需要一个MAC协议来防止延迟传输的发生 解决方案（MACA） 动态划分信道（轮询访问介质访问控制） 结合了信道划分介质访问控制的优点（不会发生传输冲突）\n和随机访问介质访问控制的优点（数据帧可以占据全部带宽）\n轮询访问介质访问控制：既要不产生冲突，发送时又占全部带宽。\n令牌转递协议主要应用于令牌环网（物理星型拓扑，逻辑环形拓扑）\n采用令牌传送方式的网络常用于负载较重、通信量较大的网络中\n轮询协议 主结点轮流\u0026quot;邀请\u0026quot;从属结点发送数据。 缺点： 轮询开销 等待延迟 单点故障 令牌传递协议 所有站连接成一个单环结构，一个站依次连接到下一站。令牌传递到下一站只是简单地从一个方向接收令牌在另一个方向上发送令牌。令牌绕着环循环到达任何一个目标站。为了阻止帧陷入无限循环，应设置帧必须从某个站取下，如可设置为最初发送帧的原始站，经历一个完整的环后取下。 令牌： 特殊格式的MAC帧，不含任何信息。令牌控制信道的使用，确保同一时刻只有一个结点独占信道。 每个结点都可以在一定的时间内(令牌持有时间）获得发送数据的权利，并不是无限制地持有令牌。 缺点： 令牌开销 等待延迟 单点故障（替代机解决） 局域网 局域网（ Local Area Ne twork, LAN) 是指在一个较小的地理范围内，将各种计算机、外部设备和数据库系统等通过双绞线、同轴电缆等连接介质互相连接起来，组成资源和 信息共享的计算机互连网络。主要特点如下：\n为一个单位所拥有，且地理范围和站点数目均有限。 所有站点共享较高的总带宽（即较高的数据传输速率）。\n较低的时延和较低的误码率。\n各站为平等关系而非主从关系。\n能进行广播和多播。\n局域网的介质访问控制方法主要有 CSMA/CD 协议、令牌总线协议和令牌环协议，其中前两 种协议主要用千总线形局域网，令牌环协议主要用于环形局域网。\n经典以太网 以太网是目前最流行的有线局域网技术。以太网逻辑上采用总线形拓扑结构，所有计算机共 享同一条总线，信息以广播方式发送，以太网使用 CSMAJCD 方式对总线进行访问控制。\n以太网采用两项措施来简化通信：\n采用无连接的工作方式，既不对发送的数据帧编号，又不要求接收方发送确认，即以太网尽最大努力交付数据，提供的是不可靠服务，对差错的纠正则由高层完成。\n发送的数据都使用曼彻斯特编码的信号，每个码元的中间出现一次电压转换，接收方利用这种电压转换方便地将位同步信号提取出来。\n网卡：\n计算机与外界局域网的连接是通过主板上嵌入的一块网络适配器 (Adapter) ［又称网络接口卡NlC)] 实现的。适配器上装有处理器和存储器，工作在数据链路层。适 配器和局域网的通信是通过电缆或双绞线以串行方式进行的，而适配器和计算机的通信则是通过 计算机的1/0 总线以并行方式进行的。因此，适配器的重要功能就是进行数据的串并转换。 适配器不仅能实现与局域网传输介质之间的物理连接和电信号匹配，还涉及帧的发送与接 收、帧的封装与拆封、介质访问控制、数据的编码与解码及数据缓存等功能。当适配器收到正确 的帧时，就使用中断来通知该计算机，并交付协议栈中的网络层。当计算机要发送 IP 数据报时， 就由协议栈把 IP 数据报向下交给适配器，组帧后发送到局域网。\n以太网的MAC地址\nlEEE 802 标准为局域网规定了一种 48 位的全球地址，是指厄域网上的每台计算机中固化在适 配器的 ROM 中的地址，称为物理地址或 MAC 地址（因为这种地址用在 MAC 帧中），这个地址用 千控制主机在树络上的数据通信。全世界所有的局域网适配器都具有不同的地址，一台计笃机只要 没有更换适配器，不管其地理位翌如何变化，共 MAC 地址都不会变化。\nMAC 地址长 6 字节，一般用由连字符（或冒号）分隔的 12 个十六进制数表示，如 02-60-8c-e4-b1-21 。高 24 位为厂商代码，低 24 位为厂商自行分配的适配器序列号。\n当路由器通过适配器连接到局域网时，适配器上的 MAC 地址就用来标志路由器的某个接口。 路由器若同时连接到两个网络上，则它需要两个适配器和两个 MAC 地址。\n以太网的MAC帧\n目标地址 如果传输出去的目标地址第一位是 0，则表示这是一个普通地址；如果是 1，则表示这是一个组地址。组地址允许多个站同时监听一个地址。当某个帧被发送到一个组地址， 该组中的所有站都要接收它。往一组地址的发送行为称为组播 (multicasting)。由全 1 组成的特殊地址保留用作广播 (broadcasting)。如果一个帧的目标地址字段为全 1，则它被网络上的所有站接收。\nMAC 地址 站的源地址有一个有趣的特点，那就是它们具有全球唯一性。\n地址字段的前 3 个字节用作该站所在的组织唯一标识符 (OUI, Organizationally Unique Identifier)。该字段的值由 IEEE 分配，指明了网络设备制造商。\n地址字段的最后 3 个字节由制造商负责分配，并在设备出厂之前把完整的地址用程序编入 NIC\n数据字段和长度范围 接下来是数据 (Data) 字段，最多可包含 1500 个字节。总帧长度最多 1518 字节。\n以太网要求有效帧必须至少 64 字节长，从目标地址算起直到校验和，包括这两个字段本身在内。如果帧的数据部分少于 46 个字节，则使用填充 (Pad) 字段来填充该帧，使其达到最小长度要求\n数据字段下限的原因 当 B 检测到它所接收到的信号比它发送的信号更强时，它知道已经发生了冲突，所以放弃了自己传送，并且产生一个 48 位的突发噪声以警告所有其他站。\n如果一个站试图传送非常短的帧，则可以想象：虽然发生了冲突，但是在突发噪声回到发送方 (2 て）之前，传送已经结束。然后，发送方将会得出刚オ一帧已经成功发送的错误结论。为了避免发生这样的情况，所有帧必须至少需要 2 て时间才能完成发送，这样当突发噪声回到发送方时传送过程仍在进行。\n二进制指数后退 (binary exponential backoff) 一般地，在第i�次冲突之后，从0∼2i−10∼2�−1之间随机选择一个数，然后等待这么多个时间槽。然而，达到 10 次冲突之后，随机数的选择区间被固定在最大值 1023，以后不再增加。在 16 次冲突之后，控制器放弃努力，并给计算机返回一个失败报告。\n交换式以太网 交换机 交换机只把帧输出到该帧想去的端口。当交换机端口接收到来自某个站的以太网帧，它就检査该帧的以太网地址，确定该帧前往的目的地端口\n在集线器中，所有站都位于同一个冲突域 (collision domain)， 它们必须使用 CSMA/CD 算法来调度各自的传输。在交换机中，每个端口有自己独立的冲突域。通常情况下，电缆是全双工的，站和端口可以同时往电缆上发送帧，根本无须担心其他站或者端口。现在冲突不可能发生，因而 CSMA/CD 也就不需要了。然后，如果电缆是半双工的，则站和端口必须以通常的 CSMA/CD 方式竞争传输。\n交换机的优点 交换机的性能优于集线器有两方面的原因。首先，由于没有冲突，容量的使用更为有效。其次，也是更重要的，有了交换机可以同时发送多个帧（由不同的站发出）。这些帧到达交换机端口并穿过交换机背板输出到适当的端口\n帧被发送到输出端口还有利于安全。大多数 LAN 接口都支持混杂模式 (promiscuous mode)，这个模式下所有的帧都被发到每台计算机，而不只是那些它寻址的机器。每个连到集线器上的计算机能看到其他所有计算机之间的流量\n有了交换机，流量只被转发到它的目的端口。\n高速以太网 速率达到或超过 100Mb/s 的以太网称为高速以太网，表 3.3 列出了几种高速以太网技术。\n快速以太网 传输速率比传统快10倍，数据传输速率达到100Mb/s。用户只需更换一个适配器，再配上一个100Mb/s的集线器就可方便地由10BASE-T以太网直接升级到100Mb/s。目前的10Mb/s和100Mb/s以太网是使用无屏蔽双绞线布线的。\n千兆以太网 数据传输速率是快速以太网的10倍，可达到1Gb/s。吉比特以太网保留了传统10BASE-T以太网的基本特征，具有相同的帧格式和类似的组网方法 特点（802.3z标准的G比特以太网）： 支持全双工和半双工两种工作方式； 在半双工方式下采用CSMA/CD协议，而在全双工方式下不采用该协议； 向后兼容10BASE-T和100BASE-T技术。 1000BASE-T，即IEEE 802.3ab，使用4对5类非屏蔽双绞线，双绞线长度可达100 m。 1000BASE-X，即IEEE 802.3z，有以下3种有关传输介质的标准： 1000BASE-CX； 1000BASE-LX； 1000BASE-SX。 万兆以太网 又称万兆以太网，使用IEEE 802.3以太网介质访问控制MAC协议 特征： 只支持双工模式，不支持单工模式，而传统的以太网标准均支持单工/双工模式。 由于传输速率高，10吉比特以太网只能使用光纤作为传输介质，而传统的以太网标准均支持同轴电缆。 不支持CSMA/CD协议，因为该协议只适用于速率较慢的单工以太网。 使用64B/66B和8B/10B两种编码方式，而传统以太网只使用8B/10B的编码方式。 具有支持局域网和广域网的接口，且有效距离可达40 km，而传统的以太网只支持局域网应用，有效传输距离不超过5 km。 无线局域网 802.11 体系结构和协议栈 有固定基础设施的无线局域网\n无固定基础设施移动自组织网络\n802.11局域网的MAC帧 数据帧的第二个字段为持续时间 (Duration) 字段，它通告本帧和其确认将会占用信道多长时间，按微秒计时。该字段会出现在所有帧中，包括控制帧，其他站使用该字段来管理各自的 NAV 机制。\n接下来是地址字段。发往 AP 或者从 AP 接收的帧都具有 3 个地址，这些地址都是标准的 IEEE802 格式。第一个地址是接收方地址，第二个地址是发送方地址。很显然，这两个地址是必不可少的，那么第三个地址是做什么用的呢？请记住，当帧在一个客户端和网络中另一点之间传输时，AP 只是一个简单的中继点。这网络中的另一点也许是一个远程客户端，或许是 Internet 接入点。第三个地址就指明了这个远程端点\n虚拟局域网 VLAN 和配置表 为了使 VLAN 正常地运行，网桥必须建立配置表。这些配置表指明了通过哪些端口可以访问到哪些 VLAN。当一帧到来时，比如说来自灰色 VLAN，那么这帧必须被转发到所有标记为 G 的端口。这一条规则对于网桥不知道目的地位置的普通流量（即单播）以及组播和广播流量都适用。注意，一个端口可以标记为多种 VLAN 颜色。\nVLAN 帧格式 VLAN 感知 因为存在一些计算机（和交换机）无法感知 VLAN，因此第一个 VLAN 感知的网桥在帧上添加一个 VLAN 字段，路径上的最后一个网桥把添加的 VLAN 字段删除。\n广域网 广域网(Wide Area Network,WAN) 通常是指毅盖范围很广（远超一个城市的范围）的长距离网络，任务是长距离运送主机所发送的数据。连接广域网各结点交换机的链路都是高速链路， 广域网首要考虑的问题是通信容昼必须足够大，以便支持日益增长的通信拭。 广域网不等千互联网。互联网可以连接不同类型的网络，通常使用路由器来连接。图 3.32 显示了由相距较远的局域网通过路由器与广域网相连而成的一个栩盖范围很广的互联网。因此，局域网可以通过广域网与另一个相隔很远的局域网通信。\n广域网由一些结点交换机（注意不是路由器，结点交换机和路由器都用来转发分组，它们的 工作原理也类似。结点交换机在单个网络中转发分组，而路由器在多个网络构成的互联网中转发 分组）及连接这些交换机的链路组成。结点交换机的功能是存储并转发分组。结点之间都是点到点连接，但为了提高网络的可靠性，通常一个结点交换机往往与多个结点交换机相连。从层次上考虑，广域网和局域网的区别很大，因为局域网使用的协议主要在数据链路层（还有少量在物理层），而广域网使用的协议主要在网络层。怎么理解“局域网使用的协议主要在数据链路层，而广域网使用的协议主要在网络层“这句话呢？若网络中的两个结点要进行数据交换， 则结点除了要给出数据，还要给数据“包装”上一层控制信息，用于实现传输控制等功能。若这 层控制信息是数据链路层协议的控制信息，则称使用了数据链路层协议；若这层控制信息是网络 层的控制信息，则称使用了网络层协议。\n数据链路层协议实例 PPP **点对点****协议（Point-to-Point Protocol， PPP）**是目前使用最广泛的数据链路层协议，用于使用拨号电话接入因特网时一般都使用PPP协议，是面向字节的数据链路层协议。 PPP协议只支持全双工链路。\n组成 一种将封装了多种协议的数据报传输到串行链路的方法。 链路控制协议（Link Control Protocol， LCP），LCP 协议是 PPP 协议的一部分。它用于建立、配置、测试数据链路的连接。 一套网络控制协议（Network Control Protocol， NCP），NCPs 是一系列协议，用于建立和配置不同的网络层协议。每个 NCP 协议都支持不同的网络层协议，比如 IP 协议，OSI 的网络层，苹果的 Appple Talk 等。 帧格式 标志字段 标志（flag）：首部的第一个字段和尾部的最后一个字段都是标志字段 F（flag），规定的值用十六进制表示为：0x7E = 01111110。如果数据字段碰巧出现了标志字段的值，则需要在数据字段进行字节填充，来消除这种歧义。 PPP 协议可以应用在异步传输或者同步传输中，异步传输以字节为单位传输，同步传输以比特为单位传输。所以填充方式也分为字节填充和比特填充。 字节填充 当 PPP 使用异步传输时，如果信息字段出现了和标志字段一样的字节（0x7E 为开始/结束字符，0x7D 为转义字符），就需要进行字节填充，核心思路是通过在该字节前面填充转义字符（escape character， ESC）。 然后用0x20 xor后面那个 比特填充 PPP 协议在用在同步光纤网络等链路时，会使用同步传输（将一连串的比特连续传送，而不是按字节为单位传送）。这时候 PPP 协议采用比特填充。 PPP协议的应满足的需求 (1) 简单。对数据链路层的帧，无需差错恢复，无需序号，无需流量控制。 (2) 封装成帧。PPP协议必须规定特殊的字符作为帧定界符（标志着一个帧的开始和结束）。 (3) 透明传输。与帧定界符一样的比特组合应该如何处理。 (4) 差错检测：接收到错误的帧就直接丢弃。 (5) 最大传送单元：数据部分最大长度MTU。 \u0026hellip;.\nPPP协议的不需要满足的需求 (1) 无需差错纠正/恢复。 (2) 无需流量控制。 (3) 无需支持多点链路。 (4) 不存在乱序交付。 差错恢复、流量控制等由高层协议处理。\nHDLC HDLC 称为“高级数据链路控制协议”，它是一个在同步网络上传输的、面向比特位的数据链路层协议。\n数据报文可透明传输，用于实现透明传输的是“零比特插入法”，易于硬件实现。\n采用全双工通信。 所有帧采用CRC校验，对信息帧进行顺序编号，可防止漏收或重传，传输可靠性高。\nHDLC站 HDLC站分为：主站、从站和复合站。 (1) 主站：发送命令（包括数据信息）帧，接收响应帧，并负责对整个链路的控制系统的初启、流程控制、差错检测或恢复等。 (2) 从站：接收由主站发来的命令帧，向主站发送响应帧，并且配合主站参与差错恢复等链路控制。 复合站：既能发送，又能接收命令帧和响应帧，并且负责这整个链路的控制。\nHDLC的帧格式 (1) 标志（Flag）字段：占一个字节，二进制位01111110。 (2) 控制（Control）字段：表示帧的类型。分为三种：信息帧（I）、监督帧（S）、无编号帧（U）。\n(1) 信息帧：控制字段第1位为0，用来传输数据信息，或使用捎带技术对数据进行确认。 (2) 监督帧：前两位比特是10，用于流量控制，执行对信息帧的确认、请求重发和请求暂停发送等功能。 (3) 无编号帧：前两位比特是11，用于提供对链路的建立、拆除等多种控制功能。\nPPP协议和HDLC协议比较 相同点： (1) PPP、HDLC协议都支持全双工链路。 (2) 都可以实现透明传输。 (3) 都可以实现差错检测，但都不纠正差错。\n不同点： (1) PPP协议面向字节，HDLC协议面向比特。 (2) HDLC协议帧格式没有协议字段。 (3) PPP协议无序号和确认机制，HDLC协议有编号和确认机制。 (4) PPP协议不可靠，HDLC协议可靠。\n（5）PPP 可以用于同步传输也可以用于异步传输，而 HDLC 只能用在同步网上\n数据链路层设备 以太网交换机 以太网交换机也称二层交换机，二层是指以太网交换机工作在数据链路层。以太网交换机实质上是一个多接口的网桥，它能将网络分成小的冲突城，为每个用户提供更大的带宽。对于传统使用集线器的共享式 10Mb/s 以太网，若共有N个用户，则每个用户的平均带宽为总带宽（10Mb/s）的 1/。使用以太网交换机（全双工方式）连接这些主机时，虽然从每个接口到主机的带宽还是10Mb/s，但是因为一个用户通信时是独占带宽的（而不是和其他网络用户共享传输介质带宽的），所以拥有N个接口的交换机的总容量为 Nx10Mb/s。这正是交换机的最大优点。\n以太网交换机的特点：1）当交换机的接口直接与主机或其他交换机连接时，可工作在全双工方式，并能同时连通多对接口，使每对相互通信的主机都能像独占通信介质那样，无冲突地传输数据，这样就不需要使用 CSMA/CD 协议。2）当交换机的接口连接集线器时，只能使用 CSMA/CD 协议且只能工作在半双工方式。当前的交换机和计算机中的网卡都能自动识别上述两种情况。3）交换机是一种即插即用设备，其内部的帧转发表是通过自学习算法，基于网络中各主机间的通信，自动地逐渐建立的。4）交换机因为使用专用交换结构芯片，交换速率较高。5） 交换机独占传输介质的带宽。\n以太网交换机主要采用两种交换模式：1） 直通交换方式。只检查帧的目的MAC 地址，以决定该帧的转发接口。这种方式的交换时延非常小，缺点是它不检查差错就直接转发，因此可能将一些无效帧转发给其他站。直通交换方式不适用于需要速率匹配、协议转换或差错检测的线路。2）存储转发交换方式。先将接收到的帧缓存到高速缓存器中，并检查数据是否正确，确认无误后通过查找表转换为输出接口，以便将该帧发送出去。若发现帧有错，则将其丢弃。优点是可靠性高，且能支持不同速率接口间的转换，缺点是时延较大。交换机一般都具有多种速率的接口，如10Mb/s、100Mb/s 的接口，以及多速率自适应接口。\n交换机的自学习功能 决定一个帧是转发到某个接口还足丢弃它称为过虎。决定一个帧应被移至哪个接口称为转发。交换机的过滤和转发借助交换表 (switch table) 完成。交换表中的一个表项至少包含： 一 个 MAC 地址和连通该 MAC 地址的接口。\n共享式以太网和交换式以太网的对比\n假设交换机已通过自学习算法逐步建立了完整的转发表，下面举例说明使用镁线器的共享式 以太网与全部使用交换机的交换式以太网的区别。 l) 主机发送普通帧。对于共享式以太网，集线器将帧转发到其他所有接口，其他各主机中\n的网卡根据帧的目的 MAC 地址决定接收或丢弃该帧。对于交换式以太网，交换机收到帧 后，根据帧的目的 MAC 地址和自身的交换表将帧明确地转发给目的主机。\n主机发送广播帧。对于共享式以太网，媒线器将帧转发到其他所有接口，其他各主机 中的网卡检测到帧的目的 MAC 地址是广播地址时，就接收该帧。对于交换式以太网， 交换机检测到帧的目的 MAC 地址是广播地址，千是从其他所有接口转发该帧，其他\n各主机收到该广播帧后，就接收该帧。两种悄况从效果上看是相同的，但它们的原理 并不相同。\n多对主机同时通信。对千共享式以太网，当多对主机同时通信时，必然产生冲突。对千 交换式以太网，交换机能实现多对接口的商速并行交换，因此不会产生冲突。 ","date":"2024-01-21T15:23:20Z","permalink":"http://localhost:1313/post/3-%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/","title":"3 数据链路层"},{"content":"栈 栈的定义 栈是一种特殊的线性表，限定插入和删除操作只能在表尾进行。后进先出。\n栈的基本操作 InitStack(\u0026amp;S)：初始化一个空栈 StackEmpty(S)：判断一个栈是否为空，若栈S为空则返回true，否则返回false。 Push(\u0026amp;S,x)：进栈，若栈s未满，则将x加入使之成为新栈顶。 Pop (\u0026amp;S,\u0026amp;x)：出栈，若栈S非空，则弹出栈顶元素，并用x返回。 GetTop(S,\u0026amp;x)：读找顶元素，但不出栈，若栈S非空，则用x返回栈顶元素。 DestroyStack(\u0026amp;S)：销毁栈，并释放栈S占用的存储空间（\u0026quot;\u0026amp;\u0026ldquo;表示引用调用）。 在解答算法题时，若题干未做出限制，则也可直接使用这些基本的操作函数。\n栈的数学性质：当n个不同元素进栈，出栈元素的不同排列数为$\\frac 1 {n+1}C^n _{2n}$\n栈的顺序存储结构 顺序栈的实现 类型描述：\n#define MaxSize 50 typedef struct{ Elemtype data[MaxSize]; int top; } 栈中的元素用一组连续的存储空间来存放的。栈底位置设置在存储空间的一个端点，而栈顶是随着插入和删除而变化的，非空栈中的栈顶指针top来指向栈顶元素的下一个位置。\n栈顶指针：S.top，初始值设置S.top=-1；栈顶元素：S.data[S.top]\n进栈操作：栈不满时，栈顶指针+1，再送值到栈\n出栈操作：栈非空时，先取栈顶元素，再将栈顶指针-1。\n栈空条件：S.top==-1；栈满条件：S.top==MaxSize-1；栈长：S.top+1\n顺序栈的基本操作 初始化 首先建立栈空间，然后初始化栈顶指针。\nvoid InitStack(SqStack \u0026amp;S){ S.top=-1; } 判栈空 bool StackEmpty(SqStack S){ if(S.top==-1){ return true; }else{ return false; } } 入栈 bool Push(SqStack \u0026amp;S,ElemType x){ if(S.top==MaxSize-1) return false; S.data[++S.top]=x; // 指针要先加1再入栈 return true; } 出栈 bool Pop(SqStack \u0026amp;S,ElemType \u0026amp;x){ if(S.top==-1) return false; x=S.data[S.top--]; // 先出栈，指针再减1 return true; } 取栈顶元素 bool GetTop(SqStack S,ElemType \u0026amp;x){ if(S.top==-1) return false; x=S.data[S.top]; return true; } 共享栈 两个顺序栈共享一个一维数组空间。\n数组(栈空间) + 两个栈顶指示\ntypedef struct{ Elemtype *top1; Elemtype *top2; Elemtype *base; int stacksize; }SqStack; 两个栈顶指针都指向栈顶元素，top1=-1时1号栈为空，top2=stacksize的时候2号栈为空；当两个栈顶指针相邻的时候top2-top1=1，栈满；\n链栈 typedef struct node{ SElemType data; struct node *next; }LinkStack; LinkStack *top; 栈顶指针（链首指针）指向队尾元素an，和单链表相反。\n链栈不需要事先分配空间\n在进行入栈操作时不需要顾忌栈的空间是否已经被填满\n链栈的节点结构和单链表的节点结构相同，由于栈只在栈顶作插入和删除操作，因此链栈中不需要头结点，但要特别注意链栈中指针的方向是从栈顶指向栈底的，这正好和单链表是相反的。\n(1)入栈 Status Push_LinkStack(LinkStack \u0026amp;top,SElemType e){ s=malloc(sizeof(LinkStack)); s-\u0026gt;data=e; s-\u0026gt;next=top; top=s; return OK; } 核心思路：创建一个结点，把结点插入到链表的第一个位置\n(2)出栈 Status Pop_LinkStack (\u0026amp;top,ElemType \u0026amp;e){ if(top==NULL) return ERROR; e=top-\u0026gt;data; p=top; top=top-\u0026gt;next; free(p); return OK; } 栈的应用举例 括号匹配检验 问题描述\n假设表达式中允许包含两种括号：圆括号和方括号，其嵌套的顺序随意，如（［ ］（））或［（［ ］［ ］）］等为正确的匹配。 算法核心思路：\n检查表达式中的字符，遇到左括号入栈，遇到右括号则出栈栈顶元素与其匹配，如果匹配成功则继续，否则退出。 表达式求值 表达式由操作数、运算符、括号组成。在此运算符仅含+ - * / % ^ ()。例如： 3*2^(4+2*2-1*3)-5\n设运算规则为： 1） 优先级（ ）→ ^ → ×、/、% → +、- ； 2）有括号出现时先算括号内的，后算括号外的，多层括号，由内向外进行； 3） 乘方连续出现时先算最右面的。\n中缀表达式求值 数据结构：运算操作数栈s1和运算符栈s2。\n算法思想：\n自左向右扫描表达式的每一个字符 若当前字符是操作数，入操作数栈 若当前字符是运算符时 若这个运算符比栈顶运算符高，则入栈，继续向后处理 若这个运算符比栈顶运算符低，则从对象栈出栈两个运算对象，从算符栈出栈一个运算符进行运算，并将其结果入对象栈 后缀表达式求值 从左往右依次扫码每一个字符，如果是操作数，入栈；如果是运算符，从栈中弹出两个操作数进行运算，并将结果入栈。\n中缀表达式表达式 3*2^（4+2*2-1*3）-5的后缀表达式为： 3 2 4 2 2 * + 1 3 * - ^ * 5 -\n中缀表达式转换成后缀表达式 操作数，加入后缀表达式 界限符()，若为(，直接入栈；若为)，依次弹出栈中的运算符，并加入后缀表达式，直到弹出(，)不入栈。 运算符 优先级高于栈顶运算符，直接入栈 否则，依次弹出栈中优先级高于或等于当前运算符的所有运算符，并加入后缀表达式，直到遇到一个优先级低于它的或)，之后将当前运算符入栈。 递归 递归算法的设计一般分为两步: 第一步，将规模较大的原问题分解为一个或多个规模较小的而又类似于原问题特性的子问题，既将较大的问题递归地用较小的子问题来描述，解原问题的方法同样可以用来解决子问题；\n第二步，是确定一个或多个不需要分解、可直接求解的最小子问题。\n递归调用的内部过程 在这两个阶段中，系统会分别完成一系列的操作。在递归调用之前，系统需完成三件事：\n为被调用过程的局部变量分配存储区； 将所有的实参、返回地址等信息传递给被调用过程保存； 将控制转移到被调过程的入口。\n从被调用过程返回调用过程之前，系统也应完成三件工作：\n保存被调过程的计算结果； 释放被调过程的数据区； 依照被调过程保存的返回地址将控制转移到调用过程。\n在计算机中，是通过使用系统栈来完成上述操作的。\n队列 队列的基本概念 定义 队列是一种特殊的线性表，限定插入和删除操作分别在表的两端进行。具有先进先出(FIFO—First In First Out)的特点\n把允许插入的一端叫队尾(rear) ，把允许删除的一端叫队头(front)。没有元素时称为空队列。\n队列的常见基本操作 InitQueue(\u0026amp;Q): 初始化队列，构造一个空队列Q。 QueueEmpty(Q)：判队列空，若队列Q为空返回true，否则返回 false。 EnQueue (\u0026amp;Q, x)：入队，若队列Q未满，将x加入，使之成为新的队尾。 DeQueue (\u0026amp;Q, \u0026amp;x)：出队，若队列Q非空，删除队头元素，并用x返回。 GetHead (Q, \u0026amp;x)：读队头元素，若队列Q非空，则将队头元素赋值给x。 队列的顺序存储结构 队列的顺序存储 #define MaxSize 50 typedef struct{ ElemType data[MaxSize]; int front,rear; }SqQueue; 两个指针front和rear分别指示队列头元素及队列尾元素的位置。 空队列时front=rear=0; 每当插入新的队列尾元素时，尾指针增1，因此在非空队列中，头指针始终指向队列头元素，而尾指针始终指向队列尾元素的下一个位置。\n随着入队出队的进行，会使整个队列整体向后移动，出现“假溢出”（最右图）\n循环队列 解决假溢出的方法：将队列的数据区看成头尾相接的循环结构，头尾指针的关系不变，将其称为循环队列。\n初始时：Q.front=Q.rear=0\n队首指针进1：Q.front=(Q.front+1)%MaxSize\n队尾指针进1：Q.rear=(Q.rear+1)%MaxSize\n可见在队满和队空情况下都有：front==rear， 这显然是必须要解决的一个问题。\n三种方法：\n附设一个存储队中元素个数的变量如num，当num==0时队空，当num==MAXSIZE时为队满。\n少用一个元素空间，当队尾指针加1就会从后面赶上队头指针，这种情况下队满的条件是：(rear+1) % MAXSIZE ==front，也能和空队区别开。\n用tag区分队满还是队空。\n我们采用第二种方法。\ntypedef struct { //队列的顺序存储结构 QElemType *base; int front; int rear; } SeQueue; (1)初始化 //初始化 Status InitQueue ( SqQueue \u0026amp;Q) { Q.base =(QElemType *)malloc(MAXQSIZE*sizeof(QElemtype) ); if(!Q.base) exit (OVERFLOW); Q.front = Q.rear = 0; return OK; } (2)判队空 Status QueueEmpty(SqQueue Q){ if(Q.front==Q.rear) return TRUE; else return FALSE; } (3)判队满 Status QueueFull(SqQueue Q){ if((Q.rear+1)%MAXQSIZE==Q.front) return TRUE; else return FALSE; } (4)求队长 int QueueLength(SqQueue Q){ return (Q.rear-Q.front+MAXQSIZE)%MAXQSIZE; } (5)入队 Statue EnQueue(SqQueue \u0026amp;Q,Elemtype e) { if ( (Q.rear +1) % MAX = = Q.front ) return ERROR; Q.base [Q.rear ]= e; Q.rear = (Q.rear +1) % MAXQSIZE; return OK; } (6)出队 Status DeQueue ( SqQueue \u0026amp;Q , Elemtype \u0026amp;e ) { if (Q.front = = Q.rear ) return ERROR; e = Q.base[Q.front ] ; Q.front = (Q.front +1) % MAXQSIZE; return OK; } 队列的链式存储结构 链式存储的队称为链队。和链栈类似，用单链表来实现链队，根据队的FIFO原则，为了操作上的方便，我们分别需要一个头指针和尾指针，如图所示。\n[类型定义] 队头指针 + 队尾指针\ntypedef struct QNode{ QElemtype data; struct QNode *next; } Qnode, *QueuePtr; typedef struct { QueuePtr front; QueuePtr rear; }LinkQueue; 带头结点的链队如图所示：\n(1) 初始化链队 Status InitQueue ( LinkQueue \u0026amp;Q ) {// 链队带头结点 Q.front = Q.rear = (QueuePtr)malloc(sizeof(Qnode)) ; if(!Q.front) exit (OVERFLOW); Q.front-\u0026gt;next = NULL; return OK; } (2) 入链队 Status EnQueue (LinkQueue \u0026amp;Q, QElemtype e) { p = (QueuePtr)malloc(sizeof(QNode)); if (!p) exit (OVERFLOW); p-\u0026gt;data=e; p-\u0026gt;next=NULL; Q.rear-\u0026gt;next=p; Q.rear=p; return OK; } (3) 出链队 Status DeQueue ( LinkQueue \u0026amp;Q, QElemtype \u0026amp;e ) { // 链队带头结点 if ( Q.front = = Q.rear ) return ERROR; //如果为空 p = Q.front-\u0026gt;next; e = p-\u0026gt;data; Q.front-\u0026gt;next = p -\u0026gt;next; if(Q.rear == p) Q.rear = Q. front; //如果出队的是最后一个元素 free (p); return OK; } 双端队列 两端都能入队出队。\n输出受限的双端队列：允许在一端进行插入和删除，但是另一端只允许插入\n输入受限的双端队列：允许在一端进行插入和删除，但是另一端只允许删除\n队列应用举例 广度优先搜索（BFS，Breadth-first_Search），适合用队列实现。\n根节点入队 若队空，结束遍历；否则重复3 队列中的第一个节点出队，并访问；如果有左右孩子，依次入队。 数组 数组的定义 任何数组A都可以看作一个线性表\n$A=\\left(a_1, a_2, \\ldots, a_i, \\ldots a_n\\right)$\n二维数组m*n时， $a_i$是数组中第i列所有元素，表中每一个元素是一个一维数组\n三维数组时， 表中每一个元素是一个二维数组；\nn维数组时， 表中每一个元素是一个(n-1)维数组。\n数组与线性表之间的关系：线性表的扩展，其数据元素本身也是线性表\n数组的特点\n数组中各元素都具有统一的类型 可以认为，d维数组的非边界元素具有d个直接前趋和d个直接后继 数组维数确定后，数据元素个数和元素之间的关系不再发生改变， 适合于顺序存储 每组有定义的下标都存在一个与其相对应的值 在数组上的基本操作\n给定一组下标，取得相应的数据元素值 给定一组下标，修改相应的数据元素值 数组的基本操作定义\n(1)构造n维数组 InitArray(\u0026amp;A, n, bound ${ }_1, \\ldots$, bound $_n$ ) (2)销毁数组A DestroyArray(\u0026amp;A) (3)取得指定下标的数组元素值 Value( $\\left.A, \u0026amp; e, \\operatorname{index}_1, \\ldots, \\operatorname{index}_n\\right)$ (4)为指定下标的数组元素重新赋值 Assign(\u0026amp;A, e, index,$\\ldots$, index $\\left._n\\right)$\n数组的存储结构 一维数组\nElemType a[n]\n二维数组\nElemType a[m][n] //n是第二维的长度\nn维数组\nElemType a[b1][b2] ... [bn] ;\n数组是一种随机存取结构:对任一元素定位时间相等.\n特殊矩阵的压缩存储 对称矩阵 [存储方法]\n只存储下(或者上)三角(包括主对角线)的数据元素。共占用n(n+1)/2个元素空间: sa[0\u0026hellip; n(n+1)/2-1] 。\n三角矩阵 [存储方法]\n重复元素c共享一个元素存储空间，共占用n(n+1)/2+1个元素空间: sa[1.. n(n+1)/2]。sa[0]=C\n带状矩阵（对角矩阵） 在n*n的方阵中，非零元素集中在主对角线及其两侧共L(奇数)条对角线的带状区域内 — L对角矩阵。\n[存储方法] 只存储带状区内的元素。\n公式推导\nk=2i+j-3推导过程：\n当i=1时，只有两个元素。当i=2~i-1时，每一行都有三个元素。在最后的i行，有j-i+1个元素。\nk=2+（i-1-2+1)*3 + (j-i+1)= 2i+j-3\ni=(k+1)/3+1,j=k-2i+3推导过程：\ni j k 1 1 0 1 2 1 2 1 2 2 2 3 2 3 4 3 2 5 3 3 6 3 4 7 4 3 8 4 4 9 k=2i+j-3 i=(k+1)/3+1 j=k-2i+3\n稀疏矩阵 大多数元素为零\n记录每一非零元素(i, j, aij) 节省空间，但丧失随机存取功能 顺序存储：三元组表 链式存储：十字(正交)链表\n","date":"2024-01-20T20:20:39Z","permalink":"http://localhost:1313/post/3-%E6%A0%88%E9%98%9F%E5%88%97%E5%92%8C%E6%95%B0%E7%BB%84/","title":"3 栈、队列和数组"},{"content":"物理层的功能 物理层是计算机网络分层结构的最低一层。物理层负责通过物理介质移动数据，涉及在介质上传输的信号和比特流。根据网络传输过程，物理层从数据链路层接收完整的帧(Frame)，将二进制编码为一系列信号，并通过本地物理介质传输这些信号。\n基本概念 信号 #card\n信号是数据的电气或电磁表现，可分为模拟信号（连续信号）和数字信号（离散信号）。\n码元 #card\n一个离散信号状态或信号事件 表示一位k进制数字（k进制码元） 1码元携带$log_2k$bit信息量\n数据率Bit rate\n数据传输速率 bps\n波特率Baud rate #card\n码元传送速率 $1 Baud = (log_2V)bps$ V是信号的电平级数\n信噪比S/N #card\n$SNR(db)=10log_{10} \\frac S N$\n$\\frac S N=10^{\\frac {SNR} {10}}$\n信道 信道Channel #card\n传送信息的媒体\n基带信号和宽带信号 信道按传输信号形式的不同，可分为传送模拟信号的模拟信道和传送数字信号的数字信道两\n大类；信道按传输介质的不同可分为无线信道和有线信道。\n基带信号(Baseband signaling) #card\n基带信号将数字信号 1 和 0 直接用两种不同的电压表示，然后送到数字信道上传输。占用整条网线的信号传输。\n宽带信号传输(Broadband signaling) #card\n宽带信号将基带信号进行调制后形成频分复用模拟信号，然后送到模拟信道上传输。一条网线可以传输多种不同的信号。\n单工/半双工/全双工 单工simplex/半双工half-duplex/全双工full-deplex #card\n单工：只有一个方向 半双工：双方都能发送信号，但是不能同时发送 全双工：通信双方都能同时发送消息 串行传输和并行传输 串行传输serial transmission和并行传输parallel transmission #card\n串行传输是指 1 比特 1 比特地按照时间顺序传输（远距离通信通常采用串行传输） 并行传输是指若干比特通过多条通信信道同时传输。 异步传输和同步传输 异步串行传输 #card\n独立时钟，无须同步 以字符为单位进行传输，发送两个字符之间的间隔是任意的 每个字节的开始位置发送一个起始位（0），结束时发送1个或者多个停止位（1），每个字节之间会有一个时间间隔 接收方依靠字符中的起始位和停止位来同步 同步串行传输 #card\n以时钟信号线对传输的数据线上的信号进行比特同步 以数据块（帧或分组）为单位传输 信道的极限容量 Nyquist 奈奎斯特准则 #card\n无噪声信道 $C=2Blog_2V$\nShannon 香农定理 #card\n有噪声信道 $C=Blog_2(1+S/N)$\n计算后取二者中的最小值\n编码与调制 把数据变换为模拟信号的过程称为调制，把数据变换为数字信号的过程称为编码。\n数字数据编码为数字信号 数字数据编码用于基带传输中，即在基本不改变数字数据信号频率的情况下，直接传输数字 信号。\n归零(RZ)编码。#card 用高电平表示 1 、低电平表示 0 （或者相反），每个码元的中间均跳变到零电平（归零），接收方根据该跳变调整本方的时钟基准，这就为收发双方提供了自同步机制。 因为归零需要占用一部分带宽，所以传输效率受到了一定的影响。 非归零 (NRZ) 编码。#card\n与 RZ 编码的区别是不用归零，一个时钟全部用来传输数据，编码效率最高。 但 NRZ 编码的收发双方存在同步问题，为此需要双方都带有时钟线。 反向非归零 (NRZI) 编码。#card\n与 NRZ 编码的区别是用电平的跳变表示 0 、电平保待不变表示 1 。 跳变信号本身可作为一种通知机制。这种编码方式媒成了前两种编码的优点，既能传输时钟信号，又能尽虽不损失系统带宽。 USB 2.0 的编码方式就是 NRZI 编码。 曼彻斯特编码。#card\n每个码元的中间都发生电平跳变，电平跳变既作为时钟信号（用于同步）， 又作为数据信号。可用向下跳变表示1、向上跳变表示0，或者采用相反的规定。 编码速率是码元速率的 2 倍，所占的频带宽度是原始基带宽度的 2 倍。 标准以太网使用的就是曼彻斯特编码。 差分曼彻斯特编码。#card\n每个码元的中间都发生电平跳变，与曼彻斯特编码不同的是，电平跳变仅表示时钟信号，而不表示数据。 数据的表示在于每个码元开始处是否有电平跳变： 无跳变表示1，有跳变表示0。 差分曼彻斯特编码拥有更强的抗干扰能力。 编码速率是码元速率的 2 倍，所占的频带宽度是原始基带宽度的 2 倍。 差分曼彻斯特编码则被广泛用于宽带高速网中。 模拟数据编码为数字信号 主要包括采样、量化、编码三个步骤。\n数据传输率=采样频率×量化位数\n采样 #card\n是指对模拟信号进行周期性扫描，将时间上连续的信号变成时间上离散的信号。 采样定理：在将模拟信号转换成数字信号时，假设原始信号中的最大频率为f，那 么采样率j采样必须大于或等于最大频率 f 的 2 倍，才能保证采样后的数字信号完整保留原模拟信号的信息（只需记住结论）。另外，采样定理又称奈奎斯特定理。\n量化 #card\n是指将采样得到的电平幅值按照一定的分级标度转换为对应的数值并取整，这样就将连续的电平幅值转换为了离散的数字量。采样和量化的实质就是分割和转换。\n编码 #card\n是指将量化得到的离散整数转换为与之对应的二进制编码。\n数字数据调制为模拟信号 调制：将二进制数据转换为带通模拟信号\n正弦波由振幅、频率、相位定义\n数字数据调制为模拟信号的方法：\n幅移键控(amplitude shift keying, ASK) #card\n振幅随基带数字信号变化，频率和相位保持不变。通过改变载波的振幅来表示数字信号1和0。这种方式比较容易实现，但抗干扰能力差。如，用有载波和无载波输出分别表示 1 和 0。 频移键控(frequency shift keying, FSK) #card\n频率随基带数字信号变化，振幅和相位保持不变。通过改变载波的频率来表示数字信号1和0。这种方式容易实现，抗干扰能力强，目前应用较广泛。如，用频率f1和频率f2分别表示 1 和 0 。 相移键控(phase shift keying, PSK) #card\n相位随基带数字信号变化，频率和振幅保持不变。通过改变载波的相位来表示数字信号1和0。又分为绝对调相和相对调相。如，用相位 0 和 π分别表示 1 和 0, 是一种绝对调相方式。 正交振幅调制(quadrature amplitude modulation, QAM) #card\n振幅和相位变化结合在一起，形成叠加信号。设波特率为 B, 采用 m 个相位，每个相位有 n 种振幅，则该QAM的数据传输速率 R 为 $R=Blog_2(nm)$ (b/s) QAM 效率最高，目前Modem（调制解调器）使用的方法。\n模拟数据调制为模拟信号 为了实现传输的有效性，可能需要较高的频率。这种调制方式还可使用频分复用 (FDM) 技 术，充分利用带宽资源。电话机和本地局交换机采用模拟信号传输模拟数据的编码方式。\n电话系统 ADSL非对称数字用户线 有256个子信道，其中6个用于电话，2个用于控制，剩下248个用于数据。 语音信道带宽为4000Hz。 上行速度为64~640Kbit/s，下行速度为500Kbit/s-7Mbit/s。 传输介质 双绞线 双绞线是最常用的古老传输介质，它由两根采用一定规则并排绞合的、相互绝缘的铜导线组版。绞合可以减少对相邻导线的电磁干扰。为了进一步提高抗电磁干扰的能力，可在双绞线的外面再加一层，即用金属丝编织成的屏蔽层，这就是屏蔽双绞线 (STP) 。无屏蔽层的双绞线称为非屏蔽双绞线 (UTP) 。\n同轴电缆 同轴电缆由内导体、绝缘层、网状编织屏蔽层和塑料外层构成。按特性阻抗数值的不同，通常将同轴电缆分为两类： 50Q同轴电缆和 75Q同轴电缆。其中， 50Q同轴电缆主 要用千传送基带数字信号，又称基带同轴电缆，它在局域网中应用广泛： 75Q同轴电缆主要用于传送宽带信号，又称宽带同轴电缆，主要用于有线电视系统。\n由于外导体屏蔽层的作用，同轴电缆具有良好的抗干扰特性，被广泛用千传输较高速率的数据，其传输距离更远，但价格较双绞线贵。\n光纤 光纤通信就是利用光导纤维（简称光纤）传递光脉冲来进行通信。有光脉冲表示 1, 无光脉冲表示 0。可见光的频率约为$10^8$MHz, 因此光纤通信系统的带宽范围极大。光纤上要由纤芯和包层构成，纤芯很细，其直径只有 8 至 100µm,光波通过纤芯进行传导，包层较纤芯有较低的折射率。当光线从高折射率的介质射向低折射率的介质时，其折射角将大于入射角。因此，只要入射角大于某个临界角度，就会出现全反射，即光线碰到包层时就会折射回纤芯，这个过程不断重复，光也就沿着光纤传输下去。\n利用光的全反射特性，可以将从不同角度入射的多条光线在一根光纤中传输，这种光纤称为 多模光纤，多模光纤的光源为发光二极管。光脉冲在多模光纤中传输时会逐渐展宽，造成失真，因此多模光纤只适合于近距离传输。\n光纤的直径减小到只有一个光的波长时，光纤就像一根波导那样，可使光线一直向前传播， 而不会产生多次反射，这样的光纤就是单模光纤 。单模光纤的纤芯很细，直径只有几微米，制造成本较高。同时，单模光纤的光源为定向性很好的半导体激光器，因此单模光纤的衰减较小，可传输数公里甚至数十干米而不必采用中继器，适合远距离传输。\n光纤不仅具有通信容址非常大的优点，还具有如下特点：\n传输损耗小，中继距离长，对远距离传输特别经济。 抗宙电和电磁干扰性能好。这在有大电流脉冲干扰的环境下尤为重要。\n无串音干扰，保密性好，也不易被窃听或截取数据。\n体积小，重量轻。这在现有电缆管道已拥塞不堪的情况下特别有利。\n无线传输介质 无线通信已广泛用于蜂窝移动电话领城。随着便携式计算机的出现，以及军事、野外等特殊场合对移动联网的需要，促进了移动通信的发展，现在无线局城网的应用己非常普遍。 （1）无线电波 无线电波具有较强的穿透能力，可以传输很长的距离，因此广泛用于通信领域，如无线手机通信、计算机冈络中的无线局城网（WLAN） 等。因为无线电波使信号向所有方向散播，所以有效距离范围内的接收设备无须对准菜个方向，就可与无线电波发射者进行通信连接，大大简化了通信连接。这也是无线电波传输的最重要优点之一。 （2）微波、红外线和激光 目前高带宽的无线通信主要使用三种技术：微波、红外线和激光，它们都需要在发送方和接收方之间有一条视线通路，有很强的方向性，沿直线传播。不同的是，红外通信和激光通信将要传输的信号分别转换为各自的信号格式，即红外光信号和激光信号，再直接在空间中传播。 微波通信的频率较高，频段范围也很宽，载波频率通常为2~40GHz，因此通信信道的容量大。例如，一个带宽为2MHz 的频段可容纳500条语音线路，若用来传输数字信号，则数据率可达数兆比特/秒。与通常的无线电波不同，微波通信的信号是沿直线传播的，因此在地面上的传播距离有限，超过一定距离后就要使用中继站来接力。 卫星通信利用地球同步卫星作为中继来转发微波信号，可以克服地面微波通信距离的限制3三颗相隔 120°的同步卫星几乎就能覆盖整个地球表面，因此基本能实现全球通信。卫星通信的优点是通信容量大、距离远、覆盖广，缺点是保密性差、端到端传播时延长。\n物理层接口的特性 物理层考虑的是如何在连接到各种计算机的传输媒体上传输数据比特流，而不指具体的传输 媒体。网络中的硬件设备和传输介质的种类繁多，通信方式也各不相同。物理层应尽可能屏蔽这些差异，让数据链路层感觉不到这些差异，使数据链路层只需考虑如何完成本层的协议和服务。\n物理层的主要任务可以描述为确定与传输媒体的接口有关的一些特性：\n机械特性。指明接口所用接线器的形状和尺寸、引脚数目和排列、固定和锁定装置等。 电气特性。指明在接口电缆的各条线上出现的电压的范围。 功能特性。指明某条线上出现的某一电乎的电压表示何种意义。\n过程特性。或称规程特性。指明对千不同功能的各种可能事件的出现顺序。\n常用的物理层接口标准有 EIA RS-232-C、 ADSL 和 SONET/SDH 等。\n物理层设备 中继器 中继器的主要功能是整形、放大并转发信号，以消除信号经过一长段电缆后产生的失真和衰减，使信号的波形和强度达到所需的要求，进而扩大网络传输的距离。其原理是信号再生（而非简单地放大衰减的信号）。中继器有两个端口，数据从一个端口输入，从另一个端口发出。端口仅作用于信号的电气部分，而不管是香有错误数据或不适于网段的数据。 中继器是用来扩大网络规模的最简单的廉价互连设备。中继器两端的网络部分是网段，而不是子网，使用中继器连接的几个网段仍是一个局城网。中继器若出现故障，则对相邻两个网段的工作都产生影响。因为中继器工作在物理层，所以不能连接两个具有不同速率的局域网。\n若某个网络设备有存储转发功能，则认为它能连接两个不同的协议；若该网络设备无存储转发功能，则认为它不能连接两个不同的协议。中继器没有存储转发功能，因此它不能连接两个速率不同的网段，中继器两端的网段一定要使用同一个协议。\n从理论上讲，中继器的使用数目是无限的，网络因而也可无限延长。但事实上这是不可能的，因为网络标准中对信号的延迟范围做了具体规定，中继器只能在该范围内进行有效的工作，否则会引起网络故障。例如，在采用粗同轴电缆的 10BASES 以太网规范中，互相串联的中继器的个数不能超过4个，而且用4 个中继器串联的5 段通信介质中，只有3 段可以挂接计算机，其余2段只能用作扩展通信范围的链路段，不能挂接计算机。这就是所谓的“5-4-3 规则”。\n放大器和中继器都起放大作用，只不过放大器放大的是模拟信号，其原理是放大豪减的信号，而中继器放大的是数字信号，其原理是整形再生袤减的信号。\n集线器 集线器 (Hub) 实质上是一个多端口的中继器。当 Hub 工作时，一个端口接收到数据信号后， 因为信号在从端口到 Hub 的传输过程中已有衰减，所以 Hub 便对该信号进行整形放大，使之再生（恢复）到发送时的状态，紧接若转发到其他所有（除输入端口外）处千工作状态的端口。若同时有两个或多个端口输入，则输出时将发生冲突，致使这些数据都无效。从 Hub 的工作方式可以 看出，它在网络中只起信号放大和转发作用，目的是扩大网络的传输范围，而不具备信号的定向传送能力，即信息传输的方向是固定的，是标准的共享式设备。\n集线器不能分割冲突域，集线器的所有端口都属于同一个冲突域。集线器在一个时钟周期内只能传输一组信息，当一台集线器连接的机器数目较多且多台机器经常需要同时通信时，将导致信息冲突，使得集线器的工作效率很差。\n","date":"2024-01-20T15:12:37Z","permalink":"http://localhost:1313/post/2-%E7%89%A9%E7%90%86%E5%B1%82/","title":"2 物理层"},{"content":"什么是计算机网络 概念 计算机网络和分布式系统 计算机网络 (Computer Networks)：由==自主计算机互联起来的集合体== (a group of interconnected computers)，与主从计算的的区别，每台计算机都有独立的操作系统，不从属某台主机。\n分布式系统 (Distributed System)：对用户看起来是一个==单独系统==的计算机集合。存在着一个能为用户自动管理资源的网络操作系统。\n关系：计算机网络是分布式系统的技术基础，而分布式系统是计算机网发展的高级阶段。www是原型在Internet的分布式系统。\n计算机网络（简称网络）由若干结点 (node, 或译为节点）和连接这些结点的链路 (link)\n组成。网络中的结点可以是计算机、菜线器、交换机或路由器等。网络之间还可通过路由器互连， 构成一个设盖范围更广的计算机网络，这样的网络称为互连网(internet)。于是，我们可以这样\n理解：网络把许多计算机连在一起，而互连网则把许多网络通过路由器连在一起。\n组成 从组成部分看 一个完整的计算机网络主要由==硬件、软件、协议==三大部分组成，缺一不可。 ==硬件==主要由主机（也称端系统）、通信链路（如双绞线、光纤）、交换设备（如路由器、交换机等）和通信处理机（如网卡）等组成。 ==软件==主要包括各种实现资源共享的软件和方便用户使用的各种工具软件（如网络操作系统、邮件收发程序、 FTP 程序、聊天程序等）。软件部分多属千应用层。 ==协议==是计算机网络的核心，如同交通规则制约汽车 驾驶一样，协议规定了网络传输数据时所遵循的规范。\n从工作方式上看 计算机网络（这里主要指 Internet,即因特网）可分为==边缘部分和核心部分==。 ==边缘部分==由所有连接到因特网上、供用户直接使用的主机组成，用来进行通信（如 传输数据、音频或视频）和资源共享； ==核心部分==由大量的网络和连接这些网络的路由器组成，它为边缘部分提供连通性和交换服务。图I. I 给出了这两部分的示意图。\n在互联网核心部分中起特殊作用的是路由器，它是一种专用计算机，是实现分组交换的关键构件，作用是按存储转发方式进行分组交换。其任务是转发收到的分组，这是网络核心部分最重要的功能。 互联网核心部分中的路由器之间一般都用高速链路相连接，而在网络边缘的主机接入到核心部分则通常以相对较低速率的链路相连接。\n主机的用途是为用户进行信息处理的，并且可以和其他主机通过网络交换信息。路由器的用途则是用来转发分组的，即进行分组交换的。\n从功能组成上 计算机网络由==通信子网和资源子网==组成。 ==通信子网==由各种传输介质、 通信设备和相应的网络协议组成，它使网络具有数据传输、交换、控制和存储的能力， 实现联网计算机之间的数据通信。 ==资源子网==是实现资源共享功能的设备及其软件的集合， 向网络用户提供共享其他计算机上的硬件资源、软件资源和数据资源的服务。\n功能 ==数据通信==是计算机网络最基本和最重要的功能，用来实现联网计算机之间各种信息的传输，并将分散在不同地理位置的计算机联系起来，进行统一的调配、控制和管理。例如，文件传输、电子邮件等应用，离开了计算机网络将无法实现。 ==资源共享==可以是软件共享、数据共享，也可以是硬件共享。它使计算机网络中的资源互通有无、分工协作，从而极大地提高硬件资源、软件资源和数据资源的利用率。 ==分布式存储==：当计算机网络中的某个计算机系统负荷过重时，可以将其处理的某个复杂任务分配给网络中的其他计算机系统，从而利用空闲计算机资源以提高整个系统的利用率。 ==提高可靠性==：计算机网络中的各台计算机可以通过网络互为替代机。 ==负载均衡==：将工作任务均衡地分配给计算机网络中的各台计算机。 Categories of computer network 按分布范固分类 广域网 (WAN) 广域网（WAN, Wide Area Network）的任务是==提供长距离通信==，运送主机所发送的数据，其覆盖范围通常是直径为几十千米到几于千米的区域，因而有时也称远程网。广域网是因特网的核心部分。连接广域网的各结点交换机的链路一般都是==高速链路==，具有较大的==通信容址==。LAN 通常存在于封闭区域中，常常共享互联网连接的单个中心点。WAN 旨在提供远距离的网络连接。它们通常由几个互相连接的 LAN 组成。常见的广域网有：专线、VPN 或 IP 隧道。\n专线 专线(leased line)是从大型网络提供商（例如 ISP，Internet Service Provider）租用的直连网络连接。对于大多数组织而言，建立自己的物理网络基础设施（包括跨越数百或数千英里的电缆、路由器和互联网交换点）几乎是不可能完成的任务。因此，他们改为从已经拥有这种基础设施的公司租用专门的直连连接。\n隧道 如果公司不想付费使用专线，他们可以使用隧道(tunneling)来连接其 LAN。在网络中，隧道是一种将数据包封装在其他数据包中的方法，以便它们可以到达原本不可及的地方。这可以比作将一个信封放在另一个信封里邮寄，两个信封分别有一个不同的地址，这样内信封就能从外信封的目的地地址邮寄出去。\n虚拟专用网络 某些网络隧道会经过加密，以保护数据包的内容，以免受到任何可能在途中拦截它们的人的攻击。加密的隧道称为虚拟专用网络(VPN，Virtual Private Network)。\n城域网(MAN) 城域网(MAN，Metropolitan Area Network)的范围可覆盖一个城市。最有名的城域网例子是许多城市都有的有线电视网。这种系统由早期的社区天线系统发展而来，主要用在那些从空中接收电视信号条件较差的地区。在这些早期系统中，常常把一个很大的天线放在附近的山上，然后电视信号通过该天线转发到订户的家里。\n局域网 (LAN) 局域网 (LAN，Local Area Network)，LAN 是包含在==较小==地理区域内的网络，通常位于同一建筑物内。\n在这些系统中，每台计算机都有一个无线调制解调器和一个天线，用来与其他计算机通信。\n**局域网的构成：**LAN中的每台计算机会与一个接入点(AP, Access Point)、无线路由器(wireless router)或者基站(base station)的设备进行通信。它主要负责中继无线计算机之间的数据包，还负责中继无线计算机和Internet之间的数据包。\n接入点(AP) 无线接入点（AP 或 WAP）是允许 Wi-Fi 设备连接到有线网络的网络设备。它主要是提供无线工作站对有线局域网和从有线局域网对无线工作站的访问，在访问接入点覆盖范围内的无线工作站可以通过它进行相互通信。\n简单来说，就是提供无线网络的设备，它有线连接在局域网内。\n路由 路由（routing）是选择一个或多个网络上的路径的过程。在诸如互联网等数据包交换网络中，路由选择互联网协议 (IP) 数据包从其起点到目的地的路径。这些互联网路由决定由称为路由器的专用网络硬件做出。\n简单来说，路由是寻找路径的过程。网络中两个计算机之间有很多个网络相连，它们的路径有很多种，路由是找到这些路径的过程.\n在路由中，任播(anycast)是一种网络寻址和路由的策略，使得数据可以根据路由拓朴来决定送到“最近”或“最好”的目的地。\n路由器 路由器(Router)是一种网络硬件，负责将数据包转发到目的地。路由器连接到两个或多个 IP 网络或子网，并根据需要在它们之间传递数据包。\n为了有效地引导数据包，路由器使用一个内部路由表——一个通往不同网络目的地的路径列表。路由器读取数据包的标头以确定其去向，然后查阅路由表以找出通往该目的地的最有效路径。然后，它将数据包转发到该路径中的下一个网络。\n现在的无线路由器是一个AP、路由器和交换机的集合体，支持有线无线组成同一子网并具有路由功能。它组成的网络称为无线局域网(WLAN)\n交换机 网络交换机(switch)是连接网络内的设备，并向或从这些设备转发数据包。与路由器不同，交换机仅将数据发送到它打算发送的单个设备（可以是另一台交换机、路由器或用户的计算机），而不是发送到多个设备的网络。\n基站 基站（Base Station），是公用移动通信基站，是移动设备接入互联网的接口设备，也是无线电台站的一种形式，是指在一定的无线电覆盖区中，通过移动通信交换中心，与移动电话终端之间进行信息传递的无线电收发信电台。\n个人区域网(Personal Area Network) 个人区域网 (PAN, Personal Area Network) 允许设备围绕着一个人进行通信。简单来说，就是==非常有限距离的连接==，其中最著名的例子就是蓝牙耳机和智能手机之间的连接。\n个人区域网连接可以是有线或无线的。#card\n有线连接方式包括 USB 和 FireWire；无线连接方式包括蓝牙（Bluetooth）、WiFi、IrDA 和 Zigbee。h 有线连接长度取决于连接线，而无线连接——WPAN(Wireless Personal Area Network) 的范围通常非常小，例如蓝牙等短距离无线协议在大于 5-10 米的距离上效率不高。 按传输技术分类 广播式网络。 所有联网计算机都共享==一个公共通信信道==。当一台计算机利用共享通信信道发送报文分组时，所有其他的计算机都会“收听”到这个分组。接收到该分组的计算机将通过检查目的地址来决定是否接收该分组。 ==局域网==基本上都采用广播式通信技术，广域网中的无线、卫星通信网络也采用广播式通信技术。 点对点网络。 ==每条物理线路连接一对计算机==。 若通信的两台主机之间没有直接连接的线路，则它们之间的分组传输就要通过中间结点进行接收、存储和转发，直至目的结点。、 目前普遍使用的传输技术有两种，分别是==广播式链路和点到点链路==\n==点到点（point-to-point）==链路将一对单独的机器连接起来。在一个由点到点链路组成的网络中，为了从源端到达接收方，短消息必须首先访问一个或多个中间机器，这种短消息在某些情况下称为数据包或包(packet)。\n通常在网络中有可能存在多条不同长度的路由，因此，找到一条好的路由对点-点网络非常重要。点-点传输只有一个发送方和一个接收方，有时候也称为==单播（unicasting）==\n相反，在一个==广播(boradcasting)==网络上，通信信道被网络上的所有机器所共享；任何一台机器发出的数据包能被所有其他任何机器收到。无线网络是广播链路的一个常见例子，一个覆盖区域内的通信由所有该区域内的机器共享，而该区域的划分取决于无线信道和传输机器。\n有些广播系统还支持给一组机器发送数据包的模式，这种传输模式称为==组播（multicasting）==\n按拓扑结构分类 网络拓扑结构（Network Topology）是指由网中结点（路由器、主机等）与通信线路（网线）之间的几何关系（如 总线形、环形）表示的网络结构，主要指通信子网的拓扑结构。 按照网络的拓扑形态来划分，网络可分为星型网络(Star)、总线型网络(Bus)、环形网络(Ring)、树形网络(Hierarchical)和网状网络(Mesh)等。 总线形网络。用单根传输线把计算机连接起来。总线形网络的优点是建网容易、增／减结点方便、节省线路。缺点是重负载时通信效率不高、总线任意一处对故障敏感。 星型网络。每个终端或计算机都以单独的线路与中央设备相连。中央设备早期是计算机，现在一般是交换机或路由器。星形网络便于集中控制和管理，因为端用户之间的通信必须经过中央设备。缺点是成本高、中央设备对故障敏感。 环形网络。所有计算机接口设备连接成一个环。环形网络最典型的例子是令牌环局域网。环可以是单环，也可以是双环，环中信号是单向传输的。 网状网络。一般情况下，每个结点至少有两条路径与其他结点相连，多用在广域网中。 在局域网中,常见的三种物理层网络拓扑结构有:\n按交换技术分类 交换技术是指各台主机之间、各通信设备之间或主机与通信设备之间为交换信息所采用的数 据格式和交换装置的方式。按交换技术可将网络分为如下几种。\n电路交换网络。==在源结点和目的结点之间建立一条专用的通路用于传送数据，包括建立连接、传输数据和断开连接三个阶段。==最典型的电路交换网是传统电话网络。该类网络的主要特点是整个报文的比特流连续地从源点直达终点，好像是在一条管道中传 送。优点是数据直接传送、时延小。缺点是线路利用率低、不能充分利用线路容盘、不便于进行差错控制。 报文交换网络。用户数据加上源地址、目的地址、校验码等辅助信息，然后封装成报文。整个报文传送到相邻结点，全部存储后，再转发给下一个结点，重复这一过程直到到达目的结点。每个报文可以单独选择到达目的结点的路径。报文交换网络也称==存储－转发网==络，主要特点是==整个报文先传送到相邻结点，全部存储后查找转发表，转发到下一个结点。==优点是可以较为充分地利用线路容量，可以实现不同链路之间不同数据传输速率的转换，可以实现格式转换，可以实现一对多、多对一的访问，可以实现差错控制。缺点是增大了资源开销（如辅助信息导致处理时间和存储资源的开销），增加了缓冲时延，需要额外的控制机制来保证多个报文的顺序不乱序，缓冲区 难以管理（因为报文的大小不确定，接收方在接收到报文之前不能预知报文的大小）。 分组交换网络，也称包交换网络。其原理是，将数据分成较短的固定长度的数据块，在每个数据块中加上目的地址、源地址等辅助信息组成分组（包），以存储－转发方式传输。 其主要特点是==单个分组（它只是整个报文的一部分）传送到相邻结点，存储后查找转发表，转发到下一个结点。==除具备报文交换网络的优点外，分组交换网络还具有自身的优点：缓冲易于管理；包的平均时延更小，网络占用的平均缓冲区更少；更易于标准化；更适合应用。现在的主流网络基本上都可视为分组交换网络。 计算机网络(computer network)是通信网络的一种，被称为数据网络(data networks)。而数据网络是一种使用数字传输的通信网络。通常来说，数据是离散的信号，数据被封装成称为数据报(Datagram)的信息，并通过一些中间网络设备从源发送到目的地。例如以太网。\n相反的，语音网络使用模拟信号传输，它是连续的信号。通常来说，语音流(voice stream)通过预先建立的连接（称为电路circuit）从源头转发到目的地。例如电话网络。\n电路交换：整个报文的比特流连续地从源点直达终点，好像在一个管道中传送。缺点是在通话的全部时间里，通话的两个用户需要始终占用端到端的通信资源。这在计算机网络中效率很低，因为计算机数据往往是突发式的出现在传输线路上的。\n报文交换：整个报文先传送到相邻结点，全部存储下来后查找转发表，转发到下一个结点。一旦出错将使整个报文失效，不够灵活。\n分组交换：分组（报文的一部分）先传送到相邻结点，全部存储下来后查找转发表，转发到下一个结点。最终，接收方接收所有的分组，并将其还原为最初的报文。优点是时延小，灵活性好，是计算机网络中最常用的交换方式。\n性能指标 速率 (Speed) /数据传送速率/数据率/比特率 #card\n单位时间内的数据传输率 单位为 b/s or 比特/秒 or bit/s or bps or kb/s=10^3b/s\n带宽(Bandwidth) #card\n最高数据率 在模拟信号系统中：通信线路允许通过的信号频带范围，单位是赫兹(Hz) 。 在计算机网络中：表示网络的通信线路所能传送数据的能力，是最高数据率，单位是b/s\n吞吐量(Throughput)：#card\n指单位时间内通过某个网络（或信道、接口）的数据量。 经常用于现实世界对网络的测量 吞吐量受网络带宽或网络额定速率的限制。\n时延(Delay)：指数据（一个报文或分组）从网络（或链路）的一端传送到另一端所需要的总时间，它由 4 部分构成：==发送时延、传播时延、处理时延和排队时延==。\n发送时延。结点将分组的所有比特推向（传输）链路所需的时间，即从发送分组的第一个比特算起，到该分组的最后一个比特发送完毕所需的时间，因此也称传输时延。计算公式为==发送时延＝分组长度／信道宽度==\n传播时延。电磁波在信道中传播一定的距离需要花费的时间，即一个比特从链路的一端传播到另一端所用的时间。计算公式为==传播时延＝信道长度／电磁波在信道上的传播速率==\n处理时延。数据==在交换结点为存储转发而进行的工作==所花费的时间。例如，分析分组的首部、从分组中提取数据部分、进行差错检验或查找适当的路由等。\n排队时延。分组在进入路由器后要先在输入队列中排队等待处理。路由器确定转发端口后，还要在输出队列中排队等待转发，这就产生了排队时延。\n时延带宽积 #card\n指发送端发送的第一个比特即将到达终点时，发送端已经发出了多少个比特 又称比特为单位的链路长度，即时延带宽积＝传播时延×信道带宽。 考虑一个代表链路的圆柱形管道，其长度表示链路的传播时延，横截面积表示链路带宽，则时延带宽积表示该管道可以容纳的比特数量。 往返时延(Round-Trip Time, RTT) #card\n指从发送端发出一个短分组，到发送端收到来自接收端的确认（接收端收到数据后立即发送确认），总共经历的时延。在互联网中，往返时延还包括各中间结点的处理时延、排队时延及转发数据时的发送时延。\n信道利用率 #card\n信道利用率＝有数据通过时间／（有＋无）数据通过时间\nNetwork architecture 计算机网络分层结构 网络架构(Network architecture)是用于网络通信的一系列层、协议和服务的名称。\n层(layer)是按照不同功能(function)将网络架构划分成层级结构。每一层都有特定的功能。 协议(Protocols) 是每一层用于执行具体功能的规则集。协议描述并规定了某个层的操作方式。 服务(Services) 是低层为高层提供的功能。每一层都利用下一层提供的服务来实现自身的功能。 协议包含了报文(message)的格式(format)和主机之间报文交换的方式，是实现网络通信的规则。协议族(Protocol suites)是按照需要组合在一起的协议集合，用来涵盖网络通信的各种功能。每个协议只负责一个特定的功能，不同协议之间相互协作来实现全面的网络通信。\n每一层上可以实现多个不同的协议。协议栈(Protocol stack)就是某个系统所采用的协议集合，每个层采用一个或多个协议。例如，TCP/IP协议栈由多种协议组成，如IP协议工作在网络层，TCP和UDP协议工作在传输层。\n在层与层之间,低层为上层提供服务。具体来说，第k层扮演服务提供者(service provider)的角色，为第k+1层即服务用户(service user)提供服务。\n服务接入点(Service Access Points, SAP)存在于层与层之间，是服务用户访问服务提供者提供的服务的接口。第k层的SAP就是第k+1层用于访问第k层服务的入口。每个SAP都有一个唯一的地址标识。\n当两台主机上的同一层进行通信时，它们必须遵守某些预定的规则和约定，这些规则和约定统称为该层的协议。如果任意一方违反了协议，将导致通信出现问题。\n不同机器上构成相应层次的实体称为对等体（peer）。这些对等体可能是软件过程、硬件设备，或者甚至是人类。换句话说，正是这些对等体为了实现彼此沟通才使用协议来进行通信。\n只有对等的层可以理解其对等数据，因为只有相同的协议之间才可以沟通。例如，我们举一个生活中的例子来解释多层通信：\n[\n两个哲学家之间的交流，只有他们之间才能明白，而翻译家得到的信息也只有翻译家之间才能明白。秘书只负责发送与接收，他们的过程也只有他们自己理解。\n在对应层的对等实体之间传递信息的基本单位叫做协议数据单元(Protocol Data Units, PDU)。PDU 由标头(Header)、载荷(Payload)和尾部校验信息(Trailer)组成，其中Trailer可选。\nHeader用于识别对等实体之间所使用的协议类型，以及对PDU的数据进行控制。标头通常包含地址信息、序列号等控制信息。 Payload是用户数据，即上层 PDU。 Trailer用于对PDU数据的校验。 分层的基本原则如下：\n每层都实现一种相对独立的功能，降低大系统的复杂度。 各层之间的接口自然清晰，易千理解，相互交流尽可能少。\n各层功能的精确定义独立于具体的实现方法，可以采用最合适的技术来实现。\n保待下层对上层的独立性，上层单向使用下层提供的服务。\n整个分层结构应能促进标准化工作。 网络协议：为实现网络中的数据交换而建立的规则标准或约定。\n三要素： 语法：数据与控制信息的格式。 语义：需要发出何种控制信息，完成何种动作，做出何种响应。 同步：事件实现顺序的详细说明。\n计算机网络的各层及其协议的媒合称为网络的体系结构 (Architecture) 。换言之，计算机网 络的体系结构就是这个计算机网络及其所应完成的功能的精确定义。要强调的是，这些功能究竞 是用何种硬件或软件完成的，是一个遵循这种体系结构的实现（Implementation) 问题。体系结构 是抽象的，而实现则是具体的，是贞正在运行的计算机硬件和软件。计算机网络体系结构通常都 具有可分层的特性，它将复杂的大系统分成若干较容易实现的层次。\n分层的基本原则如下：\nl) 每层都实现一种相对独立的功能，降低大系统的复杂度。\n各层之间的接口自然清晰，易千理解，相互交流尽可能少。\n各层功能的精确定义独立于具体的实现方法，可以采用最合适的技术来实现。\n保待下层对上层的独立性，上层单向使用下层提供的服务。\n整个分层结构应能促进标准化工作。 在计算机网络分层结构中，第 n 层中的活动元索通常称为第 n 层实体。具体来说，实体指任 何可发送或接收信息的硬件或软件进程，通常是某个特定的软件模块。不同机器上的同一层称为 对等层，同一层的实体称为对等实体。第 n 层实体实现的服务为第 n+l 层所用。在这种悄况下， 第 n 层称为服务提供者，第 n+l 层则服务于用户。\n在计算机网络体系结构中，对等层之间传送的数据单位称为该层的协议数据单元 (POU),\n第 n 层的 PDU 记为 n-PDU 。各层的 PDU 都分为数据和控制信息两部分。\n服务数据单元 CSDU): 为完成用户所要求的功能而传送的数据。第 n 层的 SDU 记为 n-SDU 。\n协议控制信息 (PC!): 控制协议操作的信息。第 n 层的 PCI 记为 n-PCl 。 每层的协议数据单元都有一个通俗的名称，如物理层的 PDU 称为比特流，数据链路层的 PDU\n称为帧，网络层的 PDU 称为分组，传输层的 POU 称为报文段。 当在各层之间传输数据时，将从第 n+l 层收到的 PDU 作为第 n 层的 SDU ，加匕第 n 层的 PCl，就封装成了第 n 层的 PDU ，交给第 n-1 层后作为 SDU 发送，接收方接收时做相反的处埋， 因此可知三者的关系为 n-SDU + n-PCI = n-PDU = (n - 1)-SDU, 具变换过程如图l.7 所示。\n具体地，层次结构的含义包括如下几方面：\nl) 第 n 层的实体不仅要使用第 n-l 层的服务来实现自身定义的功能，而且要向第 n+ I 层 提供本层的服务，该服务是第 n 层及其下面各层提供的服务总和。\n最低层只提供服务，是整个层次结构的基础；最高层面向用户提供服务。\n上一层只能通过相邻层间的接口使用下一层的服务，而不能调用其他层的服务。\n当两台主机通信时，对等层在逻辑上有一个直接信道，表现为能直接将信息传送到 对方。\n计算机网络协议、接口、服务的概念 ! 协议\u0026amp;服务 概念 Layer 层：使用了信息隐蔽、抽象数据类型以及面向对象的设计方法； 目的是向上层提供服务，上层可以使用其提供的服务，但对于其内部的状态和算法不可见 Service 服务：下层（n-1）给上层（n）提供服务，垂直的 Protocol 协议：对等层关于如何进行通信的一种约定，是对改成功能如何实现的一种定义，水平的 Interface 接口：在每一对相邻层之间的临界处，下层通过接口向上层服务 封装：某层实体在上一层交付数据前面（或后面）加上自己的控制信息，构成本层数据包，这些控制信息由协议定义 实体（entity） ：任何可发送或接收信息的硬件或软件进程 服务访问点 SAP （Service Access Point）：同一系统相邻两层的实体进行交互的地方，标识符叫做 SAPI 关系 协议是“水平的”，即协议是控制对等实体之间通信的规则 服务是“垂直的”，即服务是由下层向上层通过层间接口提供的 在协议的控制下，两个对等实体间的通信使得本层能够向上一层提供服务。 一层协议的实现需要下层的服务 服务的实现需要本层协议的支持 本层的服务用户只能看见服务而无法看见下面的协议 下层协议对上层服务用户是透明的 服务不变时，本层协议的实现改变不影响上层 k 层服务改变，k+1 层随之改变，k-1 层不受影响\ntips 为什么分层？ ①简化网络的设计和实现的难度；②各层之间依赖性较低，只要不改变服务和接口，各层内部进行修改不会影响其它层\n可能缺点：加上控制信息和处理的开销，性能比不分层的系统要差\n每一层的对等实体之间进行通信，通信要遵守协议 只有最底层是实际通信，其它各层都是虚拟通信 Information flow（数据流向）：U 形，发送系统自顶向下，最底层实际传输数据，接收系统自底向上 1.2.2\nI.协议\n要在网络中做到有条不紊地交换数据，就必须遴循一些事先约定好的规则，其规定了所交换\n数据的格式及有关的同步问题。为了在网络中进行数据交换而建立的这些规则、标准或约定称为\n网络协议 (Network Protocol), 是控制在对等实体之间进行通信的规则的集合，是水平的。不对 等实体之间是没有协议的，如用 TCP/LP 协议栈通信的两个结点 A 和结点 B, 结点 A 的传输层和 结点 B 的传输层之间存在协议，但结点 A 的传输层和结点 B 的网络层之1，司不存在协议。 协议由语法、语义和同步三部分组成。\n\u0026quot;\n..i上执， ►\n同步的定义（2020)\nl) 语法。数据与控制信息的格式。例如，\nTCP 报文段格式就是由 TCP 协议的语法定义的。\n语义．即需要发出何种控制信息、完成何种动作及做出何种应答。例如，在建立 TCP 连 接的三次握手时所执行的操作就是由 TCP 协议的语义定义的。 3) 同步（或时序）。执行各种操作的条件、时序关系等，即事件实现顺序的详细说明。例如，\n建立 TCP 连接的三次握手橾作的时序关系就是由 TCP 协议的同步定义的。\n挂口 同一结点内相邻两层的实体交换信息的逻辑接口称为服务访问点 (Service Access Po int,\nSAP) 。每层只能为紧邻的层之间定义接口，而不能跨层定义接口。服务是通过 SAP 提供给上层 使用的，第 n 层的 SAP 就是第 n+l 层可以访问第 n 层服务的地方。例如，在本书描述的 5 层体 系结构中，数据链路层的服务访问点为帧的＂类型”字段，网络层的服务访问点为 IP 数据报的“协 议”字段，传输层的服务访问点为“端口号”字段。\n股务 服务是指下层为紧邻的上层提供的功能调用，是垂直的。对等实体在协议的控制下，使得本\n层能为上层提供服务，但要实现本层协议，还需要使用下层提供的服务。当上层使用下层提供的服务时，必须与下层交换一些命令，这些命令称为服务原语。 OSI 参考模型将原语划分为四类：\nl) 请求 (Request)。由服务用户发往服务提供者，诮求完成某项工作。\n指示\u0026lt;Ind ication) 。巾服务提供者发往服务用户，指示用户做某件事情。\n响应\n(Response) 。由服务用户发往服务提供者，作为对指示的响应。\n证实（Confirmation) 。由服务提供者发往服务用户，作为对请求的证实。 这四类原语用千不同的功能，如建立连接、传输数据和断开连接等。有应答服务包括全部四 类原语，而无应答服务则只有请求和指示两类原语。四类原语的关系如图1.8 所示。 注意，协议和服务概念上是不一样的。首先，只有本层协议的实现才能保证向上一层提供服 务。本层的服务用户只能看见服务而无法看见下面的协议，即下面的协议对上层的服务用户是透 明的。其次，协议是“水平的＂，即协议是控制对等实体之间通信的规则。但是，服务是“垂直\n堕，即服务是由下层通过层间接口向上层提供的。另外，并非在一层内完成的全部功能都称为\n服务，只有那些能够被高一层实体“看得见”的功能才称为服务。\n计算机网络提供的服务可按以下三种方式分类。 (I) 面向连接服务与无连接服务\n在面向连接服务中，通信前双方必须先建立连接，分配相应的资源（如缓冲区），以保证通\n信能正常进行，传输结束后释放连接和占用的资源。因此这种服务可分为连接建立、数据传输和\n连接释放三个阶段。例如， TCP 就是一种面向连接服务的协议。 在无连接服务中，通信前双方不需要先建立连接，需要发送数据时可直接发送，将每个带有\n目的地址的包（报文分组）传送到线路上，由系统选定路线进行传输。这种服务常被描述为“尽 最大努力交付＂，是一种不可靠的服务。例如， IP、 VDP 就是一种无连接服务的协议。\n(2) 可靠服务和不可靠服务\n可靠服务是指网络具有纠错、检错、应答机制，能保证数据正确、可靠地传送到目的地。不\n可靠服务是指网络只是尽批让数据正确、可靠地传送到目的地，是一种尽力而为的服务。\n对于提供不可靠服务的网络，其网络的正确性、可靠性要由应用或用户来保陓。例如，用户 收到信息后要判断信息的正确性，若不正确，则用户就要把出错信息报告给信息的发送者，以便 发送者采取纠正措施。通过用户的这些措施，可将不可靠服务变成可靠服务。\n(3) 有应答服务和无应答服务 有应答服务是指接收方在收到数据后向发送方给出相应的应答，该应答由传输系统内部自动\n实现，而不由用户实现。发送的应答既可以是肯定应答，又可以是否定应答，通常在接收到的数\n据有错误时发送否定应答。例如，文件传输服务就是一种有应答服务。 无应答服务是指接收方收到数据后不自动给出应答。若衙要应答，则由离层实现。例如，对 千 WWW 服务，客户端收到服务器发送的页面文件后不给出应答。\n面向连接 \u0026amp; 无连接 服务 面向连接服务：3 个阶段 ①连接建立②数据传输③连接释放 无连接服务：两实体间通信不需要先建立连接；每个报文携带完整目标地址，可建立独立路由 服务原语：一个服务通常是由一组原语操作描述，用户进程通过这些操作访问该服务 区别 通信双方是否需要建立连接 能保证数据传输的可靠性 通信过程中是否需要完整的目的地地址 举例 UDP 为无连接通信协议示例 TCP 是面向连接通信协议示例 ISO/OSI 参考模型和 TCP/IP模型 OSI参考模型 应用层：\n功能：通过应用进程之间的交互来完成特定的网络应用。 交换的数据单元：报文。 协议：域名系统DNS、支持万维网应用的HTTP协议，支持电子邮件的SMTP等。 运输层：\n功能：负责向两台主机中进程之间的通信提供通用的数据传输服务。具有复用和分用的功能。 协议： 传输控制协议TCP：提供面向连接的、可靠的数据传输服务。交换的数据单元是：TCP报文段。 用户数据报协议UDP：提供无连接的尽最大努力的数据传输服务（不确保数据的可靠性）。交换的数据单元是：用户数据报。 不同的应用层协议基于不同的传输层协议。例如：HTTP协议、SMTP协议基于TCP协议，DNS协议、RTP协议基于UDP协议。 网络层：\n功能：为互联网内任意两台主机提供分组交换的通信服务。（路由器是网络层设备） 交换数据单元：分组（IP数据报）。 协议：网际协议IP。 数据链路层：\n功能：为局域网内任意两台主机提供数据帧传输。 交换的数据单元：数据帧。 物理层：\n功能；提供原始的比特流传输。 从上至下的每一层的协议数据单元PDU，都在上一层的基础上，加上自己的控制信息。\n物理层(Physical Layer)：通过有线或无线方式传输比特流的功能。\n物理层的传输斗位是比特，功能是在物理介质上为数据端设备透明地传输原始比特流。物理\n层主要定义数据终端设备 (DTE) 和数据通信设备 (DCE) 的物理与逻辑连接方法。\n物理层接口标准很多，如 EIA-232C 、 EIAffiA RS-449 、 CCITT 的X.21 等。 图I. I I 表示的是两个通信结点及它们间的一段通信链路，物理层主要研究以下内容：\nO 通信链路与通信结点的连接需要一些电路接口，物理层规定了这些接门的一些参数，如机 械形状和尺寸、交换电路的数屈和排列等，例如笔记本电脑上的网线接口。\n＠物理层规定了通信链路上所传输的信号的意义和电气特征。例如，若规定信号 X 代表数\n字 O, 则当结点传输 0 时就发出信号 X, 而当结点接收到信号 X 时就知道收到的是 0 。 注意，传输信息所用的一些物理介质（如双绞线、光缆、无线信道等）井不在物理层协议之 内，而在物理层协议下面。因此，有人将物理介质当作第 0 层。\n数据链路层(Data Link Layer)：实现介质访问(控制数据传输顺序)和确保节点间可靠传输的功能。(主要关注单个数据链路上的可靠传输)\n数据链路层的传输单位是帧。两台主机之间的数据传输总是在一段一段的链路上传送的，这 就需要使用专门的链路层协议。数据链路层将网络层交来的 IP 分组封装成帧，并且可靠地传输到\n相邻结点的网络层。主要作用是加强物理层传输原始比特流的功能，将物理层提供的可能出错的\n物理连接改造为逻辑上无差错的数据链路，使之对网络层表现为一条无差错的链路。 因为外界噪声的干扰，所以原始的物理连接在传输比特流时可能发生错误。如图I. II 所示，\n结点 A 想向结点 B 传输数字 O, 于是发出信号 X: 但在传输过程中受到干扰，信号 X 变成了信号\nY, 而信号 Y 又刚好代表 I,\n结点 B 接收到信号 Y 时，误以为结点 A 传送了数字 l ，从而发生差\n错。数据链路层协议应能检测出这些差错，然后将收到的错误信息丢弃。\n如图1. 11 所示，在两个相邻结点之间传送数据时，结点 A 的发送速率可能比结点 B 的接收 速率快，若不加以控制，则结点 B 就会丢弃很多来不及接收的正确数据，造成传输线路效率下降。 流拭控制可以协调两个结点的速率，使结点 A 的发送速率刚好是结点 B 的接收速率。\n广播式网络在数据链路层还要处理新的问题，即如何控制对共享信道的访问。数据链路层的 一个特殊子层 介质访问子层就是专门处理这个问题的。\n典型的数据链路层协议有 SDLC、 HDLC、\nPPP、 STP 和帧中继等。\n网络层(Network Layer)：决定数据包在多个节点间的最佳传输路径。\n网络层的传输单位是数据报。它关心的是迎信子网的运行控制，主要任务是将网络层的协议 数据单元（分组）从源结点传输到目的结点，为分组交换网上的不同主机提供通信服务。关键问 题是对分组进行路由选择，并实现流量控制、拥塞控制、差错控制和网际互连等功能。\n流拭控制与数据链路层的流屈控制的含义一样，都是协调 A 的发送速率和 B 的接收速率。 差错控制是通信结点之间约定的特定检错规则，接收方根据该规则检查接收到的分组是否出 错，若出错，则能纠错就纠错，不能纠错就丢弃，确保向上层提交的数据都是无误的。\n若图1.12 中的结点都来不及接收分组而丢弃大狱分组，导致结点间无法正常通信，那么网络\n就处于拥塞状态。网络层要采取措施来缓解这种拥塞，这就是拥塞控制。\n互联网是由大扯异构网络通过路由器相互连接起来的。互特网使用的网络层协议是无连接的 网际协议 (IP) 和许多种路由选择协议，因此互联网的网络层也称网际层或 IP 层。 网络层的协议有 IP、 !PX、 ICMP、 IGMP、 ARP 、 RARP 、 RlP 和 OSPF 等。\n传输层(Transport Layer)：在源和目的主机间建立端到端的可靠通信。(关注整体可靠传输，解决网络拥塞和段损坏问题)\n传输层也称运轮层，负贲主机中两个进程之间的通信，功能是为端到端连接提供可靠的传输 服务，即为端到端连接提供流屈控制、差错控制、服务质拭、数据传输管理等服务。\n数据链路层提供的是点到点通信，传输层提供的是端到端通信，两者不同。\n通俗地说，点到点可理解为主机和主机之间的通信，一个点是指一个硬件地址或 IP 地址， 网络中参与迎信的主机是通过硬件地址或 IP 地址来标识的：端到端通信是指运行在不同主机内的 两个进程之间的通信，一个进程由一个端口来标识，所以称为端到端通信。\n通过传输层的屏蔽，高层用户看不到通信子网的交替和变化。因为一台主机可同时运行多个 进程，所以传输层具有复用和分用的功能。复用是指多个应用层进程可同时使用下面传输层的服 务，分用是指传输层将收到的信息分别交付给上而应用层中相应的进程．\n传输层的协议有 TCP、 UDP.\n会话层(Session Layer)：控制主机间的会话连接(连接的建立与结束)。\n会话层允许不同主机上的各个进程之间进行会话。这种服务主要为表示层实体或用户进程建 立连接，并在连接上有序地传输数据，这就是会话，也称建立同步 (SYN) 。会话层负贲管理主 机间的会话进程，包括建立、管理和终止进程间的会话。会话层包含一种称为检查点的机制来维\n待可靠会话，使通信会话在迎信失效时从检查点继续恢复迪信，即断点下载的原理。\n表示层(Presentation Layer)：处理数据的表示格式，对数据进行展示、翻译和加密。\n表示层主要处理在两个通信系统中交换信息的表示方式。不同机器采用的编码和表示方法不\n同，为了使不同表示方法的数据和信息之间能够互相交换，表示层采用抽象的标准方法定义数据 结构，并采用标准的编码形式。此外，数据压缩、加密和解密也是表示层的功能。\n应用层(Application Layer)：用于网络应用进程之间的交互，提供各种网络服务。\n应用层是 OST 参考模型的最高层，是用户与网络的接口。应用层为特定类型的树络应用提供\n访问 OSI 参考校型坏境的手段。用户的实际应用多种多样，这就要求应用层采用不同的应用协议 来解决不同类型的应用要求，因此应用层是最复朵的一层，使用的协议也最多。典型的协议有用 千文件传送的 FTP、用千电子邮件的 SM兀）、用千万维网的 HTTP 等。\n封装 在OSI模型中，封装(Encapsulation)是指数据在各层向下传输过程中，被逐层添加该层的头部和尾部信息，形成带有headers和trailers的PDU。而反封装(De-encapsulation)则是数据在接收端向上层传递过程中，逐层移除该层添加的headers和trailers的过程。如图：\nOSI模型中数据封装的五个主要步骤:\n在应用层、表示层和会话层，数据(Data)被创建和处理。 在传输层，数据被分割为数据段(Segments)，添加传输层的头部信息，用于在源和目的端系统之间端到端传输。 在网络层，数据段被进一步封装为数据包(Packets)，添加网络层的头部信息如源和目的IP地址等。 在数据链路层，数据包被封装为帧(Frames)，添加数据链路层的头部信息如源和目的MAC地址等。 在物理层，数据帧被转换为比特(Bits)，以在物理介质上传输。 当数据在不同网络之间传输时，源主机与目的主机不一定直接连接。数据会经过多个不同的主机或网络进行传输，才能到达目的主机。在这种情况下，数据在到达接收主机之前的各个网络之间传递时，只涉及OSI模型底层的物理层、数据链路层和网络层的封装与反封装**。**如图：\n当然，不一定经过的设备均有3层，常见的网络设备中，集线器(Hub)只有第一层，交换机(Switch)只有第一第二层，路由器(Router)则有前三层。\n在网络传输的过程中，被反封装的层可以被设备改变信息。例如：\n每两个发送方与接收方的协议必须一样，但接收方可以改变这个协议并发给下个接收方。\nTCP/IP 参考模型 TCP/IP 参考模型（TCP/IP Reference Model），以其中两个最主要的协议——TCP协议和IP协议命名。如图：\nTCP/IP 模型从低到离依次为网络接口层（对应 OSI 参考模型的物理层和数据链路层）、网际层、传输层和应用层（对应 OSI 参考模型的会话层、表示层和应用层）。 TCP/IP 因为得到广泛应 用而成为事实上的国际标准。\n网络接口层 网络接口层的功能类似千 OSI 参考模型的物理层和数据链路层。它表示与物理网络的接口，但实际上 TCP/IP 本身并未真正描述这一部分，只是指出主机必须使用某种协议与网络连接，以便在其上传输 IP 分组。具体的物理网络既可是各种类型的局域网，如以太网、令牌环网、令牌总 线网等，又可是诸如电话网、 SDH 、 X.25 、帧中继和 ATM 等公共数据网络。网络接口层的作用 是从主机或结点接收 IP 分组，并将它们发送到指定的物理网络上。\n虽然链路层的任务是将整个帧从一个网络元素移动到邻近的网络元素，而物理层(physical layer)的任务是将该帧中的一个个比特从一个节点移动到下一个节点。在这层中的协议仍然是链路相关 的，并且进一步与该链路（例如，双绞铜线、单模光纤）的实际传输媒体相关。物理层常用的协议有以太网(Ethernet)。\n模型中的最低层是链路层（link layer），该层描述了链路必须完成什么功能才能满足无连接的互联网络层的需求，比如串行线和经典以太网链路。这不是真正意义上的一个层，而是主机与传输线路之间的一个接口。又称网络接口层。\n因特网的网络层通过源和目的地之间的一系列路由器路由数据报。为了将分组从一个 节点（主机或路由器）移动到路径上的下一个节点，网络层必须依靠该链路层的服务。网络层将数据报下传给链路层，链路层沿着路径将数据报传递给下一个节点。\n我们把链路层分组称为帧（frame）。\n网际层 网际层（主机－主机）是 TCP/IP 体系结构的关键部分，功能上它与 OSI 参考模型的网络层非 常相似。网际层将分组发往任何网络，并为其独立地选择合适的路由，但不保证各个分组有序地到达，各个分组的有序和可靠交付由高层负责。网际层定义了标准的分组格式和协议，即 IP。当 前采用的 IP 是第 4 版，即 1Pv4, 它的下一版本是 1Pv6 。\n互联网层（internet layer）是将整个网络体系结构贯穿在一起的关键层。该层的任务是允许主机将数据包注入到任何网络，并且让这些数据包独立地到达接收方（接收方可能在不同的网络上）。甚至数据包的到达顺序与它们被发送的顺序不同，在这种情况下，如果需要按序递交数据，那么重新排列这些数据包的任务由高层来负责完成。\n互联网层定义了官方的数据包格式和协议，该协议称为因特网协议IP（IP，Internet Protocol），与之相伴的还有一个辅助协议，称为因特网控制报文协议（ICMP，Internet Control Message Protocol）。互联网层的任务是将IP 分组投递到它们该去的地方。在网络层中，数据包的路由是最主要的问题。\n传输层 传输层（应用－应用或进程－进程）的功能同样与 OSI 参考模型中的传输层类似，即使得发送端和目的端主机上的对等实体进行会话。传输层主要使用以下两种协议：\n传输控制协议 (Transmission Control Pro tocol, TCP)。它是面向连接的，传输数据之前必须先建立连接，能够提供可靠的交付。数据传输的单位是报文段。 用户数据报协议 (User Data gram Protocol,UDP) 。它是无连接的，不保证提供可靠的交付，只能提供“尽最大努力交付＂。数据传输的单位是用户数据报。应用层（用户－用户）包含所有的高层协议，如虚拟终端协议 (Telnet)、文件传输协议 (FTP)、 域名解析服务 (DNS)、电子邮件协议 (SMTP) 和超文本传输协议 (HT「P) 。由图1. 13 可以看出， IP 是互联网中的核心协议： TCP/IP 可为各式各样的应用提供服务（所谓 everything over IP), TCP/IP 还允许 IP 在由各种网络构成的互联网上运行（所诮 IP over everything)。因此，互联网才会发展到今天的规模。 因特网的运输层(transport layer)在应用程序端点之间传送应用层报文。在因特网中，有两种运输协议，即TCP(传输控制协议，Transport Control Protocol)和UDP(用户数据报协议，User Datagram Protocol)，利用其中的任一个都能运输应用层报文。\nTCP是一个可靠的、面向连接的协议，包括了应用层报文向目的地的确保传递和流量控制。TCP也将长报文划分为短报文，并提供拥塞控制机制，因此当网络 拥塞时，源抑制其传输速率。\nUDP协议向它的应用程序提供无连接服务。这是一种不提供不必要服务的服务，没有可靠性，没有流量控制，也没有拥塞控制。适用于那些不想要TCP 的有序性或流量控制功能。\n我们把运输层的分组称为报文段(segment)。\n应用层 应用层(application layer)是网络应用程序及它们的应用层协议存留的地方。它包含了所有的高层协议，例如虚拟终端协议（TELNET）、文件传输协议（FTP）、电子邮件协议（SMTP）、超文本传输协议(HTTP)。其中还有一个非常重要的协议——DNS协议(DNS，Domain Name System)，它可以将主机名字映射到它们网络地址的域名系统。\n我们把这种位于应用层的信息分组称为报文（message）。\nTCP/IP 模型与 OSI 参考模型的比较 TCP/lP 模型与 OSl 参考模型有许多相似之处。 首先，二者都采取分层的体系结构，且分层的功能也大体相似。 其次，二者都是基千独立的协议栈的概念。 砐后，二者都可解决异构网络的互连，实现不同厂家生产的计算机之间的通信。\n它们之间的比较如图1. 14 所示。 两个模型除了具有这些基本的相似之处，也有很多差别。\n第一， OSI 参考模型的最大贡献是精确定义了三个主要概念：服务、协议和接口，这与现代 的面向对象程序设计思想非常吻合。而 TCP/IP 栈型在这三个概念上没有明确区分。\n第二， OSl 参考模型是 7 层模型，而 TCP/IP 模型是 4 层结构。 TCP/IP 模型将 OSl 参考模型 的表示层和会话层的功能合并到了应用层，还将数据链路层和物理层合并为网络接口层。\n第三， OSI 参考模型先有模型，后有协议规范，通用性良好，适合描述各种网络。 TCP/IP 模 型正好相反，即先有协议栈，后建立模型，因此不适合任何其他的非 TCP/IP 网络。\n第四， OSI 参考模型在网络层支待无连接和面向连接的通信，但在传输层仅有面向连接的通 信。而 TCP/IP 模型认为可靠性是端到端的问题，因此它在网际层仅有一种无连接的通信模式，\n但传输层支持无连接和面向连接两种模式。这个不同点常常作为考查点。\nOSI 参考模型和 TCP/IP 模型都不是完美的，对二者的批评都很多。 OSI 参考校型的设计者从 一开始就试图建立一个全世界的计算机网络都要遴循的统一标准。从技术角度看，他们追求一种 完美的理想状态，导致基于 OSI 参考模型的软件效率极低。 OSI 参考模型缺乏市场与商业动力， 结构复杂，运行效率低，这是它未能达到预期目标的重要原因。\n学习计算机网络时，我们往往采取折中的办法，即综合 OSI 参考模型和 TCP/IP 模型的优点， 采用一种如图1. 15 所示的只有 5 层协议的体系结构，本书也采用这种体系结构进行讨论。\n图1. 15：应用层-传输层-网络层-数据链路层-物理层\n","date":"2024-01-18T17:06:34Z","permalink":"http://localhost:1313/post/1-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/","title":"1 计算机网络体系结构"},{"content":"2 线性表 线性表 四个特征 唯一的第一个元素\n唯一的最后元素\n除了最后元素之外，其他元素有唯一的后继\n除了第一元素之外，其他元素有唯一的前驱\n线性表定义 线性表是最简单、最基本、也是最常用的线性结构\n具有相同数据类型的n(n\u0026gt;=0)个数据元素的有限序列，通常记为：$ (a_1,a_2,… ,a_{i-1},a_i,a_{i+1},…a_n)$\n其中n为表长， n＝0 时称为空表。线性表元素序号从1开始。\n线性表基本操作 (1) 线性表初始化：InitList(\u0026amp;L)\n(2) 销毁线性表：DestroyList(\u0026amp;L)\n(3) 将线性表置空：ClearList(\u0026amp;L)\n(4) 判断线性表是否为空：ListEmpty(L)\n(5) 求线性表的长度：ListLength (L)\n(6) 取表元：GetElem(L,i,\u0026amp;e)\n(7)按值查找：LocateElem(L,e,compare())\n返回满足条件的数据元素的位序，如果不存在返回0\n(8)前驱：PriorElem(L,cur_e, \u0026amp;pre_e)\n(9)后继：NextElem(L,cur_e,\u0026amp;next_e)\n(10)插入操作：ListInsert (\u0026amp;L,i,e)\n(11) 删除操作：ListDelete (\u0026amp;L,i,\u0026amp;e)\n(12) 遍历操作：ListTraverse (L,visit())\n依次对L的每个数据元素调用函数visit()\n线性表的顺序存储（顺序表） “用一组地址连续的存储单元依次存放线性表中的数据元素”，即以“存储位置相邻”表示“位序相继的两个数据元素之间的前驱和后继的关系(有序对\u0026lt; ai-1,ai \u0026gt;)”，并以表中第一个元素的存储位置作为线性表的起始地址，称作线性表的基地址。\n线性表的存储类型描述 静态分配：\n#define MaxSize 50 typedef struct{ ElemType data[MaxSize]; int length; }SqList; 动态分配：\n#define LIST_INIT_SIZE 50 typedef struct{ ElemType *elem; // 存储空间基址 int length; // 当前长度 int listsize; // 允许的最大存储容量 }SqList;　// 俗称 顺序表 初始化操作 // 构造一个空的线性表 L bool InitList_Sq(SqList \u0026amp;L){ L.elem = (ElemType*)malloc(LIST_INIT_SIZE*sizeof(ElemType)); if (!L.elem) exit(OVERFLOW);　// 存储分配失败 L.length = 0;　// 顺序表的初始长度为0 L.listsize = LIST_INIT_SIZE; // 初始存储容量 return OK; } // InitList_Sq 此算法的时间复杂度为O (1)。\n取表元操作 取线性表中的第i个元素即L.elem[i-1]存到e中，1\u0026lt;=i\u0026lt;=L.length\nbool GetElem_Sq(L, i, \u0026amp;e) { if (i \u0026lt; 1 || i \u0026gt; L.length) return ERROR; // i值不合法 e = L.elem[i - 1]; return OK; } 插入元素操作 把e放到第pos位（1\u0026lt;=pos\u0026lt;=L.length+1），先判断pos是否合法，若合法，将后面元素后移，再插入。\nbool ListInsert_Sq(SqList \u0026amp;L, int pos, ElemType e){ if (pos \u0026lt; 1 || pos \u0026gt; L.length + 1) return ERROR; // 插入位置不合法 if (L.length \u0026gt;= L.listsize) return ERROR; // 当前存储空间已满，无法插入 for (j = L.length; j \u0026gt;= pos; j--){ // 从最后一个到插入位置 L.elem[j] = L.elem[j - 1]; } // 插入位置及之后元素右移 L.elem[pos - 1] = e; // 插入 e L.length++; // 表长增1 return TRUE; } // ListInsert 最好情况：在表尾插入，O(1)\n最坏情况：在表头插入，O(n)\n平均情况：O(n)\n优化：\nbool ListInsert_Sq(SqList \u0026amp;L, int pos, ElemType e){ if (pos \u0026lt; 1 || pos \u0026gt; L.length + 1) return ERROR; // 插入位置不合法　if (L.length \u0026gt;= L.listsize) return ERROR; // 当前存储空间已满，无法插入 q = \u0026amp;(L.elem[pos - 1]); // q为插入位置 for (p = \u0026amp;(L.elem[L.length - 1]); p \u0026gt;= q; --p){ *(p + 1) = *p; } // 插入位置及之后元素右移 L.elem[pos - 1] = e; // 插入 e L.length++; // 表长增1 return TRUE; } // ListInsert 本算法中注意以下问题：\n① 顺序表中数据区域有MAXSIZE个存储单元，所以在向顺序表中做插入时先检查表空间是否满了，在表满的情况下除非扩展空间否则不能再做插入。\n② 要检验插入位置的有效性，这里 pos 的有效范围是：1≤pos≤n+1，其中 n 为原表长。\n③ 注意数据的移动方向。\n④ 表长的修改。\n删除元素操作 bool ListDelete_Sq(SqList \u0026amp;L, int pos, ElemType \u0026amp;e){ if(pos \u0026lt; 1 || pos \u0026gt; L.length) return FALSE ; // 删除位置不合法 e = L.elem[pos-1]; for(j = pos; j\u0026lt;L.length; j++) {//从pos后面一个开始一直到最后 L.elem[j-1] = L.elem[j]; } // 被删除元素之后的元素左移 L.length--; // 表长减1 return TRUE; } // ListDelete 本算法中注意以下问题：\n① 删除第i个元素，i的取值为 1≤i≤n ,否则第i个元素不存在，因此，要检查删除位置的有效性。\n② 当表空时不能做删除，因表空时 L.length的值为0，条件（i\u0026lt;1||i\u0026gt;L.length）也包括了对表空的检查。\n③ 删除ai 之后，该数据已不存在，如果需要，先取出，再做删除。\n④ 修改表长。\n最好情况：删除表尾元素O(1)\n最坏情况：删除表头元素O(n)\n平均情况：O(n)\n元素定位操作 在顺序表L中查找第1个值与 e 满足相等条件的元素，若找到，则返回其在 L 中的位序，否则返回0。\nint LocateElem_Sq(SqList L, ElemType e){ i = 1;　// i 的初值为第1元素的位序 p = L.elem; // p 的初值为第1元素的存储位置 while (i \u0026lt;= L.length \u0026amp;\u0026amp; !equal(*p++,e)) ++i;　// 依次进行判定 if (i \u0026lt;= L.length) return i; // 找到满足判定条件的数据元素为第 i 个元素 else return 0;　// 该线性表中不存在满足判定的数据元素 } // LocateElem 一种更通俗的解法：\nint LocateElem(SqList L,ElemType e){ int i; for(i=0;i\u0026lt;L.length;i++) if(L.data[i]==e) return i+1; return 0; } 最好情况：查找的元素就在表头O(1)\n最坏情况：查找的元素在表尾或者不存在时，O(n)\n平均情况：O(n)\n线性表的链式存储（链表） 结点定义如下：\ntypedef struct LNode{ ElemType data; struct LNode *next; }LNode，*LinkList； 通常用头指针来表示一个单链表。\n头结点和头指针的区分：\n不管带不带头结点，头指针都始终指向链表的第一个结点，而头结点是带头结点的链表中的第一个结点，结点内通常不存储信息。\n引入头结点后，可以带来两个优点:\n由于第一个数据结点的位置被存放在头结点的指针域中，因此在链表的第一个位置上的操作和在表的其他位置上的操作一致，无须进行特殊处理。 无论链表是否为空，其头指针都是指向头结点的非空指针(空表中头结点的指针域为空), 因此空表和非空表的处理也就得到了统一。 单链表 建立链表 头插法 将新节点放到表头\nLinkList List_HeadInsert(LinkList \u0026amp;L){ LNode *s; int x; L=(LinkList)malloc(sizeof(LNode)); L-\u0026gt;next=NULL; scanf(\u0026#34;%d\u0026#34;,\u0026amp;x); while(x!=9999){ //x=9999表示结束 s=(LNode*)malloc(sizeof(LNode)); s-\u0026gt;data=x; s-\u0026gt;next=L-\u0026gt;next; L-\u0026gt;next=s; } return L; } 读入数据的顺序与生成的链表中的元素的顺序相反\nO(n)\n尾插法 增加一个尾指针r\nLinkList List_TailInsert(LinkList \u0026amp;L){ int x; L=(LinkList)malloc(sizeof(LNode)); LNode *s,*r; r=L; L-\u0026gt;next=NULL; scanf(\u0026#34;%d\u0026#34;,\u0026amp;x); while(x!=9999){ //x=9999表示结束 s=(LNode*)malloc(sizeof(LNode)); s-\u0026gt;data=x; r-\u0026gt;next=s; r=s; } r-\u0026gt;next=NULL; return L; } 查找结点 按序号查找 从第1个节点出发，顺next域已知往下查找，直到找到第i个节点为止。否则返回NULL。\nLNode *GetElem(LinkList L,int i){ if(i\u0026lt;1) return NULL; int j=1; LNode *p=L-\u0026gt;next; while(p!=NULL \u0026amp;\u0026amp; j\u0026lt;i){ p=p-\u0026gt;next; j++; } return p; } O(n)\n按值查找 查找给定值e，返回该节点的指针，否则返回NULL\nLNode *LocateElem(LinkList L,ElemType e){ LNode *p=L-\u0026gt;next; while(p!=NULL \u0026amp;\u0026amp; p-\u0026gt;data!=e){ p=p-\u0026gt;next; } return p; } O(n)\n插入结点 将值为x的节点插入到单链表的第i个位置上\n先检测插入的合法性，找到前驱节点，再插入\np=GetElem(L,i-1); s-\u0026gt;next=p-\u0026gt;next; p-\u0026gt;next=s; 删除结点 将第i个节点删除，先检查删除位置合法性再找i-1节点\np=GetElem(L,i-1); q=p-\u0026gt;next; p-\u0026gt;next=q-\u0026gt;next; free(q); O(n)\n双向链表 prior data next typedef struct dlnode{ ElemType data; struct dlnode *prior,*next; }DLNode,*DLinkList; 在双向链表中，通过某结点的指针p既可以直接得到它的后继结点的指针p-\u0026gt;next，也可以直接得到它的前驱结点的的指针p-\u0026gt;prior。\np-\u0026gt;prior-\u0026gt;next == p== p-\u0026gt;next-\u0026gt;prior\n插入结点 设p指向双向链表中某结点，s指向待插入的值为x的新结点，将s插入到p的前面。操作如下：\n①s-\u0026gt;prior=p-\u0026gt;prior;\n②p-\u0026gt;prior-\u0026gt;next=s;\n③s-\u0026gt;next=p;\n④p-\u0026gt;prior=s;\n上面指针操作的顺序不是唯一的，但也不是任意的，操作①必须要放到操作④的前面完成，否则*p的前驱结点的指针就丢掉了。\n删除结点 设p指向双向链表中某结点，删除*p。\n操作如下：\n①p-\u0026gt;prior-\u0026gt;next=p-\u0026gt;next;\n②p-\u0026gt;next-\u0026gt;prior=p-\u0026gt;prior;\n③free(p);\n循环链表 表中最后一个结点的指针不是NULL而改为指向头结点\n静态链表 静态链表借助数组来描述线性表的链式存储结构，结点也有数据域data和指针域next, 与前面所讲的链表中的指针不同的是，这里的指针是结点的相对地址(数组下标) ，又称游标。和顺序表一样，静态链表也要预先分配一块连续的内存空间。\n#define MaxSize 50 typedef struct{ ElemType data; int next; }SLinkList[MaxSize]; 静态链表以next==-l作为其结束的标志.\n顺序表和链表比较 存取(读写)方式 顺序表可以顺序存取，也可以随机存取，链表只能从表头顺序存取元素。例如在第i个位置 上执行存或取的操作，顺序表仅需一次访问，而链表则需从表头开始依次访问i次。\n逻辑结构与物理结构 采用顺序存储时，逻辑上相邻的元素，对应的物理存储位置也相邻。而采用链式存储时，逻辑上相邻的元素，物理存储位置不一定相邻，对应的逻辑关系是通过指针链接来表示的。\n查找、插入和删除操作 对于按值查找，顺序表无序时，两者的时间复杂度均为On；顺序表有序时，可采用折半查找，此时的时间复杂度为O(log2n)o\n对于按序号查找，顺序表支持随机访问，时间复杂度仅为O1，而链表的平均时间复杂度为On。顺序表的插入、删除操作，平均需要移动半个表长的元素。链表的插入、删除操作，只需 修改相关结点的指针域即可。由于链表的每个结点都带有指针域，故而存储密度不够大。\n空间分配 顺序存储在静态存储分配情形下，一旦存储空间装满就不能扩充，若再加入新元素，则会出 现内存溢出，因此需要预先分配足够大的存储空间。预先分配过大，可能会导致顺序表后部大量闲置；预先分配过小，又会造成溢出。动态存储分配虽然存储空间可以扩充，但需要移动大量元 素，导致操作效率降低，而且若内存中没有更大块的连续存储空间，则会导致分配失败。链式存储的结点空间只在需要时申请分配，只要内存有空间就可以分配，操作灵活、高效。\n","date":"2024-01-16T14:56:50Z","permalink":"http://localhost:1313/post/2-%E7%BA%BF%E6%80%A7%E8%A1%A8/","title":"2 线性表"},{"content":"绪论 什么是数据结构 程序 = 算法 + 数据结构\n基本概念和术语 数据 (data)： 信息的载体，被计算机识别、存储加工处理的对象。\n数据元素（data element）：数据的基本单位。通常作为一个整体进行考虑。一个数据元素可由若干个数据项组成。\n数据项(data item)：具有独立含义的标识单位，是数据不可分割的最小单位。\n数据对象(data object)：是性质相同的数据元素的集合，是数据的一个子集。（某种数据类型元素的集合）\n数据对象可以是有限的，也可以是无限的。\n数据结构（data structure）: 相互之间存在着一种或多种特定关系的数据元素的集合。\n结构（structure）: 数据元素之间的关系，可以看做是从具体问题抽象出来的数学模型，与计算机无关，与数据的存储无关，也叫做逻辑结构。\n根据数据元素之间关系的不同特性，通常有下列 4 类基本结构：\n集合 线性结构 树形结构 图状结构或网状结构 从逻辑上可以把数据结构分成线性结构和非线性结构两大类。\n存储结构：数据结构在计算机中的表示。包括数据元素的表示和关系的表示。主要有顺序存储、链式存储、索引存储和散列存储。比如循环队列是一种顺序存储。\n数据类型（data type）：数据类型是一个值的集合和定义在此集合上的一组操作的总称 。\n原子类型 结构类型 抽象数据类型 算法和算法分析 算法的五个特征 有穷性 确定性 可行性 输入 输出 算法效率的度量 时间复杂度 语句的频度f(n)：在算法中重复执行的次数 所有语句的频度之和T(n) 时间复杂度：$T(n)=O(f(n))$，式中$O$的含义是$T(n)$的数量级 时间复杂度的数学定义：存在正常数C和n~0~，使得当$n \\geq n_0$时，都满足$0 \\leq T(n) \\leq Cf(n)$ 时间复杂度分析规则： 加法规则：$T(n)=T_1(n)+T_2(n)=O(f(n))+O(g(n))=O(max(f(n),g(n)))$ 乘法规则：$T(n)=T_1(n)*T_2(n)=O(f(n))*O(g(n))=O(f(n)*g(n))$ 空间复杂度 一个程序在执行时除需要存储空间来存放本身所用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为实现计算所需信息的辅助空间 。若输入数据所占 空间只取决于问题本身，和算法无关，则只需分析除输入和程序之外的额外空间。 算法原地工作是指算法所需的辅助空间为常量，即O(1)。\n引用和指针的区别 指针是一个存储内存地址的变量，引用是一个变量的别名。一般通过指针来访问其指向的内存地址中的内容，通过引用这个别名来使用实际的变量。\n指针有自己的存储空间，引用没有。\n指针可以不初始化，通过赋值可以指向任意同类型的内存；但是引用必须初始化，而且引用一经引用一块内存，再也不能引用其它内存了，即引用不能被改变。\n因为str是一个指针变量，作函数参数时是传值，不是传引用，并不能改变函数外变量的值。\n","date":"2024-01-15T14:56:45Z","permalink":"http://localhost:1313/post/1-%E7%BB%AA%E8%AE%BA/","title":"1 绪论"},{"content":"Mass-Storage Structure Disk Structure Disk Attachment Disk Scheduling※ FCFS SSTF SCAN scan得先到199在回去\n199-53+199-14\nC-SCAN 从199-0这一段也要计算\n199-53+199+37\nLOOK C-LOOK Disk Management Swap-Space Management ","date":"2024-01-05T15:38:45Z","permalink":"http://localhost:1313/post/8-mass-storage-structure/","title":"8 Mass-Storage Structure"},{"content":"File-System File Concept 连续的逻辑地址空间指的是操作系统为用户提供了统一的逻辑视图来访问存储设备上的信息。文件是一个命名的、相关的信息的集合，这些信息被记录在次级存储设备上。文件是逻辑次级存储的最小分配单元。常见的文件类型包括程序源代码、目标代码和数据文件(数字、字符、二进制)。文件可以是自由格式的，也可以是格式固定的。文件的信息由其创建者定义。文件通过其名称进行命名，并可以通过名称进行访问，是独立的。\nFile Attributes 文件属性包括：\n名称(Name): 仅以人类可读的形式保存的信息。 标识符(Identifier): 在系统中唯一标识文件的数字，非人类可读的文件名。 类型(Type): 用于支持不同类型的系统。 位置(Location): 设备上文件的位置指针。 大小(Size): 文件当前的大小。 保护(Protection): 访问控制信息，控制谁可以进行读、写、执行操作。 时间、日期和用户标识(Time, date, and user identification): 用于保护、安全性和使用监控的数据。 这些文件属性保存在目录结构中，该结构由维护在磁盘上的目录条目组成。目录条目由文件名和唯一的id组成，id反过来指向其他文件属性。\nFile Operations 文件是一个抽象数据类型。文件操作的最小集合包括：\nCreate - 找到空间，在目录中为文件创建条目。 Write - 文件名，要写入的信息，写入指针。 Read - 文件名，内存中的位置，读取指针。每个进程有一个当前文件位置指针。 Reposition within file - 文件seek，不需要I/O。 Delete - 文件名，释放文件空间，删除目录条目。 Truncate - 将长度重置为0，释放文件空间。 这些基本操作可以组合起来执行其他文件操作，比如复制。大多数文件操作涉及搜索目录以查找与文件名相关联的条目。 Open-file table是一个内核数据结构，包含有关所有打开文件的的信息。 Open(Fi)操作会在磁盘上的目录结构中查找Fi的条目，并将该条目的内容移动到打开文件表中。它还会返回打开文件表中该条目的一个指针，并接受访问模式信息，如创建、只读、读写、只追加等。 Close(Fi)操作会将打开文件表中Fi的条目的内容移动到磁盘上的目录结构中。\n文件共享意味着多个进程和应用程序可以同时打开同一个文件。 为此，需要两个级别的内部表：\n进程打开文件表：每个进程都有一个进程打开文件表，用于跟踪该进程打开的所有文件以及进程对文件的使用信息，如当前文件指针、访问权限、计费信息等。 系统打开文件表：包含进程无关的信息，如文件在磁盘上的位置、访问日期、文件大小等。每个进程打开文件表的条目都指向一个系统打开文件表的条目。 这样，进程可以独立地使用进程打开文件表，而系统可以使用系统打开文件表来维护进程无关的信息。 Open File Locking 文件锁允许一个进程锁定文件，防止其他进程访问它。 一些操作系统和文件系统提供文件锁，它类似读写锁，包括共享锁和独占锁。共享锁允许多个进程同时获取，独占锁类似写锁，只允许一个进程获取。 文件锁可以调解进程对文件的访问。操作系统可以提供强制或建议的文件锁机制。强制机制根据持有的锁和请求的锁来拒绝访问，而建议机制允许进程查看锁的状态并决定如何操作。\nFile types 操作系统是否应该识别并支持文件类型是一个常见的问题。实现文件类型的常见技术是将类型作为文件名的一部分。文件名被分割成两部分：文件名和扩展名，以点字符分隔。系统使用扩展名来表示文件的类型和可以对该文件进行的操作类型。应用程序也使用扩展名来表示它们感兴趣的文件类型。一些操作系统，每个文件都有一个类型和创作者属性，包含创建该文件的应用程序的名称。在UNIX系统中，一些文件在开头存储一个魔法数字，以大致表示文件的类型。\nFile Structure 文件结构可以分为三种：\n无结构 - 顺序的字符串或字节 简单记录结构 - 行、固定长度、可变长度 复杂结构 - 格式化文档、可重定位加载文件 操作系统和程序都可以决定文件的内部结构。\nInternal file structure 逻辑结构分为两类：\n文本文件：一系列8位字节 记录文件：一系列固定或可变长度的记录 逻辑地址包括文件起始位置的偏移量和逻辑记录号。 物理结构是一组磁盘块。基本I/O函数以块为单位操作。 逻辑地址到物理地址的映射包括逻辑块号、物理磁盘块号和块内偏移量。 内部碎片化是由于逻辑记录大小、物理块大小和打包技术决定的逻辑记录数与物理块数之间的差异。磁盘空间总是以块为单位分配的。\nAccess Methods 文件组织方式主要根据以下几个标准进行分类：\n反映不同的文件结构 - 不同的存储和处理数据的方式。 快速访问 - 单记录访问时需要快速访问，而在批处理模式下不需要。 更新方便性 - CD-ROM上的文件不需要更新，所以这不需要考虑。 存储经济性 - 数据冗余度最小化，冗余度可以用来加速访问，如索引。 维护简单性 - 可靠性。 根据这些标准，文件组织方式主要分为： 堆积文件(Pile File) 顺序文件(Sequential File) 索引顺序文件(Indexed Sequential File) 索引文件(Indexed File) 直接文件(Direct File，或散列文件(Hashed File)) 顺序访问方式包括：\n读取下一个记录 写入下一个记录 重置 重写，最后一次写入后不再读取 直接访问方式包括：\n读取(n) 写入(n) 定位(n) 读取下一个记录，写入下一个记录 重写(n) n为相对块号，第一个为0。 直接访问方式可以模拟顺序访问。 其他访问方式可以建立在直接访问方式之上，通常涉及为文件创建索引。索引可以保存在内存中，以快速确定要操作的数据的位置。如果索引太大，可以使用二级或多级索引文件。索引文件和相对文件的区别在于，索引文件使用索引来定位数据，而相对文件直接使用文件中的偏移量来定位数据。\nDirectory Structure 每个系统中的磁盘至少包含一个分区。有些系统允许分区的大小大于磁盘，以便将磁盘组合成一个逻辑结构。 磁盘或分区可以以原始状态使用，例如交换空间。也可以格式化一个文件系统。\n包含文件系统的实体被称为卷(volume)。 每个卷包含的文件系统也在设备目录或卷表目(volume table of contents)中跟踪该文件系统信息。 目录中包含文件名、文件类型、文件位置等信息。 磁盘或分区可以通过RAID(Redundant Arrays of Independent Drives)来防止故障。 目录结构可以看作是一个符号表，它将文件名转换成目录项(directory entry)。 目录结构为文件名和文件本身提供了映射。 目录结构本身是由操作系统拥有的一个文件。 目录结构和文件都存储在磁盘上。\nSingle-Level Directory 文件系统的基本结构 所有文件都包含在同一个目录中：这意味着文件系统没有使用子目录或分层结构，所有文件都存储在一个共同的位置。\n文件的索引方式\n文件列表，每个文件一个条目：这种方式下，系统会维护一个列表，列表中每个条目代表一个文件。这有点类似于目录，其中每个文件都有对应的条目。 顺序文件，以文件名作为关键字：这里的顺序文件可能指的是索引文件，它根据文件名（作为关键字）来组织文件，允许按文件名顺序访问文件。 遇到的问题\n命名问题 文件必须有唯一的名称：在这样的系统中，由于所有文件都在同一个目录下，因此每个文件的名称必须是唯一的，以避免混淆。 文件名的长度：文件名的长度可能受限，这可能影响到如何命名文件和组织数据。 分组问题：这可能指的是如何有效地将文件分组以便管理，尤其是当所有文件都在一个目录下时。在没有子目录或分类的情况下，组织和检索文件可能会变得更加困难。 Two-Level Directory 这种文件系统结构设计用来解决单级目录系统中文件命名冲突和文件组织问题。\n特点\n为每个用户创建单独的目录：在双级目录系统中，每个用户都有自己的目录，这有助于隔离不同用户的文件。 主文件目录和用户文件目录： 主文件目录：包含每个用户的条目，这些条目可以通过用户名或账号进行索引。它提供了用户目录的地址和访问控制信息。 用户文件目录：每个用户都有一个自己的文件目录，这个目录是该用户文件的简单列表。不同用户可以有同名的文件，因为它们存储在各自的目录中。 优势\n高效的搜索：由于文件被组织在各自的用户目录中，搜索特定用户的文件变得更加高效。 限制\n没有分组能力：这种系统不支持跨用户的文件分组，每个用户的文件都被限制在自己的目录中。 文件共享\n路径名：由用户名和文件名定义。例如，如果一个用户想要访问另一个用户的文件，他们可能需要使用特定的路径名。 特殊的用户目录：包含系统文件。这可能是为了系统管理而设置的，不同于普通用户的目录。 搜索路径：是指系统搜索文件时遍历的目录序列。这可以帮助系统决定在哪些目录中查找文件。 Tree-Structured Directories 这是一种常见的目录结构，其中每个文件都有一个独特的路径名。\n特点 允许用户创建自己的子目录：用户可以组织文件，将它们放在不同的子目录中。 每个用户目录可能包含一个或多个子目录和文件作为条目。 所有目录具有相同的内部格式。 目录条目中的一个位用于定义条目是文件（0）还是子目录（1）。 优势 高效搜索：由于其树形结构，可以快速定位文件和目录。 命名方便：每个文件的路径名是唯一的，方便用户识别和访问。 分组能力：用户可以通过创建子目录来有效地组织和管理文件。 当前目录（工作目录） 在会计文件中，存储了指向用户初始目录的指针或名称。该信息被复制到该用户的本地变量中。 创建新文件默认在当前目录中进行。 删除文件：使用命令 rm \u0026lt;文件名\u0026gt;。 更改当前目录：使用命令 cd /路径。可以使用绝对或相对路径名。 创建新的子目录 在当前目录下创建新的子目录，使用命令 mkdir \u0026lt;目录名\u0026gt;。 例如，在当前目录 /mail 下，创建一个名为 count 的新目录：mkdir count。 删除子目录 删除空目录：在某些系统（如MS-DOS）中，只能删除空目录。 删除所有文件和子目录：在某些系统（如UNIX）中，可以删除包含所有文件和子目录的目录。 Acyclic-Graph Directories 这种目录结构允许共享子目录和文件，是一种较为复杂的文件系统结构。\n特点 相同的文件或子目录可以出现在两个不同的目录中。 共享的文件/目录与文件/目录的两份拷贝不同。 实现共享文件和子目录的方式 创建一个新的目录条目，称为链接（例如UNIX中的链接）：这是指向另一个文件或子目录的指针。 路径名：目录条目被标记为链接。 解析链接：遵循指针定位文件。 链接与原始目录条目明显不同。 在所有共享目录中复制有关共享文件的所有信息： 两个条目相同且等价。 原始文件和副本无法区分。 问题：修改文件时如何保持一致性？ 问题 一个文件可能有多个绝对路径名：不同的文件名可能指向同一个文件（别名问题）。 遍历整个文件系统：累计所有文件的统计信息，将所有文件复制到备份存储中。 共享文件的删除： 删除任何人删除的文件时出现悬挂指针（dangling pointers）。 例如，如果字典删除了计数➢链接，删除链接不会影响原始文件。 删除文件条目，留下悬挂的链接。 文件引用列表，反向指针。 删除共享文件的问题（续） 保留文件直到删除了对它的所有引用： 解决方案：文件引用列表、文件引用计数、反向指针，以便我们可以删除所有指针。 可变大小记录可能是一个问题。 General Graph Directory 与无环图目录（Acyclic-Graph Directory）相比，通用图目录允许目录结构中存在循环（cycles），这意味着目录可以直接或间接地引用自身。\n优势 无环图的主要优势是遍历图的算法相对简单。例如，可以避免对共享子目录的重复搜索，也更容易确定何时没有更多对文件的引用。 问题 设计不良的算法可能导致无限循环，不断地在循环中搜索而永远不会结束。 文件删除的判定 在无环图目录结构中，当引用计数为0时可以删除文件。 在通用图目录结构中，由于存在循环，即使无法再引用目录或文件，引用计数可能不为0。 这种异常情况源于自引用的可能性（即循环）。 解决方案：使用垃圾收集。 第一遍：遍历整个文件系统，标记所有可以访问的内容。 第二遍：收集所有未标记的内容到自由空间列表中。 避免循环的方法 仅允许链接到文件而非子目录：这样可以保证没有循环。 在添加新链接时使用循环检测算法来确定是否可行。但这种方法非常昂贵，尤其是当图在磁盘存储上时。 更简单的算法：在目录遍历期间绕过链接。 File System Mounting 文件系统必须挂载后才能被访问。 挂载过程包括：操作系统被提供设备名称和挂载点(mount point) - 文件结构中用于挂载文件系统的位置。 操作系统通过设备驱动程序读取设备目录并验证目录具有期望的格式，来验证设备包含有效的文件系统。 操作系统在目录结构中记录文件系统已挂载在指定的挂载点。 系统通过语义(semantics)来明确功能：\n可能不允许在包含文件的目录上挂载文件系统。 可能使挂载的文件系统在该目录上可用，直到卸载文件系统才会遮挡该目录中现有的文件。 可能允许同一文件系统在不同的挂载点上重复挂载。 可能只允许每个文件系统挂载一次。 File Sharing 多用户系统中共享文件是必要的。文件和目录的共享可以通过保护机制来实现。多用户系统需要更多的文件和目录属性，包括文件/目录所有者、文件/目录用户、访问权限等。在多用户系统中，用户ID可以识别用户，允许为每个用户设置权限和保护。组ID可以让用户属于组，允许组访问权限。文件/目录的所有者和组可以设置访问权限。\nRemote File Systems 远程文件系统使用网络允许不同系统之间的文件系统访问。 主要有三种方法： 通过像FTP这样的程序手动传输文件，适用于匿名和认证访问。 使用分布式文件系统(DFS)，远程目录对本地机器可见，机器间集成更紧密。 通过WWW自动访问，需要浏览器，使用匿名文件交换。 云计算正在被使用。\nFailure Modes 所有文件系统都有故障模式。本地文件系统故障的原因包括磁盘故障、磁盘控制器故障、电缆故障、主机适配器故障、目录结构或其他非用户数据的损坏、用户或系统管理员的错误。远程文件系统增加了新的故障模式，例如网络故障、服务器故障。从故障中恢复可能需要涉及每个远程请求的状态信息。如果服务器和客户端都维护它们当前的活动和打开的文件的知识，那么它们就可以无缝地从故障中恢复。无状态协议像NFS V3将所有信息包含在每项请求中，这使得恢复很容易，但安全性较低。在NFS V4中，它被设计成有状态的，以证明其安全性、性能和功能。\nConsistency Semantics 一致性语义(Consistency semantics)规定了多个用户如何同时访问共享文件。它指定了一个用户对数据的修改何时对其他用户可见。它类似于第6章中的进程同步算法，但由于磁盘I/O和网络延迟(对于远程文件系统)，通常比较简单。UFS(Unix文件系统)实现了以下一致性语义：\n每个文件关联到单个物理映像。 对同一打开文件的其他用户的写入立即可见。 共享文件指针以允许多个用户并发地读取和写入。 一致性语义(Consistency semantics)规定了多个用户如何同时访问共享文件。\nAFS(Andrew File System)实现了复杂的远程文件共享语义：服务器记录客户端的行为，并保留客户端缓存的文件信息。当客户端更改文件时，服务器使用回调承诺技术通知其他客户端。只有在文件关闭后，写入才对会话可见。 不可变的共享文件，由其创建者声明为只读的。文件名不能重复，内容不能更改。 Protection 可靠性涉及文件副本的备份，保护涉及对文件的访问控制，文件所有者/创建者应该能够控制对文件可以进行什么操作以及由谁进行操作。文件访问类型包括读取、写入、执行、追加、删除、列出等。\nAccess control 访问模式：读、写、执行\n读（Read, R）：查看文件内容的权限。 写（Write, W）：修改或删除文件的权限。 执行（Execute, X）：运行文件的权限，对于脚本或程序尤其重要。 取决于用户的身份\n根据用户的身份，访问权限可能会有所不同。这通常通过以下方式管理：\n访问控制列表（Access-Control List, ACL）：一种表格，将每个文件与特定用户关联，并定义每个用户拥有的访问类型（读、写、执行）。 三类用户\n拥有者（Owner）：创建文件的用户。通常拥有最多的权限。 群组（Group）：一组需要类似访问权限的共享文件的用户。 普通用户（Universe/Public）：系统中的所有其他用户。 访问控制信息\n用户访问：读写执行（RWX，二进制表示为111，十进制表示为7） 群组访问：读写（RW，二进制表示为110，十进制表示为6） 公共访问：执行（X，二进制表示为001，十进制表示为1） 权限控制的优势与问题\n优势：增强安全性，确保只有授权用户才能访问特定的文件或目录。 问题：可能导致配置复杂，如果不正确设置，可能会不慎阻止合法用户的访问或允许非授权访问。 群组的创建和修改\n只有管理员或超级用户（superuser）能创建和修改群组。 管理员可以创建一个具有唯一名称的群组，比如G，并向群组中添加用户。 对于特定的文件（比如“game”）或子目录，可以定义适当的访问权限。 更改用户的访问方法\n例如，使用chmod命令更改文件权限：\nchmod G +w o=x file 表示给群组G增加写权限，给其他用户（public）设置执行权限。 chgrp G game 表示将文件“game”关联到群组G。 File System Implementation File System Structure 文件定义 文件：是相关信息的集合，是逻辑存储单元。它可以包含文本、图像、程序或其他数据类型。 磁盘特性 磁盘可就地写入：即在磁盘上直接修改数据，而无需先移动数据。 磁盘可直接访问任意给定的信息块：这意味着可以高效地检索和存储数据。 内存与磁盘间的I/O传输以块为单位：数据在内存和磁盘之间以块的形式进行传输。 文件系统位置 文件系统位于**次级存储（如磁盘）**上，它提供了用户对存储的接口，将逻辑地址映射到物理地址。 功能 提供有效且方便的磁盘访问：允许数据被轻松存储、定位和检索。 文件系统结构 主要设计问题 用户界面：涉及定义文件及其属性、文件操作和目录结构。 将逻辑文件系统映射到物理次级存储设备的算法和数据结构。 文件控制块：存储有关文件的信息的存储结构。 设备驱动程序：控制物理设备。 文件系统组织成层：这有助于管理和优化存储和检索操作。 总的来说，文件是存储在磁盘等次级存储设备上的逻辑存储单位，文件系统提供了有效的方式来组织、存储、检索和管理这些文件。文件系统的设计要考虑用户界面、存储映射算法和数据结构、以及文件和设备管理的不同层次。\nLayered File System 应用程序层（application programs）： 系统调用用于文件操作。 逻辑文件系统层（logical file system）： 管理元数据信息。 管理目录结构。 通过文件控制块（FCB，例如索引节点inodes）维护文件结构。 负责保护和安全性。 文件组织模块层（file-organization module）： 理解文件、逻辑地址和物理块。 将逻辑块地址转换为物理块地址。 空闲空间管理器，磁盘分配。 基本文件系统层（basic file system）： 向适当的设备驱动程序发出通用命令来读写磁盘上的物理块。 管理内存缓冲区和缓存（分配、释放、替换），例如I/O缓冲区、目录/数据的磁盘缓存。 I/O控制层（I/O control）： 设备驱动程序和中断处理程序。 在主内存和磁盘系统之间传输信息。 将如“读取驱动器1，柱面72，磨道2，扇区10”的命令转换为内存位置1060的低级硬件特定命令。 设备层（devices）： 这一层与物理硬件直接交互。 File Systems 在操作系统中，存在多种文件系统，每种都有自己的格式：\nCD-ROM使用ISO 9660格式：这是一个由制造商共同商定的标准格式。 Unix系统通常使用UFS（Unix File System）：它基于伯克利快速文件系统（Berkeley FFS）。 Windows支持多种文件系统： FAT（File Allocation Table）：较老的文件系统，曾广泛用于早期Windows版本和可移动存储设备。 FAT32：FAT的扩展版本，支持更大的磁盘和文件尺寸。 NTFS（New Technology File System）：Windows的现代文件系统，提供安全性、文件恢复和大文件支持等特性。 此外，Windows也支持软盘、CD、DVD等多种存储媒介的文件系统。 Linux支持40多种类型的文件系统： 标准Linux文件系统：扩展文件系统（extended file system），包括ext2。 常用的文件系统：ext3和ext4，它们提供了日志功能和更高的数据完整性。 分布式文件系统：专门用于分布式计算环境，如网络文件系统（NFS）等。 新的文件系统仍在不断推出： ZFS（Zettabyte File System）：一种高容量、高性能的文件系统，提供了卓越的数据完整性保护。 OpenZFS：ZFS的一个开源版本。 Google GFS（Google File System）：用于大规模分布式计算系统的文件系统。 Oracle ASM（Automatic Storage Management）：一种数据库文件系统，用于简化数据库数据的存储管理。 FUSE（Filesystem in Userspace）：一种允许用户在用户空间中创建文件系统的接口，增加了灵活性和安全性。 File System Implementation On-disk File System Structures 在磁盘上，文件系统可能包含以下部分：\n启动操作系统的信息：如果操作系统存储在该磁盘上，这部分信息会告诉计算机如何从磁盘启动操作系统。\n块的总数：磁盘上数据存储的基本单位，文件系统会跟踪总共有多少块。\n空闲块的数量和位置：文件系统需要管理空闲块以便存储新的数据。\n目录结构：包含文件和子目录的组织结构。\n个别文件：具体的数据内容。\n磁盘结构\n启动控制块（Boot Control Block）（每个卷）： 通常是卷的第一个块。 在UFS中称为启动块，在NTFS中称为分区启动扇区。 卷/分区控制块（Volume/Partition Control Block）（每个卷）： 包含块的详细信息、块大小、空闲块计数和空闲块指针、空闲文件控制块（FCB）计数和空闲FCB指针。 在UFS中称为超级块，在NTFS中是主文件表（Master File Table）的一部分。 目录结构（每个文件系统）： 在UFS中包含文件名和关联的inode编号。 在NTFS中包含在主文件表中。 文件控制块（FCB）（每个文件）： 包含关于文件的信息的存储结构，包括所有权、权限和文件内容的位置。 在UFS中称为inode，在NTFS中也是主文件表（作为关系数据库）的一部分。 以上结构确保了文件系统能够有效地管理和定位磁盘上的数据，同时也保证了数据的安全和可访问性。每种文件系统（如UFS、NTFS）都有其特定的实现方式和数据结构。\nIn-Memory File System Structures 在内存中的文件系统结构用于：\n文件系统管理：这包括管理文件系统的挂载、目录结构、文件的打开和关闭等。 通过缓存改善性能：数据缓存可以减少对次级存储（如硬盘）的访问次数，从而提高系统性能。 内存中的结构 内存中的挂载表（In-memory mount table）： 存储文件系统的挂载信息、挂载点、文件系统类型等。 内存中的目录结构缓存： 加速目录访问和查找操作。 系统范围的打开文件表（System-wide open-file table）（系统中只有一张表）： 包含每个打开文件的文件控制块（FCB）的副本。 每个打开的文件有一个条目。 每个进程的打开文件表（Per-process open-file table）（每个进程一张表）： 包含指向系统范围打开文件表中相应条目的指针。 每个由该进程打开的文件有一个条目。 缓冲区： 存放来自次级存储的数据块。 Partitions and Mounting 分区与挂载是操作系统管理磁盘存储的基本概念。\n分区\n一个磁盘可以被分成多个分区，或者一个分区可以跨越多个磁盘。 每个分区可以是： “原始”（raw）：不包含文件系统，只是一系列的块。 “已格式化”（cooked）：包含文件系统。 启动信息\n启动信息可以存储在一个单独的分区中，它有自己的格式，并作为一个镜像加载到内存中，在预定义的位置开始执行。 引导加载程序（Boot loader）\n知道足够的文件系统结构信息，能够找到并加载内核并开始执行。 理解多个文件系统和多个操作系统可以占用启动空间。 根分区\n在启动时挂载的根分区，包含操作系统内核和可能的其他系统文件。 其他分区\n其他分区可以在启动时自动挂载，或者稍后手动挂载。 挂载时检查\n在挂载时，会检查文件系统的一致性。 通过请求设备驱动程序读取目录并验证目录是否具有预期的格式。 检查所有元数据是否正确。 如果不正确，则修复后重试。 如果正确，则添加到挂载表中，允许访问。 挂载表（Mount table）\n包含已挂载文件系统的信息。 分区允许操作系统将磁盘空间划分为独立的区域，每个区域可以独立管理和挂载。挂载是操作系统识别和准备访问文件系统的过程。通过挂载表，系统可以跟踪所有已挂载的文件系统及其相关信息。这些概念对于操作系统有效管理存储和确保数据的完整性至关重要。\nVirtual File Systems 现代操作系统需要同时支持多种类型的文件系统。这是如何实现的，以及用户如何在不同类型的文件系统之间无缝切换？\n虚拟文件系统（Virtual File System, VFS）\n支持多种文件系统：\n操作系统必须能够支持多种不同的文件系统类型，包括网络文件系统。 集成到目录结构中：\n操作系统如何允许多种类型的文件系统被集成到一个目录结构中？ 用户无缝切换：\n用户如何在文件系统空间中无缝地在不同文件系统类型之间移动？ VFS的实现方法\n大多数操作系统（包括Unix）使用面向对象的技术来实现文件系统，这就是VFS。 VFS的功能\n允许不同的文件系统类型在同一个结构内实现：\n这包括本地文件系统和网络文件系统。 简化、组织和模块化实现：\n通过数据结构和过程来隔离基本的系统调用功能与实现细节。 VFS如何工作\n将文件系统通用操作与实现细节分离：\n实现可以是众多文件系统类型之一，或者是网络文件系统。 实现了节点（vnodes）：\n节点持有索引节点（inodes）或网络文件的详细信息。 将操作分派给适当的文件系统实现例程：\n这样用户通过相同的系统调用接口（API）就可以访问不同类型的文件系统。 API针对的是VFS接口：\n而不是任何特定类型的文件系统。 综上所述，VFS提供了一个抽象层，使得操作系统可以通过一个统一的接口与多种不同的文件系统交互。这样，无论用户正在访问的是本地文件系统、外部存储设备上的文件系统，还是网络文件系统，体验都是一致的。VFS的设计允许操作系统开发者在不改变用户界面的情况下，增加对新文件系统类型的支持。\nDirectory Implementation 在文件系统中，文件名通常与它们数据块的指针关联，这样的结构可以用多种方式组织：\n线性列表\n优点：编程简单。 缺点：执行时间消耗大，因为每次搜索都需要遍历整个列表。 线性搜索时间：查找文件时可能需要遍历整个文件列表，这在文件数量很多时效率低下。 排序列表\n通过对文件名列表排序，可以使用二分搜索，这样可以减少平均搜索时间。 平衡树\n平衡树（如AVL树或红黑树）可以进一步优化搜索时间，因为它们保证了在最坏的情况下仍然具有较好的搜索效率。 哈希表\n使用哈希数据结构的线性列表可以减少目录搜索时间。 碰撞问题：两个文件名可能映射到同一哈希位置（哈希冲突）。 链式溢出：一种解决哈希冲突的方法，即在冲突发生时使用链表将冲突的元素连接起来。 困难： 固定大小：哈希表的大小通常是固定的，这可能限制了文件系统的扩展性。 哈希函数选择：一个好的哈希函数应该减少冲突，同时均匀地分布数据。选择或设计一个适合文件系统需求的哈希函数可能具有挑战性。 Allocation Methods Contiguous Allocation 将一组连续的磁盘块一次性分配给文件。 记录文件起始位置和长度。 它支持顺序访问和直接访问。 优势 读写性能高：由于数据块是连续的，读取文件时磁头移动最小，可以快速连续地读写数据。 管理简单：文件系统不需要复杂的算法来跟踪文件的各个部分，因为它们总是在一起的。 不会产生外部碎片：每个文件保存为一连串连续的块，因此不会在文件之间留下未使用的空间。 逻辑地址转物理地址 假设文件开始于磁盘上的块号 B，并且每个块有 S 个字节。如果你想访问文件中的逻辑地址 L（例如，文件的第 L 个字节），你可以使用以下步骤来找到对应的物理地址： 计算逻辑地址 L 所在的块号：BlockNum = L / S。 计算逻辑地址 L 在其块内的偏移量：Offset = L % S。 然后，物理块号就是 PhysicalBlock = B + BlockNum。 物理地址就是 PhysicalBlock 块的起始地址加上 Offset。 Linked Allocation 链接分配是一种基于单个块的分配方式，每个文件都是一组散布在磁盘上的磁盘块的链表。 目录包含第一个和最后一个块的指针，每个块包含指向链表中下一个块的指针。 没有外部碎片化，任何空闲块都可以用于满足请求。 缺点是：没有随机访问，空间用于指针，可靠性较差。 访问第n块逻辑块时需要依次读$0-(n-1)$块，即$n-1$次磁盘IO 逻辑地址转物理地址 假设你要访问文件的第 L 字节，这里的 L 是文件内的逻辑地址： 确定起始块：从文件的目录项中获取指向文件第一个数据块的指针。 计算块号：确定 L 所在的数据块。这需要知道每个数据块的大小 S（不包括存储下一个块指针的空间）。计算逻辑地址 L 所在的数据块编号为 BlockNum = L / S。 遍历数据块链：从文件的第一个数据块开始，遵循每个块中的指针，直到到达第 BlockNum 个块。 计算块内偏移量：确定 L 在找到的数据块内的位置，即块内偏移量 Offset = L % S。 定位物理地址：使用块号和块内偏移量来确定数据的物理地址。 Indexed Allocation 每个文件都有自己的索引块，索引块是一个磁盘块地址的数组。 目录包含索引块的块号。 索引块可以避免外部碎片化，并实现文件的随机访问。 逻辑地址转物理地址 假设文件最大大小为256KB，块大小为1KB，逻辑地址为 LA： 一级索引分配 计算逻辑块号和块内偏移：\n$Q = \\frac{LA}{1024}$：确定逻辑地址 LA 所在的数据块编号。 $R = LA \\mod 1024$：确定 LA 在其数据块中的偏移量。 在索引表中找到相应的数据块：\n使用Q作为索引，在索引块中找到指向实际数据块的指针。 该指针指向的是文件中第Q个块的物理位置。 二级索引分配 第一级索引块号 ( Q1 ) 和 第一级块内偏移 ( R1 )： $Q1 = \\frac{LA}{1024}$ $Q2 = \\frac{Q1}{256}$ ：第二级索引块序号。 $R2 = Q1 \\mod 256$：第二级索引块内偏移。 使用 ( Q2 ) 在外索引块中找到内索引块的物理块号；然后使用 ( R2 ) 在该内索引块中找到实际数据块的物理块号。 Performance 文件访问方式的选择取决于文件访问类型。\n对于连续访问，索引块和数据块的连续分配方式比较适合。而对于链接访问，索引块和数据块的链接分配方式更适合。\n在文件创建时声明访问类型，可以选择连续分配或链接分配。索引分配方式更复杂，需要根据索引结构、文件大小以及所需块的位置来决定。\n单块访问可能需要2次I/O操作来读取索引块，然后1次操作读取数据块。或者需要3次I/O操作来读取2次索引块，然后1次操作读取数据块。群集可以提高吞吐量，减少CPU开销，将连续分配与索引分配结合使用，对于小文件(最多3-4个块)使用连续分配，如果文件变得很大，则自动切换到索引分配。\nFree-Space Management Bit map / Bit vector Linked list Grouping Counting ","date":"2023-12-30T12:45:59Z","permalink":"http://localhost:1313/post/7-file-system/","title":"7 File-System"},{"content":"Main Memory Background 计算机内存由大量存储单元组成，每个单元有地址。程序需要将指令和数据加载到内存中才能运行。 内存和寄存器是CPU可以直接访问的存储单元。寄存器访问速度快，内存访问速度较慢。 Cache位于内存和CPU之间，用于暂存常用数据，以加速CPU的访问。 指令执行需要经历取指令、解码、取操作数、执行和存储结果等多个步骤。内存访问是其中较慢的一步。 为了保护内存，需要硬件提供地址映射功能，确保每个进程只能访问自己的地址空间。 内存管理的目标是高效地为多个进程分配内存，同时满足进程对内存的需求。\nSwapping 进程可以暂时从内存中交换到备份存储设备上，然后被重新调入内存以继续执行。 进程的物理内存空间可以超过物理内存的大小。 备份存储设备Backing store - fast disk，足以容纳所有用户的内存映像副本。 交换出的进程是否会被交换回它之前使用的相同内存空间，取决于地址绑定方法。 Roll out, Roll in - 基于优先级的调度算法。 就绪队列 - 包含所有在备份存储设备上或在内存中并且准备运行的过程。 调度程序 - CPU调度器决定执行一个进程时被调用。 如果下一个进程不在内存中，且没有空闲内存区域，调度程序会交换掉当前内存中的一个进程，并调入所需进程。 上下文切换时间可能非常高。 总传输时间与交换的内存量成正比。 用户必须告知系统其对内存需求的任何变化。 永不交换带有未决I/O操作的过程。 标准交换在现代操作系统中不使用。\nContiguous Memory Allocation 内存需要同时满足操作系统和用户进程的需求。 内存通常被划分为操作系统分区(低内存，包含中断向量)和用户进程分区(高内存)。 用户空间进一步划分为多个分区。 对每个进程进行单分区分配。 使用重定位寄存器方案（relocation-register scheme）来保护用户进程，使其相互隔离，并防止改变操作系统代码和数据。 重定位寄存器Relocation/base register包含最小物理地址值。 限制寄存器limit register包含逻辑地址范围。 每个逻辑地址必须小于限制寄存器的值。 MMU动态映射逻辑地址到物理地址，调度程序加载重定位和限制寄存器，逻辑地址必须小于限制寄存器的值，否则会导致越界访问，触发trap异常。\n重定位寄存器的作用：\n基址调整：重定位寄存器的主要作用是存储一个基址值，这个值在运行时被加到进程的虚拟地址上，以产生实际的物理地址。这种机制允许系统动态地改变进程在物理内存中的位置。 支持进程隔离：通过使用重定位寄存器，操作系统可以确保一个进程不能访问到其他进程的内存空间。这提高了系统的安全性和稳定性。 内存保护：重定位寄存器也被用于内存保护。操作系统可以设置边界，以保证进程只能访问分配给它的内存区域。如果进程尝试访问超出这个范围的内存，会触发一个异常，例如段错误。 简化链接和加载：在程序加载时，重定位寄存器使得程序无需知道其在物理内存中的实际位置。程序可以在编译时使用相对地址，加载时由操作系统通过重定位寄存器调整这些地址。 上下文切换时的更新：在多任务操作系统中，当CPU从一个进程切换到另一个进程时，操作系统会更新重定位寄存器以反映新进程的内存基址。 与虚拟内存的关系：在现代操作系统中，虚拟内存的使用使得重定位寄存器的角色变得不那么直接显著，因为地址转换更多地依赖于分页机制和页表。然而，在某些体系结构和早期系统中，重定位寄存器仍然是内存管理的重要组成部分。 Fixed Partitioning 固定分区方式将内存分成多个固定大小的分区(partitions)。\n如果分区大小等于或小于进程大小，则可以将进程加载到可用的分区中。 所有分区都充满后，操作系统可以将进程从某个分区交换出去。 如果程序大小超过分区大小，程序员需要设计程序使用覆盖(overlay)技术。 分区大小不同时，内存使用效率低，任何大小程序都会占用整个分区，导致内部碎片。 Placement Algorithm with Partitions 内存分区的放置算法\n相等大小分区(Equal-size partitions)：所有分区大小相等，使用哪个分区并不重要。 不等大小分区(Unequal-size partitions)：可以为每个进程分配其最适合的较小分区。为每个分区创建一个队列，进程的分配方式要尽量减少分区内的浪费内存。 数据结构：每个分区包含分区ID、基地址、限制地址、状态等信息。 Variable-partition 可变分区(Variable-partition scheme)内存管理方式 可变分区(也称为动态分区，Dynamic Partitioning)是一种动态分配内存的方式。\n内存被分成大小和数量可变的分区(partitions)。 初始时，所有内存都可供用户进程使用，形成一个大的空闲区(hole)。 内存中散布着各种大小的空闲区。 操作系统维护一个表，包含哪些分区已被分配以及给哪个进程使用等信息。 当一个进程到达时，它从足够大的空闲区中分配内存。 进程退出时，释放其分区，相邻的空闲分区合并。 Dynamic Storage-Allocation Problem 动态存储分配问题是如何从一组空闲区中满足大小为n的请求。\nFirst-fit：选择第一个足够大的空闲区分配。 Best-fit：选择最小且足够大的空闲区分配。 Worst-fit：选择最大的空闲区分配。 首次适应法和最佳适应法在速度和存储利用率方面优于最差适应法。但是这些算法都存在外部碎片问题。 Fragmentation 内存碎片(Fragmentation)\n外部碎片(External Fragmentation)：存在足够的内存空间来满足请求，但是这些内存空间不连续。 内部碎片(Internal Fragmentation)：分配的内存可能比请求的内存略大，这个大小差异是分区内的内存，但是没有被使用。 对首次适应法(First Fit)的统计分析表明，给定N个块被分配，另外0.5N个块将因碎片化而无法使用。 1/3的内存可能无法使用 -\u0026gt; 50%规则。 该段内容主要介绍了内存碎片(Fragmentation)的问题以及通过整理内存来减少碎片的方法。 通过整理内存(Compaction)来减少外部碎片，即将所有空闲内存移动到一起形成一个大的内存块。整理内存需要在执行时动态地进行，并且需要锁定内存中的作业以避免在进行I/O操作时出现错误。 备份存储(Backing store)也会存在类似的问题。 Paging Paging 进程的物理地址空间可以是离散的：这意味着一个进程的不同部分可以存储在物理内存的不同位置，而不是必须连续。 实现分页的基本方法： 物理内存分块：物理内存被划分为固定大小的块，称为帧（frames）。 逻辑内存分块：逻辑内存（即进程视角下的内存）也被划分为与帧大小相同的块，称为页（pages）。 备份存储分块：备份存储（如硬盘）被划分为与内存帧相同大小的块，以便存储不在物理内存中的页。 页的大小：页的大小通常是2的幂次方，范围在512字节到16MB之间。 页的加载与内存分配： 当进程需要执行时，它的页被加载到内存中任何可用的帧中。 进程在帧可用时被分配内存，这有助于避免外部碎片（内存中未被使用的空间）和不同大小内存块带来的问题。 运行进程所需的内存分配：要运行一个包含n个页的程序，需要找到n个空闲的帧并将程序加载到这些帧中。 页表的作用： 操作系统为每个进程维护一个页表（page table）。 页表包含每个页在物理内存中的帧位置信息。 页表用于将进程的逻辑地址转换为物理地址。 内部碎片问题：内部碎片（internal fragmentation）通常发生在内存分配的最后一个页中，当页未完全使用时。 逻辑地址的分解： 每个逻辑地址分为两部分：页号（p）和页偏移（d）。 页号用作在页表中索引，以找到每个页在物理内存中的基地址。 页偏移与基地址组合，定义了发送给内存单元的实际物理地址。 内存访问次数 对于简单的分页系统，可能只需要一次额外的内存访问来获取页表项。两次访问内存。 对于多级页表（如现代操作系统中常用的），可能需要多次内存访问。每一级页表都可能需要单独的内存访问。n级页表访问n+1次内存。 Address structure 逻辑地址的大小一般要大于物理地址的大小。\n相等的情况：在某些系统中，逻辑地址空间的大小可以与物理地址空间的大小相等。这通常发生在不使用特殊内存管理技术（如分页或分段）的简单系统中。 逻辑地址空间大于物理地址空间：在使用虚拟内存技术的系统中，逻辑地址空间通常大于物理地址空间。这是因为虚拟内存允许操作系统利用硬盘空间作为扩展的内存，使得进程看起来拥有比实际物理内存更多的内存。在这种情况下，逻辑地址用于表示进程的地址空间，而物理地址则是实际存储在物理内存中的地址。 物理地址空间大于逻辑地址空间：这种情况较少见，但在某些特殊的硬件或操作系统设计中可能发生。例如，某些高端服务器或特殊用途的计算机可能具有更大的物理内存，而操作系统可能只允许每个进程访问其中的一部分。 动态关系：在某些系统中，逻辑地址空间和物理地址空间的大小关系可能不是静态固定的，而是根据当前的内存使用情况和操作系统策略动态变化的。\n页的大小跟帧的大小相同，以便进行无缝映射。\nFragmentation 分页式内存管理避免了外部碎片化，但存在内部碎片化问题。 例如，如果页面大小为2048字节，进程大小为72766字节，则需要35个页面，但进程只使用了1086字节的内部碎片。 最坏情况下内部碎片化等于1个页面大小，平均碎片化等于页面大小的一半。 所以页面大小越小越好吗？不是，因为每个页面表项都需要内存，页面大小越小，需要的页面表项越多。\nHardware support 使用一组寄存器用于页表的管理(\u0026lt;256项)。 对于较大的页表(例如100万项)，页表会保存在主内存中。 页表基址寄存器(PTBR)指向页表的位置。 页表长度寄存器(PTLR)表示页表的大小。 在这种方案中，每次数据/指令访问都需要访问两次内存，一次是页表项，一次是数据/指令。 为了解决两次内存访问的问题，使用了一种特殊的、小型的、快速查找的硬件高速缓存，称为翻译旁路缓冲(TLBs)或关联内存。 TLB的功能与内存高速缓存相似，它保存了最近使用的页表项，以加速页号到帧号的映射查找。 TLB \u0026ndash;Translation Look-aside Buffer TLB是一个高速的关联存储器，它包含最近使用的页表项。每个TLB项包含两个部分：键和值(页号，帧号)。给定一个逻辑地址，处理器会同时比较所有键，如果找到匹配的键(命中)，则直接获取对应的帧号并形成物理地址；如果没有找到匹配的键(未命中)，则使用逻辑地址中的页号去索引进程的页表以获取帧号。\n当TLB未命中时(miss)，会将页表项的值加载到TLB中，以便下次更快地访问。TLB通常比较小(64到1024个条目)。需要考虑替换策略(例如LRU)。一些TLB条目可以永久性地固定下来，以便快速访问，例如关键的内核代码的条目。 一些TLB在每条目中存储地址空间标识符(ASID),ASID唯一标识每个进程，用于为该进程提供地址空间保护。ASID允许多个不同的进程同时拥有TLB条目。\nEffective Access Time (EAT) EAT(有效访问时间)是CPU访问内存所需的时间，包括查找TLB的时间和访问内存的时间。其中查找TLB的时间取决于TLB的命中率，即找到页表项的概率。TLB的查找时间是一个常数，假设为ε nanoseconds。访问内存的时间取决于内存的周期时间，假设为θ nanoseconds。 当TLB命中时，有效访问时间EAT = ε + θ； 当TLB未命中时，有效访问时间EAT = (ε + 2θ) * (1 - α) + α * θ 其中α是TLB的命中率。 例如，如果TLB查找时间为20ns，内存周期时间为100ns, TLB命中率为0.8，则有效访问时间为： EAT = (20 + 100) * 0.8 + 20 * 0.2 * 100 = 140ns 如果TLB查找时间为20ns，内存周期时间为100ns, TLB命中率为0.98，则有效访问时间为： EAT = (20 + 100) * 0.98 + 20 * 0.02 * 100 = 122ns\nMemory Protection 内存保护通过在每个帧(frame)上关联保护位来实现。通常这些保护位保存在页表中。 RW位可以定义一个页是可读写的还是只读的，还可以添加更多位来指示页是只执行的等。 页表中的每个条目都带有有效位。 “有效”表示对应的页在进程的逻辑地址空间内，因此是合法的页。 “无效”表示对应的页不在进程的逻辑地址空间内。 也可以使用页表长度寄存器(PTLR)。 任何违反都会导致陷入内核。 Shared Pages Shared Pages是指多个进程共享同一只读(不可变)代码的内存页。这些共享代码必须出现在所有进程的逻辑地址空间中的相同位置。这类似于多个线程共享同一个进程空间。Shared Pages也可以用于进程间通信，如果允许共享读写页的话。 而Private Pages则是指每个进程都有自己的代码和数据的独立内存页。这些私有的代码和数据页可以在逻辑地址空间的任意位置出现。\nStructure of the Page Table Hierarchical Paging 层次页表结构：将页表自身也进行分页，可以减少内存占用。常见的有双级页表。\nHashed Page Tables Hashed Page Tables(散列表页表)在地址空间大于32位时常见。 散列表中的每个条目包含一个链表，其中元素通过哈希函数散列到同一位置。每个元素包含三个字段： (1)虚拟页号 (2)对应的物理页号 (3)指向下一个元素的指针 逻辑页号通过哈希函数散列到散列表中，并与链表中元素的(1)字段进行比较查找匹配项。如果找到匹配项，则提取对应的物理页号(2)。如果没有匹配项，则继续搜索链表中的后续元素以查找匹配逻辑页号。\nInverted Page Tables Inverted Page Table(反向页表)是一种内存管理的数据结构，其包含每个真实内存帧(frame)的一个条目，每个条目包含该帧的虚拟地址以及该帧所属进程的地址空间标识符(ASID)等信息。与标准页表相比，反向页表将虚拟地址空间和物理地址空间颠倒了，从而需要额外的地址空间来存储进程的地址空间信息。\nSegmentation 分段是将程序划分为逻辑上的段（如代码段、数据段、堆段和栈段）的过程，这些段在程序的执行过程中被映射到物理内存。\n程序由多个段组成，每个段是一个逻辑单元，如主程序、过程/函数/方法、公共块、对象、栈/符号表/数组、局部变量/全局变量等。 段的长度各不相同。 段内的元素通过相对于段起始地址的偏移来标识。 分段是一种支持用户对内存这种视图的内存管理方案。 每个段都有自己的名称和长度。\n以下是决定程序分段的几个关键步骤：\n编译阶段： 在编译时，编译器将源代码转换为机器代码，并将其组织成不同的段。 例如，编译器会将程序的函数和方法放入代码段，静态变量放入数据段，等等。 链接阶段： 链接器将编译后的代码（和库代码）合并，形成一个完整的可执行文件。 在这个过程中，链接器决定了各个段的相对位置，并创建了一个包含这些信息的段表。 加载时： 当程序被加载到内存中执行时，操作系统根据可执行文件中的信息，将这些段映射到物理内存。 操作系统还处理如何为这些段分配内存，以及这些段的保护和权限设置。 动态链接： 对于使用动态链接库（DLLs）的程序，某些段可能在程序运行时动态加载。 这种情况下，具体的段分配可能会在程序执行期间发生，而不是在程序启动时一次性完成。 Segmentation Architecture 逻辑地址由段号和偏移组成，如\u0026lt;段号，偏移\u0026gt; 分段表将二维的用户定义地址映射为一维的物理地址，每个表项包含段基址(包含段在内存中的起始物理地址)和段限制(指定段的长度) 分段表基址寄存器(STBR)指向分段表在内存中的位置 分段表长度寄存器(STLR)表示程序使用的段数 如果段号s小于STLR，则段号s是合法的。 Fragmentation 在分段式内存管理中，内存是根据段的大小动态分配的。每个段的大小根据程序的需求而定，并不是固定的。 然而，随着程序的加载和卸载，内存中会出现不连续的空闲区域。这些零散的空闲区域可能无法被有效利用，尤其是当需要分配一个大的内存段时，即使总空闲内存量足够，但由于这些空闲区域是分散的，无法满足连续内存的需求。 这种情况称为外部碎片。它发生在已分配内存块的外部，因此得名“外部碎片”。 Segmentation With Paging 段页式内存管理是一种计算机内存管理技术，它结合了分段和分页两种方法。在这种方案中，地址空间被分成多个段，每个段进一步被划分为多个页。地址映射表在段页式内存管理中扮演着至关重要的角色，它负责将虚拟地址转换为物理地址。下面是段页式内存管理中地址映射的基本过程：\n虚拟地址结构：在段页式管理中，虚拟地址通常包含两部分——段号和段内偏移。段内偏移进一步分为页号和页内偏移。 段表：系统为每个进程维护一个段表，段表存储每个段的信息，如段的基址、大小等。段表还包括指向页表的指针。 页表：每个段有一个页表，页表存储页的物理地址信息。页表负责将段内的虚拟页号映射到物理内存的页帧号。 地址转换过程： 根据虚拟地址中的段号，访问段表，获取段的基本信息和对应的页表地址。 使用虚拟地址中的页号，访问该段的页表，找到对应页的物理帧号。 将物理帧号与虚拟地址中的页内偏移结合，形成最终的物理地址。 段页存储不会产生外部碎片，因位先分段，再分页，分页后就离散化了，每个页可以分在内存的任何一个页，这个段页就成了逻辑上的概念，实质上变成了分页的管理，所以按照分页来看，是没有外部碎片的。那些理解成在一个段内再分页的同鞋，你们理解错啦！比如A页和B页逻辑上是在1号段里面，但是分页后，A页可以存在内存的任何地方B页也是，在实际的内存存放这两个页的时候，并不是先在内存化出一个段的长度出来，然后在段内分页的！\nVirtual Memory Background 代码需要加载到内存中才能执行，但整个程序很少被全部使用到。例如错误代码、不寻常的程序、大的数据结构等只需要程序的一部分代码。 整个程序代码不需要同时都在内存中。 考虑执行只部分加载的程序的能力。程序不再受物理内存的限制，每个程序在运行时需要更少的内存，因此可以在相同时间内运行更多的程序。 提高了CPU利用率和吞吐量，而响应时间和周转时间没有增加。 加载或交换程序到内存时需要的I/O更少，每个用户程序运行得更快。 虚拟内存将用户逻辑内存与物理内存分离。其主要优点包括：\n只需要程序的一部分在内存中执行，逻辑地址空间可以比物理地址空间大很多。 允许多个进程共享逻辑地址空间。 允许更高效地创建进程。 可以并发运行更多的程序。 加载或交换进程时需要的I/O更少。 按需分配内存，提高内存利用率。 Virtual-address Space虚拟地址空间是进程在内存中的逻辑视图。 它从地址0开始，地址连续直到空间结束。 物理内存以页框(page frames)的形式组织。 内存管理单元(MMU)将逻辑地址映射到物理地址。 虚拟地址空间可以比物理内存大。\nDemand Paging 需求分页是在程序需要使用某页时才将其调入内存，而不是预先将整个程序加载到内存中。它通过延迟换页(Lazy swapper)来避免不必要的内存交换。需求分页由交换程序(Swapper)负责操作整个进程，而页面程序(Pager)负责操作进程中的单个页面。当程序需要某页时，会引用它，如果该页已经在内存中，则无需换页；如果该页不在内存中，则需要检测并将其调入内存。需求分页不需要改变程序的行为，也不需要程序员改变代码。它实现了按需分配内存，提高了内存利用率。\nValid-Invalid Bit Valid-Invalid Bit(有效无效位)是与每个页表项相关联的一个位。它表示该页表项所对应的页面是否有效且在内存中。\n如果有效无效位是v，则表示页面有效且在内存中。 如果有效无效位是i，则表示页面无效或有效但不在内存中。 初始时，页表中所有页表项的有效无效位都设置为i。 当一个页面被加载到帧中时，该帧的帧号会被写入页表项，并将有效无效位设置为v。 在地址转换过程中，如果页表项中的有效无效位是i，则表示产生缺页异常。 Steps in Handling a Page Fault 如果程序访问一个未在内存中的页面，首先会产生一个页面错误中断。 操作系统会查看一个内部表格(一般指页表，与进程控制块PCB一起保存)来决定如何处理： 如果是无效的访问，则中止进程。 如果访问有效但页面不在内存中，则将页面调入内存。 找到一个空闲的帧(frame)。 通过计划磁盘操作将页面读入帧中。 重置页面表，将帧号写入页面表项，设置验证位\u0026quot;v\u0026quot;。 重新启动导致页面错误的指令。 Aspects of Demand Paging 纯按需分页是一种极端情况，在进程启动时，内存中没有任何页面。操作系统会将指令指针设置为进程的第一个指令，由于页面不在内存中，会导致缺页异常。 对于每个进程，在第一次访问时也会发生页面错误。 实际上，一个指令可能需要访问多个页面，所以会导致多次页面错误。例如，取指令和译码指令从内存中取出两个数字并存储结果，会访问4个页面，导致4次页面错误。但由于参考的局部性，这种痛苦程度会减小。 按需分页需要硬件支持，包括带有有效位无效位的页表和用于交换的二级存储(交换设备)。 在缺页异常时，需要重置指令指针，重新启动进程。 Stages in Demand Paging (worse case) 需求页面的最坏情况下的步骤如下：\n中断到操作系统。 保存用户寄存器和进程状态。 确定中断是一个页面故障。 检查页面引用是否合法，并确定页面在磁盘上的位置。 从磁盘向一个空闲帧发出读取请求： ① 在此设备队列中等待读取请求得到服务。 ② 等待设备查找和/或延迟时间。 ③ 开始将页面传输到空闲帧。 在等待期间，将CPU分配给其他用户。 从磁盘输入/输出子系统接收中断(I/O完成)。 保存其他用户的寄存器和进程状态。 确定中断来自磁盘。 修改页表和其他表，以显示页面现在在内存中。 准备好，等待CPU再次分配给此进程。 恢复用户寄存器，进程状态和新页表，然后继续中断的指令。 Performance of Demand Paging 有效访问时间EAT=(1-p)×memory access time+p×page fault service time\nCopy-on-write COW(Copy-on-Write)允许父进程和子进程在内存中共享相同的页面。只有当一个进程修改共享页面时，才会进行页面复制。这可以更高效地进行进程创建，因为只需要复制修改过的页面。只需要标记可以修改的页面为COW即可。\n空闲页面通常从一个空闲页面池中分配。池中应该总是有空的页面帧，以便快速执行按需页面替换。在分配页面之前，通常会使用零填充技术，将页面清零，擦除其之前的内容。 vfork()不使用写时复制技术。它通过挂起父进程并让子进程使用父进程的地址空间来实现高效的进程创建。 如果子进程修改了父进程的地址空间中的任何页面，这些修改在父进程恢复时将可见。 vfork()的设计是让子进程立即调用exec()函数。它是一种非常高效的进程创建方法，有时用于实现UNIX命令行shell接口。\nPage Replacement 页面替换是因为进程页面和内核/I/O缓冲区等都需要使用内存空间。 需要决定为进程页面、内核和I/O缓冲区等分配多少内存空间。 可以为I/O缓冲区预留一个固定的内存百分比。也可以让用户进程和I/O子系统竞争使用全部内存。 如果内存中没有空闲页面，可以终止用户进程、交换进程或者进行页面替换。 页面替换可以提高内存利用率，让更多进程并发执行，对用户透明。 Basic Page Replacement 基本页面替换算法包括以下步骤：\n在磁盘上查找所需页面的位置。 找到一个空闲页面帧： 如果有一个空闲页面帧，就使用它。 如果没有空闲页面帧，使用页面替换算法选择一个牺牲页面帧。 将牺牲页面帧写入磁盘，如果脏页面，还需要更改页面和页面帧表。 将所需页面读入到刚释放的页面帧中。 更新页面和页面帧表。 通过重新启动引起中断的指令，继续执行进程。 现在可能需要2次页面传输(1次出栈和1次进栈)，增加了有效访问时间。 当发生页面替换，例如将内存中的 page0 替换为 page1 时，操作系统需要执行以下步骤来更新页表和内存：\n选择替换页面：首先，操作系统使用页面置换算法（如 LRU、FIFO、时钟算法等）来选择一个要被替换出内存的页面。假设 page0 被选中。 检查替换页面的状态： 如果 page0 被修改过（脏页面），操作系统需要将它的内容写回到辅助存储（如硬盘）。这确保了修改被保存，以便将来再次访问时可以从辅助存储中重新加载。 如果 page0 未被修改（干净页面），可以直接将其从内存中移除，因为辅助存储上已有其最新副本。 更新页表： 修改 page0 对应的页表项，将其有效-无效位设置为无效（i）。这表明 page0 不再位于物理内存中。 为 page1 创建或更新相应的页表项，包括指向新分配的物理帧的帧号，并将其有效-无效位设置为有效（v）。 将新页面调入内存： 将 page1 从辅助存储读取到刚刚释放的帧中。这个过程可能涉及到磁盘的I/O操作。 重置访问控制信息：对于新调入内存的 page1，可能需要重置或更新与其相关的访问控制信息，如使用频率、最近访问时间等，这些信息常用于页面置换算法。 重新执行指令：最后，操作系统将控制权返回给导致缺页异常的程序，允许它重试原本失败的内存访问操作。由于 page1 现在已经在内存中，该操作应能够成功执行。 整个过程中，操作系统确保了内存中的数据与辅助存储之间的一致性，并通过页表项的更新保持了虚拟地址到物理地址映射的准确性。这样，进程就可以无缝地继续运行，即使其内存页面发生了替换。\n使用修改位(dirty bit)可以减少页面传输的开销。修改位用于表示页面自从上次加载到内存后是否被修改过。只有修改过的页面才会被写入磁盘。页面替换完成了逻辑内存和物理内存的分离。大容量的虚拟内存可以在较小的物理内存上提供。如果没有按需页面替换，一个进程的所有页面仍然必须驻留在物理内存中。\n帧分配算法决定了每个进程应该获得多少帧以及当发生缺页时应该替换哪些帧。页面替换算法希望在首次访问和再次访问时都能获得最低的缺页率，被替换的页面应该是未来最不可能被引用的页面。页面替换算法旨在获得页面故障的最小数量。评估页面替换算法的方法是，在特定的内存引用序列上运行算法，并计算该序列上的页面故障数量。\nreference strings FIFO (First-In-First-Out) Algorithm 先进先出\nBelady’s anomaly证明了在使用先入先出(FIFO)页面替换算法时，增加页面帧数量反而可能导致更多缺页中断。例如，对于参考字符串3,2,1,0,3,2,4,3,2,1,0,4,3槽，总共获得9次缺页中断，但如果增加槽数到4，则总共获得10次缺页中断。\nOptimal Algorithm 替换将来最长时间没被使用的。\nLeast Recently Used Algorithm 选择最长时间未被访问的页面进行替换。\nLRU implementation LRU(Least Recently Used)页面置换算法的实现需要硬件支持，主要问题是确定各个页面最后一次被使用的顺序。每个页面都包含一个计数器和时间使用字段，CPU需要增加一个逻辑时钟或计数器，每次内存访问时都会增加该计数器的值。每次访问页面时，会将计数器的值复制到页表中该页面的时间使用字段。当需要替换页面时，会查看各个计数器的值，选择具有最小时间值的页面进行替换。\n页面置换算法的实现可以使用栈来维护一个页面号码的双链表。当页面被引用时，将其移动到栈顶；不需要搜索替换页面，LRU页面总是在栈底。\nLRU Approximation Algorithms LRU 需要特殊硬件并且仍然缓慢。\n为每个页面条目关联一个比特，初始设置为0。\n当页面被引用时，由硬件将该比特置为1。\n替换值为0的页面条目(如果存在的话)。\n问题：我们不知道页面的顺序。\n每个页面在内存中的表中关联一个8位的字节。\n在定期的定时器中断中，操作系统将每个页面的引用位移入8位字节的最高位，将其他位右移1位并丢弃最低位。\n每个8位字节包含过去8个时间段中页面使用的状态。\n数值最低的页面是LRU页面，可以被替换。\nSecond chance 算法是一个FIFO页面置换算法的变种，它需要额外的参考位(reference bit)来跟踪每个页面的最近访问时间。当需要替换一个页面时，如果该页面最近被访问过(参考位为1)，则不替换该页面，而是将下一个页面(按时钟顺序)替换出去。这样可以减少页面替换的次数，提高效率。\nEnhanced Second-Chance算法考虑了参考位和修改位，将每个页面分为四个类别：\n(0,0) 既未被最近访问也未被修改的页面，是最理想的替换对象。 (0,1) 未被最近访问但已被修改的页面，在替换前需要先写回磁盘。 (1,0) 最近被访问但内容未被修改的页面，很可能很快会被再次访问。 (1,1) 最近被访问且内容已被修改的页面，在替换前需要先写回磁盘。 根据页面所属类别，从最低的非空类别中遇到的第一个页面开始替换。可能需要多次搜索环形队列。 Counting-based page replacement 算法通过为每个页面维护一个引用计数器来统计页面被访问的次数。 LFU (Least Frequently Used) 算法根据计数器的值选择引用次数最少的页面进行替换。 MFU (Most Frequently Used) 算法则选择引用次数最多的页面进行替换，认为引用次数最多的页面最有可能正在被使用。 这两种算法都不太常见，因为它们需要为每个页面维护引用计数器，增加了实现的复杂性。\nPage-Buffering Algorithm 该算法维护一个空闲帧的池子。当发生页面错误时，先选择一个受害帧，然后在受害帧被写出之前，将所需页面读入池中的一个空闲帧。当受害帧稍后被写出时，其帧被添加到空闲帧池中。可能还会维护一个被修改页面的列表。每当分页设备空闲时，选择一个被修改的页面并将其写入磁盘，然后重置其修改位。还可能保持一个空闲帧的池子，但要记住每个帧中有哪个页面。如果在该帧被重用之前需要旧页面，可以直接从空闲帧池中重用该页面。\nAllocation of Frames 操作系统中每个进程需要的最小页面数。\n这个需求根据进程使用的指令类型和内存寻址方式而变化。例如，仅使用单一内存地址指令的进程至少需要两个帧，而允许一级间接寻址的进程至少需要三个帧。特定指令，如PDP-11上的移动指令或IBM 370上的MVC指令，可能需要六页，因为它们复杂并可能涉及间接引用。该部分还提到了两种主要的帧分配方案：固定分配和优先级分配。这些分配方法确保了内存的有效使用，避免浪费。\nFixed Allocation 等量分配：例如，如果有93个帧和5个进程，每个进程分配18个帧，剩余的3个帧用作空闲帧缓冲池。 比例分配：根据每个进程的大小分配可用内存。具体来说，每个进程的虚拟内存大小为si，总虚拟内存为S（所有si之和）。每个进程的分配比例（ai）是其虚拟内存大小（si）除以总虚拟内存（S），乘以总帧数（m）。每个进程的分配数（ai）调整为大于其最小帧数的整数，且总和不超过m。分配可能根据多程序级别而变化。 Priority Allocation 使用基于优先级而非大小的比例分配方案，或者结合大小和优先级来进行分配。\n这种分配是动态的，随着多程序级别和进程大小的变化而变化。\n如果进程 P i 发生页面错误，选择替换它的某个帧。局部替换是从优先级较低的进程中选择替换一个帧。全局替换则是从整个系统范围内选择替换一个帧。\nGlobal vs. Local replacement 全局替换（Global Replacement）和局部替换（Local Replacement）是操作系统中页面替换策略的两种不同方法，它们用于决定当发生页面错误（Page Fault）时，应该从内存中移除哪个页面以便为新页面腾出空间。\n全局替换 (Global Replacement): 在全局替换策略中，当某个进程需要替换页面时，它可以从整个系统的内存帧中选择一个页面进行替换。这意味着一个进程可能会取代（或“偷取”）另一个进程的内存页面。 这种方法由操作系统来管理，它维护一个所有空闲帧的列表。当发生页面错误时，操作系统会从这个列表中选择一个页面来替换。 优点是可以提高系统吞吐量（即整个系统的效率和性能），因为它可以更灵活地分配和管理内存资源。 缺点是单个进程可能无法有效控制自己的页面错误率，因为它的页面可能被其他进程所替换。 局部替换 (Local Replacement): 局部替换策略限制页面替换仅在发生页面错误的那个进程的内存帧中进行。这意味着进程只能替换属于自己的页面。 在这种策略下，每个进程的页面错误完全由该进程自己的分页行为决定，不受其他进程的影响。 优点是进程对自己的内存管理有更大的控制权，可以更好地优化自己的页面错误率。 缺点是可能导致整体系统吞吐量降低，因为内存资源分配可能不如全局替换那样灵活和高效。 Thrashing Thrashing Thrashing(过度换页)是指当一个进程没有足够数量的页面时，页面故障率非常高。每次页面故障需要获取页面，替换现有的页面，但很快需要替换回原来的页面，这会导致：\n低CPU利用率，因为大部分时间都在进行页面替换 操作系统认为需要增加多进程的程度 向系统中添加另一个进程 当一个进程花费大部分时间在页面替换而不是执行时，就说明该进程处于过度换页状态。要避免过度换页，必须为进程分配足够数量的页面。 thrashing的发生是因为：\n进程的局部性大小(locality size)大于总内存大小(total memory size)。 使用了局部(或优先级)页面替换算法，这可以限制抖动的影响。 为了防止抖动，必须为进程提供它需要的所有页面。 如何知道进程需要多少页面？\n通过查看进程实际上使用的页面数量来确定。 进程执行的局部性模型是：\n局部性：一组正在一起使用的页面。 进程从一个局部性迁移到另一个局部性。 局部性可能重叠。 Working-Set Model 工作集窗口大小Δ: 这是衡量工作集大小的一个关键参数，表示在一定数量的页面引用中考虑的页面集合。例如，如果Δ是10,000，那么工作集包括最近10,000个页面引用。 工作集（Working Set）: 它是在最近Δ个页面引用中出现的那些页面的集合。这反映了一个进程在最近一段时间内的内存使用情况。 WSSi（进程Pi的工作集大小）: 这是指在特定时刻进程Pi的工作集中页面的数量。这个数字随时间变化，因为进程的内存需求可能会增加或减少。 工作集大小的准确性与Δ的选择有关: 如果Δ设置得太小，可能无法准确反映进程的内存需求；如果设置得太大，可能会过度估计所需的内存。理想的Δ值应该能够合理反映进程的实际内存使用模式。 总工作集大小D: 它是所有进程工作集大小的总和，用于近似表示程序的局部性（即内存访问的局限性）。如果D超过了系统中可用的内存帧数量m，可能会导致频繁的页面调度和内存抖动，就需要挂起一个进程。难点在于持续跟踪工作集。 跟踪工作集的方法：通过定期中断和维护页面访问位来跟踪工作集。这种方法有助于识别哪些页面属于当前的工作集，但可能无法精确反映快速变化的工作集。 使用定时器定期中断，例如每隔5000时间单位中断一次。 为每个页面维护两个内存位，一个用于记录页面最近一次被访问的时间，一个用于记录页面是否在工作集中。 在定时器中断时，将所有页面的访问时间位清零，并将工作集中的页面的访问时间位置1。 根据页面访问时间位判断页面是否在工作集中。 改进方法: 通过增加历史位数量和提高定时器中断频率，可以更准确地跟踪页面的工作集。这有助于操作系统更有效地管理内存，减少页面错误和提高系统性能。 Page-Fault Frequency Scheme Page-Fault Frequency Scheme是一种更直接的工作集模型替代方法。 它通过建立一个可接受的页面故障率，并使用局部替换策略来控制页面故障频率。如果实际的页面故障率过低，进程会丢失一个页面框；如果实际的页面故障率过高，进程会增加一个页面框。选择一个进程，将其交换到外部存储设备。\nMemory-mapped file Memory-mapped files(内存映射文件)通过将磁盘块映射到内存页中来简化并加速文件访问。文件初始化时使用按需调页，将文件系统中的一个页大小的文件块装入物理帧。后续的读写操作都被视为普通的内存访问。当数据被写入内存时，会在页缓存扫描脏页时或者文件关闭时才写入磁盘。\n一些操作系统(例如Solaris)选择通过特定的系统调用(如mmap())将文件映射到内存，而一些操作系统则通过特定的系统调用(如mmap())将文件映射到内核地址空间。这使得进程可以像访问内存一样访问文件，而不需要通过标准的I/O操作(open(), read(), write(), close())。这种方式利用了高效的内存管理子系统。\nMemory-mapped files允许多个进程同时映射同一个文件，从而在内存中共享该文件的页面。\nCOW(Copy-on-Write)可以用于读/写非共享页面。它允许进程以只读模式共享文件，但每个进程都可以对其修改的数据保留自己的副本。 内存映射文件可以用于共享内存。\nMemory-mapped I/O是将内存地址映射到设备寄存器，通过读写这些内存地址来在CPU和设备之间传输数据。这种方式适用于响应时间较快的设备，如视频控制器。它也可以用于其他设备，如串口和并口，用于连接调制解调器和打印机到计算机。通过这种方式，CPU通过读写几个设备寄存器(I/O端口)来与这些设备进行数据传输。\nAllocating Kernel Memory 内核内存与用户内存不同，它通常从一个不同的空闲内存池中分配，而不是和普通用户模式进程使用的内存池相同。原因有两点：\n内核请求不同大小的数据结构内存，有些小于一个页面的大小。 一些内核内存需要是连续的，例如用于设备I/O。某些硬件设备需要直接与物理内存交互，可能需要连续的内存页面。 内核内存分配使用Buddy System伙伴系统和Slab allocation两种方式。\nBuddy System 伙伴系统(Buddy System)将内存从一个固定大小的内存段中分配，该内存段由物理上连续的页面组成。 伙伴系统使用2的幂次方大小的分配器。 内存以2的幂次方大小的单元分配。 请求大小向上取2的下一个最高幂次方。 整个可用的内存空间被看作是一个大小为2U的单一块。 如果请求大小在2U-1和2U之间，则整个块被分配。 否则，块被分成两个大小相等的伙伴块。 进程继续，直到生成一个最小大小为s的块。\nSlab Allocation 将物理内存划分为固定大小的内存块，称为slab。 将多个slab组成一个缓存(cache)。 为每个内核数据结构(如进程控制块PCB)创建一个单独的缓存。 在创建缓存时，先将缓存填充一些初始化的空对象。 当需要使用该内核数据结构时，从缓存中分配一个对象(实例)并标记为已使用。 当缓存中的对象都标记为已使用时，需要分配新的slab来扩展缓存。 该分配方式可以避免内存碎片，同时可以快速地满足内存请求。 Other considerations Prepaging Prepaging是为了减少进程启动或者换出进程重新启动时产生的大量缺页中断。它通过提前将进程需要的页面加载到内存中来实现。如果预加载的页面没有被使用，就会浪费I/O和内存资源。预加载页面有一定的优势，需要比较使用预加载页面的成本和处理相应缺页中断的成本，来判断是否使用预加载页面。例如，如果预加载S个页面，实际上只使用了Sa个页面(0\u0026lt;a\u0026lt;1)，那么预加载S个页面的成本是否小于处理S(1-a)个不必要的缺页中断的成本。如果a接近1，预加载就更有优势。\nPage Size 页面表的大小：每个活跃进程都需要一个自己的页面表副本，所以较大的页面大小是可取的。 碎片化：为了最小化内部碎片化，需要较小的页面大小。 I/O开销：I/O时间主要由搜索时间和延迟时间组成，而传输时间通常较小。为了最小化I/O时间，需要较大的页面大小。 局部性：较小的页面大小可以改善局部性，减少总的I/O。但是为了最小化页面错误，需要较大的页面大小。 页面大小通常在4KB到4MB之间选择。 所以页面大小需要在减小碎片化和I/O开销与提高局部性和减少页面错误之间做权衡。 TLB Reach TLB Reach指的是从TLB(Translation Lookaside Buffer)可以访问的内存范围。 TLB Reach = (TLB Size) x (Page Size) 理想情况下，每个进程的工作集应该存储在TLB中。否则，页面错误率会很高，进程会在页表中花费大量时间而不是TLB中解析内存引用。 增加TLB Reach的方法包括：\n增加Page Size，但这可能会导致碎片化增加，因为不是所有应用程序都需要大Page Size。 提供多种Page Size，这可以让需要大Page Size的应用程序使用它们，而不会增加碎片化。 Inverted Page Tables Inverted Page Tables的目的是减少跟踪虚拟到物理地址转换所需的物理内存。它使用一个表项来跟踪每个物理帧中的虚拟内存页，表项由进程ID和页面号索引。当发生页面错误时，还需要其他信息，例如每个虚拟页的位置和页面数量。必须为每个进程保留一个外部页面表，根据需要进行页面换入和换出。页面错误现在可能需要生成另一个页面错误来换入需要的页面表。\nProgram Structure 仔细选择数据结构和编程结构可以提高局部性，从而降低缺页错误率和工作集中的页面数量。例如，栈具有很好的局部性，因为访问总是从栈顶开始。而散列表则设计成散布引用，产生较差的局部性。编译器和加载器对页面管理有很大影响。将代码和数据分离并生成可重入代码意味着代码页可以只读，永远不会被修改。加载器可以避免将程序段放在跨页面边界位置。经常相互调用的程序段可以打包到同一页面中。\nI/O interlock 考虑挂起的I/O操作：\n用于设备I/O的内存页必须被锁定，防止被页面替换算法选中用于淘汰。 不允许直接对用户内存执行I/O操作。 数据在系统内存和用户内存之间进行复制。 I/O操作只在系统内存和I/O设备之间进行。 允许将页面锁定到内存中：\n每个帧都关联一个锁定位。 被锁定的页面不能被替换。 当I/O完成后，页面解锁。 页面固定来锁定到内存中：\n操作系统内核的部分或全部被锁定在内存中。 用户进程可能需要将页面锁定到内存中。 考虑到具有需求分页、优先级调度和全局替换的系统： 低优先级进程L发生缺页。 操作系统选择一个替换帧，并调入所需页面。 然后，L进入就绪队列，可能长时间不被选中。 当L等待时，高优先级进程H发生缺页。 寻找替换页面时，可能是L刚调入的页面—它是干净的，且长时间未使用。 使用锁定位来防止新调入页面的替换，直到至少被使用一次：\n当页面被选为替换对象时，其锁定位被打开。 锁定保持到引起缺页的进程再次被调度。 大多数操作系统都提供系统调用，允许应用请求将其逻辑地址空间的一部分固定。\n危险性：锁定位可能被打开但永远不关闭。\n被锁定的帧变得无法使用。 ","date":"2023-12-25T19:54:47Z","permalink":"http://localhost:1313/post/6-main-memory-and-virtual-memory/","title":"6 Main Memory And Virtual Memory"},{"content":"外部排序 1.外部排序的基本概念 外存中的数据读入内存→在内存中排序→数据写入外存\n2.外部排序 2.1.外部排序的思想 采用归并排序的思想和方法\n1.数据初始状态\n2.将\u0026#xff08;36、8、26\u0026#xff09;\u0026#xff08;42、9、48\u0026#xff09;分别存入输入缓冲区1、输入缓冲区2\n3.将输入缓冲区1和输入缓冲区2的数据进行递增排序\n4.将输入缓冲区1和输入缓冲区2的数据通过输出缓冲区逐一写入外存\u0026#xff0c;形成一个有序归并段\n5.将\u0026#xff08;1、37、25\u0026#xff09;\u0026#xff08;45、27、28\u0026#xff09;分别存入输入缓冲区1、输入缓冲区2\n6.将输入缓冲区1和输入缓冲区2的数据进行递增排序\n7.将输入缓冲区1和输入缓冲区2的数据通过输出缓冲区逐一写入外存\u0026#xff0c;形成一个有序归并段\n8.对剩余12块内存依次进行上述操作\u0026#xff0c;总共需要进行16次读操作和16次写操作\u0026#xff0c;得到初始归并段\n9.第一次归并\u0026#xff1a;读入归并段1和归并段2中的第一块磁盘\u0026#xff08;相对最小\u0026#xff09;\u0026#xff0c;进行排序\n10.依次找出这两个输入缓冲区中最元素\u0026#xff0c;并将其移动到输出缓冲区中\u0026#xff0c;当输出缓冲区满\u0026#xff0c;则写入外存\u0026#xff08;1、8、9\u0026#xff09;\n11.继续找出这剩余元素中的最小元素\u0026#xff0c;直到某一个缓冲区中空\u0026#xff0c;则读入其所属归并段的后一个内存块的数据\u0026#xff0c;并继续进行上述操作。直到两个缓冲区都空\u0026#xff0c;且归并段1和归并段2中的元素全部读入内存\u0026#xff0c;此时归并段1和归并段2就得到了一个有序的递增序列\n输入缓冲区1空\n输入归并段1的第二块内存 排序完成\u0026#xff0c;归并段1和归并段2递增有序 12.对剩余的六个归并段进行上述操作\u0026#xff0c;八个归并段→四个归并段\n13.第二次归并\u0026#xff1a;继续采用此方法依次取出归并段1和归并段2\u0026#xff08;归并段1为八个归并段时的归并段1和归并段2\u0026#xff0c;归并段2为八个归并段时的归并段3和归并段4\u0026#xff09;的各个块进行排序操作\u0026#xff08;步骤9、10、11\u0026#xff09;→四个归并段→两个归并段\n原归并段1、2排序形成归并段1\n原归并段3、4排序形成归并段2\n14.第三次归并\u0026#xff1a;继续排序归并段1、2\u0026#xff0c;形成最后的有序递增序列\n2.2.外部排序的开销 上述外部排序中\u0026#xff1a;形成初始归并段→第一次归并\u0026#xff08;8 ~ 4\u0026#xff09;→第二次归并\u0026#xff08;4 ~ 2\u0026#xff09;→第三次归并(2 ~ 1)\u0026#xff08;每个过程都需要读和写16次\u0026#xff0c;共32 \u0026#43; 32 * 3 \u0026#61; 128次\u0026#xff09;\n总时间开销 \u0026#61; 内部排序所需时间 \u0026#43; 内部归并所需时间 \u0026#43; 外部读写所需时间\n2.3.优化——多路归并 改用四路归并\u0026#xff1a;初始化归并段→第一次归并\u0026#xff08;8 ~ 2\u0026#xff09;→第二次归并\u0026#xff08;2 ~ 1\u0026#xff09;\n需要读写次数\u0026#xff1a;32 \u0026#43; 32 * 2 \u0026#61; 96\n但是\u0026#xff0c;与此同时\u0026#xff0c;缓冲区的数量也要变成四个\u0026#xff08;k路归并需k个缓冲区\u0026#xff09;\n结论\u0026#xff1a;1.对于 r 个初始归并段进行 k 路归并\u0026#xff0c;需要归并趟数 \u0026#61; \u0026#xff08;向上取整\u0026#xff0c;归并树高度\u0026#xff09;\n2.提升外部排序的速度、减少读写磁盘的速度的方法\u0026#xff1a;提高 k 值\u0026#xff0c;降低 r 值。\n提高 r 值\u0026#xff1a;增加归并段长度\n但是\u0026#xff0c;提高 k 有负面影响\u0026#xff1a;\nA.需要的缓存空间升高\u0026#xff08;k路归并需k个缓冲区\u0026#xff09;\nB.内部归并的所需时间提高\u0026#xff08;选出最小关键字需要进行k - 1次比较\u0026#xff09;\n3.败者树 视为一棵完全二叉树\n1.将每个归并段的第一个元素作为叶子结点加入败者树中\n2.从左至右、从上往下的更新分支节点的信息\u0026#xff1a;判断其左右子树的大小\u0026#xff0c;除了根节点\u0026#xff08;最上面那个结点\u0026#xff09;记录冠军来自哪个归并段外\u0026#xff0c;其余各分支节点记录的是失败者来自哪个归并段\n3.取出最小的元素1后\u0026#xff0c;从其所属的归并段中取出下一个元素6\u0026#xff0c;依次与从叶子结点到根节点的各个结点所记录的败者信息进行对比\n引进败者树后\u0026#xff0c;选出最小的关键字\u0026#xff0c;仅需log2k次比较\u0026#xff08;向上取整\u0026#xff09;\n4.置换选择排序 4.1.算法思想 使用选择置换排序\u0026#xff0c;可以让每个初始段的长度不再受限于内存工作区大小\n设内存工作区最多容纳w个数据\n①将待排序文件FI输入w个数据到内存工作区WA中\n②选择WA中关键字最小的数据\u0026#xff0c;输出到FO中\u0026#xff0c;并且用MIN记录该最小关键字\n③若FI不空\u0026#xff0c;则从FI中继续输入文件到WA\n④ 从WA中选出比MIN更大的关键字的数据\u0026#xff0c;输出并更新此最小关键字作为新MIN\n⑤重复②~④直到WA中的每个关键字都\u0026#xff1e;MIN为止\u0026#xff0c;由此得到一个新的归并段\n⑥重复②~⑤\u0026#xff0c;直到WA空\u0026#xff0c;得到全部初始归并段\n4.2.手算过程 1.初始状态\n归并段1\u0026#xff1a; 2.4、6、9依次加入内存工作区中\u0026#xff0c;\u0026#xff08;4、6、9\u0026#xff09;选择最小的元素4\u0026#xff0c;输出4并更改MIN \u0026#61; 4\n3.加入7\u0026#xff0c;\u0026#xff08;7、6、9\u0026#xff09;选择最小元素6 \u0026gt; MIN \u0026#61; 4\u0026#xff0c;输出6并更改MIN \u0026#61; 6\n4.加入13\u0026#xff0c;\u0026#xff08;7、13、9\u0026#xff09;选择最小元素7 \u0026gt; MIN \u0026#61; 6\u0026#xff0c;输出7并更改MIN \u0026#61; 7\n5.加入11\u0026#xff0c;\u0026#xff08;11、13、9\u0026#xff09;选择最小元素9 \u0026gt; MIN \u0026#61; 7\u0026#xff0c;输出9并更改MIN \u0026#61; 9\n6.加入16\u0026#xff0c;\u0026#xff08;11、13、16\u0026#xff09;选择最小元素11 \u0026gt; MIN \u0026#61; 9\u0026#xff0c;输出11并更改MIN \u0026#61; 11\n8.加入14\u0026#xff0c;\u0026#xff08;14、13、16\u0026#xff09;选择最小元素13 \u0026gt; MIN \u0026#61; 11\u0026#xff0c;输出13并更改MIN \u0026#61; 13\n9.加入10\u0026#xff0c;\u0026#xff08;14、10、16\u0026#xff09;选择最小元素10 \u0026lt; MIN \u0026#61; 13\u0026#xff0c;标记13为不可输出\u0026#xff0c;选择第二小的元素14 \u0026gt; MIN \u0026#61; 13\u0026#xff0c;输出14并更改MIN \u0026#61; 14\n10.加入22\u0026#xff0c;\u0026#xff08;22、10、16\u0026#xff09;选择最小元素16 \u0026gt; MIN \u0026#61; 14\u0026#xff0c;输出16并更改MIN \u0026#61; 16\n11.加入30\u0026#xff0c;\u0026#xff08;22、10、30\u0026#xff09;选择最小元素22 \u0026gt; MIN \u0026#61; 16\u0026#xff0c;输出并更改MIN \u0026#61; 22\n12.加入2\u0026#xff0c;\u0026#xff08;2、10、30\u0026#xff09;选择最小元素2 \u0026lt; MIN \u0026#61; 22\u0026#xff0c;标记2为不可输出\u0026#xff0c;选择第三小的元素30 \u0026gt; MIN \u0026#61; 22\u0026#xff0c;输出30并更改MIN \u0026#61; 30\n13.加入3\u0026#xff0c;\u0026#xff08;2、10、3\u0026#xff09;选择最小元素3 \u0026lt; MIN \u0026#61; 30\u0026#xff0c;标记2为不可输出\u0026#xff0c;此时\u0026#xff0c;输出缓冲区中的三个元素都是不可输出元素\u0026#xff0c;则第一个归并区到上一个输出元素为止\u0026#xff08;4、6、7、9、11、13、14、16、22、30\u0026#xff09;\n归并段2\u0026#xff1a; 14.\u0026#xff08;2、10、3\u0026#xff09;选择最小元素2\u0026#xff0c;输出2并更改MIN \u0026#61; 2\n15.加入19\u0026#xff0c;\u0026#xff08;19、10、3\u0026#xff09;选择最小元素3 \u0026gt; MIN \u0026#61; 2\u0026#xff0c;输出3并更改MIN \u0026#61; 3\n16.加入20\u0026#xff0c;\u0026#xff08;19、10、20\u0026#xff09;选择最小元素10 \u0026gt; MIN \u0026#61; 3\u0026#xff0c;输出10并更改MIN \u0026#61; 10\n17.加入17\u0026#xff0c;\u0026#xff08;19、17、20\u0026#xff09;选择最小元素17 \u0026gt; MIN \u0026#61; 10\u0026#xff0c;输出17并更改MIN \u0026#61; 17\n18.加入1\u0026#xff0c;\u0026#xff08;19、1、20\u0026#xff09;选择最小元素1 \u0026lt; MIN \u0026#61; 17\u0026#xff0c;标记1为不可输出\u0026#xff0c;选择第二小的元素19 \u0026gt; MIN \u0026#61; 17\u0026#xff0c;输出19并更改MIN \u0026#61; 19\n19.加入23\u0026#xff0c;\u0026#xff08;23、1、20\u0026#xff09;选择最小元素20 \u0026gt; MIN \u0026#61; 19\u0026#xff0c;输出20并更改MIN \u0026#61; 20\n20.加入5\u0026#xff0c;\u0026#xff08;23、1、5\u0026#xff09;选择最小元素5 \u0026lt; MIN \u0026#61; 20\u0026#xff0c;标记5为不可输出\u0026#xff0c;选择第三小的元素23 \u0026gt; MIN \u0026#61; 23\u0026#xff0c;输出23并更改MIN \u0026#61; 23\n21.加入36\u0026#xff0c;\u0026#xff08;36、1、5\u0026#xff09;选择最小元素36 \u0026gt; MIN \u0026#61; 36\u0026#xff0c;输出36并更改MIN \u0026#61; 36\n22.加入22\u0026#xff0c;\u0026#xff08;12、1、5\u0026#xff09;选择最小元素12 \u0026lt; MIN \u0026#61; 36\u0026#xff0c;标记12为不可输出时\u0026#xff0c;输出缓冲区中的三个元素都是不可输出元素\u0026#xff0c;则第二个归并区到上一个输出元素为止\u0026#xff08;2、3、10、17、19、20、23、36\u0026#xff09;\n第三个归并段\u0026#xff1a;\n23.\u0026#xff08;12、1、5\u0026#xff09;选择最小元素1\u0026#xff0c;输出1并更改MIN \u0026#61; 1\n24.加入18\u0026#xff0c;\u0026#xff08;12、18、5\u0026#xff09;选择最小元素5 \u0026gt; MIN \u0026#61; 1\u0026#xff0c;输出5并更改MIN \u0026#61; 5\n25.加入21\u0026#xff0c;\u0026#xff08;12、18、21\u0026#xff09;选择最小元素12 \u0026gt; MIN \u0026#61; 5\u0026#xff0c;输出12并更改MIN \u0026#61; 12\n26.加入39\u0026#xff0c;此时\u0026#xff0c;待排序文件空\u0026#xff0c;将内存工作区中的剩余数据按序输出\u0026#xff0c;即18、21、39\u0026#xff0c;则第三个归并段为\u0026#xff08;1、5、12、18、21、39\u0026#xff09;\n5.最佳归并树 1.性质和构造完全相同于哈弗曼树\n2.与哈弗曼树的区别\u0026#xff1a;\nk叉树\u0026#xff0c;其中k \u0026gt; 2时\u0026#xff1a;需要判断是否能满足构造完全k叉树\u0026#xff0c;若不满足\u0026#xff0c;则需要添加长度为0的“虚段”\n①若\u0026#xff08;初始归并段数量 - 1\u0026#xff09; % \u0026#xff08;k - 1\u0026#xff09; \u0026#61; 0\u0026#xff0c;则能构成完全k叉树\n②若\u0026#xff08;初始归并段数量 - 1\u0026#xff09; % \u0026#xff08;k - 1\u0026#xff09;\u0026#61; u ≠ 0\u0026#xff0c;则说明需要添加\u0026#xff08;k - 1\u0026#xff09;- u 个虚段才能构成完全二叉树\n1.外部排序基本概念：前面介绍的排序都是内部排序，是直接在内存里面进行排序的，但是大多数情况下文件比较大，这时候我们就得把文件分割成一个个小块进行输入内存再排序。在排序过程中需要进行多次的内存与外存之间的交互，所以称之为外部排序。\n外部排序操作：以例题作为讲解\n例题1：假设文件有4500个记录，每块磁盘可以放75个记录，计算机中用于排序的内存区可以存放 450 个记录，试问： 1）可以建立多少个初始归并段？每个归并段有多少个记录？存放于多少个块中？ 2）应采用几路归并，请写出每趟需要读写磁盘的块数\n解答： 1） 文件中有4500个记录，内部排序区可容纳450个记录（其实排序过程是 依次 输入1-450，451-900… 进行排序，然后输出构成有序的初始归并段 ），则可建立的初始归并段为4500/450 = 10，每个初始归并段有450个记录，存放于 450/75 =6 个块中。 2）内存区可以容纳6个块，所以可以建立5个输入缓冲区。1个输出缓冲区，因此采用5路归并。 归并次数为 log(5)10 = 2，每次归并需要读写磁盘次数都为4500/75=60 次 ，每次归并需要读写磁盘总次数为为60 * 2 =120 次，做了两趟归并，读写总次数 2 * 120=240。 另外再来看看 2.外部排序总时间= 内部排序所需时间+外村信息读写时间+内部归并需要时间\n内部排序所需时间 ：就是第一次进行生成初始归并序列的时间，这其中就有一次读写时间，排序时间可以忽略。如上题内部排序所需时间为 120 相当于一次归并的时间 外存信息读写时间 ：其实就是归并次数乘以每次读写时间，上题为 两次归并，每次归并读写磁盘次数为120 ，所以总时间为2 * 120 = 240次。 内部归并需要时间：就是在内存中进行序列段合并为一个序列段所需时间，这一时间其实主要在于数据进行比较的时间，例如上题，进行的是5路归并，那么在5个元素中选取最小数比较次数是4次，总共有4500个记录，最后一个不需要比较，因此每趟归并需要的比较次数为 （4500-1）*4=17996次，进行两次归并，17996 *2=35992次比较。但是比较时间相比于读写时间比较短所以可以忽略。\n归并次数 S=log(k) r 。r为初始归并段，k为归并路数，证明很简单，略。若是不采用其他方法进行比较次数优化则S趟总共需要比较次数为 S( n-1 )( k-1) = [ log(k) r ] ( n-1 )( k-1)=[log2 r] (n-1)(k-1)/[log2k] ,式子中 (k-1)/log2k 随着路数k的增大而增大，这将抵消由于k增大而减少外存访问次数所得到的效益，那么能不能使用其他方法来减少比较次数呢？下面介绍败者树方法。 败者树：树中k个叶节点分别存放k个归并段在归并过程中当前参加比较的记录，内部节点用来记录左右子树的 “败者” 而胜利者继续向上比较直到到达根节点，如图所示。 在这里插入图片描述\n因为 k 路归并的败者树深度为log2k ， 因此k 个记录中选择最小关键字，最多需要 log2k次比较，所以排序总的比较次数为S(n-1)[log2k]=[log(k)r] (n-1) log2k=(n-1) log2r 。 可见使用败者树后内部归并的比较次数就与k无关了，因此只要内存空间允许，可以通过增大路数k达到减少 I/O 次数，提高外部排序速度。 值得说明的是，归并路数k并不是越大越好，归并路数k增大，相应的得增加输入缓冲区的块数，若是可使用的空间一定，势必要减少每个输入缓冲区的容量，这样也会使得内存、外存交换数据次数增加，因此仍然会导致时间增大。\n还有什么办法可以减少排序时间呢？\n3.置换选择排序（生成初始归并段） 只要增大初始归并段长度就可以减少初始归并段个数，达到减少归并时间的效果。\n在这里插入图片描述 上述算法中WA选择最小数使用败者树实现。\n综上所述：每一次归并所读取 I/O 的次数是一定的，总记录/每块磁盘容量，因此可以通过减少归并次数，达到减少读取次数减少排序时间问题，那么减少归并次数的方法有：增大归并路数 或者 增大初始序列 。 实现代码：\nvoid Select_MiniMax(LoserTree ls,WorkArea wa,int q){ int p, s, t; // ls[t]为q的双亲节点，p作为中介\nfor(t = (w+q)/2,p = ls[t]; t \u0026gt; 0;t = t/2,p = ls[t]){ // 段号小者 或者 段号相等且关键字更小的为胜者 if(wa[p].rnum \u0026lt; wa[q].rnum || (wa[p].rnum == wa[q].rnum \u0026amp;\u0026amp; wa[p].key \u0026lt; wa[q].key)){ s=q; q=ls[t]; //q指示新的胜利者 ls[t]=s; } } ls[0] = q; // 最后的冠军 } //输入w个记录到内存工作区wa,建得败者树ls,选出关键字最小的记录，并由s指示其在wa中的位置。 void Construct_Loser(LoserTree ls, WorkArea wa, FILE *fi){ int i; for(i = 0; i \u0026lt; w; ++i){ wa[i].rnum = wa[i].key = ls[i] = 0; } for(i = w - 1; i \u0026gt;= 0; \u0026ndash;i){ fread(\u0026amp;wa[i].rec, sizeof(RedType), 1, fi);// 输入一个记录 wa[i].key = wa[i].rec.key; // 提取关键字 wa[i].rnum = 1; // 其段号为＂1＂ Select_MiniMax(ls,wa,i); // 调整败者树 } }\n4.最佳归并树\n文件经过置换选择排序后，得到的是长度不等的初始归并段，下面讨论如何组织长度不等的初始归并段的归并顺序使得IO次数最少。其实也就是m叉哈夫曼树类似，很简单，不展开叙述。其中有一点不同是，可能初始归并段个数并不能构成严格的k叉树，这时就要补充虚段了。\n如何确定添加虚段的数目？ 设度为0的节点有 N0 个，度为 k的节点个数有Nk个，则对于严格k叉树 N0=(k-1) Nk+1，由此可得Nk=(N0-1)/(k-1) 。\n若是(N0-1)%(k-1) =0 , 则说明这N0个叶节点正好可以构成严格k叉树。 若是不等于0，则设需要添加 m个 长度为0 的虚段使得（N0+m-1）%（k-1）=0，即可。 以上就是外部排序的全部内容\n","date":"2023-11-01T14:57:20Z","permalink":"http://localhost:1313/post/%E5%A4%96%E9%83%A8%E6%8E%92%E5%BA%8F/","title":"外部排序"},{"content":"Deadlocks System Model Resource types：系统中有多种资源类型，包括 CPU、内存空间、文件、I/O 设备（如打印机等）。 资源可以分为物理资源和逻辑资源。 physical resources：preemptive resources，如 CPU、内存；non-preemptive resources，如打印机。 logical resources：temporary resources, known as consumable resources 资源实例：每个资源类型都有若干个实例。 进程如何使用资源：每个进程根据其需求请求、使用和释放资源。 system table：系统表记录了每个资源的状态（自由或分配），以及若资源分配给哪个进程。 请求、使用和释放：进程在需要资源时发起请求，获得资源后进行使用，并在完成任务后释放资源。 Deadlock Characterization 死锁特征是指一组进程在运行过程中，由于资源争用导致的一种特殊状态，即这些进程都在等待对方释放资源，从而导致进程无法继续执行。\n死锁的特征主要包括以下几点：\n互斥性：至少有两个进程在争夺同一资源，且至少有一个进程已经持有了该资源。 请求与等待：进程请求获取它所需要的资源，但该资源已被其他进程占用，因此请求进程处于等待状态。 不可剥夺性：已分配给进程的资源在未被该进程释放前，其他进程无法强行占用。 循环等待：存在一个进程链，每个进程都在等待下一个进程所持有的资源。 当以上特征同时满足时，系统就容易出现死锁现象。理解死锁特征有助于分析和预防死锁的发生，从而确保系统资源的合理分配和进程的正常运行。 Resource-Allocation Graph 资源分配图是一种用于描述多个进程在请求和分配资源过程中的关系图表。 在资源分配图中，每个进程用一个节点表示，每条边表示一个进程请求或分配一个资源。\n节点V：图表中的节点代表进程。每个节点包含当前进程已经分配的资源数量以及尚未请求的资源数量。 P表示进程 R表示资源 边E：图表中的边表示进程之间的资源请求关系。边有两种类型： 请求边request edge：表示一个进程可能请求另一个进程所持有的资源。请求边用虚线表示。 分配边assignment edge：表示一个进程已经分配了某个资源。分配边用实线表示。 循环：在资源分配图中，如果存在一个进程链，每个进程都在等待下一个进程所持有的资源，那么就形成了循环等待。循环等待是导致死锁的一个关键条件。 循环在资源分配图中起着关键作用，可以用来判断系统是否会发生死锁。当循环中每个资源类型只有一个实例时，系统必然会发生死锁。而当循环中的资源类型有多个实例时，虽然死锁的可能性较高，但并非必然发生死锁。 安全状态与不安全状态： 安全状态是指不存在循环等待的情况下，系统可以分配资源给进程而不会导致死锁。 不安全状态是指存在循环等待，系统分配资源可能导致死锁的情况。 通过检查资源分配图中的循环等待，系统可以确定哪些资源分配是安全的，哪些是不安全的。在不安全情况下，系统可以采取措施推迟进程的资源分配，直到资源请求不会导致死锁。 Methods for Handling Deadlocks 死锁预防 Deadlock-prevention：通过制定严格的资源请求顺序，预先避免死锁的发生。例如，为所有资源类型设定一个全局排序，并要求进程按照资源编号的升序请求资源。 死锁避免 Deadlock-avoidance：在系统运行过程中，通过检测潜在的死锁情况并采取措施避免它们。例如，使用银行家算法（Banker Algorithm）来预先分配资源，确保不会发生资源请求冲突。 允许系统进入死锁状态，检测到死锁后进行恢复（Deadlock Detection and Recovery）： 检测：通过一定的算法和策略检测到系统中的死锁情况。 恢复：当死锁发生时，通过终止进程、抢占资源或回滚进程状态等方法解除死锁。 忽略问题（Deadlock Ignoration）：假装死锁在系统中永远不会发生。大多数操作系统（包括 UNIX 和 Windows）都采用这种方法。 Deadlock Prevention 互斥性（Mutual Exclusion）是指对于不可共享的资源，进程之间需要相互排斥，确保同一时间只有一个进程可以使用该资源；而对于可共享的资源，则不需要互斥性。 持有等待（Hold and Wait）意味着进程在请求新资源时，不能持有其他资源。 这里提供了两种持有等待的策略： 进程在开始执行前，需要请求并分配所有所需资源。但这种方法的缺点是资源利用率低。 只在进程没有资源时才请求资源（先释放资源）。但这种方法的缺点是可能导致进程饥饿（starvation）。 不预先分配资源（No Preemption）。 该策略有两种实现方式： 当一个进程请求资源时，其已经持有的资源会被抢占。进程必须在没有资源的情况下等待。 如果一个持有资源的进程请求一个无法立即分配的资源，那么它将释放当前持有的所有资源。 被抢占的资源会被添加到进程等待的资源列表中。 进程在持有资源的情况下等待，但持有的资源可能会被其他请求这些资源的进程抢占。 这种策略通常适用于状态容易保存和恢复的资源，如 CPU 寄存器和内存空间。 循环等待（Circular Wait）。该策略要求对所有资源类型进行 total 排序，并规定每个进程按资源类型请求的顺序递增。 每个资源的排序位置由 F(Ri) 确定。 该策略有两种实现方式： 进程可以请求资源类型 Rj 的实例，条件是 F(Rj) \u0026gt; F(Ri)。如果需要多个相同资源类型的实例，进程必须一次请求所有实例。 每当进程请求资源类型 Rj 的实例时，它需要释放任何 F(Ri) ≥ F(Rj) 的资源。 这样可以确保系统在资源分配时遵循一定的顺序，从而降低死锁的可能性。 Deadlock Avoidance 每个进程声明可能需要的每种资源的最大数量。 死锁避免算法动态检查资源分配状态，以防止循环等待条件出现。 资源分配状态包括可用资源、已分配资源和进程的最大需求。\nSafe State 安全状态（Safe State）是指在系统中，所有进程都能够继续执行，且不会发生死锁的状态。在安全状态下，系统的资源分配满足以下条件：\n对于每个进程 Pi，其尚未请求到的资源可以通过当前可用的资源加上所有进程 Pj（其中 j\u0026lt;i）已持有的资源来满足。 如果某个进程需要的资源暂时不可用，那么该进程需要等待，直到所有进程 Pj 完成任务。 当一个进程完成任务后，它释放已持有的资源，然后继续执行下一个任务。 Resource-Allocation Graph Algorithm 资源分配图算法被用来检测系统是否处于安全状态，以避免死锁的发生。 该算法主要应用于单实例资源分配系统，通过分析资源分配图，判断资源分配是否会导致死锁。\n创建一个资源分配图，其中节点表示进程，边表示进程对资源的请求，框里点的个数表示资源个数。 使用深度优先搜索（DFS）或广度优先搜索（BFS）算法检测图中是否存在循环。 如果no circle，说明系统处于安全状态，一定没有死锁，可以进行资源分配。 如果找到循环，说明系统处于不安全状态，此时进程必须等待其他进程释放资源以避免死锁。 如果每个资源类型只有一个实例，并且这个实例被循环中的进程所持有，那么就会发生死锁。 如果循环中涉及到的每个资源类型都有多个实例，那么可能会发生死锁。 在这种情况下，尽管图中存在循环，这表明至少有一个进程在等待另一个进程释放资源，但由于每个资源类型有多个实例，因此理论上，如果循环中的进程能够获取到它们需要的资源的一个替代实例，那么死锁可以避免。因此，循环是死锁存在的必要条件，但不是充分条件。即使存在循环，只要资源分配得当，死锁是可以避免的。 \u0026ldquo;一个实例\u0026quot;通常指的是一种特定类型的资源的单个副本。假设有一个资源类型是“打印机”，那么系统中可能会有多台打印机。\n在资源分配图算法中，进程请求资源的过程如下：\n进程 Pi 请求资源 Rj。 检查将 Pi → Rj 转换为 Rj → Pi 是否会导致图中的循环。 如果没有导致循环，则允许资源分配，进程继续执行；否则，进程 Pi 需要等待。 Banker’s Algorithm 银行家算法（Banker\u0026rsquo;s Algorithm），它适用于多个实例的资源分配系统。进程需要在事先声明它们可能需要的每种资源的最大数量。当进程请求一组资源时，系统必须检查分配这些资源是否会使得系统处于安全状态。如果可以，则分配资源；否则，进程必须等待其他进程释放足够的资源。当进程获得所有所需资源后，它必须在有限的时间内归还这些资源。 银行家算法所需的数据结构:\nn：表示进程的数量。 m：表示资源类型的数量。 以下是数据结构的具体组成部分： Available：一个长度为 m 的向量。如果 Available[j] = k，意味着有 k 个 Rj 类型的资源可用。 Max：一个 n×m 的矩阵。如果 Max[i, j] = k，表示进程 Pi 最多可能请求 k 个 Rj 类型的资源。 Allocation：一个 n×m 的矩阵。如果 Allocation[i, j] = k，说明进程 Pi 目前分配了 k 个 Rj 类型的资源。 Need：一个 n×m 的矩阵。如果 Need[i, j] = k，表示进程 Pi 可能还需要 k 个 Rj 类型的资源来完成任务。 Need[i, j] 的计算公式为：Need[i, j] = Max[i, j] - Allocation[i, j]。 向量 X 和 Y，长度都是 n。X≤Y 表示向量 X 中的每个元素都小于或等于向量 Y 中的对应元素。也就是说，对于所有的 i=1，2，\u0026hellip;，n，都有 X[i]≤Y[i]。 矩阵 allocution 和 need 的每一行都可以看作是一个向量，分别被称为 $allocution_i$ 和 $need_i$。其中： $Allocation_i$ 表示当前分配给进程 Pi 的资源。 $Need_i$ 表示进程 Pi 可能还需要完成的任务所需的额外资源。 Safety Algorithm Safety Algorithm 的主要步骤：\n初始化：设置 Work 向量为可用资源，Finish 向量为长度为 n 的 vector，初始状态下，所有进程的 Finish 变量都为 false。 寻找一个索引 i，满足以下条件： a. Finish[i] 为 false b. Needi ≤ Work 如果找不到这样的 i，则执行步骤 4。 分配资源：将分配给进程 Pi 的资源添加到 Work 向量中，并将 Finish[i] 设置为 true。然后返回步骤 2。 检查系统状态：如果所有进程的 Finish[i] 都为 true，则系统处于安全状态。 Resource-Request Algorithm 【资源请求算法】（Resource-Request Algorithm）是一种在操作系统中处理资源分配和死锁问题的一种方法。该算法主要涉及到进程在请求资源时，如何判断和处理请求是否会影响系统的安全性。 在资源请求算法中，有以下几个关键点：\n每个进程都有一个请求向量（request vector），用于表示该进程所需的各种资源类型及其数量。 当一个进程请求某个资源时，系统需要检查该请求是否符合以下条件：\na. 请求的资源数量不超过进程所需的最大资源数量。\nb. 请求资源后，系统仍然处于安全状态。 系统通过检查进程的请求向量和当前系统中的可用资源，来判断请求是否可以被满足。如果满足条件，系统将为进程分配资源；否则，进程需要等待其他进程释放足够的资源。 进程在获得所需资源后，需要在有限时间内释放这些资源，以避免资源锁定现象。 资源请求算法的主要目的是确保系统在分配资源时始终保持安全状态，避免死锁的发生。通过进程提交资源请求，系统可以动态地检查资源分配状态，以便在满足进程需求的同时，确保系统资源的有效分配。这种算法有助于维护系统的稳定性和安全性，从而提高操作系统的性能。 Example of Banker’s Algorithm\nDeadlock Detection Single Instance of Each Resource Type 死锁等价于wait-for graph有环\nSeveral Instances of a Resource Type 可用资源（Available）：一个长度为m的向量，用来表示每种类型资源的可用数量。在进程需要资源时，这个向量会动态变化，以反映当前系统内每种资源的剩余数量。 分配（Allocation）：一个n×m的矩阵，用来定义当前分配给每个进程的每种类型资源的数量。矩阵的每一行代表了对应进程所分配到的资源类型和数量。 请求（Request）：一个n×m的矩阵，表示每个进程当前的资源请求。如果Request[i, j] = k，那么进程Pi正在请求k个资源类型Rj的实例。这个矩阵帮助系统了解各个进程还需要哪些资源，以便进行相应的分配。 在分配和请求矩阵中，每一行都可以被视为一个向量，分别称为Allocation i和Request i，这样可以更方便地表示和引用每个进程的分配和请求情况。\nDetection Algorithm Example of Detection Algorithm Detection-Algorithm Usage 何时以及多久调用一次死锁检测算法取决于以下几个因素：\n死锁多久可能发生一次？ 需要回滚多少个进程？ 对于每个不相关的循环，都需要一个回滚。 死锁只有在某个进程提出了一个不能立即满足的请求时才会发生。\n每当有资源分配的请求不能立即被满足时，就调用死锁检测算法。 这样做可能会在计算时间上产生相当大的开销。因此，可以定义一个时间间隔，比如每小时调用一次算法，或者当CPU利用率低于40%时调用。 如果随意调用检测算法，资源图（resource graph）中可能会有许多循环，这样我们就无法判断是哪个死锁进程“导致了”死锁。因此，需要合理地安排死锁检测的频率，以确保能够有效地识别和处理死锁，同时又不至于过度增加系统的开销。\nRecovery from Deadlock 当系统中存在死锁时：\n告知操作员，手动处理死锁。或者让系统自动从死锁中恢复。 为了打破死锁：\n终止一个或多个进程。 预占有一些资源，从死锁的进程中的一个或多个进程中。 在处理死锁时，需要考虑以下问题：\n成本：终止进程或抢占资源可能会带来一定的成本，比如重新启动进程的开销，或者可能导致系统性能下降。 规则：需要有一套明确的规则来决定如何识别和打破死锁，比如银行家算法就是一种常用的避免死锁的算法。 公平：在抢占资源时，需要考虑公平性问题，确保不会对任何进程造成不公平的待遇。 为了预防死锁，可以制定以下规则：\n资源分配规则：确保资源的分配不会导致循环等待条件的发生。 进程调度规则：合理安排进程的执行顺序，避免多个进程因为资源竞争而相互等待。 死锁检测和恢复机制：定期检测系统是否存在死锁，并在发现死锁时采取恢复措施，比如终止或抢占资源。 Process Termination 为了通过终止进程来消除死锁：\n终止所有死锁的进程。 逐个终止进程，直到死锁循环被消除。 系统会回收所有分配给已终止进程的资源。那么，我们应该按照什么顺序选择一个进程来终止呢？这里涉及到成本考虑：\n进程的优先级。 进程已经计算了多长时间，以及还需要多长时间才能完成。 进程已经使用了多少资源，以及是什么类型的资源。 进程完成还需要多少更多的资源。 需要终止多少个进程。 进程是交互式的还是批处理的？ Resource Preemption 连续从进程预占一些资源，并将这些资源分配给其他进程，直到打破死锁循环。选择一个牺牲品——哪些资源和哪些进程应该被预占？\n最小化成本。 回滚——将进程恢复到某个安全状态，并从该状态重新启动。 总体回滚：终止进程，然后重新启动它。 饥饿——同一个进程可能总是被选为牺牲品。 在成本因素中包括回滚的次数。 在选择牺牲品时，需要考虑以下因素来最小化成本：\n优先级：通常，优先级较低的进程更容易被选为牺牲品。 资源使用情况：已经占用较多资源的进程可能更容易导致死锁，因此可能被选为牺牲品。 进程的状态：如果进程处于一个可以安全回滚的状态，那么它可能被选为牺牲品。 回滚的代价：如果一个进程需要频繁回滚，那么它的成本可能较高，因此可能被选为牺牲品。 为了避免饥饿现象，即同一个进程总是被选为牺牲品，可以采取一些策略，比如轮流选择牺牲品，或者在选择牺牲品时考虑进程的公平性。 在考虑成本时，需要将回滚的次数作为一个重要因素。如果一个进程经常因为死锁而需要回滚，那么它的总体成本可能会很高，因此在选择牺牲品时需要考虑这一情况。 Combined Approach to Deadlock Handling 综合方法处理死锁：\n预防（Prevention） 避免（Avoidance） 检测（Detection） 将三种基本方法结合起来，允许针对系统中每种资源使用最优方法。\n将资源划分为层次结构化的类别。 在每个类别内使用最合适的死锁处理技术。 期末考计算题 根据资源、进程间的请求关系，画出Resource-Allocation Graph 根据资源分配图分析死锁出现的资源条件，或避免死锁的资源条件 Deadlock Avoidance 当每类资源只有一个资源实例，利用Resource-Allocation Graph Algorithm判断有无死锁/系统是否安全 当资源可有多个资源实例时，利用Banker Algorithm判断系统是否安全?(无死锁?), 进程的资源请求是否be granted Deadlock Detecting 当每类资源只有一个资源实例，利用waiting graph判断有无死锁? 当资源可有多个资源实例时，利用deadlock detecting algorithm 判断有死锁? ","date":"2023-10-21T21:27:13Z","permalink":"http://localhost:1313/post/5-deadlocks/","title":"5  Deadlocks"},{"content":"Process Synchronization Background Bounded-Buffer Procedure-Consumer Problem Bounded-Buffer Procedure-Consumer Problem（有界缓冲程序-消费者问题）是一个经典的并发编程问题，通常用于展示多进程/多线程同步和互斥的概念。问题的背景通常是一个有界缓冲区，其中生产者生产项目并将其放入缓冲区，而消费者则从缓冲区中取出项目并进行处理。\n以下是问题的要点和解决方法：\n问题描述：\n有一个固定大小的缓冲区，可以容纳有限数量的项目。 生产者进程生产项目并尝试将其放入缓冲区。 消费者进程从缓冲区中取出项目并进行处理。 缓冲区在满时不允许生产者继续生产，当缓冲区为空时不允许消费者继续消费。 解决方法： 问题通常通过使用互斥锁（mutex）和条件变量（condition variable）来解决。这些是线程同步的工具，用于确保生产者和消费者之间的正确互斥操作。\n互斥锁：用于保护共享缓冲区，以确保在任何时刻只有一个线程可以访问它。 条件变量：用于通知其他线程缓冲区的状态，如是否为空或已满。 解决方法的关键点：\n当缓冲区满时，生产者会等待，直到有空间可用。 当缓冲区为空时，消费者会等待，直到有项目可用。 当生产者放置项目或消费者取出项目后，它们会通知其他等待的线程。 这样，通过互斥锁和条件变量的协同作用，可以实现生产者和消费者之间的正确同步，确保没有数据竞争或死锁。\nThe Critical-Section Problem The Critical-Section Problem（临界区问题）是并发编程中的一个经典问题，通常用于展示如何实现多个进程或线程之间的互斥访问共享资源。问题的核心是多个进程（或线程）需要同时访问共享资源，但要确保它们不会在同一时间访问该资源，以避免数据竞争和不一致性。\n概念：\n同步：指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。 互斥：当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。 问题描述：\n多个进程或线程需要访问一个共享资源，如共享内存区域、全局变量或文件。 任何时刻，只允许一个进程/线程访问共享资源，其他进程/线程必须等待。 进程/线程必须在进入临界区（临界区是访问共享资源的代码段）之前获得访问权限，然后在退出临界区后释放访问权限。 解决方法： 问题通常通过使用互斥锁（mutex）和信号量（semaphore）等同步工具来解决。这些工具用于确保只有一个进程/线程可以进入临界区，而其他进程/线程必须等待。\n临界区资源访问过程：\nEntry Section 进程发送请求以获取许可或锁，以指示其希望进入临界区域。 检查是否可进入临界区 Critical Section 临界部分通常包括需要保护的关键代码，以确保数据一致性。 Exit Section 在退出部分，进程释放许可或锁，以允许其他进程进入临界区域。 进程也可以执行一些清理操作或更新共享数据。 Remainder Section 在完成退出部分后，进程可以执行其余下部分的代码，这些代码通常不需要互斥保护。 Solution must satisfy three requirements\n互斥 同一时刻只能有一个进程在其关键部分执行。 空闲让进 进展性确保如果当前没有进程在其关键部分执行，而有些进程希望进入其关键部分，那么选择下一个进入关键部分的进程不应无限期地被延迟。 有限等待 有界等待对其他进程在允许一个进程请求进入其关键部分并在该请求获得批准之前进入其关键部分的次数设置了限制。 这一要求旨在防止其他进程不断地超越某个进程，确保进程执行的公平性。 竞争条件： 竞争条件是指多个进程或线程试图同时访问共享资源，可能导致数据不一致或其他问题。在操作系统中，一些潜在的竞争条件包括管理文件、内存分配、进程列表维护以及中断处理等方面。\n抢占式和非抢占式： 处理竞争条件的方法取决于操作系统是否支持抢占。 抢占式操作系统允许内核模式下的进程被抢占，这可能导致在多处理器系统中难以设计，因为两个内核模式进程可能在不同处理器上同时运行。 非抢占式操作系统在内核模式下一直运行，直到它退出内核模式、阻塞或自愿放弃 CPU。这种情况下，内核模式下几乎没有竞争条件。 Peterson’s Solution Peterson 算法是基于双线程互斥访问的LockOne与LockTwo算法而来。LockOne算法使用一个 flag 布尔数组，LockTwo 使用一个 turn的整型量，都实现了互斥，但是都存在死锁的可能。Peterson 算法把这两种算法结合起来，完美地用软件实现了双线程互斥问题。\n首先，我们来看看下面这段代码：\nPi进程： flag[i] = True; while(flag[j]); critical section; flag[i] = False; remainder section; Pj进程： flag[j] = True; while(flag[i]); critical section; flag[j] = False; remainder section; 以上是用来实现两个进程互斥访问临界区的两端代码，我们可以这样来理解这两段代码，其中flag[i]表示进程Pi表示想要进入临界区，while(flag[j])可以理解为Pi在自己进临界区之前，先问问Pj是否想要进入临界区，如果Pj想进的话它就等待（Pi品德高尚）；类似的，Pj也是同样的。双方互相谦让的结果是，最终两个进程谁也进不了临界区。（可以想象这样一个生活场景，两个人同时想进屋，结果在门口谦让了了半天，过了很久都没进去）\nPeterson算法就是在上面代码的基础之上，又引入了一个变量turn，打破了这种因为谦让而导致“饥饿”的现象。下面我们先来看看Peterson算法的代码：\nPi进程： flag[i] = True; turn = j; while(flag[j] \u0026amp;\u0026amp; turn == j); critical section; flag[i] = False; remainder section; Pj进程： flag[j] = True; turn = i; while(flag[i] \u0026amp;\u0026amp; turn == i); critical section; flag[j] = False; remainder section; 怎么理解变量turn呢？可以将turn变量理解成轮到谁进入临界区了。举个例子：turn = i，表示轮到Pi进入临界区。那么上面这个代码就可以理解为：首先，Pi想进入临界区（flag[i] = True），然后，还是和前面的代码一样，Pi会先把进入临界区的机会让给Pj（turn = j），同样地，当Pj想进入临界区时，也会将进入临界区的权利先让给Pi。紧接着，变量turn的作用就显现出来了，当Pj把进入临界区的机会又让给Pi的时候（注意：这是发生在Pi将进入临界区的优先权让给Pj之后），Pi这次就会直接进入临界区。就不会再次出现一直互相谦让，最终导致均无法进入临界区的情况了。\n关于为什么当进入临界区的权利（即turn = i）又回到Pi手里时，Pi会直接进入临界区的分析？我们可以分析一下Pi能够成功进入临界区的条件（即：while(flag[j] \u0026amp;\u0026amp; turn == j)语句）： 总的分为以下两种情况：\nPj不想进入临界区（flag[j] = False） 当Pj不想进入临界区时，自然也就不存在Pi和Pj冲突的情况，Pi当然就直接进入临界区。 Pj想进入临界区（flag[j] = True） 当Pj想进入临界区，又分为以下两种情况： 当 turn = i turn = i说明当前轮到i进入临界区了 ，这个时候i就直接进入临界区了，不再谦让。（其实这个挺合理的，根据Peterson算法的代码我们不难发现因为turn的值是根据先后想要进入临界区的顺序排列的） 当 turn != i turn != i 说明当前轮到i进入临界区了没有轮到Pi进入临界区，Pi自然需要等待。 仅过上面的分析，我们就不难理解，当Pi和Pj经过一轮谦让之后，就会直接根据turn的值（即：该轮到谁进临界区了）来直接决定谁该进入临界区。现在回过头回顾整个算法，其实我们会发现，Peterson算法的思想会更贴近于生活中的真实情况，大家一般都是略微谦让一下，然后直奔主题，难道不是吗？哈哈\n*Bakery Algorithm 面包店算法为n个进程的临界区问题提供了一种解决方案。在进入临界区之前，每个进程都会接收到一个编号。持有最小编号的进程首先进入临界区。如果两个进程Pi和Pj接收到相同的编号，那么比较它们的进程ID：如果i\u0026lt;j，则Pi先被服务；否则Pj先被服务。编号方案始终按枚举的递增顺序生成编号，例如1, 2, 3, 3, 3, 3, 4, 5等等。\n这里的“\u0026lt;”表示字典顺序（票号，进程ID号）。如果(a, b)\u0026lt;(c, d)，那么要么是a\u0026lt;c，要么在a=c的情况下b\u0026lt;d。max(a0, …, an-1)是一个数字k，满足对于所有i = 0, …, n – 1，k≥ai。\nShared data boolean choosing[n];//false int number[n]; //0 Pi while (1) { choosing[i] = true; // Pi is taking a number number[i] = max(number[0], number[1], …, number [n–1])+1; //排队取号 choosing[i] = false; // end of number taking for (j = 0; j \u0026lt; n; j++) { while (choosing[j]) ; while ((number[j] != 0) \u0026amp;\u0026amp; ((number[j], j)\u0026lt;(number[i], i)); //排队等待 } critical section number[i] = 0; remainder section } Synchronization Hardware Synchronization Hardware 许多系统提供硬件支持以保护临界区代码。\n禁用中断disable interrupts 在单处理器系统中，当前正在执行的代码可以在不被抢占的情况下执行。而在多处理器系统中，这种做法效率太低，时间成本很高。这也会影响系统时钟的精度，特别是当时钟的更新是通过中断来完成的。 锁（Lock）：一个简单的工具，用于实现互斥。 进程在进入临界区之前必须获取一个锁。 当进程退出临界区时，它会释放锁，使其他进程能够进入。 atomic hardware instructions 现代计算机提供特殊的原子硬件指令，这些指令是不可中断的。 原子操作（Atomic） 意味着操作过程不会被中断。 例如，TestAndSet() 指令用于测试内存单元的值并设置新的值。 Swap() 指令用于交换两个内存单元的内容。 这些原子硬件指令可以在多线程或多进程的情况下，用来保护临界区代码，确保多个执行单元在同时访问共享资源时不会发生竞争条件。这些原子指令提供了一种有效的方式来执行互斥操作，而无需禁用中断或使用锁。\nSolution using TestAndSet() 使用 TestAndSet() 来解决临界区问题的解决方案如下：\nShared data: boolean lock = FALSE; Process Pi while(TRUE) { while (TestAndSet(\u0026amp;lock)); critical section lock = FALSE; remainder section } 共享数据：boolean lock = FALSE;，lock 是一个布尔变量，初始值为 FALSE。 进程 Pi： 进入一个无限循环，表示一直在运行。 在进入临界区之前，使用 TestAndSet(\u0026amp;lock) 来测试并设置 lock，如果 lock 的值为 TRUE，则继续等待，直到 lock 变为 FALSE。 一旦获得了 lock，进入临界区执行临界区代码。 执行完临界区后，将 lock 设置为 FALSE，表示离开了临界区。 最后，执行剩余部分。 这个解决方案使用 TestAndSet() 指令来确保在一个时刻只有一个进程能够进入临界区，其他进程必须等待。这样，它满足了互斥性的要求。\nSolution using Swap() 使用 Swap() 来解决临界区问题的解决方案如下：\nShared data: boolean lock = FALSE; Process Pi while(TRUE) { key = TRUE; while (key == TRUE) Swap (\u0026amp;lock, \u0026amp;key); critical section lock = FALSE; remainder section } 共享数据：boolean lock = FALSE;，lock 是一个布尔变量，初始值为 FALSE。 进程 Pi： 进入一个无限循环，表示一直在运行。 首先将 key 设置为 TRUE。 在进入临界区之前，使用 Swap(\u0026amp;lock, \u0026amp;key) 将 lock 和 key 互换，如果 lock 的值是 TRUE，那么 key 的值将变成 TRUE，表示继续等待。如果 lock 的值是 FALSE，那么 key 的值将变成 FALSE，表示进入临界区。 一旦获得了锁，进入临界区执行临界区代码。 执行完临界区后，将 lock 设置为 FALSE，表示离开了临界区。 最后，执行剩余部分。 这个解决方案使用 Swap() 指令来确保在一个时刻只有一个进程能够进入临界区，其他进程必须等待。这样，它满足了互斥性的要求。\nMutual Exclusion Machine Instructions 优势：\n适用于任意数量的进程，无论是在单处理器还是在共享主内存的多处理器系统上。 简单，易于验证。 可用于支持多个临界区。 劣势：\nBusy-waiting会占用处理器时间，这可能会导致资源的浪费。 可能出现starvation情况，当一个进程离开临界区并且有多个进程在等待时。 deadlock：如果一个优先级较低的进程拥有临界区，而一个优先级较高的进程需要进入临界区，那么高优先级的进程将获得处理器，但它只是等待临界区。 Revised Solution Using TestAndSet() 经过修订的使用TestAndSet()的解决方案如下：\nShared data(initialized to FALSE) : boolean lock; boolean waiting[n]; Process Pi while (TRUE) { waiting[i] = TRUE; key = TRUE; while (waiting[i] \u0026amp;\u0026amp; key) key = TestAndSet(\u0026amp;lock); waiting[i] = FALSE; // critical section j = (i + 1) % n; while ((j != i) \u0026amp;\u0026amp; !waiting[j]) j = (j + 1) % n; if (j == i) lock = FALSE; else waiting[j] = FALSE; // remainder section } 共享数据（初始化为FALSE）：\nboolean lock; // 用于表示临界区是否被锁定 boolean waiting[n]; // 用于表示每个进程是否在等待 这是使用TestAndSet()进行修订的解决方案，以实现多个进程之间的互斥。当进程需要访问临界区时，它首先等待其他进程完成，然后尝试使用TestAndSet()获取锁。在进入临界区后，它会检查是否有其他进程在等待，如果没有，就释放锁；否则，将等待标志设置为FALSE，以允许其他进程尝试获取锁。这有助于确保只有一个进程可以同时进入临界区。\nMutex Locks 以前的硬件解决方案复杂且通常不易被程序员所使用，操作系统设计者通过编写软件工具来解决关键段问题。最为简单的解决方案是互斥锁（又称互斥机制）。 保护关键段的方法是：首先获取（acquire）锁，然后释放（release）锁。 采用一个布尔变量available来表示锁的状态，用以判断锁是否可用。 acquire()和release()锁的操作必须是原子性的，通常通过硬件原子指令来实现原子性操作。 然而，这种解决方案需要忙等待，即在获取锁时，线程需要不断尝试直到锁可用。因此，这种锁被称为自旋锁（spinlock）。自旋锁通常在多处理器系统中使用，以解决多个处理器同时访问共享资源的问题。\nacquire() { while (!available) ; /* busy wait */ available = false; } release() { available = true; } Semaphores 信号量（Semaphore）是一种用于进程同步的工具，它提供了比互斥锁更复杂的方法。与互斥锁不同，信号量不需要busy waiting。 信号量是一个特殊的变量，通常用整数来表示，可以初始化为非负数。它只能通过两个不可分割的操作来访问：\nwait(S)：等待操作，用于获取信号量，操作会减小信号量的值。S\u0026ndash; signal(S)：信号操作，用于释放信号量，操作会增加信号量的值。S++ 这两个操作是不可中断的，它们在执行过程中不会被中断。 信号量用于实现进程同步和互斥，它可以帮助控制多个进程之间的访问共享资源的顺序。 Semaphore usage 信号量的使用可以分为两种主要类型：二进制信号量和计数信号量。\nBinary Semaphore 整数值只能在 0 和 1 之间取值。 通常用于互斥控制，类似于互斥锁（Mutex Lock）。 一个进程可以通过 wait(S) 操作获取二进制信号量，使其值变为 0，表示资源已被占用。 通过 signal(S) 操作释放二进制信号量，使其值变为 1，表示资源可用。 Counting Semaphore 整数值可以在一个不受限制的范围内取值。 通常用于控制对一组有限数量资源的访问。 计数信号量的初始值通常设置为资源的可用数量。 当一个进程希望使用资源时，它执行 wait() 操作，减小信号量的值。 当一个进程释放资源时，它执行 signal() 操作，增加信号量的值。 当计数信号量的值降至 0 时，表示所有资源都被使用，此后希望使用资源的进程将会被阻塞，直到计数信号量的值再次大于 0。 为了确保 wait() 和 signal() 操作的原子性：\n在单处理器系统中，通常的做法是在执行这些操作时禁止（抑制）中断。这样可以防止进程在执行这些操作时被中断，从而保证了操作的原子性。\n在多处理器系统中，禁止中断并不是一个可行的解决方案，因为即使在一个处理器上禁止了中断，其他处理器上的进程仍然可以执行这些操作。因此，需要使用锁定技术来确保操作的原子性。一个常见的锁定技术是使用自旋锁（spinlocks），它会让进程在尝试获取锁时循环检查锁是否可用，而不是放弃处理器的控制权。 计数信号量可用于控制对共享资源的并发访问，确保资源在同一时刻不被过多的进程使用。\n在解决临界区问题时，信号量可以用来协调多个进程的访问。下面是一个关于 n 个进程的临界区问题的示例，以及如何使用信号量来同步它们的执行：\nCritical Section of n Processes Shared data: semaphore mutex; // 初始值为 1 Process Pi: while (true) { wait(mutex); // 临界区代码 signal(mutex); // 剩余部分代码 } 在此示例中，有 n 个进程（P1, P2, \u0026hellip;, Pn），它们共享一个信号量 mutex，它的初始值为 1。每个进程在进入临界区之前都会执行 wait(mutex) 操作，以等待获取信号量。当一个进程完成临界区的操作后，它会执行 signal(mutex) 操作，释放信号量，允许其他进程进入临界区。\n这种方式可以确保在同一时刻只有一个进程能够进入临界区，从而避免了竞争条件。但需要注意的是，如果某个进程在等待获取信号量时，它会处于忙等待状态，这可能会浪费 CPU 资源。这种类型的信号量也被称为自旋锁（spinlock），因为进程在等待锁时会自旋（忙等待）。\n此外，示例中的 n 可以是任意正整数，表示有多少个进程需要协调访问临界区。\n在信号量的实现中，可以使用等待队列来避免忙等待。信号量可以被定义为一个 C 结构，每个信号量具有以下属性：\n一个整数值，表示信号量的计数。 一个进程列表（等待队列），用于存储等待获取信号量的进程。 信号量操作包括：\nblock(): 当一个进程调用此操作时，它会被放置到适当的等待队列中，表示它正在等待获取信号量。 wakeup(P): 当需要释放信号量时，可以从等待队列中选择一个等待的进程，并将其移至就绪队列，以便它可以继续执行。 这种方式允许进程在等待信号量时不会浪费 CPU 资源，因为它们不需要忙等待。相反，它们会进入等待队列，直到信号量可用，然后才会被移至就绪队列。\n这种信号量的实现方式更高效，特别适用于多进程协同工作的情况，以避免资源竞争和提高系统的整体性能。\n这是一个使用等待队列的信号量实现，其中包括 wait 和 signal 操作。以下是这两个操作的伪代码示例：\nwait 操作:\nwait(semaphore *S) { S-\u0026gt;value--; // 减少信号量值 if (S-\u0026gt;value \u0026lt; 0) { // 如果信号量值小于零，表示资源不可用，将当前进程加入等待队列并阻塞 add this process to S-\u0026gt;List; block(); // 阻塞当前进程 } } signal 操作:\nsignal(semaphore *S) { S-\u0026gt;value++; // 增加信号量值 if (S-\u0026gt;value \u0026lt;= 0) { // 如果信号量值不小于零，表示有等待的进程，唤醒其中一个 remove a process P from S-\u0026gt;List; wakeup(P); // 唤醒一个等待的进程 } } 这种实现方式可以确保在资源不可用时，等待的进程不会浪费 CPU 资源，而是会被阻塞，直到资源可用。一旦资源可用，信号量会唤醒一个等待的进程，使其可以继续执行。这有助于避免忙等待，提高系统的效率和性能。\n这个信号量实现采用了等待队列，以确保没有两个进程可以同时执行相同信号量上的 wait() 和 signal() 操作。为了避免竞态条件，必须确保这两个操作在临界区内执行。\n具体实现的方式取决于系统的特性：\n在单处理器系统中，可以通过禁用中断来防止进程切换，从而实现临界区的互斥。 在多处理器系统中，需要使用锁定技术，如自旋锁（spinlocks），以确保 wait() 和 signal() 操作在同一信号量上不会同时执行。 虽然这种实现方式并没有完全消除忙等待，但它将忙等待限制在 wait() 和 signal() 操作的关键部分。由于这两个操作的实现代码很短（通常不超过10条指令），因此关键部分很少被占用，因此忙等待发生得很少。\n这种方法允许系统高效地等待资源的可用性，同时尽量减少不必要的忙等待。这有助于提高系统性能和效率。\n问题：死锁和饥饿\n死锁：指两个或多个进程无限期地等待一个只能由等待中的进程中的一个触发的事件。死锁是并发系统中的一种严重问题。\n示例：假设有两个信号量S和Q，它们都被初始化为1。\nP0 P1 wait (S); wait (Q); wait (Q); wait (S); … … signal (Q); signal (S); signal (S); signal (Q); 在这个示例中，P0和P1都试图以相反的顺序等待S和Q，这可能导致死锁。\n饥饿：饥饿是指进程无限期地被阻塞。这种情况下，进程可能永远无法从其挂起的信号量队列中被移除。饥饿可能导致一些进程无法获得所需的资源，从而降低系统性能。\n示例：一个使用LIFO（后进先出）队列的信号量可能导致某些进程永远无法获得资源，因为它们总是排在队列的末尾。\n这些问题是在并发编程中需要小心处理的关键问题。解决方法包括使用适当的算法和数据结构，以及在设计时考虑进程的优先级和资源分配策略，以避免死锁和饥饿的发生。\nPriority Inversion 定义：优先级反转是指在多任务系统中，当一个具有较低优先级的任务持有一个较高优先级任务所需的资源时，可能导致高优先级任务受阻的情况。 例子： 假设有三个进程，分别为L、M和H： H（高优先级）需要资源R，而L（低优先级）正在使用该资源。因此，H必须等待L完成对R的使用。 在此时，M（中等优先级）可以运行，并抢占了L的执行。 此时，由于M的运行，L被抢占，导致H等待更长时间才能获得对R的访问。这种情况称为优先级反转，因为高优先级的任务被低优先级的任务所阻塞。 solution：优先级继承协议priority-inheritance protocol 当一个任务（例如L）持有一个资源（例如R）时，任何试图访问这个资源的任务都会继承该任务的优先级（例如H的优先级）。 在上述例子中，L在使用R期间临时继承了H的优先级，以确保H不会被低优先级的M所阻塞。 一旦任务完成对资源的使用，它的优先级就会恢复到原始值。 Classic Problems of Synchronization The Bounded-Buffer Problem 有界缓冲区问题 假设缓冲池由 n 个缓冲区组成，每个缓冲区可以容纳一个项目。 共享数据包括三个信号量：mutex、empty 和 full。 初始状态如下：\nmutex = 1：互斥信号量，确保每次只有一个进程能够进入临界区。 empty = n：表示空缓冲区的数量，初始时所有缓冲区都是空的。 full = 0：表示已满缓冲区的数量，初始时没有缓冲区是满的。 有界缓冲区问题的解决方案通常包括生产者和消费者两个进程。生产者负责将产品放入缓冲区，而消费者从中获取产品。这里的代码示例描述了生产者和消费者的基本循环：\n公有信号量-互斥\n私有信号量-同步\nThe Readers-Writers Problem 竞争：读-写、写-写 共享：读-读\n有两个经典的读者-写者问题：\n第一个读者-写者问题（读者优先）：\n只有读取内容的读者和可以更新内容的写者。 读者可以同时访问共享对象。 写者具有独占访问共享对象的权限。 在这个问题中，没有读者会一直等待，除非有一个写者已经获得了访问共享对象的权限。 写者可能会饥饿，即等待时间较长。 rw-mutex是读写的互斥信号量，mutex_r是控制读者数量的信号量。 先等能控制读者数量的时候，如果有个读者进程出现，就会让read_count的数量++，如果是第一个读者，要等rw_mutex信号量为1的时候才能进行下一步。 当最后一个读者读完了，要把rw_mutex信号量释放\n第二个读者-写者问题（写者优先）：\n一旦写者准备好，它将尽快执行写入。 如果有一个写者正在等待访问共享对象，那么新的读者将无法开始阅读。 在这个问题中，读者可能会饥饿，因为一旦写者准备好，读者将无法访问共享对象。 The Dining-Philosophers Problem 这是著名的\u0026quot;哲学家就餐问题\u0026quot;（Dining Philosophers Problem）的示例，通常用于说明并发编程中的同步和资源分配问题。在这个问题中，有五位哲学家坐在一张圆形餐桌周围，每位哲学家面前放着一只筷子。他们交替地思考（thinking）和进餐（eating），但只有在同时拿到两只筷子时才能进餐。解决这个问题需要协调哲学家的活动，以避免死锁和竞态条件。\n在这个示例中，semaphore chopstick[5] 是五个信号量，代表五只筷子。每位哲学家都需要拿起两只相邻筷子才能吃饭。解决方案的核心是确保一位哲学家在拿筷子时不会与其邻居发生竞争。\n哲学家的活动循环包括以下部分：\n思考（thinking）：哲学家在思考时不需要资源，因此直接进入思考状态。 饥饿（hunger）：哲学家想要进餐，但必须获取两只筷子。他们通过等待两只相邻筷子的信号量来表示他们的饥饿。 进餐（eating）：当哲学家拿到两只筷子后，他们可以进餐。进餐后，他们释放筷子。 semaphore chopstick[5]={1,1,1,1,1}; //Pi while(1){ hunger wait(chopstick[i]); wait(chopstick[(i+1)%5]); eating signal(chopstick[i]); signal(chopstick[(i+1)%5]); thinking } solution1 最多4个人吃饭，至少有一只筷子多出来 增加一个count信号量\nsemaphore chopstick[5]={1,1,1,1,1}; semaphore count=4; //Pi while(1){ hunger wait(count); wait(chopstick[i]); wait(chopstick[(i+1)%5]); eating signal(chopstick[i]); signal(chopstick[(i+1)%5]); signal(count); thinking } solution2 奇数拿左边，偶数拿右边 如果拿不到就吃不上，等下次再拿\nsemaphore chopstick[5]={1,1,1,1,1}; //Pi while(1){ hunger if(i%2==1){ wait(chopstick[i]); wait(chopstick[(i+1)%5]); }else{ wait(chopstick[(i+1)%5]); wait(chopstick[i]); } eating signal(chopstick[i]); signal(chopstick[(i+1)%5]); thinking } Monitors Define Monitor Monitors（管程）是一种高级同步构造，用于在并发进程之间安全共享抽象数据类型。Monitor是一个软件模块，通常用于控制对共享资源的访问，以避免竞态条件和确保数据的一致性。\n局部数据变量: 这些变量仅限于Monitor内部的过程访问。 进程入口: 进程通过调用Monitor中的某个过程来进入。 互斥执行: 任何时候，Monitor内只允许一个进程执行。 一个Monitor的概念示意图如下：\n+------------------------+ | Monitor | | | | Data Variables | | | | Procedures | | | | Condition Variables| | | +------------------------+ 上面的示意图展示了一个监视器的基本结构。监视器内部包括以下主要组成部分：\n数据变量（Data Variables）：这些是局部数据变量，只能由Monitor内的过程访问。它们用于存储Monitor所管理的共享数据。 过程（Procedures）：这些是Monitor内定义的过程，通常用于对共享数据进行操作。只有进入Monitor的进程才能调用这些过程。 条件变量（Condition Variables）：条件变量是一种用于等待和通知的机制。它们允许进程在满足某些条件之前等待，然后在条件满足时被通知继续执行。条件变量通常与等待（wait）和通知（signal）操作相关联。 Condition Variable 条件变量（Condition Variable）是管程（Monitor）内的一个重要组成部分，用于实现进程的等待和通知机制。条件变量通常与等待（wait）和通知（signal）操作相关联。\n声明条件变量：在monitor内，你可以声明一个或多个条件变量condition x, y; wait() 操作：调用此操作的进程将被挂起（suspended），直到另一个进程调用x.signal(); signal() 操作：恢复（resumes）一个被挂起的进程。如果没有进程被挂起，则signal操作没有任何效果。 条件变量和相关操作使监视器内的进程能够更灵活地协同工作，等待特定条件的满足，并在条件满足时得到通知。这有助于避免忙等待（busy waiting）和提高系统的效率。不同编程语言和操作系统可能会提供不同的条件变量实现，但它们的基本概念是相似的。\n","date":"2023-10-21T21:19:31Z","permalink":"http://localhost:1313/post/4-process-synchronization/","title":"4 Process Synchronization"},{"content":"CPU Scheduling Basic Concepts The objective of multiprogramming is to have some process running at all times. To maximize CPU utilization. 多程序调度目标：最大化 CPU 利用率 CPU-I/O burst 周期 CPU burst 分布\nCPU Scheduler CPU调度器（Scheduler）的主要任务是从内存中准备执行的进程中选择一个，并将CPU分配给其中一个进程。 CPU调度决策可能在以下情况下发生：\n进程终止。 进程从运行状态切换到等待状态。 进程从运行状态切换到就绪状态。 进程从等待状态切换到就绪状态。 这些情况导致了CPU调度器重新选择下一个要执行的进程，以确保CPU资源得到有效利用。 Decision Mode 决策模式是关于操作系统中CPU调度方式的两种主要类型：\n非抢占式（Nonpreemptive）： 一旦进程进入运行状态，它将一直运行，直到终止或因I/O操作而阻塞自己。 一旦CPU被分配给一个进程，该进程将一直保持CPU，直到它释放CPU（要么因终止，要么切换到等待状态）。 非抢占式调度可能导致一个进程长时间独占处理器。 抢占式（Preemptive）： 当前运行的进程可能会被操作系统中断并移动到就绪状态。 抢占式调度允许更好的服务，因为任何一个进程不能长时间占用处理器。 抢占式调度有时可能会导致竞争条件，尤其当数据被多个进程共享时。 抢占式调度允许操作系统随时暂停正在执行的进程，以便分配CPU时间给其他进程，这有助于确保公平地共享CPU资源。非抢占式调度则在分配CPU时较为保守，只有在进程主动释放CPU时才会切换。 Dispatcher 进程调度器，它是操作系统中的一个关键模块，负责分配和调度 CPU 时间片给各个就绪状态的进程。 Dispatcher 的主要功能如下：\n控制 CPU：Dispatcher 负责将 CPU 控制权交给选定的进程。在操作系统中，有一个短期调度器（也称为 Dispatcher）负责在就绪队列中的进程之间分配 CPU 时间片。 切换上下文：当 CPU 控制权发生变化时，Dispatcher 负责在各个进程之间切换上下文。这包括保存当前进程的状态，加载下一个进程的状态，以及将 CPU 执行环境切换到下一个进程。 进程切换：Dispatcher 负责实现进程之间的切换。当一个进程完成执行或者主动让出 CPU 时，Dispatcher 会选取下一个就绪进程并将其投入执行。 调度 latency：Dispatcher 决定了进程切换所需的时间，即调度 latency。这是 Dispatcher 停止一个进程并开始执行另一个进程所需的时间。 优先级调度：Dispatcher 还负责根据进程的优先级进行调度。优先级较高的进程更容易获得 CPU 时间片，以确保系统资源得到合理分配。 总之，Dispatcher 是操作系统中的核心模块，负责管理 CPU 时间片分配和进程调度。它确保系统资源得到高效利用，同时确保进程能够在合适的时机获得执行。 Scheduling Criteria 调度准则 是指用于评估和选择调度算法的标准或指标。这些准则通常用于衡量操作系统中进程调度器的性能和效率。 调度准则可以分为两类：性能相关和性能无关。\n性能相关：这类准则关注的是调度算法在提高系统性能方面的表现，主要包括以下几个方面： CPU 利用率：尽量让 CPU 保持繁忙，提高系统资源利用率。 吞吐量：衡量单位时间内完成进程数量的表现。 周转时间（Turnaround Time）：从进程提交到完成执行所花费的时间。 等待时间：进程在就绪队列中等待 CPU 分配的时间。 响应时间：从提交请求到产生第一个响应的时间（对于时间共享环境）。 性能无关：这类准则主要关注调度算法的公平性和可预测性，包括以下几个方面： 公平性：确保各个进程能够公平地获得 CPU 资源。 截止日期（Deadline）：确保关键任务在规定的时间内完成。 系统导向：通过优化系统整体性能，提高系统的稳定性和可靠性。 在选择调度算法时，需要根据具体场景和需求来权衡这些准则的相对重要性。常见的调度算法评估方法包括确定性建模、排队论、模拟和实现等。根据这些评估结果，可以选择最适合特定系统的调度算法。 Scheduling Algorithms First-Come, First-Served (FCFS) Scheduling 先来先服务调度算法。在这种算法中，每个进程加入就绪队列，形成一个先进先出的队列。当当前进程执行结束时，选择就绪队列中the oldest的进程继续执行。FCFS 算法是非抢占式的，即当前进程在执行过程中不会被其他进程中断。\nShortest-Job-First (SJF) Scheduling 短作业优先调度算法。SJF 算法根据进程的预计下一个 CPU burst 时间来设置进程的优先级，优先级越高的进程越有可能被调度执行。SJF 算法可以分为抢占式和非抢占式两种，其中非抢占式算法只是在进程到达时将其放入队列末尾，不会中断当前进程。\nPrediction of the Length of the Next CPU Burst 由于下一个 CPU burst 的实际长度是不确定的，所以我们只能对其进行估计。预测可以通过使用之前 CPU burst 的长度，采用指数平均法来实现。 具体计算公式如下： 下一次 CPU burst 预测长度 = α * 上一次 CPU burst 实际长度 + (1 - α) * 指数平均法预测长度 其中，α 是一个在 0 到 1 之间的参数，表示预测权重。当α接近 1 时，表示更倾向于选择上一次 CPU burst 的实际长度；当α接近 0 时，表示更倾向于选择指数平均法预测的长度。\nPriority Scheduling 优先级调度算法。这种算法根据进程的优先级来决定调度顺序，优先级高的进程优先执行。（通常数字越小优先级越高）优先级可以根据进程的性质（如交互式进程、批量进程等）或进程的 burst 时间来设置。优先级调度可以是抢占式的，也可以是非抢占式的。\n静态优先级、非抢占式调度 静态优先级、抢占式调度 优先级调度算法会导致饥饿问题，解决办法是随着时间的增长优先级提高。\nRound Robin (RR) Scheduling 轮转调度算法。RR 算法为每个进程分配一个固定的时间片，进程按照顺序轮流执行。当一个进程的时间片用完后，将其放回队列末尾，继续下一个进程执行。RR 算法保证了每个进程都能得到公平的 CPU 时间片，但可能导致较长作业长时间无法执行。\nExample of RR with Time Quantum=20\n在就绪队列中有 n 个进程，时间片为 q 的情况下，每个进程将获得 CPU 时间的 1/n，且每个进程等待时间不会超过 (n-1)q。 性能取决于时间片的大小：\n如果时间片 q 非常大（无限大），那么将实现先来先服务（FCFS）调度算法； 如果时间片 q 非常小，那么将导致大量上下文切换； 为了避免过高的时间片切换开销，时间片 q 必须相对于上下文切换较大。 总之，合适的时间片大小对于 CPU 调度性能至关重要。时间片过大或过小都会导致性能下降。因此，在实际应用中，需要根据系统实际情况和需求来设置合适的时间片大小。 Multilevel Queue Scheduling 多级队列调度算法。这种算法将进程分为多个队列，根据进程的性质和优先级将它们放入相应的队列。每个队列都有自己的调度算法，如前台进程使用 RR 算法，后台进程使用 FCFS 算法。多级队列调度可以在不同队列之间实现抢占式或非抢占式调度。\nMultilevel Feedback Queue Scheduling 多级反馈队列调度算法。这种算法在多级队列的基础上，根据进程的执行情况和反馈信息调整进程的优先级。进程可以在队列之间流动，根据优先级和反馈信息进行调度。这种算法旨在平衡系统性能和资源利用率，实现公平和高效的调度。\n如果一个进程使用太多的 CPU 时间，它将被移动到较低优先级的队列。\n将I/O绑定和交互式进程留在较高优先级的队列中。 如果一个进程在较低优先级的队列中等待太久，它可能被移动到更高优先级的队列。\n这种老化方式防止了饥饿现象。 Three queues：\nQ0 \u0026ndash; 最高优先级 \u0026ndash; 时间片为 8 毫秒\nQ1 \u0026ndash; 较低优先级 \u0026ndash; 时间片为 16 毫秒\nQ2 \u0026ndash; 最低优先级 \u0026ndash; FCFS\n多级反馈队列调度器由以下参数定义：\n队列的数量。\n每个队列的调度算法。\n确定何时将进程升级到更高优先级队列的方法。\n确定何时将进程降级到更低优先级队列的方法。\n确定进程在需要服务时进入哪个队列的方法。\nHighest Response-Ratio Next Scheduling 最高响应比优先调度是一种非抢占式调度算法，它综合考虑了进程的等待时间和 CPU burst 时间。响应比是指进程完成任务所需的响应时间与任务执行时间的比值。响应比越高，说明进程完成任务的速度越快，因此优先级越高。 在该算法中，系统会实时计算每个进程的响应比，并选择响应比最高的进程进行调度。这种算法旨在优化系统的响应时间，提高用户满意度。然而，该算法的缺点是计算响应比的过程较为复杂，会带来一定的系统开销。\nResponse-Ratio ： R=(W+T)/T=1+W/T W：waiting time in ready queue T：CPU-burst time\nMultiple-Processor Scheduling 多处理器系统的分类：\na. 松耦合多处理器（Loosely coupled multiprocessor）：每个处理器具有自己的内存和 I/O 通道。这种结构中的处理器之间相互独立，互不干扰。\nb. 紧耦合多处理器（Tightly coupled multiprocessing）：处理器共享主内存。这种结构中的处理器在执行任务时需要更多的协作和同步。\nc. 功能专业化处理器：如 I/O 处理器，这种处理器专门负责处理 I/O 操作，由主处理器控制。 homogeneous 处理器：在多处理器系统中，任何可用的处理器都可以运行队列中的任何进程。这意味着系统中的所有处理器具有相同的性能和功能。 Heterogeneous 系统：在这种系统中，只有为特定处理器指令集编译的程序才能在该处理器上运行。这意味着系统中的处理器具有不同的指令集和性能。\nApproaches to Multiple-Processor Scheduling Asymmetric multiprocessing（非对称多处理器）和 Symmetric multiprocessing（对称多处理器）是两种不同的多处理器调度方式。 在非对称多处理器系统中，有一个主处理器负责处理所有的调度决策、I/O 处理和其他系统活动。其他从处理器仅执行用户代码。主处理器访问系统数据结构，从而减少了数据共享的需求。从处理器向主处理器发送服务请求。这种方法的缺点是，如果主处理器出现故障，整个系统将受到影响；此外，主处理器可能会成为性能瓶颈。 在对称多处理器（SMP）系统中，架构是对等的，操作系统可以在任何处理器上执行。每个处理器都可以自行调度。准备队列有两种方式：一是每个处理器拥有自己的私有准备队列；二是共享一个公共准备队列。使用私有队列时，可以为主处理器提供专用短期队列，但可能会导致负载不平衡。使用公共队列时，需要确保两个处理器不会选择相同的进程，并且进程不会从队列中丢失。\nProcessor Affinity 处理器亲和力（Processor Affinity）\n非统一内存访问（NUMA，Non-Uniform Memory Access）\n处理器亲和力是指操作系统将进程分配给特定处理器的能力。在这个过程中，操作系统尽量让一个进程在同一处理器上运行，但并不保证一定实现。这主要是为了提高系统的性能和资源利用率。 非统一内存访问（NUMA）是一种现象，指的是 CPU 对内存的不同部分访问速度不同。通常，这种情况出现在含有 CPU 和内存板的系统中。在这种系统中，一个主板上的 CPU 访问该主板上的内存速度要比访问其他主板上的内存速度快。\nLoad balancing 负载均衡是指在 SMP（对称多处理器）系统中，保持工作负载在所有处理器上均匀分布。 负载均衡仅在每个处理器都有自己的准备队列（private ready queue）的系统中才有必要。 负载均衡有两种方法：\n推迁移（Push migration）：特定任务周期性地检查每个处理器的负载，如果存在负载不平衡，将从负载过重的处理器上将进程推到空闲或较不繁忙的处理器上。 拉迁移（Pull migration）：空闲处理器从繁忙的处理器中拉取等待的任务。 然而，负载均衡往往抵消了处理器亲和性（processor affinity）的优点。 Multiprocessor Thread Scheduling 负载分享（Load sharing）：在这种策略下，进程不会被分配到特定的处理器上。这意味着处理器会在多个进程之间共享，以实现更高的资源利用率。 组调度（Gang scheduling）：这种策略是指一组相关的线程同时在一组处理器上运行。这种方法可以提高程序的执行效率，特别是当这些线程之间存在很强的相关性时。 专用处理器分配（Dedicated processor assignment）：在这种策略下，线程被分配到特定的处理器上。这种方法可以确保每个线程都能获得固定的处理器资源，从而提高程序的执行效率。 动态调度（Dynamic scheduling）：这种策略是指在程序执行过程中，可以动态地改变线程的数量。这使得系统可以根据当前的系统负载和资源状况，灵活地调整线程数量，以实现更高的资源利用率。 总的来说，这段内容主要介绍了多处理器线程调度的一些基本概念和策略，以及如何根据不同的需求和场景选择合适的调度方法。这些策略可以提高系统的资源利用率、执行效率，并确保程序的正常运行。 Thread Scheduling 线程是独立于进程其他部分执行的，一个应用程序可以是一组合作的线程，在相同的地址空间中并行执行。线程在不同的处理器上运行可以带来性能的显著提升。线程可以分为内核级线程和用户级线程，内核级线程由操作系统调度，用户级线程由线程库管理，内核无法感知到它们。要在一台 CPU 上运行，用户级线程最终必须映射到相关的内核级线程，这个映射可能是间接的，可能使用轻量级进程（LWP）。\n竞争范围（Contention Scope）包括进程竞争范围（PCS）和系统竞争范围（SCS）。在 PCS 中，线程库将用户级线程调度到可用的 LWP 上。CPU 的竞争仅在同一进程的线程之间进行。在 SCS 中，内核决定将哪个内核级线程调度到 CPU 上。CPU 与 SCS 的竞争发生在系统中的所有线程之间。\n线程调度包括局部调度（PCS）和全局调度（SCS）。局部调度指的是进程竞争范围，采用 m:1 和 m:n 模型。全局调度指的是系统竞争范围，采用 1:1 模型。Pthread 调度 API 允许在创建线程时指定 PCS 或 SCS。在实现多对多模型的系统中，PTHREAD_SCOPE_PROCESS 策略将用户级线程调度到可用的 LWP 上，线程库维护 LWP 的数量。PTHREAD_SCOPE_SYSTEM 策略将为每个用户级线程创建并绑定一个 LWP，实际上将线程映射为一对一策略。操作系统可能会限制这些选项，例如 Linux 和 Mac OS X 仅允许 PTHREAD_SCOPE_SYSTEM。\nOperating System Examples Linux Scheduling Linux调度算法，是Linux操作系统中用于分配CPU资源的进程调度策略。其核心目标是公平、高效地为各进程分配CPU时间片，以实现最大的系统资源利用率。\n1. 任务优先级\n任务的优先级与其数值成反比。 实时任务：优先级为0-99，拥有较高的优先级。 非实时任务：优先级为100-140，拥有较低的优先级。 2. 时间共享 (100-140)\n优先给予具有最多积分的进程CPU时间片。 定时器中断发生时，进程积分逐渐减少。 积分为0时，切换至另一进程。 所有进程积分归零时，重新分配积分。 3. 实时调度 (0-99)\n符合Posix.1b标准的软实时调度。 先来先服务（FCFS） 循环轮转（RR） 总是优先执行最高优先级的进程。 4. 任务优先级的类别\n实时任务：分配固定的静态优先级，因需满足严格的时间限制。 其他任务：动态优先级，由其\u0026quot;nice\u0026quot;值（相对优先级）决定，取值范围为-20到19。值越低，优先级越高。调度时根据此优先级确定。 5. 优先级索引的任务列表\n该列表根据任务优先级排序，存放所有就绪状态的任务。 高优先级任务优先执行，保证关键和实时任务获得足够资源。 低优先级任务在资源充裕时得以执行，以保证系统的公平与效率。 调度器会按照此列表优先级，从高到低地选择并执行任务。 Windows Scheduling 基于优先级的抢先式调度\n调度器：调度器即为分派器。\n线程的运行状态：\n遭遇阻塞。 时间片用完。 被高优先级的线程抢占。 线程终止。 实时线程与非实时线程：实时线程可以抢占非实时线程。\n优先级方案：\n共有32个优先级。 变量类的优先级范围是1-15，实时类的优先级范围是16-31。 优先级0被分配给内存管理线程。 多级队列：每个优先级都有一个对应的队列。\n无可运行线程时的状态：如果没有可运行的线程，系统会运行空闲线程。\nWindows XP的优先级制度\n线程的优先级：每个线程的优先级都是基于其优先级类和相对优先级来决定的。 进程的优先级通常设为NORMAL_PRIORITY_CLASS。 线程的初始优先级通常是进程的基础优先级。 时间片用尽时的处理：当时间片用尽时，线程的优先级会被降低，但绝不会低于基础优先级；当线程从等待操作恢复时，其优先级会被提高。 Solaris Scheduling 基于优先级的线程调度\n相同优先级的处理方式：当线程具有相同的优先级时，采用循环轮转（RR，Round Robin）方式进行调度。\n线程分类：每个线程都属于以下六个类别中的一个：\n时间共享（Time Sharing, TS） 交互式（Interactive, IA） 实时（Real Time, RT） 系统（System, SYS） 公平共享（Fair Share, FSS） 固定优先级（Fixed Priority, FP） 每类特点：在每个类别中，都有不同的优先级和调度算法。\n默认调度类别：对于进程，其默认的调度类别是时间共享。\nAlgorithm Evaluation 度量标准： CPU利用率：这是一个度量CPU活跃程度的指标，通常表示为百分比。理想情况下，我们希望CPU保持高效的利用，但同时也要确保它不会过载。 响应时间：表示从请求提交到收到第一个响应所需的时间。对于交互式系统或实时系统，响应时间是一个关键指标。 吞吐量：在单位时间内完成的任务数量。对于批处理系统或高性能计算系统，吞吐量是一个重要指标。 度量标准的相对重要性： CPU利用率的最大化：但要在一个限制下，即响应时间的最大值不能超过1秒。这意味着，尽管我们希望CPU尽可能多地被利用，但我们也希望系统的响应时间保持在用户可以接受的范围内。 吞吐量的最大化：但要满足一个条件，即周转时间（从任务提交到任务完成的总时间）与任务的总执行时间成线性关系。这意味着，随着任务执行时间的增加，周转时间也会按相同的比例增加，从而确保系统的公平性。 Deterministic modeling 这段内容主要介绍了确定性建模（Deterministic modeling）的概念。确定性建模是一种针对特定预先确定的工作负载（workload）来评估调度算法性能的方法。在这种方法中，系统会对每种算法在工作负载下的性能进行定义。 举一个例子来说明，假设我们有以下的工作负载：\nFCFS（First-Come-First-Serve，先来先服务）算法 SJF（Shortest Job First，最短作业优先）算法 RR（Round Robin，轮转）算法，其中队列长度为 10 接下来，我们需要比较这三种算法的平均等待时间。 进程的 burst time（执行时间）如下： P1:10 P2:29 P3:3 P4:7 P5:12 计算每种算法的平均等待时间： FCFS：((0+10+39+42+49)/5)=28 SJF：((10+32+0+3+20)/5)=13 RR：((0+32+20+23+40)/5)=23 通过这个例子，我们可以看到不同调度算法在同一工作负载下的性能表现。在这个案例中，FCFS、SJF 和 RR 算法的平均等待时间分别为 28、13 和 23。 Queuing models 排队模型（Queuing models）是一种用于描述系统中进程等待服务的模型。在这个模型中，关键的概念是进程到达时间分布、服务时间分布以及进程队列的类型。 排队模型的主要目的是分析系统在给定资源限制下的性能表现，例如计算平均等待时间、响应时间等指标。在排队模型中，通常会考虑以下几个方面： 进程到达时间分布：这是指进程在系统中的到达时间是如何分布的。常见的到达时间分布有泊松分布、均匀分布等。 服务时间分布：这是指进程在获得 CPU 资源后执行的时间分布。常见的服务时间分布有指数分布、均匀分布等。 进程队列类型：根据系统中的进程队列类型，排队模型可以分为单队列模型和多队列模型。在单队列模型中，所有进程按照到达顺序排队等待服务；而在多队列模型中，进程会被分为多个队列，每个队列有自己的服务规则。 通过对这些参数进行建模，可以分析不同调度算法在特定系统负载下的性能表现。排队模型有助于我们了解系统在不同条件下的响应时间、吞吐量等性能指标，从而为系统优化提供依据。\nSimulations 模拟（Simulations）在评估 CPU 调度算法性能中的应用。模拟是指通过编写计算机系统的模型来进行实验，以评估不同调度算法的性能。 在模拟过程中，主要涉及以下几个方面：\n编程模型：模拟过程中需要编写计算机系统的软件数据结构，这是系统的主要组成部分。 变量：模拟中使用的一个关键变量是时钟（clock），它可以表示时间的推移。 性能统计：在模拟执行过程中，会收集和打印表明算法性能的统计数据。 数据生成：模拟所需的数据可以通过随机数生成器（random-number generator）来生成。 分布定义：模拟中的数据分布可以通过数学方式或经验方式（empirically）定义。 分布驱动模拟：但由于实际系统中连续事件之间的关系，分布驱动的模拟可能存在一定的不准确性。 这段内容主要介绍了模拟仿真在评估 CPU 调度算法性能时的优势。它与队列模型相比，具有更高的准确性。 simulations，即模拟仿真，是一种通过程序构建计算机系统模型的方式，用于评估不同调度算法的性能。在模拟过程中，钟（clock）被作为一个变量，用以表示时间的推移。通过模拟，可以收集表明算法性能的统计数据。 与之相比，队列模型（queueing models）的限制在于它们是基于固定的概率分布和系统参数进行建模的，而这些参数可能在实际运行过程中发生变化。模拟仿真则更灵活，可以生成不同分布的数据来驱动仿真，从而更准确地反映实际情况。 模拟仿真的数据可以通过以下方式收集：\n随机数生成器（random number generator）：根据设定的概率生成不同的事件序列。 数学或经验定义的分布（distributions defined mathematically or empirically）：根据实际情况设定进程到达、执行时间和完成时间的分布。 轨迹带（trace tapes）：记录实际系统中真实事件的序列。 通过这些数据，可以对不同的调度算法进行性能评估。从而为 CPU 调度算法的选择和优化提供依据。 Implementation Implementation 部分指的是将实际的调度算法在现实系统中进行评估。这个过程需要在现实操作系统的环境下运行，以便更好地了解算法的性能和适用性。 在实施过程中，主要面临以下困难： 成本问题：实施算法不仅需要编写算法代码和修改操作系统以支持它，以及其所需的数据结构，还需要考虑用户对不断变化的操作系统的反应。这可能导致额外的成本支出。 环境变化：环境变化不仅来自于新程序的编写和问题类型的变化，而且还可能是调度器性能的结果。这使得调度算法在现实系统中的实施变得更加困难，因为需要不断地调整和优化算法以适应不断变化的环境。\n","date":"2023-10-21T21:12:53Z","permalink":"http://localhost:1313/post/3-cpu-scheduling/","title":"3 CPU Scheduling"},{"content":"2 Processes And Threads Process Concept 进程是执行中的程序。 程序是存储在磁盘上的可执行文件。 当可执行文件加载到内存中时，程序成为进程。\n一个进程包括：\n程序代码，称为文本部分。 数据部分，包含全局变量。 进程控制块（PCB） 进程映像=代码段+数据段+PCB，进程映像是静态的，进程是动态的； 进程是进程映像/进程实体的运行过程，是系统进行资源分配和调度的一个独立单位； 进程控制块PCB是存放进程的管理和控制信息的数据结构，进程控制块PCB是进程存在的唯一标志（类似于身份证）； 所谓创建进程实质上就是创建进程映像中的PCB，撤销进程实质上是撤销进程的PCB；\n进程的执行必须按顺序进行。进程就是一个程序的运行时，包含了一些权限控制。 进程之间不共享数据，每个进程有自己独立的地址空间，一个进程至少包含一个或多个线程；\n一个进程本身可以是其他代码的执行环境，例如JVM 可执行的Java程序在Java虚拟机（JVM）中执行。 JVM作为一个进程执行： 解释加载的Java代码 代表该代码采取行动（通过本机机器指令）。 例如，java程序：命令java将JVM作为普通进程运行。JVM执行Java程序。 Process State 随着进程的执行，它会改变状态。一个进程可能处于以下状态之一：\nnew：进程正在被创建。 running：正在执行指令。 waiting：进程正在等待某个事件发生。 ready：进程等待被分配到处理器。 terminated：进程已经执行完成。 在任何给定时间，每个处理器上只能运行一个进程，但有许多进程可能处于就绪和等待状态。\nProcess Control Block(PCB) 每个进程都由一个 PCB（进程控制块）表示，也被称为进程控制块。PCB是进程存在的唯一标志！ PCB 包含与每个进程相关的信息：\n进程状态 程序计数器 CPU 寄存器 CPU 调度信息 - 优先级、调度队列指针 内存管理信息 账户信息 - 使用的 CPU 时间量，自启动以来经过的时钟时间，时间限制，帐户号码等 I/O 状态信息 - 分配给进程的 I/O 设备列表，打开文件列表等 进程号 - 标识符，例如：该进程的标识符，其父进程的标识符，用户标识符等。 PID是操作系统中的进程标识符，操作系统中每打开一个程序都会创建一个进程ID也就是PID，在运行时每个进程有唯一的PID编号，进程终止后PID标识符会被系统回收利用； CPU Switch From Process to Process 进程的地址空间 地址空间分为物理地址空间(内存、磁盘)和虚拟地址空间；\n因为操作系统的缘故，对一个进程/程序来说似乎独占所有硬件资源，一般一个进程会分为如下几个段，其中堆向上生长，栈向下生长（注意这里的地址空间是虚拟地址空间，之后也会讲，分段常用于用户视图）\nProcess Feature 进程的基本特征是对比单个程序的顺序执行提出的，也是对进程管理提出的基本要求：\n动态性：进程具有一定的生命周期，是动态产生、变化和消亡； 并发性：指多个进程实体同时存于内存中，能在一段时间内同时运行； 独立性：指进程实体是一个能够独立运行、独立获得资源和独立接受调度的基本单位； 异步性：进程按照各自独立的、不可预知的速度向前推进，为了避免异步，在操作系统中必须配置相应的进程同步机制； 结构性：结构上看，进程实体是由程序段、数据段以及进程控制块三部分组成；\nWhen to Switch a Process 时钟中断（Clock interrupt）: 进程已经执行了最大允许的时间片。\nI/O 中断（I/O interrupt）: 处理内存错误时，可能需要将虚拟内存中的数据载入主内存。\n陷阱（Trap）: 当发生错误时，可能会导致进程进入终止/退出状态。\n系统调用（System call）: 例如，文件打开等操作。\nProcess Scheduling 多道程序设计的目标是最大化CPU利用率。通过在多个进程之间频繁切换CPU，使用户感觉好像它们都在同时运行。分时共享的目标则是让用户在程序运行时与之互动。\n进程调度程序负责选择一个可用的进程在CPU上执行。在单处理器系统上，由于硬件资源的限制，最多只能运行一个进程。其余的进程将不得不等待，直到CPU空闲并可以重新调度它们。\n通过合理的进程调度和时间分配，多道程序设计和分时共享可以有效地提高系统的整体性能和用户满意度。\nCPU管理的最终结构概括为操作系统启动多个进程，并能够在多个进程之间调度/切换，从而实现CPU高效管理；\n（1）在操作系统中现在有三个进程，其PID分别是1、2、3；\n（2）现在正在执行的是2号进程；\n（3）进程1执行到53地址处停了下来，进程3执行到250地址处停了下来，进程1停下来的原因是进程1用完了时间片，进程3停下来的原因是进程3要等到磁盘读写完成；\n（4）进程1和进程3停下来的执行现场分别存放在各自的PCB中；\n（5）操作系统通过这些PCB可以感知、了解并控制各个进程，操作系统对进程的管理关键在于对这些PCB的管理；\n多进程视图是操作系统的核心视图.操作系统在从开机启动到最后关机的全部运行过程中都要围绕这个多进程视图工作；\n一个进程执行完毕以后可以调用exit（）来退出自己，但shell不会调用exit（）退出自己，除非关机。因此shell进程会一直执行，不断创建新的进程，并用这些新进程完成各种各样的任务。在操作系统最终关机时，会将系统中所有进程杀死；\n编写操作系统中的进程管理模块，需要做到以下两点：\n从上层用户角度想象系统中的多个进程，要在头脑里形成这样的画面，操作系统里有多个进程，每个进程各司其职，要做新的工作就会在系统中创建出的新进程等； 从下层系统内核角度感知和控制系统中的多个进程； Scheduling Queues 作业队列 - 系统中的所有进程集合。\n就绪队列 - 驻留在主存储器中、准备好等待执行的所有进程的集合。\n通常存储为链表。\n头部包含指向列表中第一个和最后一个PCB的指针。\n设备队列 - 等待I/O设备的进程列表。每个设备都有自己的设备队列。\nRepresentation of Process Scheduling Schedulers Long-term scheduler (or job scheduler)选择哪些进程应该被带入就绪队列。 Short-term scheduler (or CPU scheduler)选择下一个应该执行哪个进程并分配CPU。\n主要区别：执行频率。\n短期调度器被调用频率非常高（毫秒）（调度器必须快）。 长期调度器被调用频率非常低（调度器可能很慢）（秒，分钟）（调度器必须快）。 长期调度器控制多道程序的程度，即在内存中的进程数。\n进程可以分为以下两种：\nI/O密集型进程（I/O-bound process）：花费大量时间进行I/O操作而不是计算，存在许多短暂的CPU突发。 计算密集型进程（CPU-bound process）：花费大量时间进行计算；很少有非常长的CPU突发。选择好的进程组合。 如果所有进程都是I/O密集型的，准备队列将几乎总是空的，CPU调度程序几乎没有工作要做。如果所有进程都是计算密集型的，I/O等待队列将几乎总是空的，设备将无法使用。\n短期调度（Short-term Scheduling）\n目的：短期调度，也称为CPU调度，主要负责决定哪个就绪进程应该被分配CPU时间。 频率：这种类型的调度发生得非常频繁，通常以毫秒级别计算。 调度对象：它关注的是处于就绪队列中的进程或线程。 特点： 快速和频繁：因为必须频繁地做出决策，所以短期调度算法需要非常快速和高效。 决定进程执行顺序：它负责选择下一个将使用CPU的进程。 中期调度（Medium-term Scheduling）\n目的：中期调度主要负责调整系统的多道程序程度，通过实施进程的挂起和唤醒来控制系统的负载。 频率：这种调度发生的频率低于短期调度，但比长期调度更频繁。 调度对象：它主要处理已经开始执行但暂时被挂起的进程。 特点： 内存管理：中期调度常常与内存管理相关联，如页面置换算法。 减少负载：通过将进程移出或移入就绪队列来减少系统负载。 长期调度（Long-term Scheduling）\n目的：长期调度，也称为作业调度，负责决定哪些进程应从作业池中移入就绪队列。 频率：这种调度发生得较不频繁，通常以秒或更长的时间间隔计算。 调度对象：它涉及决定哪些新进程被引入内存的就绪队列。 特点： 影响系统的多道程序程度：长期调度决定了系统中同时运行的进程数。 性能和资源利用率：它影响整体系统性能和资源的利用率。 Medium-Term Scheduling 该进程被中程调度程序交换出去，存储在磁盘上，稍后又被交换进来。\nMedium-Term Scheduling（中期调度）的主要作用是避免某些进程长时间等待。当一个进程在等待I/O操作完成时，它会被移至I/O等待队列。如果进程在等待过程中被换出（swapped out），则它将被存储在磁盘上，并在稍后被换入（swapped in）由中期调度器进行操作。这样，当CPU执行速度超过I/O操作速度时，所有进程都可以等待I/O操作完成，从而释放更多的内存空间。在等待期间，进程的状态变为“交换等待”（swapped waiting）。\nSwapped/Suspended Processes 处理器的速度通常比I/O设备快，因此在某些情况下，所有的进程都可能在等待I/O操作。为了释放更多内存，这些进程会被交换到磁盘上。\n等待状态被转换为“swapped waiting”，表示进程已被交换到磁盘上。在这个过程中，还引入了两种新的状态：\n\u0026ldquo;swapped waiting\u0026rdquo;（挂起等待/阻塞）：表示进程已被交换到磁盘，正在等待某些事件的发生。 \u0026ldquo;swapped ready\u0026rdquo;（挂起就绪）：表示进程已准备好执行，但仍然位于磁盘上，等待被交换回内存执行。 Reasons for Process swapped out 进程被换出的原因有多种，包括：\n在多道程序环境下，系统会根据优先级、CPU时间片、内存使用情况等因素来调度进程，如果一个进程在等待I/O操作（例如磁盘读写），或者它的优先级低于其他进程，那么它可能会被暂时换出，以便其他进程可以继续执行。 当CPU切换到另一个进程时，系统需要保存旧进程的状态并加载新进程的保存状态，这个过程被称为上下文切换。如果系统频繁地进行上下文切换，那么每个进程可能会被短暂地暂停并被换出，以便其他进程可以执行。 在内存不足时，系统会将一些进程暂时换出到磁盘上，以便为其他进程腾出空间。 在某些情况下，父进程可能会希望暂停其子进程的执行，以检查或修改被暂停的进程，或者协调多个进程的活动。这可以通过将子进程换出到磁盘来实现。 操作系统需要释放足够的内存来引入其他进程，如果当前没有足够的内存，那么一些进程可能会被暂停并被换出到磁盘上。 进程可能由于其他原因被换出，例如它已经完成了它的任务或者出现了错误。 Context Switch 当CPU切换到另一个进程时，需要进行上下文切换（Context Switch）。这是指系统必须保存当前进程的状态，并加载下一个进程的保存状态。这个过程包括保存处理器状态，包括程序计数器和其它寄存器，更新PCB以及内存管理数据结构，并恢复选定进程的上下文。这个过程是纯开销，系统在切换过程中并不执行任何有用的工作。上下文切换的时间取决于很多因素，包括系统的设计和进程的性质。在多任务处理中，上下文切换是很重要的，它使得各个进程可以共享CPU资源，并且可以有效地管理系统的运行。\n上下文在进程的 PCB 中表示。\n当 CPU 切换到另一个进程时，系统必须保存旧进程的状态并加载新进程的已保存状态。这被称为上下文切换。\n上下文切换包括以下步骤：\n保存处理器的上下文，包括程序计数器和其他寄存器。 更新当前正在运行的进程的 PCB。 将 PCB 移动到适当的队列 - 就绪队列或等待队列。 选择另一个进程执行（调度）。 更新所选进程的 PCB。 更新内存管理数据结构。 恢复所选进程的上下文。 上下文切换时间是纯粹的开销，系统在切换期间不执行有用的工作。上下文切换时间取决于硬件支持。\n多进程视图工作的核心是多个进程之间的来回切换，这也是并发的基本含义，操作系统实现多进程视图需要解决如下两点：\n什么时候切换； 具体如何切换； 切换的时机就是当CPU出现空闲的时候，这种空闲点也被称为调度点，调度点可以是当前进程在执行过程中产生的如exit()，也可以是操作系统强行加入的如进程分配的时间片耗尽；\n//一个调度点的实例代码 某个进程{ 启动磁盘写； pCur.state=\u0026lsquo;W\u0026rsquo;;//将进程状态修改为阻塞态 将pCur放在DiskWaitQueue;//pCur就是用于保存 “CPU中当前进程执行现场” 的PCB结构，当然它就是当前进程的PCB，便于将来能够切换回当前进程 schedule();//调用schedule函数完成进程切换 }\n操作系统调用函数schedule()实现切换，其实现原理如下：\n从就绪队列中选出下一个进程的PCB，我们称为pNew； 用PCB结构pNew中存放的执行现场去替换CPU中的PC、AX等寄存器； 为了能够切换回当前进程，切换之前还应将CPU中的“当前进程执行现场”保存在当前进程的PCB结构中，该PCB结构我们称为pCur； 这其中如何选择pNew需要精心设计算法，如果只是简单的选择就绪队列首部的进程作为下一个进程，这样公平但是对于某些应当需要优先执行的进程来说非常致命；\n简单给出schedule函数的基本代码结构\nschedule(){ pNew=getNext(ReadyQueue); switch_to(pCur,pNew); } switch_to(pCur,pNew){ //保存当前进程的PCB结构 pCur.ax=CPU.ax; pCur.bx=CPU.bx; \u0026hellip; //用pNew中的执行现场替换CPU中的寄存器 CPU.ax=pNew.ax; CPU.bx=pNew.bx; }\n进程的组织 要论述操作系统是如何实现多进程视图（前面已经给出过图示）的，第一步要解决的问题就是在计算机中如何组织多个进程；\n操作系统管理进程的关键就是管理进程对应的PCB数据结构，所以很容易就能想到，组织多个进程就是用合适的数据结构来管理这些PCB；\nPCB之间存在简单的线性关系，简单而高效的方式就是将这些PCB组织成队列，并且在管理进程时需要区分进程位于哪个队列，根据进程状态概念可以分类描述操作系统中的进程：\n运行态：当前占有CPU、正在执行的进程状态； 就绪态：一个进程具备所有可执行的条件，只要获得了CPU就能开始执行； 阻塞态：也称为睡眠态或等待态，指进程缺少某些条件（比如磁盘正在读写、打印机忙等），即使分配了CPU也无法执行的状态； 基于单CPU的背景，因此只有一个CPU意味着只会有一个处于运行态的进程，多个阻塞队列（多种等待事件），一个就绪队列（都在等待CPU），故形成下图所示多进程基本组织方式\n上图类似于一张合照，是某一时刻下多个进程在操作系统中的样子，当然利用进程状态还可以描述一个进程在其执行过程中的演化过程（该过程常被称为进程的生存周期）\n进程隔离 尽管多个进程同时在内存中交替执行可以提高CPU的使用效率，但是同时在内存中的多个进程也会相互影响（比如某个进程把另一个进程的内存地址给修改了）；\n解决上述问题的办法就是使用地址隔离\n进程操作的地址并不是真的物理内存地址，而是通过一个映射表对应到一个真实的物理地址，这也是需要用GDT表和页表来翻译CS:EIP的根本原因；\n操作系统给每个进程分配的真实的内存区域是只属于该进程的、互相不重叠的，就算进程1和进程2同时访问的地址是100，但是通过映射表后访问的真实地址其实是2100和1100；\nOperations on Processes Process Creation 允许一个进程创建另一个进程，此时创建者称为父进程，被创建的进程称为子进程： 子进程可以继承父进程所拥有的资源； 子进程被撤销的时候需要将从父进程那里获得的资源归还给父进程； 撤销父进程必须同时撤销其所有的子进程；\n创建一个新进程的过程：\n为新进程分配唯一的PID并申请一个空白的PCB，若PCB申请失败则创建失败； 为新进程的程序和数据以及用户栈分配必要的内存空间，若资源不足不会导致创建失败，而是处于阻塞态等待内存资源； 初始化PCB，主要包括初始化标志信息、初始化处理机状态信息以及初始化处理机控制信息、进程优先级等； 若就绪队列能够接纳新进程则将新进程插入就绪队列等待被调度运行； 进程创建的原因\n提交批处理作业 用户登录 创建以提供打印等服务的目的 进程创建另一个进程 创建进程涉及以下步骤：\n为进程分配一个唯一的进程标识符，通常是一个整数。 为进程分配内存空间。 初始化进程控制块（PCB）。 建立适当的链接，例如将新进程添加到用于调度队列的链接列表中。 创建或扩展其他数据结构，以维护相关信息，例如维护一个账户文件。 处理资源共享，这涉及确定新进程与其父进程之间共享的资源，可以有不同的模式，如父进程和子进程共享所有资源、子进程共享父进程的一部分资源、或父进程和子进程之间不共享任何资源。 当创建一个进程时，通常会传递初始化数据，这些数据可能从父进程传递给子进程，以便子进程能够正确初始化。 在进程创建方面，有一些执行和地址空间的选择：\n执行方面，有两种可能性： 父进程和子进程并发执行。 父进程等待，直到其一些或全部子进程终止。 地址空间方面，有两种可能性： 子进程是父进程的副本，它们共享相同的地址空间。 子进程有一个程序加载到它自己的地址空间中，独立于父进程。 在UNIX系统中，每个进程都由其进程标识符（PID）唯一标识，可以通过系统调用fork创建新进程。在创建子进程后，可以使用exec系统调用将子进程的内存空间替换为新程序，实现程序的更改。这些机制允许UNIX系统创建和管理进程，支持各种并发和应用程序切换操作。\nProcess Termination 引起进程终止的事件有：\n正常结束：表示进程的任务完成并准备退出运行； 异常结束：进程运行过程中发生异常导致程序无法继续运行； 外界干预：进程因为外界的请求而终止运行； 撤销原语如下：\n1.根据被终止进程的标识符检索PCB，从中读出该进程的状态； 2.若被终止的进程处于执行状态则立即终止该进程的执行，将处理机的资源分配给其他进程； 3.若该进程有子孙进程则将其所有子孙进程终止； 4.将该进程拥有的全部资源归还给其父进程或操作系统； 5.将该PCB从所在队列删除；\n进程终止的原因可以有很多，包括但不限于：\n正常完成：进程成功完成其任务。 超出时间限制：进程运行时间超过了设定的最大限制。 内存不足：进程需要的内存资源不可用。 边界违规：进程试图访问超出其分配边界的内存。 保护错误：例如，尝试向只读文件写入。 算术错误：进程执行的数学运算导致错误。 时间超出：进程等待某个事件的时间超过了指定的最大等待时间。 I/O 失败：例如，尝试打开一个不存在的文件。 无效指令：当尝试执行非法或无效的指令时发生。 特权指令：尝试执行只有特权进程才能执行的指令。 数据滥用：例如，类型错误。 操作系统干预：当操作系统介入处理进程问题，如解决死锁时。 父进程终止：子进程会在其父进程终止时终止。 这些是可能导致进程终止的各种情况，操作系统会根据不同的终止原因采取适当的处理措施。\n进程终止可以由多种方式触发：\n进程执行完最后一条语句，然后请求操作系统删除它（通过 exit）。\n进程将数据输出给父进程，然后等待父进程的确认（通过 wait）。\n操作系统会释放进程占用的资源，包括内存和其他系统资源。\n此外，父进程也可以由多种原因来终止其子进程的执行，例如：\n子进程占用的资源超出了分配的限额。 子进程执行的任务不再需要。 父进程本身终止。 需要注意的是，如果一个父进程终止，操作系统通常不允许其子进程继续运行，这可以防止子进程在没有父进程的情况下执行。因此，通常由操作系统来处理子进程的终止。\n进程的阻塞和唤醒 进程的阻塞是进程自身的一种主动行为，只有处于运行状态的进程才可能转换为阻塞态，阻塞原语的执行过程如下：\n1.找到将要被阻塞进程的PID对应的PCB； 2.若该进程为运行态则保护其现场并将其状态转换为阻塞态； 3.把该PCB插入相应事件的等待队列，将处理机资源调度给其他就绪进程；\n当被阻塞进程需要的资源到达，由相关进程调用唤醒原语，将等待该事件的进程唤醒，唤醒原语如下：\n1.在该事件的等待队列中找到相应进程的PCB； 2.将其从等待队列中移出，并置其状态为就绪态； 3.把该PCB插入就绪队列，等待调度程序调度；\n注意：Block 原语和Wakeup 原语是一对作用刚好相反的原语，必须成对使用。Block原语是由被阻塞进程自我调用实现的，而Wakeup原语则是由一个与被唤醒进程合作或被其他相关的进程调用实现的；\nInterprocess Communication 独立进程（Independent process）不能影响或被另一个进程的执行所影响。\n协作进程（Cooperating process）可以影响或被另一个进程的执行所影响。进程协作的优点包括：\n信息共享：允许进程之间共享数据和信息，从而实现协同工作。 计算加速：多个进程协同工作可以加速计算和任务的完成。 模块化：将系统划分为多个协作的模块或进程，使系统更易于管理和维护。 方便性：允许不同的进程协同执行各自的任务，从而提高系统的灵活性和效率。 进程协作通常可以使用两种基本模型来实现：\n共享内存（Shared-memory）：多个进程可以访问相同的内存空间，从中读取和写入数据，以实现协同工作。允许进程之间以最大的速度和便利进行通信。 消息传递（Message passing）：进程之间通过发送和接收消息来进行通信，以协同执行任务。这种方式更加分离，进程之间互相独立。 数据交换的方式：消息传递适用于需要交换较少数据的情况，因为它不需要考虑数据冲突。每个进程可以将消息发送给其他进程，实现数据交换。 跨计算机通信：消息传递更容易在不同计算机之间实现，因为它允许进程在不同计算机上发送和接收消息，适用于分布式系统和网络通信。 Shared-memory systems 在通信的进程之间存在一块可直接访问的共享空间，通过对这片共享空间进行写/读操作实现进程之间的信息交换。 在对共享空间进行写/读操作时，需要使用同步互斥工具（如P操作、V操作），对共享空间的写/读进行控制。 共享存储又分为两种： 低级方式的共享是基于数据结构的共享； 高级方式的共享则是基于存储区的共享。 操作系统只负责为通信进程提供可共享使用的存储空间和同步互斥工具，而数据交换则由用户自己安排读/写指令完成。 注意，进程空间一般都是独立的，进程运行期间一般不能访问其他进程的空间，想让两个进程共享空间，必须通过特殊的系统调用实现，而进程内的线程是自然共享进程空间的。 Message-passing systems 在消息传递系统中，进程间的数据交换以格式化的消息（Message） 为单位。若通信的进程之间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信。 进程通过系统提供的发送消息和接收消息两个原语进行数据交换。这种方式隐藏了通信实现细节，使通信过程对用户透明，简化了通信程序的设计，是当前应用最广泛的进程间通信机制。 在微内核操作系统中，微内核与服务器之间的通信就采用了消息传递机制。由于该机制能很好地支持多处理机系统、分布式系统和计算机网络，因此也成为这些领域最主要的通信工具。\n消息传递的基本结构:\n发送消息：send(message) 接收消息：receive(message) 当进程P和Q需要通信时，它们需要：\n建立一个用于连接它们的通信链路。 使用send和receive操作来交换消息。 通信链路的实现包括逻辑方面和物理方面：\n逻辑方面：涉及逻辑属性，例如通信链路的属性。 物理方面：可能涉及共享内存或硬件互连等物理元素。 1）直接通信方式。发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息。\n直接通信中的命名问题包括以下内容：\n进程必须显式地为对方命名： send(P, message)：向进程P发送消息。 receive(Q, message)：从进程Q接收消息。 通信链路的属性： 通信链路是自动建立的。 一个通信链路与恰好一个进程对相关联。 每对通信进程之间存在恰好一个通信链路。 通信链路可以是单向的，但通常是双向的。 寻址的不对称性：receive(id, message)会导致定义的进程模块的可重用性受限。 2)间接通信方式。发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息。 这种中间实体一般称为信箱（也称为端口）。该通信方式广泛应用于计算机网络中。\n特点： 每个邮箱都有唯一的标识符（id）。 进程只有在共享同一个邮箱的情况下才能进行通信。 通信的原语包括： send(A, message)：将消息发送到邮箱A。 receive(A, message)：从邮箱A接收消息。 通信链路的属性包括： 链路只有在进程共享一个邮箱时才会建立。 一个链路可以与多个进程相关联。 每对进程可以共享多个通信链路。 链路可以是单向的或双向的。 多进程共享邮箱的通信难题： 当多个进程共享一个邮箱，例如进程P1、P2和P3共享邮箱A时，如果P1使用send(A, message)发送消息到邮箱A，实际的接收者成为了一个问题。 为此，存在几种可能的解决方案： 允许一个链路与多个进程相关联：例如，消息可以被发送到与此链路相关联的任一进程。 限制同时接收的进程：只允许一个进程执行receive()操作，确保只有特定进程接收到消息。 系统随机选择接收者：系统选择一个接收者，但会通知发送者哪个进程接收了消息。这种方式需要进一步同步和协调，但为发送者和接收者提供了关于消息交付状态的明确信息。 邮箱的所有权： 邮箱可以由特定的进程拥有，或者由操作系统独立地拥有。 进程拥有的邮箱：此邮箱的所有者是唯一可以通过它接收消息的进程。而其他进程可以发送消息到这个邮箱。 操作系统拥有的邮箱：此类邮箱是独立的，不属于任何特定进程。进程可以通过操作系统提供的机制对邮箱执行一系列操作，如创建、发送/接收消息以及删除。 消息传递的同步性： 消息传递可能是同步的（阻塞）或异步的（非阻塞）。 阻塞消息传递： 发送方阻塞：直到消息被接收。 接收方阻塞：直到消息可用。 非阻塞消息传递： 发送方：发送消息后继续执行其他操作。 接收方：无论消息是否可用，都会立即检索。 消息队列缓冲： 消息队列是与通信链路相关的，并有三种可能的缓冲方式： 零容量：没有消息缓存。发送方必须等待接收方准备好会合。 有界容量：队列具有固定的大小，例如n条消息。当队列满时，发送方必须等待。 无界容量：队列大小是无限的，所以发送方无需等待，可以随时发送消息。 Producer-Consumer Problem 协作进程中的常见范例是生产者-消费者问题，其中一个生产者进程生成信息，而一个消费者进程获取并使用该信息。\nShared-memory 定义：使用一个共同的内存区域或缓冲区，该区域可以由生产者写入数据，并由消费者读取和消费数据。\n主要有两种类型的缓冲区：\n无界缓冲区（unbounded-buffer）：不对缓冲区的大小设定实际限制，可以不断地存储项目。 有界缓冲区（bounded-buffer）：假定缓冲区有一个固定的大小，即缓冲区中可以存储的项目数量有限。 不论使用哪种缓冲区类型，生产者和消费者之间需要进行同步。这确保生产者不会在缓冲区已满时添加数据，也确保消费者不会从空的缓冲区中读取数据。\n关于同步：在多进程环境中，由于调度和执行顺序是不确定的，可能会导致数据不一致或其他错误。因此，引入了临界区的概念，确保在给定时间内只有一个进程可以访问共享资源或数据。\nPipe 管道是一种在进程间进行通信的方法。它允许一个进程的输出成为另一个进程的输入。\n定义：管道是一个通信机制，允许一个进程向管道的一端写入数据，而另一个进程从另一端读取数据。 特性： 数据在管道中是先进先出的。 如果管道为空，读进程会被阻塞，直到有数据可读。 如果管道已满，写进程会被阻塞，直到有空间可写。 管道在Linux中通常有一个固定的大小（例如，4KB）。当管道满时，写操作会被阻塞。当管道空时，读操作会被阻塞。 管道可以用于父子进程间的通信。一个进程可以创建一个管道，并将其传递给其子进程。 通常，管道只支持单向通信。要进行双向通信，可能需要两个管道。 注意：从管道读取的数据是一次性的。一旦数据被读取，它就从管道中删除了。\nExample of IPC Systems POSIX shared memory\nMessage passing in the Mach operating system\nWindows\nCommunication in Client-Server Systems Sockets 套接字（Socket）\n套接字是用于通信的端点。\n它是 IP 地址与端口号的组合。例如，套接字 161.25.19.8:1625 指的是主机 161.25.19.8 上的端口 1625。\n通信是在一对套接字之间进行的。\n所有低于 1024 的端口都被认为是众所周知的，可以用来实现标准服务。\n例如，FTP 服务器监听端口 21，telnet 服务器监听端口 23，Web 或 HTTP 服务器监听端口 80。\n当客户端进程发起连接请求时，它会由其主机计算机分配一个端口（大于 1024）。\nSocket通信是一种常见且高效的分布式进程通信方式。它是一种低级通信形式，允许在分布式进程之间交换未经结构化的字节流。在Socket通信中，所有的连接必须是唯一的。\nRemote Procedure Calls (RPC) 远程过程调用（RPC）是一种抽象的过程调用方法，用于在网络系统上的进程之间进行通信。通过RPC，交换的消息是结构良好的。\n每个消息都是发送到远程系统上某个端口的RPC守护进程。每个消息包含要执行的函数标识符和要传递给该函数的参数。然后按照请求执行该函数，并将任何输出以单独的消息发送回请求者。\n端口是消息数据包的起始处的一个数字。系统拥有一个网络地址，但可以在该地址内有多个不同的端口，以区分支持的多个网络服务。如果远程进程需要某项服务，它会将消息地址定向到适当的端口。RPC的语义允许客户端以与本地调用过程相同的方式调用远程主机上的过程。\n为此，客户端提供了一个存根（stub），作为服务器上实际过程的客户端代理。客户端存根用于定位服务器上的端口，对参数进行编组，并向服务器发送消息。服务器端存根接收此消息，解包编组的参数，并在服务器上执行过程。返回值使用相同的技术传递回客户端。\n数据的表示在不同机器上可能是不同的，因此需要一种机器无关的数据表示方式，如外部数据表示（XDR）。客户端将机器相关数据转换为XDR，服务器将XDR数据解组并转换为机器相关表示。\n调用的语义为“仅一次”——将时间戳附加到每条消息，服务器必须保留其已经处理的消息的所有时间戳历史记录，以确保不会处理重复消息。还有“正好一次”——服务器向客户端发送确认消息，确保消息的唯一性。\n绑定信息可以预先确定，即使用固定端口地址，也可以通过约会机制进行动态绑定，根据需要绑定端口。\nRemote Method Invocation (RMI, Java) RMI（远程方法调用）是类似于RPC的Java机制，允许一个机器上的Java程序调用远程对象的方法。\nRMI使用存根（stubs）和骨架（skeletons）来实现远程对象，因此对于客户端和服务器来说，远程方法是透明的。存根是远程对象的代理，位于客户端。骨架负责解组参数并在服务器上调用所需的方法。\nRMI有关参数传递行为的规则如下：\n如果已经编组的参数是本地对象，它们将使用对象序列化技术进行复制传递。 如果参数也是远程对象，它们将通过引用传递。 如果要将本地对象作为参数传递给远程对象，它们必须实现java.io.Serializable接口。 Threads Threads 线程，也称为轻量级进程（LWP），是CPU利用的基本单位。\n包括线程ID、程序计数器、寄存器集合和堆栈。 与属于同一进程的其他线程共享其代码段、数据段和其他操作系统资源，如打开的文件和信号。 引入进程之后，进程是资源（除CPU外的系统资源）分配的单位，内核级线程是处理器调度和分配的单位。 线程本身不具有资源，它可以共享所属进程的全部资源 一个线程可以创建和撤销另一个线程，同一进程中的多个线程之间可以并发执行。 线程与进程的比较：\n调度 在同一进程中，线程的切换不会引起进程切换。但从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。 资源 线程不拥有系统资源（仅有一点必不可少、能保证独立运行的资源），但线程可以访问其隶属进程的系统资源 独立性 每个进程都拥有独立的地址空间和资源，除了共享全局变量，不允许其他进程访问。某进程中的线程对其他进程不可见。同一进程中的不同线程是为了提高并发性及进行相互之间的合作而创建的，它们共享进程的地址空间和资源。 系统开销 由于一个进程内部有多个线程，若线程的切换发生在同一个进程内部，则只需要很少的时空开销。 由于同一进程内的多个线程共享进程的地址空间，因此这些线程之间的同步与通信非常容易实现。 支持多处理机系统 可以将进程中的多个线程分配到多个处理机上执行。 线程的属性\n每个线程都应有一个唯一的标识符和一个线程控制块，线程控制块记录了线程执行的寄存器和栈等现场状态。 不同的线程可以执行相同的程序，即同一个服务程序被不同的用户调用时，操作系统把它们创建成不同的线程。 Thread States 线程的三种基本状态：Running, ready, waiting\n与线程状态变化相关的操作包括：\nSpawn：创建另一个线程 Block、Unblock：阻塞或解除阻塞线程 Finish：释放寄存器上下文和堆栈资源 Multicore Programming 多核编程是一种允许系统同时执行多个任务的编程方法。并行性意味着系统能够同时执行多个任务，而并发性则支持多个任务同时取得进展。在单处理器/核心系统中，调度程序提供并发性。CPU设计者通过添加硬件来提高线程性能，以提高系统性能。\nMultithreading Models 用户级线程，在内核之上支持，无需内核支持而由用户程序管理。 所有线程管理由应用程序完成。内核不知道线程的存在。用户线程是在内核之上支持的，由用户级别的线程库实现。该库提供线程的创建、调度和管理支持，无需内核的支持。 在用户级线程中，有关线程管理(创建、撤销和切换等)的所有工作都由应用程序在用户空间中完成，内核意识不到线程的存在。应用程序可以通过使用线程库设计成多线程程序。通常，应用程序从单线程开始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生例程创建一个在相同进程中运行的新线程。 三种主要的线程库： POSIX Pthreads Win32 线程 Java 线程 内核线程，由操作系统直接支持和管理。 最终，用户线程和内核线程之间必须存在关系。 受操作系统直接支持。内核在内核空间中执行线程的创建、调度和管理。内核维护进程和线程的上下文信息。 在操作系统中，无论是系统进程还是用户进程，都是在操作系统内核的支持下运行的，与内核紧密相关。内核级线程同样也是在内核的支持下运行的，线程管理的所有工作也是在内核空间内实现的。内核空间也为每个内核级线程设置一个线程控制块，内核根据该控制块感知某线程的存在，并对其加以控制。图2.5(b)说明了内核级线程的实现方式。 这种实现方式的优点如下：①能发挥多处理机的优势，内核能同时调度同一进程中的多个线程并行执行。②如果进程中的一个线程被阻塞，内核可以调度该进程中的其他线程占用处理机，也可运行其他进程中的线程。③内核支持线程具有很小的数据结构和堆栈，线程切换比较快、开销小。④内核本身也可采用多线程技术，可以提高系统的执行速度和效率。 这种实现方式的缺点如下：同一进程中的线程切换，需要从用户态转到核心态进行，系统开销较大。这是因为用户进程的线程在用户态运行，而线程调度和管理是在内核实现的。 调度是以线程为基础进行的。支持内核线程的系统示例包括Windows XP/2000、Solaris、Linux、Tru64 UNIX和Mac OS X。 有三种常见的线程实现类型： 多对一（Many-to-One） 在单个内核线程映射到多个用户级线程。线程管理在用户空间中完成。如果一个线程执行了一个阻塞的系统调用，整个进程会被阻塞。在多处理器上，多个线程无法并行运行，因为每次只能有一个线程访问内核。这种模型适用于不支持内核线程的系统，但目前很少有系统使用这种模型。例如，Solaris 2中提供的Solaris Green Threads是一个可用于Solaris的线程库，还有GNU Portable Threads。 一对一（One-to-One） 在这种模型中，每个用户级线程都映射到一个内核线程。当一个线程执行一个阻塞的系统调用时，允许另一个线程运行。这允许多个线程在多处理器上并行运行。创建一个用户线程需要创建相应的内核线程。系统支持的线程数量受到限制。使用这种模型的 系统包括Windows、Linux以及Solaris 9及更高版本。 多对多（Many-to-Many） 这种模型允许许多用户级线程映射到许多内核线程。操作系统可以创建足够数量的内核线程。当一个线程执行一个阻塞的系统调用时，内核可以调度另一个线程进行执行。支持这种模型的系统示例包括Solaris 9之前的版本以及具有ThreadFiber包的Windows。 这三种模型之间的比较如下： Many-to-One模型允许开发人员创建任意数量的用户线程，但无法实现真正的并发，因为内核一次只能调度一个线程。 One-to-One模型允许更大的并发性，但开发人员必须小心，不要在应用程序中创建过多的线程。 Many-to-Many模型允许开发人员创建必要数量的用户线程，而相应的内核线程可以在多处理器上并行运行。 这些模型的选择取决于应用程序的性质和运行环境。Many-to-Many模型通常提供最大的灵活性和性能，因为它允许更好的并发性和利用多处理器系统的优势。但是，开发人员必须小心管理线程的数量，以避免过多的开销。 Threads Libraries 线程库（Thread Libraries）提供了程序员创建和管理线程的API。有两种主要的实现方式：\n在用户空间提供一个完全不依赖内核支持的库。所有的代码和数据结构都存在于用户空间中。 实现一个在操作系统直接支持的内核级库。所有的代码和数据结构都存在于内核空间中。 主要的线程库包括： POSIX Pthreads：一种通用的线程库，支持多个操作系统，包括Linux和Unix系统。 Win32：Windows操作系统上的线程库。 Java：Java编程语言内置的线程支持。 这些库允许程序员轻松地创建、管理和同步线程，从而实现多线程应用程序。不同的操作系统和编程语言可能提供不同的线程库来满足特定需求。 在多线程编程中，全局数据（Global Data）和局部数据（Local Data）之间存在不同的访问规则：\n对于POSIX和Windows线程，在全局范围声明的数据将在同一进程中的所有线程之间共享。这意味着多个线程可以访问和修改这些全局数据。 Java没有全局数据的概念，因此访问共享数据必须在线程之间进行显式安排。在Java中，局部数据通常存储在栈上，因为每个线程都有自己的栈，所以局部数据的每个线程都有一份拷贝。 创建多个线程的一般策略包括异步线程和同步线程：\n异步线程（Asynchronous Threading）：在这种策略中，一旦父线程创建了子线程，父线程就会继续执行，使得父线程和子线程同时执行。这种策略通常用于多线程服务器等场景。 同步线程（Synchronous Threading）：在这种策略中，父线程会等待子线程完成其任务后再继续执行。这种策略用于需要等待子线程结果的场景。 同步线程（Synchronous Threading）是一种策略，当父线程创建一个或多个子线程后，必须等待所有子线程终止后才能继续执行。这被称为\u0026quot;fork-join\u0026quot;策略。 在同步线程策略中，由父线程创建的各个子线程会并发执行工作，但父线程必须等待这些工作完成后才能继续执行。一旦每个线程完成了它的工作，它就会终止并与其父线程合并（join）。只有在所有子线程都已合并后，父线程才能恢复执行。 通常，同步线程涉及大量线程之间的数据共享。例如，父线程可能会合并其各个子线程计算的结果。 这种策略适用于需要等待子线程完成工作并收集结果的情况。 Threading Issues fork() 和 exec() 系统调用的问题。 当一个程序中的线程调用 fork() 时，新的进程会复制所有线程还是只有一个线程？ ・ 如果一个线程调用 fork()，那么新进程会复制所有线程。\n・ 新的进程只复制发起 fork() 系统调用的那个线程。 如果 fork() 后立即调用 exec()，那么只复制调用线程是合适的。 ・ 如果一个线程调用 exec()，那么指定参数中的程序将替换整个进程，包括所有线程。\n・ 如果分离的进程在 fork() 后没有调用 exec()，那么分离的进程应复制所有线程。 这段内容主要阐述了在操作系统中，当程序创建新进程时，如何处理线程的复制问题。根据不同的情况，新进程会复制所有线程或仅复制发起 fork() 的线程。同时，当新进程调用 exec() 时，会替换整个进程的所有线程。如果新进程没有立即调用 exec()，那么需要复制所有线程。这是因为操作系统在处理进程创建和线程复制时，需要确保进程和线程的资源正确分配和执行路径。\nthread cancellation 线程取消是指在线程完成之前终止线程的过程。线程取消主要有两种场景：异步取消和延迟取消。 异步取消：当一个线程立即终止目标线程时，这种方式就是异步取消。在这种方式下，终止线程的操作是立即发生的，不需要等待目标线程执行到某个取消点。 延迟取消：在这种场景下，目标线程会定期检查是否需要终止。当满足取消条件时，线程才会被终止。这种方式相对于异步取消，更加灵活，但需要线程自身具备检查和处理取消的机制。 线程取消的困难之处在于，当线程被取消时，可能正在执行的任务没有完成，或者正在占用资源。为了解决这个问题，操作系统和线程库通常提供了一种机制，使线程能够在被取消时释放资源并进行清理工作。 在 Pthreads 库中，线程取消是通过 pthread_cancel() 函数实现的。该函数请求终止指定线程，但实际的终止取决于线程的状态。线程可以设置自己的取消状态和类型，也可以在运行过程中检查是否需要终止。默认情况下，线程的取消类型是延迟取消，即线程在达到取消点时才会被终止。在 Linux 系统中，线程取消是通过信号处理的机制实现的。 这段内容主要讲述了线程取消的相关知识。在线程取消中，Pthread 库提供了一个用于取消线程的函数：pthread_cancel（tid）。 ◼ 当调用 pthread_cancel（tid）时，请求取消线程。但实际的取消操作取决于线程的状态： • 线程可以通过 API 设置其取消状态和类型。\n• 如果线程禁用了取消功能，那么取消操作将一直保持待处理状态，直到线程启用它。 ◼ Pthread 库的默认取消类型是延迟取消。 • 只有在线程达到取消点时，才会发生取消。\n• 取消点可以通过调用 pthread_testcancel() 函数来创建。\n• 当取消点被触发时，清理处理程序将被调用，以释放资源。 ◼ 在 Linux 系统中，线程取消是通过信号处理的机制实现的。 综上所述，这段内容主要介绍了线程取消的原理和方法，以及 Pthread 库在线程取消过程中的作用。线程取消分为异步取消和延迟取消，其中延迟取消是默认方式。在线程达到取消点时，线程将被取消，并执行清理处理程序以释放资源。在 Linux 系统中，线程取消是通过信号处理的机制实现的。\nsignal handling 【信号处理】（Signal handling）是操作系统中用于处理进程接收到的信号的过程。信号是一种用于通知进程某个特定事件已发生的方式。这些事件可能包括硬件信号（如内存访问错误、除以零等，）、软件信号（如终止进程的特定键盘操作，如 Ctrl+C）以及其他各种事件。 信号处理的主要目的是让进程在接收到信号后能够采取相应的措施。信号处理可以分为两类：同步信号处理和异步信号处理。\n同步信号处理：同步信号是由进程自身的行为引发的，例如非法内存访问或除以零等操作。这类信号会直接传递给引发该信号的进程。当同步信号发生时，进程必须处理该信号。 异步信号处理：异步信号是由进程外部的事件引发的，如终止进程的特定键盘操作。这类信号会传递给正在运行的进程。与同步信号不同，异步信号的处理方式取决于信号类型和进程的配置。有些异步信号需要发送给所有线程，如 Ctrl+C；而有些信号只发送给非阻塞信号的线程。 在多线程程序中，信号处理需要确保信号传递给应该处理的线程。信号处理的方法取决于信号类型。同步信号需要传递给生成该信号的线程，而某些异步信号需要发送给所有线程，或者仅发送给非阻塞信号的线程。某些 UNIX 版本的多线程允许线程指定它接受哪些信号并阻塞哪些信号。 thread pools 【线程池】（Thread pools）是一种用于管理和管理线程的技术。其核心思想是在程序启动时创建一批线程，并将它们放入一个池中等待分配任务。当服务器接收到请求时，它会从线程池中唤醒一个线程，将请求传递给它进行处理。线程处理完请求后，会返回线程池等待下一次分配任务。如果线程池中没有可用的线程，服务器会等待直到有线程空闲为止。 线程池的优点主要有以下几点：\n通常比等待创建新线程更快地服务请求。 允许将应用程序中的线程数量与线程池的大小绑定。 提高系统资源利用率，降低上下文切换的开销。 总之，线程池有助于提高程序的运行效率，特别是在处理大量并发请求的场景中。 thread-specific data 【线程特定数据】（Thread-specific data）是指在多线程程序中，每个线程都有自己的数据副本，这些数据与其他线程中的数据相互独立。线程特定数据允许每个线程拥有自己的数据副本，以便在并发环境下实现数据隔离，避免数据冲突和竞争条件。 线程特定数据的主要优点如下：\n提高程序的并发性能，因为每个线程可以独立地处理任务，而无需等待其他线程完成操作。 降低数据竞争和同步开销，因为每个线程都有自己的数据副本，从而减少了锁和其他同步原语的使用。 使线程能够更好地协同工作，因为每个线程可以独立地处理任务，并根据需要共享结果。 线程特定数据与本地变量、静态数据有所不同： 本地变量：本地变量仅在单个函数调用期间可见，而在多线程环境下，不同线程之间的本地变量是相互独立的。 静态数据：静态数据在程序运行期间始终保持不变，可以被所有线程共享。然而，在多线程环境下，静态数据可能引发竞争条件和死锁等问题。 总之，线程特定数据是一种在多线程程序中管理和保护数据的方法，有助于提高程序的性能和稳定性。 Scheduler Activations 【调度器激活】（Scheduler Activations）是一种在操作系统中实现线程与内核之间通信的方法。它允许用户线程库与内核线程之间进行交互，以便内核能够通知应用程序关于某些事件的信息。调度器激活在多线程应用程序中发挥着重要作用，因为它提供了一种机制，使应用程序能够在适当的时候接收内核的通知并进行相应的处理。 调度器激活的主要特点如下：\n提供了一种用户线程与内核线程之间通信的机制。 内核可以通过调度器激活向应用程序通知特定事件，如信号、时间戳等。 用户线程库可以处理内核通知，并在适当的时候执行相应的操作。 调度器激活通常使用轻量级进程（Lightweight Process，LWP）作为用户线程与内核线程之间的中介。 在 openEuler 操作系统中，线程的实现采用了 1:1 模型，其线程库是 NPTL（Native POSIX Thread Library）。openEuler 的进程和线程在地址空间中的布局采用了类似的方式，即一个进程由一个线程组及其共享的资源组成。当应用程序中的一个线程即将阻塞时，内核会向该线程发送一个调度器激活，通知应用程序分配一个新的轻量级进程。然后，应用程序在这个新的轻量级进程中运行一个调度器激活处理程序，用于处理阻塞线程的状态保存和重新调度等操作。 总之，调度器激活是操作系统中实现线程与内核之间通信的一种重要机制，它有助于提高多线程应用程序的性能和稳定性。 ","date":"2023-10-21T20:54:29Z","permalink":"http://localhost:1313/post/2-processes-and-threads/","title":"2 Processes And Threads"},{"content":"1 Introduction Computer System Components\n可以计算机系统分成三个基本组成部分：底层的计算机硬件、中间层的操作系统以及上层的计算机应用程序，操作系统属于承上启下的中间层，所以它在计算机系统中的地位和作用尤为重要。\n操作系统是计算机系统中最基本的系统软件；\nWhat Operating Systems do? User view System view resource allocator control program Defining Operating Systems Kernel（nucleus）内核\nOS is the one program running at all times on the computer.(all else being system programs and application programs) Portion of operating system that is in main memory. 常驻内存 Contains most-frequently used functions.频繁使用 操作系统是计算机系统中的一个系统软件，是一些程序模块的集合，它们能以尽量有效、合理的方式组织和管理计算机的软硬件资源，合理地组织计算机的工作流程，控制程序的执行，向用户提供各种服务功能\n操作系统是安装在计算机硬件之上的一层软件；操作系统之上可以安装各种应用程序软件； 用户可以通过应用程序软件来间接使用操作系统，也可以直接使用操作系统，但通常都是通过操作系统来最终使用计算机硬件的； 直接使用操作系统：让用户通过编写程序来调用操作系统提供的系统接口从而进入操作系统。 用户通过系统接口进入操作系统后使用计算机硬件，即用户必须“穿过”操作系统才能使用计算机硬件； 操作系统管理计算机硬件，目的是让用户对计算机硬件的使用更加简便，也更加高效； Operating System Feature 操作系统是一种系统软件，操作系统的基本特征包括并发、共享、虚拟和异步\nConcurrence 并发是指两个或多个事件在同一时间间隔内发生。操作系统的并发性是指计算机系统中同时存在多个运行的程序，因此它具有处理和调度多个程序同时执行的能力。\n引入进程的目的是使程序能并发执行。\nQ：并发和并行的区别？ A： 并发：同一时间间隔 并行：同一时刻 基于单处理机的背景，实际上每个时刻仅能有一道程序执行，在一段时间内，宏观上有多道程序在同时执行，微观上这些程序仍然是分时交替执行的 —— 操作系统的并发性是通过分时得以实现的；\n而并行性需要有相关硬件的支持，要么是多流水线，要么是多处理机硬件；\nSharing 共享也就是资源共享，是指系统中的资源可供内存中多个并发执行的进程共同使用，共享可分为以下两种资源共享方式： 互斥共享方式：规定在一段时间内只允许一个进程访问资源，将在一段时间内只允许一个进程访问的资源成为临界资源或独占资源； 同时访问方式：“同时”通常是指宏观上的，微观上这些进程可能是交替地对资源进行访问，即“分时共享”；\nVirtual 虚拟是指将一个物理上的实体变为若干逻辑上的对应物； 操作系统利用了多种虚拟技术来实现虚拟处理器、虚拟内存和虚拟外部设备等： 利用多道程序设计技术把一个物理上的CPU虚拟为多个逻辑上的CPU（即分时使用一个处理器），称为虚拟处理器； 将用户感受到的存储器称为虚拟存储器（实际存储器我们编程的时候根本接触不到）； 简单来说，操作系统的虚拟技术可以归纳为：时分复用技术（处理器的分时共享）和空分复用技术（虚拟存储器）\nAsynchronism 异步是指由于资源有限，进程的执行不是一贯到底的，而是以不可预知的速度向前推进。\n异步是在多道程序环境下允许多个程序并发执行极有可能导致的进程与时间有关的错误。\nOperating-System Function fundamental management modules：进程管理、存储器管理、设备管理以及文件系统\nDevice Management The device management module is responsible for managing all the hardware devices of the computer. This includes monitoring the status of hardware devices, installing and configuring device drivers, and handling input/output operations.\nDevice Management in an operating system primarily encompasses the following functions:\nBuffer Management: Buffer management is crucial for handling input/output operations efficiently. It involves temporarily storing data in a buffer while it is being transferred between two places, such as between a device and the main memory. This process helps in managing the speed differences between the devices and the CPU. Device Allocation: Device allocation refers to the allocation of various hardware resources to different processes or users. The operating system must manage the allocation of devices in a way that optimizes their usage while avoiding conflicts and ensuring fair access for all processes. Device Handling: Device handling involves managing the actual operation of the hardware devices. This includes interpreting commands, initiating operations, and monitoring the status of devices. The operating system communicates with device drivers, which are specific to each hardware device, to perform these operations. Virtual Devices: The concept of virtual devices involves abstracting the physical hardware into a more manageable form. This allows the operating system to provide more flexible and efficient device management by presenting hardware resources as virtual devices, which can be easier to manage and share among multiple processes. Process Management A process is a program in execution 进程在执行过程中需要分配资源，当进程完成任务或终止时，需要回收其占用的资源，以便其他进程可以使用。 单线程进程有一个程序计数器（PC, Program Counter），用于指定下一条要执行的指令位置；多线程进程具有多个线程，每个线程都有一个独立的PC。 计算机系统可以在一个或多个 CPU 上并发运行多个进程，以提高系统性能。 操作系统在与进程管理相关的活动中负责以下任务：\n创建和删除用户和系统进程 挂起和恢复进程 提供进程同步的机制 提供进程通信的机制 提供死锁处理的机制 Memory Management CPU 能够直接寻址和访问的唯一大型存储设备是内存。 内存管理负责管理内存中存储的内容，从而提高 CPU 利用率和计算机响应用户的速度。 内存管理活动包括以下几个方面： 跟踪当前正在使用内存的部分以及使用者。 决定将哪些进程和数据移入和移出内存。 根据需要分配和释放内存空间。 Storage Management 操作系统为信息存储提供了uniform, logical view，使得用户和程序能够以更加简洁的方式处理存储设备。 操作系统将物理存储介质抽象为逻辑存储单元，即文件。这种抽象使得用户可以忽略底层物理存储细节，更容易地管理和操作数据。 每种存储介质都由特定的设备控制，如磁盘驱动器、磁带驱动器等。这些设备具有不同的属性，如访问速度、容量、数据传输速率以及访问方法（顺序或随机）。 File-System Management 文件通常组织成目录。 大多数系统具有访问控制来确定谁可以访问什么。\n操作系统的活动包括：\n创建和删除文件 创建和删除目录以组织文件 支持用于操作文件和目录的基本操作 将文件映射到辅助存储设备 备份文件到稳定的（非易失性）存储介质。 Mass-Storage Management 通常，磁盘用于存储无法容纳在主内存中的数据，或者需要在较长时间内保留的数据。\n操作系统在磁盘管理方面的活动包括：\n空闲空间管理 存储分配 磁盘调度 计算机操作的整体速度高度依赖于磁盘子系统及其算法。\n某些存储设备不必很快，三级存储包括光盘、磁带。 存储介质可能是WORM（只写一次，多次读取）或RW（可读写）。 虽然对系统性能不是至关重要的，但仍然需要进行管理，包括挂载和卸载、分配和释放，以及将数据从二级存储迁移到三级存储。\nCaching 缓存旨在将正在使用的信息从较慢的存储复制到较快的存储中，以提高数据处理速度。 缓存应用于多个计算机层次，包括硬件、操作系统和软件。主内存被视为辅助存储的最后一级缓存。 系统在访问数据前会首先检查缓存，若信息已存在，则直接从缓存中获取；若不存在，则将数据复制到缓存并在其中使用。 由于缓存容量有限，缓存管理策略（如数据替换算法）和设计决策（如缓存大小）至关重要。\n具体类型如下： 磁盘缓存（Disk Cache）： 利用主内存的一部分作为缓冲区，临时存储磁盘数据。 磁盘写入时进行聚类，预计会再次被引用的数据可以从软件缓存中快速检索，避免从磁盘缓慢读取。 缓存内存（Cache Memory）： 对操作系统不可见，由硬件直接管理。 提高内存速度，缓解处理器速度与内存速度之间的差距。 作为处理器的高速存储区域，提高数据访问效率。 Operating-System Structure Uniprogramming Uniprogramming（单道批处理系统）是一种计算机操作系统的早期模式，其中在计算机系统上一次只能执行一个程序。这种模式通常是单任务操作系统的基础，它允许计算机执行一个程序，直到该程序完成或发生错误。一旦程序执行完毕，用户可以手动或通过重启系统来加载和执行下一个程序。\nUniprogramming的特点包括：\n单道性： 计算机一次只能执行一个程序。 简单性： 由于只有一个程序在运行，Uniprogramming系统相对简单，不需要复杂的任务调度或多任务管理机制。 顺序性： 资源（如内存和CPU时间）完全由当前运行的程序占用，而其他程序必须等待。 Uniprogramming有一些明显的局限性。最显著的是效率问题，因为计算机在执行一个程序时，其他程序无法运行，导致资源利用率低下。此外，用户体验也受到影响，因为用户必须等待一个程序完成后才能运行下一个程序。 这包括：\n性能低下： 由于Uniprogramming一次只能执行一个程序，因此性能有限，计算机不能同时处理多个任务，导致了性能低下的问题。 I/O速度慢： 输入/输出操作的速度较慢，因为计算机必须等待I/O指令完成后才能继续执行。这意味着I/O操作会阻塞其他计算任务的执行。 Multiprogramming 保持CPU和I/O设备始终繁忙： 多道程序设计旨在最大程度地利用计算机资源，以确保CPU和I/O设备在任何给定时间都保持繁忙状态，以提高系统的性能和资源利用率。 组织作业以保持CPU繁忙： 多道程序设计将不同的作业（包括代码和数据）组织在系统中，以确保CPU始终有一个作业可供执行，从而减少CPU空闲时间。 内存中的作业子集： 系统中只保留了作业的一个子集（通常是部分作业）在内存中，以便它们可以立即被执行。 作业调度： 作业调度是多道程序设计的一部分，它选择要在CPU上运行的作业。作业调度算法根据不同的策略选择下一个要执行的作业。 等待I/O时切换作业： 当一个作业需要等待I/O操作完成时，操作系统会将CPU的控制权切换到另一个可执行的作业，以充分利用CPU时间，而不让CPU处于空闲状态。 两个程序的多道程序设计： 这是多道程序设计的一种特定情况，其中只有两个程序同时存在在内存中，操作系统可以根据需要在这两个程序之间切换，以确保CPU忙碌。 多道程序设计的核心思想是在系统中同时运行多个作业，以减少计算机资源的浪费，提高性能和响应速度。这种方法允许计算机在一个作业等待I/O操作的时候，执行另一个可执行的作业，从而最大化了资源的利用率。\nTime sharing systems 时间共享和交互式计算：时间共享系统通过频繁地在不同作业之间切换CPU，使得多个程序能够似乎同时运行，为用户提供交互式的体验。分时技术，是指把处理器的运行时间分成很短的时间片，按时间片轮流把处理器分配给各联机作业使用。 系统响应和进程： 快速响应：为了维持交互性，系统的响应时间必须很短，最好小于1秒。 多进程：每个用户在系统中都有至少一个或多个正在运行的程序，这些程序称为进程。 CPU调度和资源管理： 当多个进程同时请求CPU时，需要一个调度机制来决定哪个进程应该获得CPU。 不所有进程都能完全装入内存。当内存不足时，某些进程会被移到磁盘上，需要时再被调入内存。这种操作称为交换，由交换程序（Swapper）执行。 虚拟内存允许不完全在内存中的进程执行，提高了内存的使用效率。 多用户系统和在线通信： 多个用户可以同时使用计算机并运行自己的程序。 用户可以通过终端与系统实时通信，发送命令和接收响应。 与传统的从外部设备（如卡片阅读机）获取指令不同，现代操作系统直接从用户键盘获取指令。 在线系统的可用性：在线系统必须始终可用，以供用户随时访问数据和代码。 Real-time operating system 实时操作系统与一般的操作系统相比，最大的特色就是“实时性”，如果有一个任务需要执行，实时操作系统会马上（在较短时间内）执行该任务，不会有较长的延时。\n经常用作专用应用中的控制设备，例如控制科学实验、医学成像系统、工业控制系统以及某些显示系统。 具有明确固定的时间约束。 必须在定义的约束内完成处理，否则系统将失败。 实时系统有两类： 硬实时系统 目标：保证关键任务及时完成。 次要存储有限或不存在，数据存储在短期内存或只读内存（ROM）中。 与时间共享系统冲突，不被通用操作系统支持。 软实时系统 关键实时任务优先于其他任务，并保持该优先级直到完成。 缺乏截止时间支持，在工业控制或机器人技术中应用受限。 在需要高级操作系统功能的应用中有用（例如多媒体、虚拟现实、科学项目）。 Operating-System Operations Modern operating systems are interrupt driven. Interrupt driven by hardware Software error or request creates exception or trap Division by zero, request for operating system service Other process problems include infinite loop, processes modifying each other or the operating system Dual-mode operation Dual-mode operation allows OS to protect itself and other system components.\nuser mode and kernel mode 两种操作模式： User mode：代表用户执行，主要用于普通应用程序的运行。 Kernel mode：代表操作系统执行，用于处理操作系统内核及相关功能。 内核组成部分： 硬件密切相关的模块：时钟管理、中断处理等。 运行频率较高的程序：进程管理、设备管理等。 操作系统内核主要包括以下几个方面： 时钟管理：计算机最关键的设备，系统管理依赖于时钟。 中断机制：现代操作系统靠中断驱动。 原语Atomic Operation：特殊程序，运行具有原子性。 数据结构管理：操作系统需对系统中的数据结构进行有效管理，包括进程管理、存储器管理、设备管理等。 在用户态和核心态发生的事件 核心态 系统调用 中断 输入输出指令会引起中断 操作系统会完成：提供中断服务、初始化中断向量表、保存中断屏蔽字 时钟 置时钟指令只能在核心态运行 用户态 用户程序在用户态下使用特权指令引起的中断叫访管中断 访管仅在用户态执行 用户态到核心态的转换是通过硬件完成的 用户设计程序时，使用系统调用命令，该命令经过编译之后，形成若干参数和陷入（trap）指令。\nImplementation of Dual-mode operation 双模态是由操作系统和硬件一起实现的，硬件主要实现下面的功能：\n特权指令 特权指令：只能在 CPU 处于内核态时执行，具有较高的权限，可以访问和控制系统的硬件资源。 特权指令包括危险的指令，如 I/O 指令、置中断指令、存取用于内存保护的寄存器等。 为了防止用户程序对系统造成破坏，特权指令不允许用户直接执行，操作系统提供了接口（称为系统调用）来协助用户执行特权指令。 （系统调用命令工作在内核态） 非特权指令：在 CPU 的 user 态和 kernel 态下执行，主要访问用户的地址空间，权限较低。 非特权指令允许用户直接使用，主要访问用户的地址空间，不能直接访问系统中的软硬件资源。 非特权指令在用户程序中广泛应用，用于实现程序的控制逻辑、数据计算和存储等操作。 操作系统在内存中划分用户态内存和内核态内存，并设置各自的特权级别。内核态内存特权级别较高，用于操作系统及其组件的运行；用户态内存特权级别较低，用于用户程序的运行。 用户程序在访问内存时，CPU 会进行特权级检查。当用户程序试图访问特权级别高于自身的内存区域时，CPU 会拒绝执行该指令，从而实现操作系统的保护机制。 特权级检查通过 CPU 提供的特权环机制实现。特权环是一种硬件机制，用于在执行指令时进行特权级检查，以确保程序在适当的权限级别下运行。 特权级检查涉及两个重要数值：当前特权级（CPL）和描述符特权级（DPL）。CPL 表示当前执行指令的特权级，DPL 表示目标内存区域的特权级，二者用于判断程序是否具有访问目标内存的权限。 内存保护 保证物理地址与虚拟地址隔离，现代操作系统采用分页法。分页法涉及虚拟地址到物理地址的转换，由硬件（CPU 中的 MMU）执行映射，操作系统决定映射策略，页表存储在内存中。 时间片中断 一个让操作系统重新获取CPU控制权的方式。 在定时器中断后，操作系统安排另一个进程（可能是被中断的同一个进程）运行。 为了防止无限循环或进程占用过多资源，操作系统使用计时器，在特定时间后设置中断，不断递减计数器以追踪时间，并在计数器归零时产生中断，从而使操作系统能够重新获得控制权或终止超出分配时间的程序，同时确保修改计时器内容的指令是特权且安全的。 上下文切换 当一个进程被替换并由另一个进程取代时，系统保存当前进程的状态并加载新进程的状态。 Interruption When an interrupt or fault occurs hardware switches to kernel mode. 中断是唯一让用户态切换到核心态的方式； 核心态转换为用户态只需要修改程序状态字PSW的标志位（通过执行特权指令来修改）； 发生中断或异常时，运行用户态的CPU会立即进入核心态，这是通过硬件实现的（一位寄存器0表示核心态、1表示用户态）\nDefining Interruption 中断也称外中断（外设请求、人工干预），指来自CPU执行指令以外的事件发生（I/O中断、时钟中断），这一类中断通常是与当前指令执行无关的事件； 访管中断，又称软件中断或自愿中断，是一种由用户程序在运行过程中主动请求操作系统提供服务而引发的中断。 访管在用户态使用。 外部中断：也称为硬件中断，是由外部设备或硬件信号引发的中断。例如，I/O 设备完成数据传输、硬件故障、计时器到期等。外部中断通常使用中断向量表中的中断向量来处理。 处理外部中断时，应由操作系统保存通用寄存器里的内容。 定时器产生时钟中断时，由时钟中断服务程序更新的部分是内核中时钟变量的值、当前进程占用的CPU时间、当前进程在时间片内剩余执行时间。 异常也称内中断（例外、陷入），指来自CPU执行指令内部的事件（程序非法操作码、地址越界），对异常的处理通常依赖当前程序的运行现场，且异常不能被屏蔽，一旦出现应当立即处理； 开中断（Enabling Interrupts）：这是指允许中断信号被处理的状态。当系统处于“开中断”状态时，如果出现中断信号，CPU将响应这个信号，并根据中断的类型执行相应的中断处理程序。这是计算机正常操作时的常态，因为它允许系统对如输入/输出请求、硬件故障等事件做出及时响应。\n关中断（Disabling Interrupts）：这是指暂时屏蔽或禁止中断信号的状态。在“关中断”状态下，即使有中断信号产生，CPU也不会对其进行处理。这通常用于保护关键的代码段不被中断，例如在操作系统内核执行一些关键任务时，可能会暂时关中断，以保证任务的连续性和数据的一致性。完成这些关键任务后，系统通常会重新开启中断。\nComputer-System Organization Computer-System Operation 在计算机系统中，CPU 与 I/O 设备可以同时执行任务，实现高效的数据传输。设备控制器负责管理特定类型的设备，并具备本地缓冲区。CPU 负责在主内存与本地缓冲区之间传输数据，而 I/O 操作则从设备到控制器本地缓冲区进行。当设备控制器完成操作时，它会通过引发中断通知 CPU，从而实现顺畅的数据处理和设备控制。这种机制使得计算机系统能够在处理数据和控制设备时保持高效和稳定。\nInterrupt Timeline \u0026ldquo;Interrupt Timeline\u0026rdquo;（中断时间线）通常指的是计算机系统中的中断事件序列，记录了中断的发生时间和处理时间。在操作系统和计算机体系结构中，中断是一种用于处理异步事件的机制，例如硬件故障、外部设备的输入、定时器事件等。中断允许计算机系统在正常执行的过程中响应和处理这些事件，而不需要等待或轮询。\nInterrupt Timeline包括以下关键元素：\n中断源：表示引发中断事件的来源，例如硬件故障、I/O设备请求、时钟中断等。 中断请求时间：指中断事件发生的确切时间戳。 中断处理时间：指操作系统或处理器开始处理中断事件的时间戳。这包括了操作系统的中断服务例程或中断处理程序的执行时间。 中断完成时间：指整个中断处理过程完成的时间戳。这包括了中断服务例程的执行以及可能的上下文切换。 Storage Structure Main memory \u0026ndash; only large storage area that the processor can access directly. Secondary storage \u0026ndash; extension of main memory that provides large nonvolatile storage capacity. Magnetic disks \u0026ndash; rigid metal or glass platters covered with magnetic recording material. Disk surface is logically divided into tracks, which are subdivided into sectors. The disk controller determines the logical interaction between the device and the computer. Magnetic tapes \u0026ndash; used for backup, for storage of infrequently used information. Storage Hierarchy Storage systems organized in hierarchy. Speed Cost Volatility Volatile storage loses its contents when the power to the device is removed. Principle of design a computer memory system： uses only as much expensive memory as necessary. provides as much inexpensive, nonvolatile memory as possible. Storage-Device Hierarchy I/O Structure Programmed I/O\nInterrupt-Driven I/O\nSynchronous I/O\nAsynchronous I/O\nDMA\nI/O通道控制方式\nI/O operation 设备控制器 device controller Local buffer storage A set of special-purpose registers Moving data between device and its local buffer storage. 设备控制器是一种硬件组件，用于管理特定类型的外部设备（如磁盘驱动器、键盘、鼠标等）。它包括一组特殊用途的寄存器，用于控制设备的操作和状态。设备控制器还包括本地缓冲存储，用于在设备和计算机之间传输数据。 设备驱动程序 device driver One for each device controller. Presents a uniform interface to the device. 设备驱动程序是用于与设备控制器通信的软件组件。每种设备控制器都有一个相应的设备驱动程序。设备驱动程序提供了一个统一的接口，以便操作系统可以与不同类型的设备进行交互。 I/O 操作 I/O operation ：I/O 操作是指计算机系统与外部设备之间的数据传输和交互过程。它包括以下步骤： Device driver loads registers within the controller. 设备驱动程序加载设备控制器内的寄存器，以配置设备的操作。 Device controller examines the contents of the registers to determine what action to take. 设备控制器检查寄存器的内容，以确定应采取什么操作。 Device controller starts the transfer of data between the device and its local buffer. 设备控制器开始在设备和其本地缓冲存储之间传输数据。 Once done, device controller sets its status, or informs the driver via an interrupt. 一旦完成数据传输，设备控制器设置其状态，或者通过中断通知设备驱动程序。 Device driver returns control to the OS, with data if \u0026lsquo;read\u0026rsquo;. 设备驱动程序将控制返回给操作系统，如果是“读”操作，可能会将读取的数据一并返回。 Modern Computer System high-end systems use switch architecture. multiple components can talk to other components concurrently, rather than competing for cycles on a shared bus. 在计算机系统中，高端系统采用了一种称为\u0026quot;交换架构\u0026quot;的设计。这种设计允许多个系统组件同时相互通信，而不是竞争共享总线周期。在传统的计算机架构中，多个组件（如CPU、内存、输入/输出设备）必须通过共享总线来访问系统资源，这可能会导致资源争用和性能瓶颈。而交换架构允许各个组件之间以更高效的方式进行通信，从而提高了系统的并发性和性能。\n在交换架构中，不同组件之间可以直接建立点对点的连接，而无需通过共享总线进行通信。这种架构通常使用交换网络或高速互连来实现，允许组件之间并行传输数据，提供更大的带宽和更低的延迟。这对于高性能计算、大规模服务器和数据中心等需要处理大量数据并进行高度并发处理的应用非常重要。\nProtection and Security 保护：操作系统中的保护机制控制进程或用户对系统资源的访问，确保资源的安全使用和访问控制。 安全：操作系统需要抵御内部和外部攻击，包括拒绝服务、蠕虫、病毒、身份盗窃和服务盗用等安全威胁。 访问控制：操作系统规定用户对系统的访问权限，以确定用户能够执行的操作。 信息流控制：操作系统控制数据在系统内的流动以及传递给用户的方式。 认证：证明访问控制和信息流控制是否按照规范执行的过程。 系统首先区分用户，以确定谁可以执行什么操作。用户标识（用户 ID、安全 ID）包括用户名和相关编号，每个用户有一个。 用户 ID 与用户的所有文件和进程相关联，以确定访问控制。组标识符（组 ID）允许定义一组用户，并进行管理，然后也与每个进程和文件相关联。 特权提升：操作系统允许用户切换到具有更多权限的有效 ID，以便执行需要更高权限的操作。 Operating-System Structures Operating System Services 操作系统提供了一个程序执行的环境，并向程序和用户提供各种服务。\n操作系统提供一组服务，旨在满足用户的需求，包括以下功能：\n用户界面 (UI)： 操作系统提供不同类型的用户界面，以便用户与计算机系统交互。这包括命令行界面 (CLI)，批处理界面，图形用户界面 (GUI) 等。用户可以通过这些界面执行命令、操作文件和访问系统功能。 程序执行： 操作系统负责加载程序到内存并执行它。它可以正常或异常地终止程序的执行，以指示是否发生了错误。 I/O 操作： 操作系统管理输入/输出操作，允许用户访问磁盘上的文件，输出到打印机或屏幕等。这包括文件的读写、目录的创建和删除、文件搜索、权限管理等。 文件系统操作： 操作系统支持对文件和目录的操作，包括读取和写入文件，创建和删除文件和目录，搜索文件，列出文件信息以及权限管理。 通信： 进程可以在同一台计算机上或在网络上的不同计算机之间交换信息。这可以通过共享内存、消息传递等方式实现。 错误检测： 操作系统能够检测硬件、I/O 设备或用户程序中可能发生的错误。对于每种类型的错误，操作系统应采取适当的措施以确保计算的正确性和一致性。 调试功能： 操作系统提供调试工具，以帮助用户和程序员高效地使用系统。这些工具可以用于识别和解决程序中的错误，从而提高系统的可靠性和稳定性。 操作系统还具备一组功能，旨在通过资源共享来确保系统自身的高效运行，这包括以下方面：\n资源分配： 当多个用户或多个作业同时运行时，必须为它们分配资源。不同类型的资源需要不同的分配策略，例如 CPU 时间、主内存、文件存储等。某些资源可能需要特殊的分配代码，而其他资源可能使用通用的请求和释放代码，例如 I/O 设备。 记账（Accounting）： 记账是跟踪用户使用了多少以及什么类型的计算机资源的过程。这有助于了解资源的使用情况，以便进行资源管理和计费。 保护和安全性： 多用户或网络化计算机系统中存储的信息的所有者可能希望控制该信息的使用。同时运行的进程不应相互干扰。保护涉及确保对系统资源的所有访问都受到控制。系统的安全性要求用户进行身份验证，并扩展到保护外部 I/O 设备免受非法访问尝试的攻击。如果要保护和确保系统的安全性，必须在整个系统中采取预防措施。 操作系统提供的服务分为面向客户（命令接口）和面向编程人员（系统调用）。\n命令接口：用户通过这些操作命令来组织和控制作业的执行。 命令行界面（CLI）和图形用户界面（GUI）属于命令接口 根据控制方式的不同，命令接口可分为两类： 脱机控制接口：也称为批处理命令接口，适用于批处理系统，由一组作业控制命令组成。 联机控制接口：也称为交互式命令接口，适用于分时或实时系统。用户可以与操作系统进行实时交互，操作系统根据用户的指令实时执行任务。 程序接口： 程序接口指的是操作系统提供给程序员的所有编程接口，包括但不限于系统调用。它还可以包括应用程序接口（APIs）、库函数、框架等。 编程人员使用这些接口请求操作系统服务，实际上就是系统调用。当我们说“程序接口是编程人员用来请求操作系统服务的，实际上就是系统调用”的时候，我们是在强调系统调用作为程序接口的一个核心和最直接的部分。 User Operating System Interface Command Interpreter (CLI) 命令解释程序（Command Interpreter）是用户与操作系统之间的接口。它负责解释用户输入的命令并将其传达给操作系统执行。命令解释程序可以以不同的方式实现，取决于操作系统的设计和类型：\n内核中实现（例如 MS-DOS）： 在某些操作系统中，命令解释程序可以直接内置在内核中，这使得它更加紧密地与操作系统集成。 由系统程序实现（例如 Windows / UNIX）： 在其他操作系统中，命令解释程序是作为系统程序运行的，不在内核中。这种设计允许更灵活地扩展和定制命令解释程序。 Shell（例如 UNIX / Linux）： 在类UNIX系统中，通常使用一个称为\u0026quot;Shell\u0026quot;的特殊程序来充当命令解释程序。不同的Shell可以有不同的特性和功能，例如Bourne Shell、C Shell等。 命令解释程序的主要职责是接收用户输入的命令并执行它。命令可以通过两种方式来实现：\n内置命令（例如 MS-DOS）： 一些命令解释程序支持内置命令，这意味着某些命令的实现是直接嵌入到命令解释程序中的。这些命令通常执行速度快，但无法轻松扩展或添加新功能。 系统程序（例如 UNIX）： 在其他系统中，大多数命令是通过系统程序来实现的，这些程序可以独立于命令解释程序进行开发和维护。这种方法使得添加新功能和扩展系统功能变得更加容易，因为不需要修改命令解释程序本身。 Graphical User Interface (GUI) 图形用户界面（Graphical User Interface，GUI）是一种用户友好的桌面元喻界面，通常使用鼠标、键盘和显示器来与计算机进行交互。GUI的特点包括：\n图标表示文件、程序和操作： GUI使用图标来代表不同的文件、程序、操作等，使用户可以通过可视化方式来管理和执行任务。 鼠标操作： 用户可以使用鼠标来点击、拖动、右键单击等与界面中的对象互动，触发不同的操作和功能。 提供信息和选项： 用户可以通过鼠标操作来获取对象的信息，查看选项，执行功能，等等。 文件夹结构： GUI通常使用文件夹（也称为目录）来组织文件和数据，用户可以打开文件夹以查看其中的内容，这个操作通常被称为\u0026quot;打开目录\u0026quot;。 GUI的概念最早在20世纪70年代初由帕洛阿尔托研究中心（Xerox PARC）发明。现代操作系统通常提供了CLI和GUI两种接口，以满足不同用户的需求。一些相关的系统和信息包括：\nMicrosoft Windows： Windows操作系统使用GUI界面，但也包含了命令行界面（CLI）。 Apple Mac OS X： Mac OS X使用名为\u0026quot;Aqua\u0026quot;的GUI界面，底层采用UNIX内核，并提供了多种不同的shell来满足不同的需求。 Unix和Linux： Unix和Linux系统通常提供CLI界面，并可选择性地提供GUI界面，例如Common Desktop Environment（CDE）、KDE Desktop Environment和GNOME GNU Desktop等。 System Calls 系统调用是操作系统提供的接口，允许应用程序与底层硬件和文件系统交互。\n系统调用按照功能可分为以下几类：\n设备管理：完成设备的请求、释放和启动等功能。 文件管理：完成文件的读、写、创建和删除等功能。 进程控制：完成进程的创建、撤销、阻塞和唤醒等功能。 进程通信：完成进程之间的消息传递或信号传递等功能。 内存管理：完成内存的分配、回收以及获取作业占用内存区大小和始址等功能。 操作系统内核程序负责处理系统调用，运行在核心态。大多数应用程序通过高级应用程序接口（API）而不是直接的系统调用来访问操作系统的功能。API 提供了一组可供程序员使用的函数，简化了与操作系统交互的过程。操作系统通常使用高级编程语言（如 C/C++）编写，并通过库（如 libc）提供 API，使程序员能够更轻松地访问和利用操作系统的功能。这提高了应用程序的开发和维护效率，同时降低了底层系统调用的复杂性。\n库函数与系统调用的区别和联系: 库函数是语言或应用程序的一部分，可以运行在用户空间中。而系统调用是操作系统的一部分，是内核为用户提供的程序接口，运行在内核空间中，而且许多库函数都会使用系统调用来实现功能。未使用系统调用的库函数，其执行效率通常要比系统调用的高。因为使用系统调用时，需要上下文的切换及状态的转换（由用户态转向核心态）。\nSystem Call Implementation 运行时支持系统（run-time support system）提供了一个系统调用接口，它作为与系统调用的连接。 这个接口通常包含在与编译器一起提供的库中，这些库中内置了一组函数。 通常，每个系统调用都与一个数字相关联，系统调用接口维护一个表，根据这些数字进行索引。\n系统调用接口的功能包括：\n拦截API中的函数调用。 调用操作系统中所需的系统调用。 返回系统调用的状态以及任何返回值。 调用者无需了解系统调用的实现方式，或者在执行期间它执行了什么操作。 他们只需要遵守API，并理解作为结果操作系统将执行的操作。 API隐藏了程序员不需要了解的大部分操作系统接口的细节，这些细节由运行时支持库进行管理。\nSystem Call Parameter Passing 通常，传递给操作系统的信息通常不仅仅是所需的系统调用的标识。所需的信息类型和数量因操作系统和调用而异。\n有三种常见的方法用于将参数传递给操作系统：\nRegisters，最简单的方法。 Memory block，参数存储在内存中的块或表中，块的地址作为参数传递给寄存器（Linux 和 Solaris 采用这种方法）。 Stack，程序将参数推送到栈上，由操作系统从栈上弹出。 Types of System Calls Process control 进程控制 结束、中止、加载和执行进程：用于管理进程的创建和终止。 创建进程、终止进程：用于创建和终止进程。 获取进程属性、设置进程属性：用于获取和设置进程的属性信息。 等待时间、等待事件、信号事件：用于处理等待时间、事件和信号的操作。 分配和释放内存：用于管理内存的分配和释放。 内存转储：在发生错误时将内存内容转储到文件中，以进行故障诊断。 调试器：用于识别和调试程序中的错误，支持单步执行和监视程序的执行。 锁：用于管理多个进程之间对共享数据的访问，以确保数据的一致性和互斥访问。 fork、exec、wait 和 exit 这四个系统调用是和进程有关的最为重要的四个系统调用：\nfork 用来创建进程； exec 从磁盘上载入并执行某个可执行程序； exit 是进程自己退出时要调用的函数； wait 调用的进程会等到子进程退出时才继续执行。 fork fork 系统调用的函数原型定义为：\nint fork(); 这个函数没有参数，调用该函数的进程会再创建一个进程，新创建的进程是原进程的子进程。两个进程都从 fork() 这个地方继续往下执行，并且执行“同样”的代码。但是父进程执行 fork() 会返回子进程的ID，而子进程调用 fork() 会返回0。父子进程正是通过对这个返回值的判断（用if语句）来决定分别执行哪段代码。\nexec exec() 系统调用的功能是在当前进程中执行一段新程序，进程的PID保持不变。可以这样形象地理解，一个进程就像一个壳子，在这个壳子里可以装各种可执行代码。fork() 创建了这个壳子，并且将父进程的代码装在这个壳子中执行，而 exec() 是用一个磁盘上的可执行程序（exec() 的参数告诉操作系统是哪个可执行程序）替换了这个壳子里原有的内容。\nexec() 函数分为两类，分别以 execl 和 execv 开头，其函数原型定义如下：\nvoid execl(const char* filepath, const char* arg1, char* arg2, …); void execlp(const char* filename, const char* argl, char* arg2, …); void execv(const char* filepath, char* argv[]); void execvp(const char* filename, char* argv[]); 这些函数基本上一样，只是 execl 中对应可执行程序入口函数的参数，即其中的 arg1、arg2 等，是一个一个列举出来的，而 execv 是将这些参数组织成一个数组告诉操作系统的。\nexit exit() 系统调用用来终止一个进程，在进程中可以显式调用 exit 来终止自己，也可以隐式调用 exit。操作系统在编译 main() 函数时，当遇到 main() 函数的最后一个 } 时会“塞入”一个 exit。\nexit() 函数的原型定义为：\nvoid exit(int status); exit 中的参数 status 是退出进程返回给其父进程的退出码。同时，退出的进程会向其父进程发送一个 SIGCHILD 信号，一个进程执行 wait 系统调用时就会\n暂停自己的执行来等待这个信号。所以 wait 和 exit 合在一起可以完成这样一种进程之间的同步合作：父进程启动了一个子进程，调用 wait 等待子进程执行完毕；子进程执行完毕以后调用 exit 给父进程发送一个信号 SIGCHILD，父进程被唤醒继续执行。\nwait wait 系统调用的函数原型定义为：\nint wait(int *stat_addr); 其返回值是 exit 子进程的PID，stat_addr 是进程中定义的一个变量，用于存放子进程调用 exit 时的退出码，即 exit 系统调用的参数 status。\nFile management 创建文件（Create file）: 用于创建新的文件，分配必要的存储空间和初始化文件属性。 删除文件（Delete file）: 用于移除现有文件，释放其占用的存储空间，并更新文件系统的记录。 打开文件（Open）: 用于打开一个文件以进行读取、写入或其他操作。在文件打开时，操作系统通常会在内部维护一个文件描述符或句柄。 关闭文件（Close）: 在文件操作完成后，关闭文件以释放操作系统维护的资源和句柄。 读取文件（Read）: 用于从文件中读取数据到内存中。 写入文件（Write）: 将内存中的数据写入到文件中。 重新定位文件指针（Reposition）: 改变文件读写操作的当前位置，例如移动到文件的特定位置开始读写操作。 获取文件属性（Get file attributes）: 用于查询文件的属性信息，如大小、创建时间、修改时间、权限等。 设置文件属性（Set file attributes）: 允许修改文件的属性，如更改文件权限、修改时间戳等。 Device management 请求设备（Request Device）: 用于请求使用特定设备，如磁盘驱动器、打印机等。 释放设备（Release Device）: 用于释放先前请求的设备，使其可供其他进程或任务使用。 读取设备（Read Device）: 用于从设备读取数据，如从硬盘读取数据或从键盘接收输入。 写入设备（Write Device）: 将数据写入设备，例如向硬盘写入数据或向显示器发送数据。 重新定位设备指针（Reposition Device Pointer）: 用于移动设备指针到不同位置，如改变磁盘读写头的位置。 获取设备属性（Get Device Attributes）: 用于获取设备的属性信息，如设备类型、状态、配置参数等。 设置设备属性（Set Device Attributes）: 用于设置设备的属性，如配置参数、状态等。 逻辑附加或分离设备（Logical Attach/Detach Device）: 将设备逻辑连接或分离到系统中，以便程序可以访问它。 库函数 printf 和 scanf\nprintf:\n用于格式化输出，将数据显示到控制台或其他输出设备。 函数原型：void printf(const char* format, ...); 例如：printf(\u0026quot;ID:%d\u0026quot;, 3); 会在屏幕上显示 ID:3。 scanf:\n用于格式化输入，从键盘或其他输入设备读取数据。 函数原型：void scanf(const char* format, ...); 例如：scanf(\u0026quot;ID:%d\u0026quot;, \u0026amp;id); 会从用户输入中读取一个整数并存储在变量 id 中。 注意：printf 和 scanf 是标准库函数，不是系统调用。它们在内部可能依赖于系统调用如 write 和 read 来实现对设备的“写”和“读”操作。库函数提供了比系统调用更高级的抽象，使得程序员可以更容易地进行输入输出操作。\nQ：库函数和系统调用的区别在哪里？\nA：系统调用是最底层的应用，是面向硬件的。而库函数的调用是面向开发的，相当于应用程序的API接口； 各个操作系统的系统调用是不同的，因此系统调用一般是没有跨操作系统的可移植性，而库函数的移植性良好； 库函数属于过程调用，调用开销小；系统调用需要在用户空间和内核上下文环境切换，开销较大； 库函数调用函数库中的一段程序，这段程序最终还是通过系统调用来实现的；系统调用调用的是系统内核的服务；\nCommunications 消息传递模型（Message-Passing Model）： 在消息传递模型中，进程通过操作系统提供的进程间通信（IPC）机制来交换信息。这种模型涉及创建和删除通信连接，以及通过发送和接收消息来进行通信。进程可以使用系统调用来发送消息给其他进程，同时也需要相应的系统调用来接收消息。这种模型通常用于实现进程间的协作和数据传输。 共享内存模型（Shared-Memory Model）： 在共享内存模型中，进程使用映射内存的系统调用来访问其他进程拥有的内存区域。这允许多个进程在相同的内存区域中读取和写入数据，从而实现了共享数据。进程可以使用系统调用来附加或分离共享内存区域，以便其他进程可以访问它。这种模型通常用于实现高效的数据共享和协作。 Information maintenance 系统调用概述 获取时间或日期（Get Time or Date）:\n用于获取当前系统时间或日期。 通常返回时间和日期的详细信息，如年、月、日、小时、分钟、秒等。 设置时间或日期（Set Time or Date）:\n允许设置或修改系统的当前时间和日期。 这通常是一个受保护的操作，可能需要管理员权限或特殊权限。 获取系统数据（Get System Data）:\n用于获取操作系统的各种数据，如系统性能、资源利用率、配置设置等。 设置系统数据（Set System Data）:\n用于修改系统设置或配置。 这些更改可能影响系统的整体行为或性能，通常需要特定权限。 获取进程、文件或设备属性（Get Process, File, or Device Attributes）:\n用于查询进程、文件或设备的特定属性，如进程状态、文件大小、设备类型等。 设置进程、文件或设备属性（Set Process, File, or Device Attributes）:\n允许修改进程、文件或设备的属性。 这可能包括更改进程优先级、修改文件权限、调整设备配置等。 Protection 控制资源访问（Control Access to Resources）:\n涉及限制对文件、设备、网络资源等的访问。 通常基于用户身份、组成员资格或角色来实现。 获取和设置权限（Get and Set Permissions）:\n用于查询或修改文件、目录或其他系统资源的访问权限。 权限可以包括读取、写入、执行等操作的允许或禁止。 允许和拒绝用户访问（Allow and Deny User Access）:\n用于授权特定用户或用户组访问资源，或者拒绝他们的访问请求。 这涉及到用户账户的管理和权限分配。 System Programs 系统程序是计算机操作系统中的一组程序，用于提供各种服务和功能。\n文件管理：\n创建、删除、复制、重命名、打印、导出、列出文件和目录。 状态信息：\n一些系统程序可以获取系统信息，如日期、时间、可用内存、磁盘空间和用户数量。 其他系统程序提供详细的性能、日志记录和调试信息，通常将输出格式化并显示在终端或其他输出设备上。 一些系统实现了注册表，用于存储和检索配置信息。 文件修改：\n文本编辑器用于创建和修改文件，而特殊命令可搜索文件内容或进行文本转换。 编程语言支持：\n编译器、汇编程序、调试器和解释器有时会提供编程语言支持。 程序加载和执行：\n包括绝对装载程序、可重定位装载程序、链接编辑器和覆盖加载程序等。 还包括用于高级语言和机器语言的调试系统。 通信：\n提供创建进程、用户和计算机系统之间虚拟连接的机制。 允许用户将消息发送到其他用户的屏幕、浏览网页、发送电子邮件、远程登录、在不同机器之间传输文件等。 系统实用程序/应用程序：\n由用户运行，通常不被视为操作系统的一部分。 可通过命令行、鼠标点击或手指触摸等方式启动。 例如，Web浏览器、文字处理器、电子表格、数据库系统、编译器、统计分析软件和游戏等。 后台服务：\n在系统启动时启动，一些在系统启动后终止，一些在系统启动到关机期间一直运行。 提供诸如磁盘检查、进程调度、错误日志记录、打印等功能。 在用户上下文中运行，而非内核上下文中。 通常被称为服务、子系统或守护程序。 Operating System Design and Implementation 操作系统的设计与实现是一个复杂的任务，没有一个“完美”的解决方案，但一些方法已被证明是成功的。不同操作系统的内部结构可以有很大的差异。\n目标与规格定义：\n操作系统的设计首先需要明确定义目标和规格。这些目标受到硬件选择、系统类型（批处理、分时、实时、单用户或多用户、分布式等）的影响。 难以规定的要求：\n操作系统的需求难以精确定义，因为它们需要满足多方面的用户和系统目标。 用户目标包括方便使用、易学易用、可靠、安全和高效。 系统目标包括易于设计、实现和维护、灵活、可靠、无错误和高效。 规定和设计操作系统是软件工程的高度创造性任务。 策略与机制分离：\n重要原则是将策略与机制分离。 策略是关于“做什么”的问题，而机制是关于“如何做”的问题。 分离策略和机制是一个非常重要的原则，它允许在以后更改策略决策时具有最大的灵活性。 例如，设置时间片长度和给予某些类型的程序优先级就是策略和机制分离的例子。 Unix和Windows的调度策略就是这种分离的例子。 多种编程语言的使用：\n操作系统的实现通常包含多种编程语言的混合使用。 较低层次的部分可能使用汇编语言编写，主体部分通常使用C语言编写。 系统程序可能使用C、C++以及脚本语言（如PERL、Python、Shell脚本）编写。 使用更高级别的语言使操作系统更容易移植到不同的硬件平台，但可能会导致性能较差和存储需求较大。 模拟（Emulation）：\n模拟允许操作系统在非本机硬件上运行。 模拟可以通过模拟硬件或虚拟机来实现。 这样的模拟可以提高操作系统在不同平台上的可移植性。 操作系统性能的提升：\n提高操作系统性能的主要方法包括改进数据结构和算法。 仅有少量代码对于高性能至关重要，包括中断处理程序、I/O管理、内存管理和CPU调度器。 写好并正确运行后，可以识别性能瓶颈的关键例程，然后将其替换为汇编语言等效代码以提高性能。 Operating System Structure 简单结构 Simple structure MS-DOS MS-DOS（Microsoft Disk Operating System）是为了在最小的空间内提供最大功能而编写的操作系统。它存在一些结构上的不足：\n缺乏模块化分割： MS-DOS没有被精心分割为模块化的组件。这意味着其功能没有被很好地分离和隔离，而是被混杂在一起，这使得系统的维护和扩展变得更加困难。\n接口和功能的分离问题： MS-DOS中，接口和功能的分离程度较低。这意味着不同功能的代码没有被清晰地分隔开，这可能导致代码的不稳定性和难以维护。\n受限于硬件： MS-DOS在某种程度上受到了硬件的限制。例如，它最初是设计用于Intel 8088处理器，这个处理器缺乏一些现代操作系统所需的功能，比如双模式（用户模式和内核模式）和硬件保护机制。\n因此，MS-DOS虽然在其时间内非常重要，但由于结构上的不足，它在面对较新的硬件和复杂的任务时变得不够灵活。这促使了后来的操作系统设计采用更模块化、分层的方法，以提高系统的稳定性和可维护性。\nOriginal UNIX 原始的UNIX操作系统在结构上较为有限，这主要是由硬件功能的限制所决定的。它由两个可分离的部分组成：\n系统程序： 这部分包括用户可以运行的各种应用程序，如文本编辑器、编译器等。系统程序构成了用户与操作系统交互的一部分。\n内核： 内核是操作系统的核心部分，位于系统的最底层。内核被分为一系列接口和设备驱动程序，包括系统调用接口、文件系统、CPU调度、内存管理等功能。内核位于系统调用接口以下，位于物理硬件之上，它为系统提供了基本的操作系统功能。\nUNIX操作系统的API（应用程序编程接口）是通过系统调用定义的，而通常可用的系统程序则构成了用户界面。这种结构使得用户可以运行各种程序，而内核负责管理硬件和提供系统服务。\n需要注意的是，原始的UNIX操作系统的结构相对简单，这是因为它诞生于较早的计算机时代，当时的硬件功能和资源有限。后来的UNIX变种和其他操作系统采用了更模块化和层次化的结构，以适应更复杂的硬件和应用需求。\n分层结构 Layered Approach 操作系统可以分解成多个层次（或称为层级），每一层建立在较低层次之上。这些层次构成了操作系统的层次结构，其中最底层（第0层）是硬件，而最高层（第N层）是用户界面。\n在这种层次结构中，每个操作系统层次都表示一个抽象对象，由数据和可以操作这些数据的函数组成。模块化设计使得每一层次都可以使用较低层次的函数和服务，以构建更高层次的功能。\n这种结构使系统各部分相互隔离，降低复杂性，更易于维护和扩展。主要优点是简化系统设计和开发，降低错误风险，更容易扩展和维护，有助于管理复杂性。\n将操作系统视为一系列层次结构是一种有助于管理系统复杂性的方法。这个方法的主要思想是将系统的功能和组件分解为多个层次，每个层次负责执行相关的功能，同时依赖于较低层次的功能来完成更基本的操作。这种分解有以下主要优势：\n主要优势：\n构建和调试的简单性：通过将系统划分为多个层次，每个层次有明确定义的功能，使得系统的构建和调试变得更加简单。每个层次都可以独立开发和测试，减少了复杂性。 设计和实施的简化：层次结构化方法有助于将系统的设计和实施任务分解为更小的、可管理的子问题。这种分解有助于管理复杂性，使整个过程更加清晰。 主要困难：\n层次的仔细定义：确定每个层次的功能和接口需要仔细的定义。不同层次之间的依赖性和接口必须清晰明确，以确保系统的正确运行。 复杂性的分层结构：在一些情况下，分层结构可能导致复杂性的增加，尤其是在处理诸如磁盘驱动器和内存管理等关键组件时。这可能需要更复杂的协作和通信。 在操作系统中，将其视为一系列层次结构可以帮助管理系统的复杂性，但这种方法可能不如其他结构类型高效。在这种分层结构中，每个层次负责一组相关的功能，而每个系统调用必须经过多个层次才能达到硬件层面，这可能会导致性能开销。以下是有关这一点的详细信息：\n效率较低：这种分层结构可能导致系统调用的效率较低。当执行系统调用时，它必须经过多个层次，每个层次可能需要对参数进行修改、传递数据等。这会增加系统调用的开销。\n举例：考虑执行I/O操作的情况。当应用程序执行I/O操作时，它会触发系统调用，该系统调用被传递到I/O层次。然后，I/O层次可能需要与内存管理层次和CPU调度层次进行通信，最终数据被传递给硬件执行。这些多次通信和数据传递可能导致性能下降。\n宏内核（Monolithic Kernel）：在宏内核结构中，整个核心操作系统运行在内核空间和监管者模式下。这种结构通常没有明确的层次结构，所有功能都在一个单一的内核中实现。这可能会导致较低的模块化和较高的性能，但也可能增加维护的复杂性。\n总的来说，分层结构虽然有助于管理系统复杂性，但可能在性能方面存在一些开销。不同的操作系统采用不同的设计方法，以在性能和复杂性之间取得平衡。对于某些用途，如实时系统，可能更倾向于采用更紧凑的内核结构，而对于通用用途的操作系统，可能更愿意牺牲一些性能以获得更好的可维护性和可扩展性。\n微内核结构 Microkernels 微内核（Microkernel）是一种操作系统设计结构，旨在将操作系统的基本功能模块化，并将尽可能多的功能移到用户空间，以提高系统的模块性、灵活性和可维护性。以下是有关微内核的一些关键概念和优点：\n基本功能： 微内核包含操作系统的基本功能，如内存管理、CPU调度和进程间通信（IPC）。这些功能通常被认为是不可或缺的，但微内核试图将其他功能从内核中分离出来。\n用户空间服务： 微内核将额外的服务移到用户空间中，这些服务可以在用户空间中运行并与客户程序通信。客户程序可以使用这些服务来执行特定任务，而无需直接涉及内核。这提高了系统的可定制性和灵活性。\n通信方式： 微内核系统通常使用消息传递来实现客户程序和用户空间服务之间的通信。消息传递允许客户程序发送请求或数据给服务，并通过消息响应来执行相应的操作。\n优点： 微内核结构的主要优点包括：\n模块化：它允许操作系统的各个部分相对独立地开发和维护，减少了模块之间的相互影响，提高了可维护性。 灵活性：新的服务可以相对容易地添加到用户空间，而不必更改整个内核，提供了更大的可配置性和扩展性。 安全性和可靠性：微内核的模块化设计使得每个模块都可以进行严格测试，如果一个服务出现问题，不会影响整个操作系统的稳定性。 然而，微内核结构可能会导致一定的性能开销，因为消息传递和用户空间切换可能比在内核中执行相同功能更慢。因此，在对性能要求非常高的应用程序中，可能会选择其他内核结构。不同的操作系统采用不同的内核结构，以满足其设计目标和需求。\n微内核结构的劣势在于性能可能受到一定的影响，主要表现在以下方面：\n系统功能开销增加： 使用微内核结构会引入更多的系统功能开销，例如消息传递和用户空间切换。这些额外的开销可能会导致性能下降，特别是在对性能要求非常高的应用程序中。\n性能历史问题： 一个明显的例子是Windows NT操作系统的性能历史。最初的Windows NT 1.0采用了分层微内核组织，导致性能较低，与Windows 95相比表现不佳。随后的Windows NT 4.0部分改进了性能问题，将某些层次从用户空间移到内核空间，并更加紧密地集成它们。然而，随着Windows XP的设计，Windows的架构变得更加单片化，不再典型的微内核结构。\n大内核和微内核 大内核系统将操作系统的主要功能模块都作为一个紧密联系的整体运行在核心态，从而为应用提供高性能的系统服务；由于复杂的交互关系使得层次之间的界限极其模糊，定义清晰的层次间接口非常困难； 微内核将内核中最基本的功能保留在内核，将那些不需要在核心态执行的功能移到用户态执行；微内核结构最大的问题是性能问题，需要频繁在核心态与用户态之间进行切换； 模块化结构 Modules 现代许多操作系统采用可加载的内核模块。内核包含一组核心组件，并通过模块动态链接其他服务，可以在启动时或运行时进行。这种方法在现代UNIX的实现中非常常见，例如Solaris、Linux和Mac OS X，以及Windows。以下是有关可加载内核模块的一些关键概念：\n常见性： 可加载内核模块在现代操作系统中广泛采用，尤其是在UNIX系列操作系统中。\n面向对象的方法： 可加载内核模块采用面向对象的方法。每个核心组件都是独立的模块，它们之间使用已知接口进行通信。\n模块化： 每个核心组件都是可加载的，可以根据需要在内核中加载。这增加了系统的可扩展性和定制性。\n受保护接口： 每个核心组件都有定义的受保护接口，确保安全性和隔离性。\n更高的灵活性： 与微内核结构相似，可加载内核模块具有更高的灵活性，因为任何模块都可以调用其他模块，而不必通过消息传递来进行通信。\n更高的效率： 相对于一些其他结构，可加载内核模块通常更加高效，因为模块之间的通信无需调用消息传递，从而减少了开销。\n总的来说，可加载内核模块是一种在现代操作系统中广泛采用的内核结构，它融合了模块化、面向对象和高效的设计原则，以提供更大的灵活性和可扩展性。\nVirtual Machines 操作系统虚拟化：\n通过CPU调度和虚拟内存，操作系统为多个进程创造了在各自处理器上执行以及拥有自己虚拟内存的幻觉。 物理计算机的资源被共享来创建虚拟机。 虚拟机将分层方法推向逻辑极限，将硬件和操作系统内核视为硬件层。 虚拟机提供与裸机硬件相同的接口，允许操作系统作为其他操作系统内的应用程序运行。 虚拟机管理器（VMM）提供虚拟化服务，支持本机编译的客户操作系统运行在本机编译的宿主操作系统上。 在源CPU类型与目标类型不同的情况下，使用模拟，如 \u0026ldquo;Rosetta\u0026rdquo; 允许IBM CPU编译的应用程序在Intel CPU上运行。 虚拟机特性：\n提供了对系统资源的完全保护。 每个虚拟机与所有其他虚拟机隔离，不允许直接共享资源。 系统的开发和测试可在虚拟机上进行，不干扰正常系统操作。 虚拟机的普及解决了系统兼容性问题，但实现复杂，需提供与底层机器完全相同的副本。 虚拟化方法：\n第一类虚拟化：类似操作系统，运行在裸机上，提供多道程序功能，向上层提供若干台虚拟机，每台都是裸机硬件的精确复制品。支持不同操作系统的运行。 第二类虚拟化：依赖于宿主操作系统分配和调度资源，伪装成具有CPU和设备的完整计算机。如VMware Workstation。客户操作系统安装在虚拟磁盘上。 虚拟化应用：\nWeb主机领域中虚拟化十分流行，提供了成本效益高的解决方案，如“云”主机。 第一类虚拟化也称为裸金属架构，第二类称为寄居架构。 Operating System Generation 操作系统生成 操作系统的生成是一个定制化和配置过程，用以确保操作系统能够在特定的计算机硬件上运行。\n针对特定硬件的设计：\n操作系统被设计为能够在某一类计算机硬件上运行。 需要对每个具体的计算机站点进行详细配置。 系统生成程序（SYSGEN）：\nSYSGEN 程序用于获取硬件系统的特定配置信息。 这些信息帮助操作系统更好地理解并适应当前的硬件环境。 系统生成的方法：\n修改操作系统源代码：根据具体硬件需求调整操作系统的源代码副本。 预编译库选择：从预编译的库中创建表格并选择适合的模块。 表格驱动系统：创建适当的表格以描述系统配置，系统完全由这些表格驱动。 执行时选择：系统在运行时根据这些表格进行配置选择和调整。 System Boot 操作系统引导过程 操作系统引导是计算机启动和加载操作系统的一系列过程。这个过程涉及多个步骤，确保硬件和软件正确地协同工作，从而启动计算机系统。以下是引导过程的详细步骤：\n激活CPU:\nCPU被激活并读取ROM中的引导程序（Boot Program）。 将指令寄存器设置为BIOS（基本输入输出系统）的第一条指令，开始执行BIOS。 硬件自检:\nBIOS启动后，首先进行硬件自检（POST - Power-On Self Test）。 检查硬件是否存在故障，如有故障，主板会发出警告声，启动中止。 若无故障，屏幕显示CPU、内存、硬盘等硬件信息。 加载操作系统所在的硬盘:\nBIOS读取Boot Sequence（启动顺序），这通常保存在CMOS中，或通过用户交互设置。 控制权传递给启动顺序中排在第一位的存储设备。 CPU将该存储设备的引导扇区内容加载到内存中。 加载主引导记录（MBR）:\n主引导记录（MBR）位于硬盘的第一个扇区。 MBR包含特定标识符，区分引导硬盘和非引导硬盘。 MBR的作用是告诉CPU去哪个主分区找操作系统。 扫描硬盘分区表，加载活动分区:\nMBR包含硬盘分区表，该表区分活动分区和非活动分区。 MBR扫描分区表，识别含有操作系统的硬盘活动分区。 找到活动分区后，开始加载，将控制权交给该分区。 加载分区引导记录（PBR）:\n读取活动分区的第一个扇区，即分区引导记录（PBR）。 PBR的作用是找到并激活用于引导操作系统的程序（如启动管理器）。 加载启动管理器:\n分区引导记录搜索并加载活动分区中的启动管理器。 加载操作系统:\n启动管理器进一步加载操作系统，完成引导过程。 这个过程是操作系统启动和运行的基础，确保了从硬件的初始化到操作系统完全加载的顺利进行。\n","date":"2023-09-12T09:26:35Z","permalink":"http://localhost:1313/post/1-introduction/","title":"1 Introduction"}]